{
  "info": {
    "id": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
    "slug": "curious-sailor",
    "projectID": "51ce91990cdb80fb62489f7028ffc023d69077fd",
    "directory": "/Users/alex/repos/vfp/dark-factory",
    "title": "Gitter-commit: Clean, multi-commit repo preparation",
    "version": "1.2.5",
    "summary": {
      "additions": 20564,
      "deletions": 0,
      "files": 7
    },
    "time": {
      "created": 1771212661110,
      "updated": 1771213579255
    }
  },
  "messages": [
    {
      "info": {
        "role": "user",
        "time": {
          "created": 1771212661124
        },
        "summary": {
          "title": "Process: gitter-commit commit organization guide",
          "diffs": [
            {
              "file": "scripts/install.sh.ts",
              "before": "#!/usr/bin/env bun\n\nimport { join } from \"node:path\";\nimport { findRepoRoot } from \"./helpers/run_root.sh.ts\";\nimport { runCommandSteps } from \"./helpers/run_steps.sh.ts\";\n\nconst repoRoot = findRepoRoot(import.meta.dir);\n\nawait runCommandSteps([\n  {\n    name: \"Proto install\",\n    command: \"bun\",\n    args: [join(repoRoot, \"scripts\", \"proto_install.sh.ts\")],\n    cwd: repoRoot,\n  },\n]);\n",
              "after": "#!/usr/bin/env bun\n\nimport { join } from \"node:path\";\nimport { findRepoRoot } from \"./helpers/run_root.sh.ts\";\nimport { runCommandSteps } from \"./helpers/run_steps.sh.ts\";\n\nconst repoRoot = findRepoRoot(import.meta.dir);\n\nawait runCommandSteps([\n  {\n    name: \"Proto install\",\n    command: \"bun\",\n    args: [join(repoRoot, \"scripts\", \"proto_install.sh.ts\")],\n    cwd: repoRoot,\n  },\n]);\n",
              "additions": 0,
              "deletions": 0,
              "status": "modified"
            }
          ]
        },
        "agent": "build",
        "model": {
          "providerID": "openai",
          "modelID": "gpt-5.3-codex"
        },
        "variant": "low",
        "id": "msg_c6480617a001AqblgPdC33DAKi",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "text",
          "text": "Use the `gitter-commit` skill from `.opencode/skills/gitter-commit/SKILL.md` and route commit execution through `@gitter`.\n\nGoal:\n\n- Turn the current working tree into a clean set of meaningful commits (not a single `git add -A` dump)\n- End with a clean `git status`\n\nProcess:\n\n1. Inspect the repository state (`git status`, staged/unstaged diffs, and recent commit titles for style).\n2. Group changes into logical commit units (by feature, fix, docs, config, refactor, etc.).\n3. For each commit unit:\n   - Stage only the relevant files.\n   - Write a commit title using this repo format:\n     - `{Component/Meta} // {Optional Addition} // {Short Description} (Optional,Tags)`\n   - Add a short commit body rationale and signature when possible.\n4. Repeat until all intended tracked changes are committed.\n5. Confirm final `git status` is clean.\n\nRules:\n\n- Prefer multiple small meaningful commits over one large mixed commit.\n- Do not commit likely secret files (`.env`, credentials, private keys).\n- Do not push.\n- If no commit-worthy changes exist, report that clearly.\n\nReturn:\n\n- Commit list in order (hash + title + files)\n- Any skipped files and why\n- Final `git status` summary",
          "id": "prt_c64806185001TdsD8Xd6LSsl4y",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6480617a001AqblgPdC33DAKi"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771212661133,
          "completed": 1771212667398
        },
        "parentID": "msg_c6480617a001AqblgPdC33DAKi",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 15897,
          "input": 15713,
          "output": 184,
          "reasoning": 162,
          "cache": {
            "read": 0,
            "write": 0
          }
        },
        "variant": "low",
        "finish": "tool-calls",
        "id": "msg_c6480618d001b5NgSTrvESvq3i",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "a3a3b3e9329d498d56674e83b1e28f2701c051c9",
          "id": "prt_c648069ed0016qxPRV1tRTV80f",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6480618d001b5NgSTrvESvq3i"
        },
        {
          "type": "reasoning",
          "text": "**Planning commit via gitter skill and task**",
          "metadata": {
            "openai": {
              "itemId": "rs_0ce996e1f4c681ed0169928f77b1688194b8ad55120559924e",
              "reasoningEncryptedContent": "gAAAAABpko97ua4U4qoL-IkKhqEaGQiliiiNZzsJxClhQMnJhvkpRLiA7WIz8tr9fGTUkaPlrs3Oo3czuc_4jVmtYnB1WeCyDlIahecgYKhcZkIeUW5uXkS-rYM7agiKSWRamfIWn7d7-w2nJhzbLg7sqoBu3a2kO_1Y9SooSd39BplyK-r3JdM920D6YYW965cmVHKxBcFMbj5_qvmu47kxIYHsl2vk6YiMeRgveK9afR3o-R-kjnKiTr7ftxJX-UqTvbD-vERFkx0dvSG0_NaLMCc-F9b7ISvpnt2GwMIBsFbqZkekiG55OPBNi4b2JtlCmLHs1T9ouCCD8_fRgI_Hjnqe5A8MS8YTvR_XDE_Ds6ILIp6gUaeQ3d_07tFXfytxSsnE_hfLbKk9Hwybbc7EXSZIJ-TZx1FGoiLt8q-7S4r1Kk5T_KyauOSQU62rkvNFZZqerpf4dI9mm6d-h3w9QsdtP5fU-G7sUzg0-zZvQyAeAMuyCYCZNtRQWgUBMdkW35LtYgMEKLabSP5aybmPKpddFavYx88KliHLun_Eiu-QcN0Vt2zJatbigWIH3nO_p2kiXv-jkE3V65Usup3JhOURSf0eoIAKl2QA9oKKf1k3Bw5pFBBrKlH-vLlO6veBSneqmAvMqaafKC6P95BrQbW3GGDns9zCLxQm2a06-_hCY6KCzS01RwLfMM2_wGUnzgYR6m9lGbN0d5ZqD9hVAdM_r8sYhMlm2HFnghjwPuGyB-TGZkP7N8WkLusLOZHQ3ZKS6CZcRwWJDdbMxu2RVDSYaNnaF10GdcN4hJLS5-e-cKDHK4zJlDlLxrwseewqLpjNFSWUua0dUjpRy9_tWeASYbhRkaUx0oFrcU63_q728HRbTfMFC5f_fNl-32ZIU65MtJy-3avYOJTnTG5k2-t5ptbIs4iNdZ-KxpZYJPgoZToCGrMlYUF4sd4Cf1sMSfPiMdEXW8OS_sCit3rrf8Wc2nD1FuXpoOtjHlQN4bQqOyd7XCAjWVM1HWD-IJAOrIzg-OuVNWRYS9XdT5Hy5ovUg74_mtRyJuNZA5REyqdsZl1kTChkNpV_NpqjvUoTF2HSP4B5mbk8ni2K9rQ2_i3Y_EaWEB1fHt5WXZiQ0gbhaJbZcQjscEllw5a_0EjKE5OgF9anXV0iscDXJzaDh0ELdE6oDvMH2wHPJuJHR93lc8JLkCw9ddKk-oMWeSS_UM3S3O6idf0egdVHlRUTZg1mR9YvqsZEU90JBvxRlteWTLVodDKvE_-dTTv2IjrBDDCZ2lCkNIAWmSSYpVzvljAhZ3YxYTYNKtvZUZ4EiMyUdZlWcRivtesRP7agIViZQDNaS9eSG9f8mu_4z5nEr6i2UotjYudNcl7-O3TGsaszKRDMsLBYqGy5gb6dnfEerUJA3Z6kcKaDTvAmbjM10zLNxI9r4VhqSzrfqGrq5BAH2c5T87Pc4xW8eVkHJIO0C_frqGSG9euZZxy0qbbsQYq2q-FW9l9Xz52a6fVlnMkhAs_nXs59BJrjDrVkZDighFdWD8CCTQtXzkayspsSjjcTf741lJYOp5EqT1MAAxIeMDp5-l0OF9Bmh_JAYy1nEF9-ocnZxFlCCzYbXe0vk3q6lzhkom2aVaN9J3Ek1LI_PKylMR3wYXy74mEbcovxwwiavIBwfHsKmIdPbu3z2QIBgShPssMDlvp5J9rgnVWWMlUXYkR_AAPTNgIdx-JUa6CWBKeD7LMI3VDDoljEWhS463fBPpnc76VENygTaR1vt0ir0CjVoVFUImdqLeIuCvPYtYLLOjCso1oSVo_t3tDiA13p11QkAHZamfNyacatTo5qTMgwuVxbvAcS6PNBQDt7_5h4d605o3Vjc_04uZqmN8rGrg=="
            }
          },
          "time": {
            "start": 1771212663776,
            "end": 1771212667215
          },
          "id": "prt_c64806be0001KGA2a9IMzp9wka",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6480618d001b5NgSTrvESvq3i"
        },
        {
          "type": "tool",
          "callID": "call_3A8HNUF10Gubjlod29Wcyuc1",
          "tool": "skill",
          "state": {
            "status": "completed",
            "input": {
              "name": "gitter-commit"
            },
            "output": "<skill_content name=\"gitter-commit\">\n# Skill: gitter-commit\n\n## What I do\n\n- Remind parent agents to invoke `@gitter` when commits are requested or changes should be captured.\n- Provide a short template for the handoff context (scope, intent, and any constraints).\n\n## When to use me\n\nUse this whenever the user asks for commits, when a task introduces meaningful changes, or when the working tree should be cleaned up into commits.\n\n## Handoff template\n\nSend `@gitter` a short summary like:\n\n- Goal: <what the user asked for>\n- Scope: <files or areas touched>\n- Notes: <any constraints, tests run, or commit grouping preferences>\n\nBase directory for this skill: file:///Users/alex/repos/vfp/dark-factory/.opencode/skills/gitter-commit\nRelative paths in this skill (e.g., scripts/, reference/) are relative to this base directory.\nNote: file list is sampled.\n\n<skill_files>\n\n</skill_files>\n</skill_content>",
            "title": "Loaded skill: gitter-commit",
            "metadata": {
              "name": "gitter-commit",
              "dir": "/Users/alex/repos/vfp/dark-factory/.opencode/skills/gitter-commit",
              "truncated": false
            },
            "time": {
              "start": 1771212667306,
              "end": 1771212667318
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_0ce996e1f4c681ed0169928f7b2b8c8194a4f609881ee8271e"
            }
          },
          "id": "prt_c648079500014miz4Bkh3H7a0M",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6480618d001b5NgSTrvESvq3i"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "a3a3b3e9329d498d56674e83b1e28f2701c051c9",
          "cost": 0,
          "tokens": {
            "total": 15897,
            "input": 15713,
            "output": 184,
            "reasoning": 162,
            "cache": {
              "read": 0,
              "write": 0
            }
          },
          "id": "prt_c648079d9001SXxsxRrM696BVY",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6480618d001b5NgSTrvESvq3i"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771212667399,
          "completed": 1771212735364
        },
        "parentID": "msg_c6480617a001AqblgPdC33DAKi",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 16370,
          "input": 378,
          "output": 248,
          "reasoning": 23,
          "cache": {
            "read": 15744,
            "write": 0
          }
        },
        "variant": "low",
        "finish": "tool-calls",
        "id": "msg_c64807a07001uuzbjElkXFeMa4",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "9d6f15c7b06acb730f3f74807178e28dcff70941",
          "id": "prt_c648081a3001DQeuCrod5lQbzh",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64807a07001uuzbjElkXFeMa4"
        },
        {
          "type": "reasoning",
          "text": "**Preparing commit grouping and output**",
          "metadata": {
            "openai": {
              "itemId": "rs_03eb4b2357cef4960169928f7db9208190a87fee96f7522d1e",
              "reasoningEncryptedContent": "gAAAAABpko9-vs89EM8SOQoSJ96ac-68ymCv8BQIzx4bMHxnC2n6iWYJ39qBXSDubadDJ_tAhEOtxszt2aXDprJnzbkAs3VVH4MGivkNHomP5_F85uFwHhW91hiF2XlJ0EF3nuBQTYKUjCZhFcjy3Vn8fHaJNAXWf7rzJkcMfeuTEURGU_5E5dXVClJC4-wgvs2pz85ZpEhJaruJyNcDfs3cI6R9NcpW0xie200Cn5Ied1PHzhkIOEpjDAe3OGvexzRxMyC5iqs-ob1YnWkHW1I4Uv1yGJWl27E_slIP_4ttMr5XfYGPwbyMRv8EhvMABkovZOGPG0P-VSUMYwcTJyqImzEiJnpACqGakhLOTH7xbQWxXIZUg8b1avKi4n_kzRG9OqgYKKBMkFuwtLLfb-O3LuYvc6OhNqpp95xSNCJPiK3DLyVdeeawenSMd11f9pfkKESxGIvwhIty_BA6zCebL1HTHmSrQzeq8lEDyY48MqysRjSMsCz5QEPzeKmhhmWSUrdRME3auqG1avhtO4hW3BoN9ENE_DOP391V9YSFS7bTKZnz434gRfhLNUOhJ4ey_9sExt5hjl1mjNJYDzFjyScEgW_Q-0s05F0iD5mdTxHlClc0oUJ5g82U5y9BfX_VcVbOYWJV277vv5pUJjRbxTPB36QhxZC4-a3agUFLIqghOZuDuSad1ImOk6MqknQPueCe9PBvGyg1a3hpjHuI8PLQBwX54yYB7QxL8geZon4HNCjpe-vOiJnEWCpakaLvEHG_MBW6dBX5T4d6kWHDwXXa_URAxrh8M8oqGPmecl25V7ysCMKAFoADndN_qFtbuRw-sZKOpqacHq7YzeKmcqK-xSPEt5RFbKDDGRznfOOWY03DxO8bZ7ETWPeHYg4Al6wxovDQAaDAk6Q14181glv0pgiLruqOKYLfWEVnQTUwEjqczoDOxQOJaXlhIeeSIcXDt5nYetU0McH6MlCkFA39QKSJ-w=="
            }
          },
          "time": {
            "start": 1771212669753,
            "end": 1771212670418
          },
          "id": "prt_c648083390019WljfazjZ4fY33",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64807a07001uuzbjElkXFeMa4"
        },
        {
          "type": "tool",
          "callID": "call_2ecomTrNqdqxi8CvrYr28wyf",
          "tool": "task",
          "state": {
            "status": "completed",
            "input": {
              "description": "Create logical commits",
              "subagent_type": "gitter",
              "prompt": "Goal: Turn current working tree into a clean set of meaningful commits and end with clean git status.\nScope: Entire repository current changes.\nNotes/Constraints:\n- Inspect git status, staged+unstaged diffs, and recent commit titles for style.\n- Group into logical commit units (feature/fix/docs/config/refactor etc.), prefer multiple small meaningful commits.\n- For each unit stage only relevant files and commit.\n- Commit title format: {Component/Meta} // {Optional Addition} // {Short Description} (Optional,Tags)\n- Include short commit body rationale and signature when possible.\n- Do not commit likely secret files (.env, credentials, private keys).\n- Do not push.\n- If no commit-worthy changes exist, report clearly.\nReturn:\n1) commit list in order with hash + title + files\n2) skipped files and reason\n3) final git status summary\nExecute now."
            },
            "output": "task_id: ses_39b7f65c2ffephtC1JYRZ2CETu (for resuming to continue this task if needed)\n\n<task_result>\nDone ‚Äî I grouped and committed the full working tree into 3 meaningful commits, and the repo is now clean.\n\n1) Commit list (in order)\n\n- `c0626aa` ‚Äî `Tooling // Scripts // Add Bun install and proto install entrypoints`\n  - `.prototools`\n  - `scripts/helpers/run_root.sh.ts`\n  - `scripts/helpers/run_steps.sh.ts`\n  - `scripts/install.sh.ts`\n  - `scripts/proto_install.sh.ts`\n\n- `2253ea7` ‚Äî `Meta // OpenCode Workflow // Add script authoring and commit command docs`\n  - `.opencode/commands/capture_script_from_context.md`\n  - `.opencode/commands/commit_all.md`\n  - `.opencode/commands/make_script.md`\n  - `.opencode/skills/proto-install/SKILL.md`\n  - `.opencode/skills/script-authoring/SKILL.md`\n  - `AGENTS.md`\n  - `README.md`\n\n- `294c050` ‚Äî `Docs // Reference // Add elysia-protobuf README snapshot`\n  - `docs/readmes/elysia-js.README.md`\n\n2) Skipped files and reason\n\n- None skipped.\n- No likely secret files (`.env`, credentials, private keys) were present in the current change set.\n\n3) Final git status summary\n\n- Working tree is clean (`git status --short` returned no output).\n- No push was performed.\n</task_result>",
            "title": "Create logical commits",
            "metadata": {
              "sessionId": "ses_39b7f65c2ffephtC1JYRZ2CETu",
              "model": {
                "modelID": "gpt-5.3-codex",
                "providerID": "openai"
              },
              "truncated": false
            },
            "time": {
              "start": 1771212675642,
              "end": 1771212735322,
              "compacted": 1771213545701
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_03eb4b2357cef4960169928f7e609c81908bf255d66f34c9ca"
            }
          },
          "id": "prt_c648085d2001CTqwF5SKOkIaGo",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64807a07001uuzbjElkXFeMa4"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "9d6f15c7b06acb730f3f74807178e28dcff70941",
          "cost": 0,
          "tokens": {
            "total": 16370,
            "input": 378,
            "output": 248,
            "reasoning": 23,
            "cache": {
              "read": 15744,
              "write": 0
            }
          },
          "id": "prt_c6481835b001gFkgmS8sGjPrqZ",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64807a07001uuzbjElkXFeMa4"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771212735365,
          "completed": 1771212742779
        },
        "parentID": "msg_c6480617a001AqblgPdC33DAKi",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 17052,
          "input": 468,
          "output": 328,
          "reasoning": 22,
          "cache": {
            "read": 16256,
            "write": 0
          }
        },
        "variant": "low",
        "finish": "stop",
        "id": "msg_c64818385001n65YBDrT61WY9m",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "9d6f15c7b06acb730f3f74807178e28dcff70941",
          "id": "prt_c64818c56001IEGNrWNpdwLN7x",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64818385001n65YBDrT61WY9m"
        },
        {
          "type": "reasoning",
          "text": "",
          "metadata": {
            "openai": {
              "itemId": "rs_03e6d687416ac86f0169928fc1ffa48194b8af2982d862031c",
              "reasoningEncryptedContent": "gAAAAABpko_CC5z5oecsu6a_NtVGQ8Z928NmrdG1oSAv9jH1OKuWwgIxdHQyHsT1R93bpzmy-F_BFzcKMHEPyhOwvSSG5iLXSj04F-jbavj9g0cwPnBuUYzxsSx17Kc1Pv7d7PeqM2Mho0aN65sIVjaBt-x7ktR_tClHxttoeT7zu50uvfLjB-qWr8endkXX-F2Xn7Ed1539omKifQFIsB94rv8bZZ_idEnyp46Kem4J2o9ctsECKu6HMh6Gcm2X9nVjuYLsf0UxOrHaOf0BJMVlfxcvVOP0wswHGNP2fX6JQUrTmFDqHJmEQIrkjKnndjjFsPELnHZw-V3PVvLicZCQ5xeed_7SxouG8LTM0Dbjn2O8WkqPhB5Ek_-zkd-DsqJVckhss0lAVVOa5AA1JXkUtXVU0p0N0OtUpzFKtKapx4fy3ano1FBwanUw87QAFRx7RYqDMQ4YAkLSIzM84DEvsjOEEQ29G-mBiqt8NGTD7adpra9H4-vVQk57OMSGGBceDPfC1_m2SgFvtxDWh9jSEtvRaGEOQ4oXrFgPmBPk4bf1r3I_EuGwtL7ypVNgLgjmjFoxMcbfVxM0fllrScLuYBz8uU8gD5Ynl00ff3svl9kq5Hg0fTYg4CwZyMoOMV7oY61ElrS382Nf9DeqVy3tVqWEIImwiyLSX70Fe8lGtEdMPADgXQ74e-wEvPP-LraAv7zVphacFPybfLpYMJvW4Gc2JPDmoRRKoM9HZWYePb_CKGmeMtpzV3wyr_4u2x4tcju8phLFeZTJ6pAgjAMQnW7GO3ohglGOOOOZKGH5IHlqQO3YOESftpPt7v9wDkULSWWlhmdVXp1rWBAQzwKI4xrQJ3TfKTVl8g8dfZAqGGeTWECitqYqvLTIsNG4NFUuL7swpmfdiHoxxYZPibFgGkufjQIExlbnIZusdMYzZw3jJ8rQ4T6FPuJke5P1sIdf1NY_RuMa"
            }
          },
          "time": {
            "start": 1771212738026,
            "end": 1771212738641
          },
          "id": "prt_c64818dea001GeoES4xtT5qMAo",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64818385001n65YBDrT61WY9m"
        },
        {
          "type": "text",
          "text": "Done ‚Äî I used the `gitter-commit` skill guidance and routed execution through `@gitter`.\n\n- Created 3 logical commits (not a single dump), grouped by tooling/docs/reference scope.\n- No secret-like files were committed.\n- Final working tree is clean, and nothing was pushed.\n\nCommit list (in order):\n- `c0626aa` ‚Äî `Tooling // Scripts // Add Bun install and proto install entrypoints`\n  - `.prototools`\n  - `scripts/helpers/run_root.sh.ts`\n  - `scripts/helpers/run_steps.sh.ts`\n  - `scripts/install.sh.ts`\n  - `scripts/proto_install.sh.ts`\n- `2253ea7` ‚Äî `Meta // OpenCode Workflow // Add script authoring and commit command docs`\n  - `.opencode/commands/capture_script_from_context.md`\n  - `.opencode/commands/commit_all.md`\n  - `.opencode/commands/make_script.md`\n  - `.opencode/skills/proto-install/SKILL.md`\n  - `.opencode/skills/script-authoring/SKILL.md`\n  - `AGENTS.md`\n  - `README.md`\n- `294c050` ‚Äî `Docs // Reference // Add elysia-protobuf README snapshot`\n  - `docs/readmes/elysia-js.README.md`\n\nSkipped files:\n- None\n\nFinal `git status` summary:\n- Clean working tree (`git status --short` empty)",
          "time": {
            "start": 1771212742677,
            "end": 1771212742677
          },
          "metadata": {
            "openai": {
              "itemId": "msg_03e6d687416ac86f0169928fc29b488194b807e6fa38501598"
            }
          },
          "id": "prt_c64819053001BsEJaDKT0hM6e8",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64818385001n65YBDrT61WY9m"
        },
        {
          "type": "step-finish",
          "reason": "stop",
          "snapshot": "9d6f15c7b06acb730f3f74807178e28dcff70941",
          "cost": 0,
          "tokens": {
            "total": 17052,
            "input": 468,
            "output": 328,
            "reasoning": 22,
            "cache": {
              "read": 16256,
              "write": 0
            }
          },
          "id": "prt_c6481a0490011qrSNDg3285Gju",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64818385001n65YBDrT61WY9m"
        }
      ]
    },
    {
      "info": {
        "role": "user",
        "time": {
          "created": 1771212923416
        },
        "summary": {
          "title": "Web research notes to @docs and create @.opencode/skills/ for protobuf schemas v2/v3 and protoc usage for Rust/TypeScript",
          "diffs": [
            {
              "file": ".opencode/skills/protobuf-schema-authoring/SKILL.md",
              "before": "",
              "after": "---\nname: protobuf-schema-authoring\ndescription: Author proto2/proto3 schemas and provide protoc generation workflows for Rust and TypeScript.\n---\n\n## What I do\n\n- Turn user requirements into clear, evolvable `.proto` schemas.\n- Support both `proto2` and `proto3` syntax.\n- Ask for syntax preference when not explicitly provided, and explain version-specific constraints.\n- Provide practical `protoc` workflows for Rust and TypeScript.\n\n## When to use me\n\nUse this when the task includes any of the following:\n\n- Create a new protobuf schema from product or API requirements.\n- Update an existing `.proto` safely.\n- Explain if a feature is `proto2`-only or `proto3`-only.\n- Generate Rust or TypeScript artifacts from `.proto` files.\n\n## Required clarification flow\n\nIf not already specified, ask these in order:\n\n1. Which schema syntax should be used: `proto2` or `proto3`?\n   - Recommended default: `proto3` with explicit `optional` on scalar fields when presence matters.\n2. For TypeScript generation, which plugin should be targeted: `ts-proto` or `@protobuf-ts/plugin`?\n   - Recommended default: `ts-proto`.\n\nWhen answering, always note version-specific features involved in the request.\n\n## Proto2 vs proto3 guardrails\n\n- `required` fields are proto2-only and should be avoided for new design.\n- Explicit scalar defaults (`[default = ...]`) are proto2-only.\n- Extensions are proto2-oriented; not a general proto3 field pattern.\n- Groups are deprecated legacy proto2 and should not be introduced.\n- Proto3 enums must start with a zero-valued first entry.\n- Proto3 scalar presence should use `optional` when presence semantics are needed.\n- Repeated scalar numerics are packed-by-default in proto3; in proto2, use `[packed = true]` for new fields.\n\n## Schema authoring workflow\n\n1. Confirm syntax version and target language outputs.\n2. Propose package and file layout.\n3. Define messages/enums/services with stable field numbering.\n4. Add comments only where semantics are non-obvious.\n5. Reserve removed field numbers and names.\n6. Validate with `protoc` descriptor output when possible.\n7. Provide generation commands for Rust and TypeScript.\n\n## Command templates\n\n- Validate schema and emit descriptor:\n\n```bash\nprotoc -I proto --include_imports --descriptor_set_out=gen/schema.pb proto/path/to/file.proto\n```\n\n- Rust via `prost-build` (`build.rs`):\n\n```rust\nfn main() -> std::io::Result<()> {\n    prost_build::compile_protos(&[\"proto/service.proto\"], &[\"proto\"])?;\n    Ok(())\n}\n```\n\n- Rust via `tonic-prost-build` (`build.rs`):\n\n```rust\nfn main() {\n    tonic_prost_build::configure()\n        .compile_protos(&[\"proto/service.proto\"], &[\"proto\"])\n        .unwrap();\n}\n```\n\n- TypeScript via `ts-proto`:\n\n```bash\nprotoc \\\n  --plugin=./node_modules/.bin/protoc-gen-ts_proto \\\n  --ts_proto_out=gen/ts \\\n  --ts_proto_opt=esModuleInterop=true \\\n  -I proto \\\n  proto/path/to/file.proto\n```\n\n- TypeScript via `@protobuf-ts/plugin`:\n\n```bash\nnpx protoc --ts_out gen/ts --proto_path proto proto/path/to/file.proto\n```\n\n## Output expectations\n\n- Deliver the requested `.proto` file(s) and a short note on compatibility choices.\n- Explicitly call out any use of proto2-only/proto3-only features.\n- Include exact generation commands for the selected Rust and TypeScript toolchains.\n",
              "additions": 101,
              "deletions": 0,
              "status": "added"
            },
            {
              "file": "AGENTS.md",
              "before": "# Dark Factory - Agent Operating Guide\n\nThis file is for coding agents working in `dark-factory`.\nIt reflects only what is currently true in this repository.\n\n## 1) Current Repository Context\n\n- The repo is early-stage and mostly docs/config right now.\n- Tracked project files currently include:\n  - `README.md`\n  - `TODO.md`\n  - `AGENTS.md`\n  - `opencode.jsonc`\n  - `.opencode/agents/gitter.md`\n  - `.opencode/skills/gitter-commit/SKILL.md`\n- No application code tree is committed yet (`src/`, `apps/`, `crates/`, etc.).\n\n## 2) Build/Lint/Test Status (Current Truth)\n\n- There are no validated build, lint, typecheck, or test commands yet.\n- Do not invent or assume project commands in commits or PR notes.\n- If new tooling is added, document only commands that are verified in this repo.\n\n## 3) Cursor and Copilot Rules\n\n- Checked and currently absent:\n  - `.cursor/rules/`\n  - `.cursorrules`\n  - `.github/copilot-instructions.md`\n- If any of these files appear later, treat them as authoritative and update this guide.\n\n## 4) Coding Style (Minimal Baseline)\n\nUntil language/tool-specific configs exist, follow pragmatic defaults:\n\n- Favor readable, explicit code over clever shortcuts.\n- Keep functions focused and avoid hidden side effects.\n- Avoid dead code, unused imports, and speculative abstractions.\n- Keep naming consistent (`PascalCase` types, `camelCase` values/functions, `UPPER_SNAKE_CASE` constants).\n- Handle errors with context; do not swallow exceptions silently.\n- Never log secrets or credentials.\n- Log messages should follow: `System // Optional Sub system // Message (Metadata)`.\n  - Example: `Core // HTTP // Listening (env=development,host=127.0.0.1,port=4150)`.\n\n## 5) Git Workflow\n\n- Commit meaningful units of work; avoid giant mixed commits.\n- Do not push unless the user explicitly requests it.\n- Commit message format:\n  - `{Component/Meta} // {Optional Addition} // {Short Description} (Optional,Tags)`\n- Examples:\n  - `Docs // Added converted PDF docs`\n  - `Pipelines // ODM // Added initial ODM pipeline (WIP)`\n- In commit body, add a short rationale and signature when possible:\n  - `// Chappie/Model (your model if known)`\n\n## 6) OpenCode Integration\n\n- `.opencode/agents/gitter.md` is the git-focused subagent.\n- `.opencode/skills/gitter-commit/SKILL.md` documents when to route commit tasks to `@gitter`.\n- `.opencode/skills/proto-install/SKILL.md` documents standardized script-based `proto install` usage.\n- `.opencode/skills/script-authoring/SKILL.md` documents how to build reusable Bun scripts from prompt/example/bash/context.\n- Use `@gitter` when the user asks for commit support or cleanup.\n\n## 7) Local Fork Workflow (`elysia-protobuf`)\n\n- `elysia-protobuf` is also cloned locally at `~/repos/vfp/elysia-protobuf`.\n- If Core hits a bug in that dependency, patch it in the local fork repo, push the fork, then update the pinned git ref in `core/package.json` and refresh `core/bun.lock`.\n- Core currently tracks `elysia-protobuf` from the fork `master` branch in `core/package.json`; after pushing fork changes, refresh `core/bun.lock` in this repo.\n\n## 8) Script Conventions\n\n- Project scripts use shebanged Bun TypeScript files (`#!/usr/bin/env bun`) under `scripts/`.\n- Script naming uses `*.sh.ts` to indicate executable shell-style Bun scripts.\n- Shared script helpers live under `scripts/helpers/`.\n- `scripts/install.sh.ts` runs a reusable ordered list of install steps.\n- `scripts/proto_install.sh.ts` runs `proto install` from repository root.\n- After a new command sequence succeeds in a conversation, suggest capturing it into a reusable script via `.opencode/commands/capture_script_from_context.md`.\n\n## 9) Keep This File Updated\n\n- Update this file when real code, tooling, or CI is added.\n- Keep instructions tied to verified repository behavior.\n- Prefer short, accurate guidance over aspirational process docs.\n",
              "after": "# Dark Factory - Agent Operating Guide\n\nThis file is for coding agents working in `dark-factory`.\nIt reflects only what is currently true in this repository.\n\n## 1) Current Repository Context\n\n- The repo is early-stage and mostly docs/config right now.\n- Tracked project files currently include:\n  - `README.md`\n  - `TODO.md`\n  - `AGENTS.md`\n  - `opencode.jsonc`\n  - `.opencode/agents/gitter.md`\n  - `.opencode/skills/gitter-commit/SKILL.md`\n- No application code tree is committed yet (`src/`, `apps/`, `crates/`, etc.).\n\n## 2) Build/Lint/Test Status (Current Truth)\n\n- There are no validated build, lint, typecheck, or test commands yet.\n- Do not invent or assume project commands in commits or PR notes.\n- If new tooling is added, document only commands that are verified in this repo.\n\n## 3) Cursor and Copilot Rules\n\n- Checked and currently absent:\n  - `.cursor/rules/`\n  - `.cursorrules`\n  - `.github/copilot-instructions.md`\n- If any of these files appear later, treat them as authoritative and update this guide.\n\n## 4) Coding Style (Minimal Baseline)\n\nUntil language/tool-specific configs exist, follow pragmatic defaults:\n\n- Favor readable, explicit code over clever shortcuts.\n- Keep functions focused and avoid hidden side effects.\n- Avoid dead code, unused imports, and speculative abstractions.\n- Keep naming consistent (`PascalCase` types, `camelCase` values/functions, `UPPER_SNAKE_CASE` constants).\n- Handle errors with context; do not swallow exceptions silently.\n- Never log secrets or credentials.\n- Log messages should follow: `System // Optional Sub system // Message (Metadata)`.\n  - Example: `Core // HTTP // Listening (env=development,host=127.0.0.1,port=4150)`.\n\n## 5) Git Workflow\n\n- Commit meaningful units of work; avoid giant mixed commits.\n- Do not push unless the user explicitly requests it.\n- Commit message format:\n  - `{Component/Meta} // {Optional Addition} // {Short Description} (Optional,Tags)`\n- Examples:\n  - `Docs // Added converted PDF docs`\n  - `Pipelines // ODM // Added initial ODM pipeline (WIP)`\n- In commit body, add a short rationale and signature when possible:\n  - `// Chappie/Model (your model if known)`\n\n## 6) OpenCode Integration\n\n- `.opencode/agents/gitter.md` is the git-focused subagent.\n- `.opencode/skills/gitter-commit/SKILL.md` documents when to route commit tasks to `@gitter`.\n- `.opencode/skills/proto-install/SKILL.md` documents standardized script-based `proto install` usage.\n- `.opencode/skills/protobuf-schema-authoring/SKILL.md` documents how to author proto2/proto3 schemas and provide Rust/TypeScript codegen workflows.\n- `.opencode/skills/script-authoring/SKILL.md` documents how to build reusable Bun scripts from prompt/example/bash/context.\n- Use `@gitter` when the user asks for commit support or cleanup.\n\n## 7) Local Fork Workflow (`elysia-protobuf`)\n\n- `elysia-protobuf` is also cloned locally at `~/repos/vfp/elysia-protobuf`.\n- If Core hits a bug in that dependency, patch it in the local fork repo, push the fork, then update the pinned git ref in `core/package.json` and refresh `core/bun.lock`.\n- Core currently tracks `elysia-protobuf` from the fork `master` branch in `core/package.json`; after pushing fork changes, refresh `core/bun.lock` in this repo.\n\n## 8) Script Conventions\n\n- Project scripts use shebanged Bun TypeScript files (`#!/usr/bin/env bun`) under `scripts/`.\n- Script naming uses `*.sh.ts` to indicate executable shell-style Bun scripts.\n- Shared script helpers live under `scripts/helpers/`.\n- `scripts/install.sh.ts` runs a reusable ordered list of install steps.\n- `scripts/proto_install.sh.ts` runs `proto install` from repository root.\n- `scripts/scrape_moon_docs.sh.ts` scrapes moonrepo docs into `docs/external/moonrepo/*.ext.md`.\n- After a new command sequence succeeds in a conversation, suggest capturing it into a reusable script via `.opencode/commands/capture_script_from_context.md`.\n\n## 9) Keep This File Updated\n\n- Update this file when real code, tooling, or CI is added.\n- Keep instructions tied to verified repository behavior.\n- Prefer short, accurate guidance over aspirational process docs.\n",
              "additions": 2,
              "deletions": 0,
              "status": "modified"
            },
            {
              "file": "README.md",
              "before": "# Dark Factory - Autonomous Agentic Development At Scale\n\n# Concept\n\n- A central `dark-factory` \"core\" is used to track `worlds`\n- A `world` is an `env` + `actor`(s)\n- `env` is like a project and represents where an `actor` is spawned.\n  - Similar to `projets` in OpenCode or other agent orchestrators\n  - `env` may be a directory on host (simplest and most common) or later expanded to:\n    - Remote directory on a SSH-connected machine\n    - Dockershell w/ virutal FS\n    - Git Worktree\n- `world` can link multiple `envs` - which assume to all be multiple versions of the same root project\n  - we call this concept `dimensions`\n  - Examples:\n    - Multiple cloned directories of the same root project\n    - Git worktree supportds\n    - Instanced Docker shells\n- When an agent is spawned - it is linked to a given env\n  - Linking can just be spawning the agent at the directory (IE: `opencode .`)\n  - Link in the future can be custom tools/mcps to overwrite default shell and FS tools to ones that understand multi-verses\n- `actor` is a spawned agent that operates on an env.\n  - Can be various agent backends (currently scoped in OpenCode, Codex and a custom agent) - but first iteration is JUST opencode\n  - Currently is 1-1 agent to env but future work will allow multiple agents per world or even env if operations allow.\n\n# Stack + Tools\n\n- Agentic Coding: `opencode`\n- Main languages: `rust` and `bun` / `typscript`\n- Scripting: shebanged Bun TypeScript scripts under `scripts/` (`*.sh.ts`)\n- Optional build system: `moon` / `proto`\n- Common Schema Defintion: `prisma`\n  - [ ] TODO: Investigate use of protobuff\n\n# Scripts\n\n- Project shell-style scripts are Bun TypeScript files with shebangs: `#!/usr/bin/env bun`.\n- Shared helpers live in `scripts/helpers/`.\n- `scripts/install.sh.ts` runs an ordered array of install steps from repository root.\n- `scripts/proto_install.sh.ts` runs `proto install` from repository root.\n- OpenCode skill reference: `.opencode/skills/proto-install/SKILL.md`.\n- OpenCode skill reference: `.opencode/skills/script-authoring/SKILL.md`.\n\n# Components\n\n## Core\n\n- Central service that manages tracking of all worlds/envs/settigns etc.\n  - TBD: will either be stateless w/ DB and route all commands just to the agents\n    - OR: a background API service (Rest even) we can query from frontends\n- Currently looking lile will be Bun + Elysia JS\n\n## Frontends\n\n- Various frontends that invoke / connect to Core\n- Main way of iterating with the system\n- Uses the Core API to communicate (REST / WS or GRPC in the future)\n- Some Frontends:\n  - Rust TUI (Ratatui.rs) - First One\n  - Web Client (Bun + Vite + Shadcn + React)\n  - Pure CLI (Rust)\n\n## Agents\n\n- Abstracted communication with actual agents doing work\n- First is OpenCode\n",
              "after": "# Dark Factory - Autonomous Agentic Development At Scale\n\n# Concept\n\n- A central `dark-factory` \"core\" is used to track `worlds`\n- A `world` is an `env` + `actor`(s)\n- `env` is like a project and represents where an `actor` is spawned.\n  - Similar to `projets` in OpenCode or other agent orchestrators\n  - `env` may be a directory on host (simplest and most common) or later expanded to:\n    - Remote directory on a SSH-connected machine\n    - Dockershell w/ virutal FS\n    - Git Worktree\n- `world` can link multiple `envs` - which assume to all be multiple versions of the same root project\n  - we call this concept `dimensions`\n  - Examples:\n    - Multiple cloned directories of the same root project\n    - Git worktree supportds\n    - Instanced Docker shells\n- When an agent is spawned - it is linked to a given env\n  - Linking can just be spawning the agent at the directory (IE: `opencode .`)\n  - Link in the future can be custom tools/mcps to overwrite default shell and FS tools to ones that understand multi-verses\n- `actor` is a spawned agent that operates on an env.\n  - Can be various agent backends (currently scoped in OpenCode, Codex and a custom agent) - but first iteration is JUST opencode\n  - Currently is 1-1 agent to env but future work will allow multiple agents per world or even env if operations allow.\n\n# Stack + Tools\n\n- Agentic Coding: `opencode`\n- Main languages: `rust` and `bun` / `typscript`\n- Scripting: shebanged Bun TypeScript scripts under `scripts/` (`*.sh.ts`)\n- Optional build system: `moon` / `proto`\n- Common Schema Defintion: `prisma`\n  - [ ] TODO: Investigate use of protobuff\n\n# Scripts\n\n- Project shell-style scripts are Bun TypeScript files with shebangs: `#!/usr/bin/env bun`.\n- Shared helpers live in `scripts/helpers/`.\n- `scripts/install.sh.ts` runs an ordered array of install steps from repository root.\n- `scripts/proto_install.sh.ts` runs `proto install` from repository root.\n- `scripts/scrape_moon_docs.sh.ts` captures moonrepo docs into `docs/external/moonrepo/*.ext.md`.\n- OpenCode skill reference: `.opencode/skills/proto-install/SKILL.md`.\n- OpenCode skill reference: `.opencode/skills/script-authoring/SKILL.md`.\n\n# Components\n\n## Core\n\n- Central service that manages tracking of all worlds/envs/settigns etc.\n  - TBD: will either be stateless w/ DB and route all commands just to the agents\n    - OR: a background API service (Rest even) we can query from frontends\n- Currently looking lile will be Bun + Elysia JS\n\n## Frontends\n\n- Various frontends that invoke / connect to Core\n- Main way of iterating with the system\n- Uses the Core API to communicate (REST / WS or GRPC in the future)\n- Some Frontends:\n  - Rust TUI (Ratatui.rs) - First One\n  - Web Client (Bun + Vite + Shadcn + React)\n  - Pure CLI (Rust)\n\n## Agents\n\n- Abstracted communication with actual agents doing work\n- First is OpenCode\n",
              "additions": 1,
              "deletions": 0,
              "status": "modified"
            },
            {
              "file": "docs/designs/core_gen1.design.md",
              "before": "",
              "after": "# Notes\n\n- Use moon and proto to manage tools and deps\n- Use a shared schemas language to define our types / API's\n    - This will allow us to port to a new language eaier\n    - Prisma was first choice but lacks solid rust support\n    - Protobuf using elysia-protobuf seems like a good option\n        - Libray is a bit immature - so we forked it to allow patches\n- Bun + Elysia JS based server for Gen 1 API for the following reasons:\n    - Faster iteration\n    - Nice OpenAPI support which will is nice for testing and open source development\n    - Out of the box plugins for stuff like llms.txt - userful for the spirit\n    - In theroy - can do ProtoBuff -> OpenAPI -> Routes / Docs all out of the box.\n- High level architecture is a core service that handles world / env / actor tracking and provides an API for agentic comms. The core service will be used by the agents to interact with the world and each other. The core service will also handle logging and other helpers.\n- Core acts a spawnable api server that reads from a local database oof our stored world / env / actor state. It exposes HTTP/WebSocket APIs to query / manipulate this state, as well as an API for agentic comms. The core service is designed to be lightweight and fast, allowing for quick iteration and development.\n- Frontend (first one being a simple CLI, followed by a TUI) will interact with the core service to provide a user interface for monitoring and interacting with the world and agents. The frontend will also provide tools for debugging and visualizing the state of the world and agents.",
              "additions": 16,
              "deletions": 0,
              "status": "modified"
            },
            {
              "file": "docs/external/moonrepo/moonrepo_docs.ext.md",
              "before": "",
              "after": "----\n## External Docs Snapshot // moonrepo\n\n- Captured: 2026-02-16T03:38:46.200Z\n- Source root: https://moonrepo.dev/docs\n- Scope: 171 pages under /docs (excluding /docs/tags)\n- Keywords: moon, monorepo, task graph, hashing, cache, toolchain, proto, workspace, codegen, query, migration, CI\n- Summary: moonrepo documentation centers on deterministic task orchestration, project/dependency graphs, and reproducible toolchains with proto-backed version pinning.\n----\n\n## /docs\n\nSource: https://moonrepo.dev/docs\n\nmoonrepo is a productivity platform that aims to eliminate pain points for both developers and companies, by automating tiresome and complex workflows, and improving the overall developer experience.\n\nWe currently achieve this through the following tools and services:\n\nmoon[‚Äã](http://moonrepo.dev/docs#moon \"Direct link to moon\")\n------------------------------------------------------------\n\n[moon](https://moonrepo.dev/moon) is a repository _m_ anagement, _o_ rganization, _o_ rchestration, and _n_ otification tool for the web ecosystem, written in Rust. Many of the concepts within moon are heavily inspired from Bazel and other popular build systems, but tailored for our [supported languages](http://moonrepo.dev/docs#supported-languages).\n\nYou can think of a moon as a tool that sits firmly in the middle between Bazel (high complexity, full structure), and make/just/etc scripts (low complexity, no structure).\n\n### Why use moon?[‚Äã](http://moonrepo.dev/docs#why-use-moon \"Direct link to Why use moon?\")\n\nWorking in a language's ecosystem can be very involved, especially when it comes to managing a repository effectively. Which language version to use? Which dependency manager to use? How to use packages? Or how to build packages? So on and so forth. moon aims to streamline this entire process and provide a first-class developer experience.\n\n*   **Increased productivity** - With [Rust](https://www.rust-lang.org/) as our foundation, we can ensure robust speeds, high performance, and low memory usage. Instead of long builds blocking you, focus on your work.\n*   **Exceptional developer experience** - As veterans of developer tooling, we're well aware of the pain points and frustrations. Our goal is to mitigate and overcome these obstacles.\n*   **Incremental adoption** - At its core, moon has been designed to be adopted incrementally and is _not_ an \"all at once adoption\". Migrate project-by-project, or task-by-task, it's up to you!\n*   **Reduced tasks confusion** - Tasks (for example, `package.json` scripts) can become unwieldy, very quickly. No more duplicating the same task into every project, or reverse-engineering which root scripts to use. With moon, all you need to know is the project name, and a task name.\n*   **Ensure correct versions** - Whether it's a programming language or dependency manager, ensure the same version of each tool is the same across _every_ developer's environment. No more wasted hours of debugging.\n*   **Automation built-in** - When applicable, moon will automatically install dependencies (`node_modules`), or [sync project dependencies](https://moonrepo.dev/docs/config/toolchain#syncprojectworkspacedependencies), or even [sync TypeScript project references](https://moonrepo.dev/docs/config/toolchain#syncprojectreferences).\n*   And of course, the amazing list of [features](http://moonrepo.dev/docs#features) below!\n\n### Supported languages[‚Äã](http://moonrepo.dev/docs#supported-languages \"Direct link to Supported languages\")\n\nmoon's long-term vision is to robustly support multiple programming languages (and dependency managers) so that a repository composed of projects with differing languages and tools can all work in unison. This is a lofty vision that requires a massive amount of time and resources to achieve, and as such, is not available on initial release, but will gradually be supported over time.\n\nTo help achieve this vision, language support is broken down into 4 tiers, allowing us to incrementally integrate and improve them over time. The 4 tiers are as follows:\n\n*   Tier 0**No direct integration** - Tool is not directly supported in moon, but can still be run using the [\"system\" task toolchain](https://moonrepo.dev/docs/faq#can-we-run-other-languages), which expects the tool to exist in the current environment.\n*   Tier 1**Project categorization** - Projects can configure their primary [language in `moon.yml`](https://moonrepo.dev/docs/config/project#language), and have a dedicated Rust crate for metadata.\n*   Tier 2**Ecosystem platformization** - moon deeply integrates with the language's ecosystem by parsing manifests, lockfiles, and other semantic files to infer dependencies, tasks, and other necessary information.\n*   Tier 3**Toolchain integration** - Language is directly supported in the toolchain, configured in [`.moon/toolchains.yml`](https://moonrepo.dev/docs/config/toolchain), and will automatically be downloaded and installed.\n\n|  | Tier 0 | Tier 1 | Tier 2 | Tier 3 |\n| --- | --- | --- | --- | --- |\n| Bash/Batch | üü¢ | üü¢ |  |  |\n| Bun (JavaScript, TypeScript) | üü¢ | üü¢ | üü¢ | üü¢ |\n| Deno (JavaScript, TypeScript) | üü¢ | üü¢ | üü¢ | üü¢ |\n| Go | üü¢ | üü¢ | üü¢ | üü¢ |\n| Node (JavaScript, TypeScript) | üü¢ | üü¢ | üü¢ | üü¢ |\n| ‚îî‚îÄ npm, pnpm, yarn | üü¢ | ‚ö™Ô∏è | üü¢ | üü¢ |\n| PHP | üü¢ | üü¢ |  |  |\n| ‚îî‚îÄ Composer | üü¢ | ‚ö™Ô∏è |  |  |\n| Python | üü¢ | üü¢ | üü£ | üü£ |\n| ‚îî‚îÄ Pip | üü¢ | ‚ö™Ô∏è | üü£ |  |\n| Ruby | üü¢ | üü¢ |  |  |\n| ‚îî‚îÄ Gems, Bundler | üü¢ | ‚ö™Ô∏è |  |  |\n| Rust | üü¢ | üü¢ | üü¢ | üü¢ |\n| ‚îî‚îÄ Cargo | üü¢ | ‚ö™Ô∏è | üü¢ | üü¢ |\n| Other (Kotlin, Java, C#, ...) | üü¢ |  |  |  |\n\n*   ‚ö™Ô∏è Not applicable\n*   üü£ Partially supported (experimental)\n*   üü¢ Fully Supported\n\n### Supported targets[‚Äã](http://moonrepo.dev/docs#supported-targets \"Direct link to Supported targets\")\n\nBecause moon is written in Rust, we only support targets that are explicitly compiled for, which are currently:\n\n| Operating system | Architecture | Target |\n| --- | --- | --- |\n| macOS 64-bit | Intel | `x86_64-apple-darwin` |\n| macOS 64-bit | ARM | `aarch64-apple-darwin` |\n| Linux 64-bit | Intel GNU | `x86_64-unknown-linux-gnu` |\n| Linux 64-bit | Intel musl | `x86_64-unknown-linux-musl` |\n| Linux 64-bit | ARM GNU | `aarch64-unknown-linux-gnu` |\n| Linux 64-bit | ARM musl | `aarch64-unknown-linux-musl` |\n| Windows 64-bit | Intel | `x86_64-pc-windows-msvc` |\n\n### Features[‚Äã](http://moonrepo.dev/docs#features \"Direct link to Features\")\n\n#### Management[‚Äã](http://moonrepo.dev/docs#management \"Direct link to Management\")\n\n*   **Smart hashing** - Collects inputs from multiple sources to ensure builds are deterministic and reproducible.\n*   **Remote caching** - Persists builds, hashes, and caches between teammates and CI/CD environments.\n*   **Integrated toolchain** - Automatically downloads and installs explicit versions of Node.js and other tools for consistency across the entire workspace or per project.\n*   **Multi-platform** - Runs on common development platforms: Linux, macOS, and Windows.\n\n#### Organization[‚Äã](http://moonrepo.dev/docs#organization \"Direct link to Organization\")\n\n*   **Project graph** - Generates a project graph for dependency and dependent relationships.\n*   **Code generation** - Easily scaffold new applications, libraries, tooling, and more!\n*   **Dependency workspaces** - Works alongside package manager workspaces so that projects have distinct dependency trees.\n*   **Code ownership** - Declare owners, maintainers, support channels, and more. Generate CODEOWNERS.\n\n#### Orchestration[‚Äã](http://moonrepo.dev/docs#orchestration \"Direct link to Orchestration\")\n\n*   **Dependency graph** - Generates a dependency graph to increase performance and reduce workloads.\n*   **Action pipeline** - Executes actions in parallel and in order using a thread pool and our dependency graph.\n*   **Action distribution**Coming soon - Distributes actions across multiple machines to increase throughput.\n*   **Incremental builds** - With our smart hashing, only rebuild projects that have been touched since the last build.\n\n#### Notification[‚Äã](http://moonrepo.dev/docs#notification \"Direct link to Notification\")\n\n*   **Flakiness detection** - Reduce flaky builds with automatic retries and passthrough settings.\n*   **Webhook events**Experimental - Receive a webhook for every event in the pipeline. Useful for metrics gathering and insights.\n*   **Terminal notifications**Experimental - Receives notifications in your chosen terminal when builds are successful... or are not.\n*   **Git hooks** - Manage Git hooks to enforce workflows and requirements for contributors.\n\nproto[‚Äã](http://moonrepo.dev/docs#proto \"Direct link to proto\")\n---------------------------------------------------------------\n\n[proto](https://moonrepo.dev/proto) is a version manager for your favorite programming languages. [View proto documentation](https://moonrepo.dev/docs/proto).\n\n## /docs/cheat-sheet\n\nSource: https://moonrepo.dev/docs/cheat-sheet\n\nDon't have time to read the docs? Here's a quick cheat sheet to get you started.\n\nTasks[‚Äã](http://moonrepo.dev/docs/cheat-sheet#tasks \"Direct link to Tasks\")\n---------------------------------------------------------------------------\n\nLearn more about [tasks](https://moonrepo.dev/docs/concepts/task) and [targets](https://moonrepo.dev/docs/concepts/target).\n\n#### Run all build and test tasks for all projects[‚Äã](http://moonrepo.dev/docs/cheat-sheet#run-all-build-and-test-tasks-for-all-projects \"Direct link to Run all build and test tasks for all projects\")\n\n`moon check --all`\n\n#### Run all build and test tasks in a project[‚Äã](http://moonrepo.dev/docs/cheat-sheet#run-all-build-and-test-tasks-in-a-project \"Direct link to Run all build and test tasks in a project\")\n\n`moon check project`\n\n#### Run all build and test tasks for closest project based on working directory[‚Äã](http://moonrepo.dev/docs/cheat-sheet#run-all-build-and-test-tasks-for-closest-project-based-on-working-directory \"Direct link to Run all build and test tasks for closest project based on working directory\")\n\n`moon check`\n\n#### Run a task in all projects[‚Äã](http://moonrepo.dev/docs/cheat-sheet#run-a-task-in-all-projects \"Direct link to Run a task in all projects\")\n\n`moon run :task`\n\n#### Run a task in all projects with a tag[‚Äã](http://moonrepo.dev/docs/cheat-sheet#run-a-task-in-all-projects-with-a-tag \"Direct link to Run a task in all projects with a tag\")\n\n`moon run '#tag:task'# ORmoon run \\#tag:task# ORmoon run :task --query \"tag=tag\"`\n\n#### Run a task in a project[‚Äã](http://moonrepo.dev/docs/cheat-sheet#run-a-task-in-a-project \"Direct link to Run a task in a project\")\n\n`moon run project:task`\n\n#### Run multiple tasks in all projects[‚Äã](http://moonrepo.dev/docs/cheat-sheet#run-multiple-tasks-in-all-projects \"Direct link to Run multiple tasks in all projects\")\n\n`moon run :task1 :task2`\n\n#### Run multiple tasks in any project[‚Äã](http://moonrepo.dev/docs/cheat-sheet#run-multiple-tasks-in-any-project \"Direct link to Run multiple tasks in any project\")\n\n`moon run projecta:task1 projectb:task2`\n\n#### Run a task in applications, libraries, or tools[‚Äã](http://moonrepo.dev/docs/cheat-sheet#run-a-task-in-applications-libraries-or-tools \"Direct link to Run a task in applications, libraries, or tools\")\n\n`moon run :task --query \"projectLayer=application\"`\n\n#### Run a task in projects of a specific language[‚Äã](http://moonrepo.dev/docs/cheat-sheet#run-a-task-in-projects-of-a-specific-language \"Direct link to Run a task in projects of a specific language\")\n\n`moon run :task --query \"language=typescript\"`\n\n#### Run a task in projects matching a keyword[‚Äã](http://moonrepo.dev/docs/cheat-sheet#run-a-task-in-projects-matching-a-keyword \"Direct link to Run a task in projects matching a keyword\")\n\n`moon run :task --query \"project~react-*\"`\n\n#### Run a task in projects based on file path[‚Äã](http://moonrepo.dev/docs/cheat-sheet#run-a-task-in-projects-based-on-file-path \"Direct link to Run a task in projects based on file path\")\n\n`moon run :task --query \"projectSource~packages/*\"`\n\nTask configuration[‚Äã](http://moonrepo.dev/docs/cheat-sheet#task-configuration \"Direct link to Task configuration\")\n------------------------------------------------------------------------------------------------------------------\n\nLearn more about [available options](https://moonrepo.dev/docs/config/project#tasks).\n\n#### Disable caching[‚Äã](http://moonrepo.dev/docs/cheat-sheet#disable-caching \"Direct link to Disable caching\")\n\nmoon.yml\n\n`tasks:  example:    # ...    options:      cache: false`\n\n#### Re-run flaky tasks[‚Äã](http://moonrepo.dev/docs/cheat-sheet#re-run-flaky-tasks \"Direct link to Re-run flaky tasks\")\n\nmoon.yml\n\n`tasks:  example:    # ...    options:      retryCount: 3`\n\n#### Depend on tasks from parent project's dependencies[‚Äã](http://moonrepo.dev/docs/cheat-sheet#depend-on-tasks-from-parent-projects-dependencies \"Direct link to Depend on tasks from parent project's dependencies\")\n\nmoon.yml\n\n`# Also inferred from the languagedependsOn:  - 'project-a'  - 'project-b'tasks:  example:    # ...    deps:      - '^:build'`\n\n#### Depend on tasks from arbitrary projects[‚Äã](http://moonrepo.dev/docs/cheat-sheet#depend-on-tasks-from-arbitrary-projects \"Direct link to Depend on tasks from arbitrary projects\")\n\nmoon.yml\n\n`tasks:  example:    # ...    deps:      - 'other-project:task'`\n\n#### Run dependencies serially[‚Äã](http://moonrepo.dev/docs/cheat-sheet#run-dependencies-serially \"Direct link to Run dependencies serially\")\n\nmoon.yml\n\n`tasks:  example:    # ...    deps:      - 'first'      - 'second'      - 'third'    options:      runDepsInParallel: false`\n\nmoon.yml\n\n`tasks:  example:    command: 'noop'    deps:      - 'app:watch'      - 'backend:start'      - 'tailwind:watch'    preset: 'server'`\n\n> The `local` or `persistent` settings are required for this to work.\n\nLanguages[‚Äã](http://moonrepo.dev/docs/cheat-sheet#languages \"Direct link to Languages\")\n---------------------------------------------------------------------------------------\n\n#### Run system binaries available on `PATH`[‚Äã](http://moonrepo.dev/docs/cheat-sheet#run-system-binaries-available-on-path \"Direct link to run-system-binaries-available-on-path\")\n\nmoon.yml\n\n`language: 'bash' # batch, etctasks:  example:    command: 'printenv'`\n\nmoon.yml\n\n`tasks:  example:    command: 'printenv'    toolchain: 'system'`\n\n#### Run language binaries not supported in moon's toolchain[‚Äã](http://moonrepo.dev/docs/cheat-sheet#run-language-binaries-not-supported-in-moons-toolchain \"Direct link to Run language binaries not supported in moon's toolchain\")\n\nmoon.yml\n\n`language: 'ruby'tasks:  example:    command: 'rubocop'    toolchain: 'system'`\n\n#### Run npm binaries (Node.js)[‚Äã](http://moonrepo.dev/docs/cheat-sheet#run-npm-binaries-nodejs \"Direct link to Run npm binaries (Node.js)\")\n\nmoon.yml\n\n`language: 'javascript' # typescripttasks:  example:    command: 'eslint'`\n\nmoon.yml\n\n`tasks:  example:    command: 'eslint'    toolchain: 'node'`\n\n## /docs/commands\n\nSource: https://moonrepo.dev/docs/commands\n\n[Skip to main content](http://moonrepo.dev/docs/commands#__docusaurus_skipToContent_fallback)\n\n[![Image 1: moon](https://moonrepo.dev/img/logo.svg)](https://moonrepo.dev/)\n\n[Products](http://moonrepo.dev/docs/commands#)\n\n*   [**moon** Build system for managing codebases](https://moonrepo.dev/moon)\n*   [**proto** Multi-language version manager](https://moonrepo.dev/proto)\n\n[Docs](http://moonrepo.dev/docs/commands#)\n\n*   [**moon**](https://moonrepo.dev/docs)\n*   [**proto**](https://moonrepo.dev/docs/proto)\n\n[Guides](https://moonrepo.dev/docs/guides/ci)[Blog](https://moonrepo.dev/blog)[GitHub](https://github.com/moonrepo)\n\n1.   [Home](https://moonrepo.dev/)\n2.   [Commands](https://moonrepo.dev/docs/commands) \n\nwarning\n\nDocumentation is currently for [moon v2](https://moonrepo.dev/blog/moon-v2-alpha) and latest proto. Documentation for moon v1 has been frozen and can be[found here](https://moonrepo.github.io/website-v1/).\n\n[üìÑÔ∏èOverview ----------- The following options are available for all moon commands.](https://moonrepo.dev/docs/commands/overview)[üìÑÔ∏èaction-graph --------------- The moon action-graph [target] (or moon ag) command will generate and serve a visual graph of](https://moonrepo.dev/docs/commands/action-graph)[üìÑÔ∏èbin ------ The moon bin command will return an absolute path to a tool's binary within the](https://moonrepo.dev/docs/commands/bin)[üìÑÔ∏ècheck -------- The moon check [...projects] (or moon c) command will run all](https://moonrepo.dev/docs/commands/check)[üìÑÔ∏èci ----- The moon ci command is a special command that should be ran in a continuous integration (CI)](https://moonrepo.dev/docs/commands/ci)[üìÑÔ∏èclean -------- The moon clean command will clean the current workspace by deleting stale cache. For the most](https://moonrepo.dev/docs/commands/clean)[üìÑÔ∏ècompletions -------------- The moon completions command will generate moon command and argument completions for your current](https://moonrepo.dev/docs/commands/completions)[üóÉÔ∏èdocker --------- 4 items](https://moonrepo.dev/docs/commands/docker)[üìÑÔ∏èexec ------- The moon exec (or moon x, or moonx) command is a low-level command for executing tasks in the](https://moonrepo.dev/docs/commands/exec)[üìÑÔ∏èext ------ The moon ext command will execute an extension (a WASM plugin) that has been configured with](https://moonrepo.dev/docs/commands/ext)[üóÉÔ∏èextension ------------ 2 items](https://moonrepo.dev/docs/commands/extension)[üìÑÔ∏ègenerate ----------- The moon generate (or moon g) command will generate code (files and folders) from a](https://moonrepo.dev/docs/commands/generate)[üìÑÔ∏èhash ------- Use the moon hash command to inspect the contents and sources of a generated hash, also known as](https://moonrepo.dev/docs/commands/hash)[üìÑÔ∏èinit ------- The moon init command will initialize moon into a repository and scaffold necessary config files](https://moonrepo.dev/docs/commands/init)[üìÑÔ∏èmcp ------ The moon mcp command will start an MCP server that listens for](https://moonrepo.dev/docs/commands/mcp)[üìÑÔ∏èproject ---------- The moon project [id] (or moon p) command will display all available information about a project](https://moonrepo.dev/docs/commands/project)[üìÑÔ∏èprojects ----------- The moon projects command will list all projects configured in the workspace as a table of](https://moonrepo.dev/docs/commands/projects)[üìÑÔ∏èproject-graph ---------------- The moon project-graph [id] (or moon pg) command will generate and serve a visual graph of all](https://moonrepo.dev/docs/commands/project-graph)[üóÉÔ∏èquery -------- 4 items](https://moonrepo.dev/docs/commands/query)[üìÑÔ∏èrun ------ The moon run (or moon r) command will run one or many targets and all of](https://moonrepo.dev/docs/commands/run)[üìÑÔ∏èsetup -------- The moon setup command can be used to setup the developer and pipeline environments. It achieves](https://moonrepo.dev/docs/commands/setup)[üóÉÔ∏èsync ------- 4 items](https://moonrepo.dev/docs/commands/sync)[üìÑÔ∏ètask ------- The moon task [target] (or moon t) command will display information about a task that has been](https://moonrepo.dev/docs/commands/task)[üìÑÔ∏ètasks -------- The moon tasks command will list all tasks available in the workspace as a table of information.](https://moonrepo.dev/docs/commands/tasks)[üìÑÔ∏ètask-graph ------------- The moon task-graph [target] (or moon tg) command will generate and serve a visual graph of all](https://moonrepo.dev/docs/commands/task-graph)[üìÑÔ∏èteardown ----------- The moon teardown command, as its name infers, will teardown and clean the current environment,](https://moonrepo.dev/docs/commands/teardown)[üìÑÔ∏ètemplate ----------- The moon template [id] command will display information about a template, its files, and](https://moonrepo.dev/docs/commands/template)[üìÑÔ∏ètemplates ------------ The moon templates command will list all templates available for code generation.](https://moonrepo.dev/docs/commands/templates)[üóÉÔ∏ètoolchain ------------ 2 items](https://moonrepo.dev/docs/commands/toolchain)[üìÑÔ∏èupgrade ---------- The moon upgrade command can be used to upgrade your current moon binary (if installed globally)](https://moonrepo.dev/docs/commands/upgrade)\n\n## /docs/commands/action-graph\n\nSource: https://moonrepo.dev/docs/commands/action-graph\n\naction-graph | moonrepo\n===============\n\n[Skip to main content](http://moonrepo.dev/docs/commands/action-graph#__docusaurus_skipToContent_fallback)\n\n[![Image 1: moon](http://moonrepo.dev/img/logo.svg)](http://moonrepo.dev/)\n\n[Products](http://moonrepo.dev/docs/commands/action-graph#)\n*   [**moon**Build system for managing codebases](http://moonrepo.dev/moon)\n*   [**proto**Multi-language version manager](http://moonrepo.dev/proto)\n\n[Docs](http://moonrepo.dev/docs/commands/action-graph#)\n*   [**moon**](http://moonrepo.dev/docs)\n*   [**proto**](http://moonrepo.dev/docs/proto)\n\n[Guides](http://moonrepo.dev/docs/guides/ci)[Blog](http://moonrepo.dev/blog)[GitHub](https://github.com/moonrepo)\n\nSearch\n\n*   [Introduction](http://moonrepo.dev/docs)\n*   [Install moon](http://moonrepo.dev/docs/install)\n*   [How it works](http://moonrepo.dev/docs/how-it-works) \n*   [Getting started](http://moonrepo.dev/docs/commands/action-graph#) \n    *   [Setup workspace](http://moonrepo.dev/docs/setup-workspace)\n    *   [Create a project](http://moonrepo.dev/docs/create-project)\n    *   [Setup toolchain](http://moonrepo.dev/docs/setup-toolchain)\n    *   [Create a task](http://moonrepo.dev/docs/create-task)\n    *   [Run a task](http://moonrepo.dev/docs/run-task)\n    *   [Migrate to moon](http://moonrepo.dev/docs/migrate-to-moon)\n\n*   [Concepts](http://moonrepo.dev/docs/concepts) \n*   [Config files](http://moonrepo.dev/docs/config) \n*   [Editors](http://moonrepo.dev/docs/editors) \n*   [Commands](http://moonrepo.dev/docs/commands) \n    *   [Overview](http://moonrepo.dev/docs/commands/overview)\n    *   [action-graph](http://moonrepo.dev/docs/commands/action-graph)\n    *   [bin](http://moonrepo.dev/docs/commands/bin)\n    *   [check](http://moonrepo.dev/docs/commands/check)\n    *   [ci](http://moonrepo.dev/docs/commands/ci)\n    *   [clean](http://moonrepo.dev/docs/commands/clean)\n    *   [completions](http://moonrepo.dev/docs/commands/completions)\n    *   [docker](http://moonrepo.dev/docs/commands/docker) \n    *   [exec](http://moonrepo.dev/docs/commands/exec)\n    *   [ext](http://moonrepo.dev/docs/commands/ext)\n    *   [extension](http://moonrepo.dev/docs/commands/extension) \n    *   [generate](http://moonrepo.dev/docs/commands/generate)\n    *   [hash](http://moonrepo.dev/docs/commands/hash)\n    *   [init](http://moonrepo.dev/docs/commands/init)\n    *   [mcp](http://moonrepo.dev/docs/commands/mcp)\n    *   [project](http://moonrepo.dev/docs/commands/project)\n    *   [projects](http://moonrepo.dev/docs/commands/projects)\n    *   [project-graph](http://moonrepo.dev/docs/commands/project-graph)\n    *   [query](http://moonrepo.dev/docs/commands/query) \n    *   [run](http://moonrepo.dev/docs/commands/run)\n    *   [setup](http://moonrepo.dev/docs/commands/setup)\n    *   [sync](http://moonrepo.dev/docs/commands/sync) \n    *   [task](http://moonrepo.dev/docs/commands/task)\n    *   [tasks](http://moonrepo.dev/docs/commands/tasks)\n    *   [task-graph](http://moonrepo.dev/docs/commands/task-graph)\n    *   [teardown](http://moonrepo.dev/docs/commands/teardown)\n    *   [template](http://moonrepo.dev/docs/commands/template)\n    *   [templates](http://moonrepo.dev/docs/commands/templates)\n    *   [toolchain](http://moonrepo.dev/docs/commands/toolchain) \n    *   [upgrade](http://moonrepo.dev/docs/commands/upgrade)\n\n*   [Migrations](http://moonrepo.dev/docs/commands/action-graph#) \n*   [Cheat sheet](http://moonrepo.dev/docs/cheat-sheet)\n*   [Feature comparison](http://moonrepo.dev/docs/comparison)\n*   [Terminology](http://moonrepo.dev/docs/terminology)\n*   [FAQ](http://moonrepo.dev/docs/faq)\n*   [Changelog](https://github.com/moonrepo/moon/releases)\n\n1.   [Home](http://moonrepo.dev/)\n2.   [Commands](http://moonrepo.dev/docs/commands) \n3.   [action-graph](http://moonrepo.dev/docs/commands/action-graph) \n\nwarning\n\nDocumentation is currently for [moon v2](http://moonrepo.dev/blog/moon-v2-alpha) and latest proto. Documentation for moon v1 has been frozen and can be[found here](https://moonrepo.github.io/website-v1/).\n\nOn this page\n\naction-graph\n============\n\nv1.15.0\nThe `moon action-graph [target]` (or `moon ag`) command will generate and serve a visual graph of all actions and tasks within the workspace, known as the [action graph](http://moonrepo.dev/docs/how-it-works/action-graph). In other tools, this is sometimes referred to as a dependency graph or task graph.\n\n`# Run the visualizer locally$ moon action-graph# Export to DOT format$ moon action-graph --dot > graph.dot`\n\n> A target can be passed to focus the graph, including dependencies _and_ dependents. For example, `moon action-graph app:build`.\n\n### Arguments[‚Äã](http://moonrepo.dev/docs/commands/action-graph#arguments \"Direct link to Arguments\")\n\n*   `[target]` - Optional target to focus.\n\n### Options[‚Äã](http://moonrepo.dev/docs/commands/action-graph#options \"Direct link to Options\")\n\n*   `--dependents` - Include dependents of the focused target.\n*   `--dot` - Print the graph in DOT format.\n*   `--host` - The host address. Defaults to `127.0.0.1`. v1.36.0\n*   `--json` - Print the graph in JSON format.\n*   `--port` - The port to bind to. Defaults to a random port. v1.36.0\n\n### Configuration[‚Äã](http://moonrepo.dev/docs/commands/action-graph#configuration \"Direct link to Configuration\")\n\n*   [`runner`](http://moonrepo.dev/docs/config/workspace#runner) in `.moon/workspace.yml`\n*   [`tasks`](http://moonrepo.dev/docs/config/tasks#tasks) in `.moon/tasks/all.yml`\n*   [`tasks`](http://moonrepo.dev/docs/config/project#tasks) in `moon.yml`\n\nExample output[‚Äã](http://moonrepo.dev/docs/commands/action-graph#example-output \"Direct link to Example output\")\n----------------------------------------------------------------------------------------------------------------\n\nThe following output is an example of the graph in DOT format.\n\n`digraph {    0 [ label=\"SetupToolchain(node)\" style=filled, shape=oval, fillcolor=black, fontcolor=white]    1 [ label=\"InstallWorkspaceDeps(node)\" style=filled, shape=oval, fillcolor=gray, fontcolor=black]    2 [ label=\"SyncProject(node, node)\" style=filled, shape=oval, fillcolor=gray, fontcolor=black]    3 [ label=\"RunTask(node:standard)\" style=filled, shape=oval, fillcolor=gray, fontcolor=black]    1 -> 0 [ arrowhead=box, arrowtail=box]    2 -> 0 [ arrowhead=box, arrowtail=box]    3 -> 1 [ arrowhead=box, arrowtail=box]    3 -> 2 [ arrowhead=box, arrowtail=box]}`\n\n[Edit this page](https://github.com/moonrepo/moon/tree/master/website/docs/commands/action-graph.mdx)\n\n[Overview](http://moonrepo.dev/docs/commands/overview)\n\n[bin](http://moonrepo.dev/docs/commands/bin)\n\n*   [Arguments](http://moonrepo.dev/docs/commands/action-graph#arguments)\n*   [Options](http://moonrepo.dev/docs/commands/action-graph#options)\n*   [Configuration](http://moonrepo.dev/docs/commands/action-graph#configuration)\n*   [Example output](http://moonrepo.dev/docs/commands/action-graph#example-output)\n\nFooter\n------\n\n###### Learn\n\n*   [Docs](http://moonrepo.dev/docs)\n*   [Guides](http://moonrepo.dev/docs/guides/ci)\n*   [Blog](http://moonrepo.dev/blog)\n\n###### Ecosystem\n\n*   [Releases](https://github.com/moonrepo/moon/releases)\n*   [Shared configs](https://github.com/moonrepo/moon-configs)\n*   [Developer tools](https://github.com/moonrepo/dev)\n*   [Examples repository](https://github.com/moonrepo/examples)\n\n###### Support\n\n*   [GitHub](https://github.com/moonrepo)\n*   [Discord](https://discord.gg/qCh9MEynv2)\n*   [Twitter](https://twitter.com/tothemoonrepo)\n\n###### Contact us\n\nWant to learn more about moonrepo? Have questions?\n\nSubject \n\nNext\n\nBacked by\n\nCopyright ¬© 2026, moonrepo, Inc.\n\n[GitHub](https://github.com/moonrepo)[Discord](https://discord.gg/qCh9MEynv2)[Twitter](https://twitter.com/tothemoonrepo)\n\n## /docs/commands/bin\n\nSource: https://moonrepo.dev/docs/commands/bin\n\nbin | moonrepo\n===============\n\n[Skip to main content](http://moonrepo.dev/docs/commands/bin#__docusaurus_skipToContent_fallback)\n\n[![Image 1: moon](http://moonrepo.dev/img/logo.svg)](http://moonrepo.dev/)\n\n[Products](http://moonrepo.dev/docs/commands/bin#)\n*   [**moon**Build system for managing codebases](http://moonrepo.dev/moon)\n*   [**proto**Multi-language version manager](http://moonrepo.dev/proto)\n\n[Docs](http://moonrepo.dev/docs/commands/bin#)\n*   [**moon**](http://moonrepo.dev/docs)\n*   [**proto**](http://moonrepo.dev/docs/proto)\n\n[Guides](http://moonrepo.dev/docs/guides/ci)[Blog](http://moonrepo.dev/blog)[GitHub](https://github.com/moonrepo)\n\nSearch\n\n*   [Introduction](http://moonrepo.dev/docs)\n*   [Install moon](http://moonrepo.dev/docs/install)\n*   [How it works](http://moonrepo.dev/docs/how-it-works) \n*   [Getting started](http://moonrepo.dev/docs/commands/bin#) \n    *   [Setup workspace](http://moonrepo.dev/docs/setup-workspace)\n    *   [Create a project](http://moonrepo.dev/docs/create-project)\n    *   [Setup toolchain](http://moonrepo.dev/docs/setup-toolchain)\n    *   [Create a task](http://moonrepo.dev/docs/create-task)\n    *   [Run a task](http://moonrepo.dev/docs/run-task)\n    *   [Migrate to moon](http://moonrepo.dev/docs/migrate-to-moon)\n\n*   [Concepts](http://moonrepo.dev/docs/concepts) \n*   [Config files](http://moonrepo.dev/docs/config) \n*   [Editors](http://moonrepo.dev/docs/editors) \n*   [Commands](http://moonrepo.dev/docs/commands) \n    *   [Overview](http://moonrepo.dev/docs/commands/overview)\n    *   [action-graph](http://moonrepo.dev/docs/commands/action-graph)\n    *   [bin](http://moonrepo.dev/docs/commands/bin)\n    *   [check](http://moonrepo.dev/docs/commands/check)\n    *   [ci](http://moonrepo.dev/docs/commands/ci)\n    *   [clean](http://moonrepo.dev/docs/commands/clean)\n    *   [completions](http://moonrepo.dev/docs/commands/completions)\n    *   [docker](http://moonrepo.dev/docs/commands/docker) \n    *   [exec](http://moonrepo.dev/docs/commands/exec)\n    *   [ext](http://moonrepo.dev/docs/commands/ext)\n    *   [extension](http://moonrepo.dev/docs/commands/extension) \n    *   [generate](http://moonrepo.dev/docs/commands/generate)\n    *   [hash](http://moonrepo.dev/docs/commands/hash)\n    *   [init](http://moonrepo.dev/docs/commands/init)\n    *   [mcp](http://moonrepo.dev/docs/commands/mcp)\n    *   [project](http://moonrepo.dev/docs/commands/project)\n    *   [projects](http://moonrepo.dev/docs/commands/projects)\n    *   [project-graph](http://moonrepo.dev/docs/commands/project-graph)\n    *   [query](http://moonrepo.dev/docs/commands/query) \n    *   [run](http://moonrepo.dev/docs/commands/run)\n    *   [setup](http://moonrepo.dev/docs/commands/setup)\n    *   [sync](http://moonrepo.dev/docs/commands/sync) \n    *   [task](http://moonrepo.dev/docs/commands/task)\n    *   [tasks](http://moonrepo.dev/docs/commands/tasks)\n    *   [task-graph](http://moonrepo.dev/docs/commands/task-graph)\n    *   [teardown](http://moonrepo.dev/docs/commands/teardown)\n    *   [template](http://moonrepo.dev/docs/commands/template)\n    *   [templates](http://moonrepo.dev/docs/commands/templates)\n    *   [toolchain](http://moonrepo.dev/docs/commands/toolchain) \n    *   [upgrade](http://moonrepo.dev/docs/commands/upgrade)\n\n*   [Migrations](http://moonrepo.dev/docs/commands/bin#) \n*   [Cheat sheet](http://moonrepo.dev/docs/cheat-sheet)\n*   [Feature comparison](http://moonrepo.dev/docs/comparison)\n*   [Terminology](http://moonrepo.dev/docs/terminology)\n*   [FAQ](http://moonrepo.dev/docs/faq)\n*   [Changelog](https://github.com/moonrepo/moon/releases)\n\n1.   [Home](http://moonrepo.dev/)\n2.   [Commands](http://moonrepo.dev/docs/commands) \n3.   [bin](http://moonrepo.dev/docs/commands/bin) \n\nwarning\n\nDocumentation is currently for [moon v2](http://moonrepo.dev/blog/moon-v2-alpha) and latest proto. Documentation for moon v1 has been frozen and can be[found here](https://moonrepo.github.io/website-v1/).\n\nOn this page\n\nbin\n===\n\nThe `moon bin <toolchain>` command will return an absolute path to a tool's binary within the toolchain. If a tool has not been configured or installed, this will return a 1 or 2 exit code with no value respectively.\n\n`$ moon bin node/Users/example/.proto/tools/node/x.x.x/bin/node`\n\n> A tool is considered \"not configured\" when not in use, for example, querying yarn/pnpm when the package manager is configured for \"npm\". A tool is considered \"not installed\", when it has not been downloaded and installed into the tools directory.\n\n### Arguments[‚Äã](http://moonrepo.dev/docs/commands/bin#arguments \"Direct link to Arguments\")\n\n*   `<toolchain>` - Name of the toolchain to query.\n\n[Edit this page](https://github.com/moonrepo/moon/tree/master/website/docs/commands/bin.mdx)\n\n[action-graph](http://moonrepo.dev/docs/commands/action-graph)\n\n[check](http://moonrepo.dev/docs/commands/check)\n\n*   [Arguments](http://moonrepo.dev/docs/commands/bin#arguments)\n\nFooter\n------\n\n###### Learn\n\n*   [Docs](http://moonrepo.dev/docs)\n*   [Guides](http://moonrepo.dev/docs/guides/ci)\n*   [Blog](http://moonrepo.dev/blog)\n\n###### Ecosystem\n\n*   [Releases](https://github.com/moonrepo/moon/releases)\n*   [Shared configs](https://github.com/moonrepo/moon-configs)\n*   [Developer tools](https://github.com/moonrepo/dev)\n*   [Examples repository](https://github.com/moonrepo/examples)\n\n###### Support\n\n*   [GitHub](https://github.com/moonrepo)\n*   [Discord](https://discord.gg/qCh9MEynv2)\n*   [Twitter](https://twitter.com/tothemoonrepo)\n\n###### Contact us\n\nWant to learn more about moonrepo? Have questions?\n\nSubject \n\nNext\n\nBacked by\n\nCopyright ¬© 2026, moonrepo, Inc.\n\n[GitHub](https://github.com/moonrepo)[Discord](https://discord.gg/qCh9MEynv2)[Twitter](https://twitter.com/tothemoonrepo)\n\n## /docs/commands/check\n\nSource: https://moonrepo.dev/docs/commands/check\n\ncheck | moonrepo\n===============\n\n[Skip to main content](http://moonrepo.dev/docs/commands/check#__docusaurus_skipToContent_fallback)\n\n[![Image 1: moon](http://moonrepo.dev/img/logo.svg)](http://moonrepo.dev/)\n\n[Products](http://moonrepo.dev/docs/commands/check#)\n*   [**moon**Build system for managing codebases](http://moonrepo.dev/moon)\n*   [**proto**Multi-language version manager](http://moonrepo.dev/proto)\n\n[Docs](http://moonrepo.dev/docs/commands/check#)\n*   [**moon**](http://moonrepo.dev/docs)\n*   [**proto**](http://moonrepo.dev/docs/proto)\n\n[Guides](http://moonrepo.dev/docs/guides/ci)[Blog](http://moonrepo.dev/blog)[GitHub](https://github.com/moonrepo)\n\nSearch\n\n*   [Introduction](http://moonrepo.dev/docs)\n*   [Install moon](http://moonrepo.dev/docs/install)\n*   [How it works](http://moonrepo.dev/docs/how-it-works) \n*   [Getting started](http://moonrepo.dev/docs/commands/check#) \n    *   [Setup workspace](http://moonrepo.dev/docs/setup-workspace)\n    *   [Create a project](http://moonrepo.dev/docs/create-project)\n    *   [Setup toolchain](http://moonrepo.dev/docs/setup-toolchain)\n    *   [Create a task](http://moonrepo.dev/docs/create-task)\n    *   [Run a task](http://moonrepo.dev/docs/run-task)\n    *   [Migrate to moon](http://moonrepo.dev/docs/migrate-to-moon)\n\n*   [Concepts](http://moonrepo.dev/docs/concepts) \n*   [Config files](http://moonrepo.dev/docs/config) \n*   [Editors](http://moonrepo.dev/docs/editors) \n*   [Commands](http://moonrepo.dev/docs/commands) \n    *   [Overview](http://moonrepo.dev/docs/commands/overview)\n    *   [action-graph](http://moonrepo.dev/docs/commands/action-graph)\n    *   [bin](http://moonrepo.dev/docs/commands/bin)\n    *   [check](http://moonrepo.dev/docs/commands/check)\n    *   [ci](http://moonrepo.dev/docs/commands/ci)\n    *   [clean](http://moonrepo.dev/docs/commands/clean)\n    *   [completions](http://moonrepo.dev/docs/commands/completions)\n    *   [docker](http://moonrepo.dev/docs/commands/docker) \n    *   [exec](http://moonrepo.dev/docs/commands/exec)\n    *   [ext](http://moonrepo.dev/docs/commands/ext)\n    *   [extension](http://moonrepo.dev/docs/commands/extension) \n    *   [generate](http://moonrepo.dev/docs/commands/generate)\n    *   [hash](http://moonrepo.dev/docs/commands/hash)\n    *   [init](http://moonrepo.dev/docs/commands/init)\n    *   [mcp](http://moonrepo.dev/docs/commands/mcp)\n    *   [project](http://moonrepo.dev/docs/commands/project)\n    *   [projects](http://moonrepo.dev/docs/commands/projects)\n    *   [project-graph](http://moonrepo.dev/docs/commands/project-graph)\n    *   [query](http://moonrepo.dev/docs/commands/query) \n    *   [run](http://moonrepo.dev/docs/commands/run)\n    *   [setup](http://moonrepo.dev/docs/commands/setup)\n    *   [sync](http://moonrepo.dev/docs/commands/sync) \n    *   [task](http://moonrepo.dev/docs/commands/task)\n    *   [tasks](http://moonrepo.dev/docs/commands/tasks)\n    *   [task-graph](http://moonrepo.dev/docs/commands/task-graph)\n    *   [teardown](http://moonrepo.dev/docs/commands/teardown)\n    *   [template](http://moonrepo.dev/docs/commands/template)\n    *   [templates](http://moonrepo.dev/docs/commands/templates)\n    *   [toolchain](http://moonrepo.dev/docs/commands/toolchain) \n    *   [upgrade](http://moonrepo.dev/docs/commands/upgrade)\n\n*   [Migrations](http://moonrepo.dev/docs/commands/check#) \n*   [Cheat sheet](http://moonrepo.dev/docs/cheat-sheet)\n*   [Feature comparison](http://moonrepo.dev/docs/comparison)\n*   [Terminology](http://moonrepo.dev/docs/terminology)\n*   [FAQ](http://moonrepo.dev/docs/faq)\n*   [Changelog](https://github.com/moonrepo/moon/releases)\n\n1.   [Home](http://moonrepo.dev/)\n2.   [Commands](http://moonrepo.dev/docs/commands) \n3.   [check](http://moonrepo.dev/docs/commands/check) \n\nwarning\n\nDocumentation is currently for [moon v2](http://moonrepo.dev/blog/moon-v2-alpha) and latest proto. Documentation for moon v1 has been frozen and can be[found here](https://moonrepo.github.io/website-v1/).\n\nOn this page\n\ncheck\n=====\n\nThe `moon check [...projects]` (or `moon c`) command will run _all_[build and test tasks](http://moonrepo.dev/docs/concepts/task#types) for one or many projects. This is a convenience command for verifying the current state of a project, instead of running multiple [`moon run`](http://moonrepo.dev/docs/commands/run) commands.\n\n`# Check project by name$ moon check app# Check multiple projects by name$ moon check client server# Check project at current working directory$ moon check --closest# Check ALL projects (may be costly)$ moon check --all`\n\n### Arguments[‚Äã](http://moonrepo.dev/docs/commands/check#arguments \"Direct link to Arguments\")\n\n*   `[...id]` - List of project IDs or aliases to explicitly check, as defined in [`projects`](http://moonrepo.dev/docs/config/workspace#projects).\n\n### Options[‚Äã](http://moonrepo.dev/docs/commands/check#options \"Direct link to Options\")\n\nInherits all options from [`moon exec`](http://moonrepo.dev/docs/commands/exec) except for `--on-failure`.\n\n*   `--all` - Run check for all projects in the workspace.\n*   `--closest` - Run check for the closest project starting from the current working directory.\n\n### Configuration[‚Äã](http://moonrepo.dev/docs/commands/check#configuration \"Direct link to Configuration\")\n\n*   [`projects`](http://moonrepo.dev/docs/config/workspace#projects) in `.moon/workspace.yml`\n*   [`tasks`](http://moonrepo.dev/docs/config/tasks#tasks) in `.moon/tasks/all.yml`\n*   [`tasks`](http://moonrepo.dev/docs/config/project#tasks) in `moon.yml`\n\n[Edit this page](https://github.com/moonrepo/moon/tree/master/website/docs/commands/check.mdx)\n\n[bin](http://moonrepo.dev/docs/commands/bin)\n\n[ci](http://moonrepo.dev/docs/commands/ci)\n\n*   [Arguments](http://moonrepo.dev/docs/commands/check#arguments)\n*   [Options](http://moonrepo.dev/docs/commands/check#options)\n*   [Configuration](http://moonrepo.dev/docs/commands/check#configuration)\n\nFooter\n------\n\n###### Learn\n\n*   [Docs](http://moonrepo.dev/docs)\n*   [Guides](http://moonrepo.dev/docs/guides/ci)\n*   [Blog](http://moonrepo.dev/blog)\n\n###### Ecosystem\n\n*   [Releases](https://github.com/moonrepo/moon/releases)\n*   [Shared configs](https://github.com/moonrepo/moon-configs)\n*   [Developer tools](https://github.com/moonrepo/dev)\n*   [Examples repository](https://github.com/moonrepo/examples)\n\n###### Support\n\n*   [GitHub](https://github.com/moonrepo)\n*   [Discord](https://discord.gg/qCh9MEynv2)\n*   [Twitter](https://twitter.com/tothemoonrepo)\n\n###### Contact us\n\nWant to learn more about moonrepo? Have questions?\n\nSubject \n\nNext\n\nBacked by\n\nCopyright ¬© 2026, moonrepo, Inc.\n\n[GitHub](https://github.com/moonrepo)[Discord](https://discord.gg/qCh9MEynv2)[Twitter](https://twitter.com/tothemoonrepo)\n\n## /docs/commands/ci\n\nSource: https://moonrepo.dev/docs/commands/ci\n\nci | moonrepo\n===============\n\n[Skip to main content](http://moonrepo.dev/docs/commands/ci#__docusaurus_skipToContent_fallback)\n\n[![Image 1: moon](http://moonrepo.dev/img/logo.svg)](http://moonrepo.dev/)\n\n[Products](http://moonrepo.dev/docs/commands/ci#)\n*   [**moon**Build system for managing codebases](http://moonrepo.dev/moon)\n*   [**proto**Multi-language version manager](http://moonrepo.dev/proto)\n\n[Docs](http://moonrepo.dev/docs/commands/ci#)\n*   [**moon**](http://moonrepo.dev/docs)\n*   [**proto**](http://moonrepo.dev/docs/proto)\n\n[Guides](http://moonrepo.dev/docs/guides/ci)[Blog](http://moonrepo.dev/blog)[GitHub](https://github.com/moonrepo)\n\nSearch\n\n*   [Introduction](http://moonrepo.dev/docs)\n*   [Install moon](http://moonrepo.dev/docs/install)\n*   [How it works](http://moonrepo.dev/docs/how-it-works) \n*   [Getting started](http://moonrepo.dev/docs/commands/ci#) \n    *   [Setup workspace](http://moonrepo.dev/docs/setup-workspace)\n    *   [Create a project](http://moonrepo.dev/docs/create-project)\n    *   [Setup toolchain](http://moonrepo.dev/docs/setup-toolchain)\n    *   [Create a task](http://moonrepo.dev/docs/create-task)\n    *   [Run a task](http://moonrepo.dev/docs/run-task)\n    *   [Migrate to moon](http://moonrepo.dev/docs/migrate-to-moon)\n\n*   [Concepts](http://moonrepo.dev/docs/concepts) \n*   [Config files](http://moonrepo.dev/docs/config) \n*   [Editors](http://moonrepo.dev/docs/editors) \n*   [Commands](http://moonrepo.dev/docs/commands) \n    *   [Overview](http://moonrepo.dev/docs/commands/overview)\n    *   [action-graph](http://moonrepo.dev/docs/commands/action-graph)\n    *   [bin](http://moonrepo.dev/docs/commands/bin)\n    *   [check](http://moonrepo.dev/docs/commands/check)\n    *   [ci](http://moonrepo.dev/docs/commands/ci)\n    *   [clean](http://moonrepo.dev/docs/commands/clean)\n    *   [completions](http://moonrepo.dev/docs/commands/completions)\n    *   [docker](http://moonrepo.dev/docs/commands/docker) \n    *   [exec](http://moonrepo.dev/docs/commands/exec)\n    *   [ext](http://moonrepo.dev/docs/commands/ext)\n    *   [extension](http://moonrepo.dev/docs/commands/extension) \n    *   [generate](http://moonrepo.dev/docs/commands/generate)\n    *   [hash](http://moonrepo.dev/docs/commands/hash)\n    *   [init](http://moonrepo.dev/docs/commands/init)\n    *   [mcp](http://moonrepo.dev/docs/commands/mcp)\n    *   [project](http://moonrepo.dev/docs/commands/project)\n    *   [projects](http://moonrepo.dev/docs/commands/projects)\n    *   [project-graph](http://moonrepo.dev/docs/commands/project-graph)\n    *   [query](http://moonrepo.dev/docs/commands/query) \n    *   [run](http://moonrepo.dev/docs/commands/run)\n    *   [setup](http://moonrepo.dev/docs/commands/setup)\n    *   [sync](http://moonrepo.dev/docs/commands/sync) \n    *   [task](http://moonrepo.dev/docs/commands/task)\n    *   [tasks](http://moonrepo.dev/docs/commands/tasks)\n    *   [task-graph](http://moonrepo.dev/docs/commands/task-graph)\n    *   [teardown](http://moonrepo.dev/docs/commands/teardown)\n    *   [template](http://moonrepo.dev/docs/commands/template)\n    *   [templates](http://moonrepo.dev/docs/commands/templates)\n    *   [toolchain](http://moonrepo.dev/docs/commands/toolchain) \n    *   [upgrade](http://moonrepo.dev/docs/commands/upgrade)\n\n*   [Migrations](http://moonrepo.dev/docs/commands/ci#) \n*   [Cheat sheet](http://moonrepo.dev/docs/cheat-sheet)\n*   [Feature comparison](http://moonrepo.dev/docs/comparison)\n*   [Terminology](http://moonrepo.dev/docs/terminology)\n*   [FAQ](http://moonrepo.dev/docs/faq)\n*   [Changelog](https://github.com/moonrepo/moon/releases)\n\n1.   [Home](http://moonrepo.dev/)\n2.   [Commands](http://moonrepo.dev/docs/commands) \n3.   [ci](http://moonrepo.dev/docs/commands/ci) \n\nwarning\n\nDocumentation is currently for [moon v2](http://moonrepo.dev/blog/moon-v2-alpha) and latest proto. Documentation for moon v1 has been frozen and can be[found here](https://moonrepo.github.io/website-v1/).\n\nOn this page\n\nci\n==\n\nThe `moon ci` command is a special command that should be ran in a continuous integration (CI) environment, as it does all the heavy lifting necessary for effectively running tasks.\n\nBy default this will run all tasks that are affected by touched files and have the [`runInCI`](http://moonrepo.dev/docs/config/project#runinci) task option enabled.\n\n`$ moon ci`\n\nHowever, you can also provide a list of targets to explicitly run, which will still be filtered down by `runInCI`.\n\n`$ moon ci :build :lint`\n\n> View the official [continuous integration guide](http://moonrepo.dev/docs/guides/ci) for a more in-depth example of how to utilize this command.\n\n### Arguments[‚Äã](http://moonrepo.dev/docs/commands/ci#arguments \"Direct link to Arguments\")\n\n*   `...[target]` - [Targets](http://moonrepo.dev/docs/concepts/target) to run.\n\n### Options[‚Äã](http://moonrepo.dev/docs/commands/ci#options \"Direct link to Options\")\n\nInherits all options from [`moon exec`](http://moonrepo.dev/docs/commands/exec) except for `--affected`, `--on-failure`, and `--only-ci-tasks`.\n\n### Configuration[‚Äã](http://moonrepo.dev/docs/commands/ci#configuration \"Direct link to Configuration\")\n\n*   [`tasks`](http://moonrepo.dev/docs/config/tasks#tasks) in `.moon/tasks/all.yml`\n*   [`tasks`](http://moonrepo.dev/docs/config/project#tasks) in `moon.yml`\n*   [`tasks.*.options.runInCI`](http://moonrepo.dev/docs/config/project#runinci) in `moon.yml`\n\n[Edit this page](https://github.com/moonrepo/moon/tree/master/website/docs/commands/ci.mdx)\n\n[check](http://moonrepo.dev/docs/commands/check)\n\n[clean](http://moonrepo.dev/docs/commands/clean)\n\n*   [Arguments](http://moonrepo.dev/docs/commands/ci#arguments)\n*   [Options](http://moonrepo.dev/docs/commands/ci#options)\n*   [Configuration](http://moonrepo.dev/docs/commands/ci#configuration)\n\nFooter\n------\n\n###### Learn\n\n*   [Docs](http://moonrepo.dev/docs)\n*   [Guides](http://moonrepo.dev/docs/guides/ci)\n*   [Blog](http://moonrepo.dev/blog)\n\n###### Ecosystem\n\n*   [Releases](https://github.com/moonrepo/moon/releases)\n*   [Shared configs](https://github.com/moonrepo/moon-configs)\n*   [Developer tools](https://github.com/moonrepo/dev)\n*   [Examples repository](https://github.com/moonrepo/examples)\n\n###### Support\n\n*   [GitHub](https://github.com/moonrepo)\n*   [Discord](https://discord.gg/qCh9MEynv2)\n*   [Twitter](https://twitter.com/tothemoonrepo)\n\n###### Contact us\n\nWant to learn more about moonrepo? Have questions?\n\nSubject \n\nNext\n\nBacked by\n\nCopyright ¬© 2026, moonrepo, Inc.\n\n[GitHub](https://github.com/moonrepo)[Discord](https://discord.gg/qCh9MEynv2)[Twitter](https://twitter.com/tothemoonrepo)\n\n## /docs/commands/clean\n\nSource: https://moonrepo.dev/docs/commands/clean\n\nclean | moonrepo\n===============\n\n[Skip to main content](http://moonrepo.dev/docs/commands/clean#__docusaurus_skipToContent_fallback)\n\n[![Image 1: moon](http://moonrepo.dev/img/logo.svg)](http://moonrepo.dev/)\n\n[Products](http://moonrepo.dev/docs/commands/clean#)\n*   [**moon**Build system for managing codebases](http://moonrepo.dev/moon)\n*   [**proto**Multi-language version manager](http://moonrepo.dev/proto)\n\n[Docs](http://moonrepo.dev/docs/commands/clean#)\n*   [**moon**](http://moonrepo.dev/docs)\n*   [**proto**](http://moonrepo.dev/docs/proto)\n\n[Guides](http://moonrepo.dev/docs/guides/ci)[Blog](http://moonrepo.dev/blog)[GitHub](https://github.com/moonrepo)\n\nSearch\n\n*   [Introduction](http://moonrepo.dev/docs)\n*   [Install moon](http://moonrepo.dev/docs/install)\n*   [How it works](http://moonrepo.dev/docs/how-it-works) \n*   [Getting started](http://moonrepo.dev/docs/commands/clean#) \n    *   [Setup workspace](http://moonrepo.dev/docs/setup-workspace)\n    *   [Create a project](http://moonrepo.dev/docs/create-project)\n    *   [Setup toolchain](http://moonrepo.dev/docs/setup-toolchain)\n    *   [Create a task](http://moonrepo.dev/docs/create-task)\n    *   [Run a task](http://moonrepo.dev/docs/run-task)\n    *   [Migrate to moon](http://moonrepo.dev/docs/migrate-to-moon)\n\n*   [Concepts](http://moonrepo.dev/docs/concepts) \n*   [Config files](http://moonrepo.dev/docs/config) \n*   [Editors](http://moonrepo.dev/docs/editors) \n*   [Commands](http://moonrepo.dev/docs/commands) \n    *   [Overview](http://moonrepo.dev/docs/commands/overview)\n    *   [action-graph](http://moonrepo.dev/docs/commands/action-graph)\n    *   [bin](http://moonrepo.dev/docs/commands/bin)\n    *   [check](http://moonrepo.dev/docs/commands/check)\n    *   [ci](http://moonrepo.dev/docs/commands/ci)\n    *   [clean](http://moonrepo.dev/docs/commands/clean)\n    *   [completions](http://moonrepo.dev/docs/commands/completions)\n    *   [docker](http://moonrepo.dev/docs/commands/docker) \n    *   [exec](http://moonrepo.dev/docs/commands/exec)\n    *   [ext](http://moonrepo.dev/docs/commands/ext)\n    *   [extension](http://moonrepo.dev/docs/commands/extension) \n    *   [generate](http://moonrepo.dev/docs/commands/generate)\n    *   [hash](http://moonrepo.dev/docs/commands/hash)\n    *   [init](http://moonrepo.dev/docs/commands/init)\n    *   [mcp](http://moonrepo.dev/docs/commands/mcp)\n    *   [project](http://moonrepo.dev/docs/commands/project)\n    *   [projects](http://moonrepo.dev/docs/commands/projects)\n    *   [project-graph](http://moonrepo.dev/docs/commands/project-graph)\n    *   [query](http://moonrepo.dev/docs/commands/query) \n    *   [run](http://moonrepo.dev/docs/commands/run)\n    *   [setup](http://moonrepo.dev/docs/commands/setup)\n    *   [sync](http://moonrepo.dev/docs/commands/sync) \n    *   [task](http://moonrepo.dev/docs/commands/task)\n    *   [tasks](http://moonrepo.dev/docs/commands/tasks)\n    *   [task-graph](http://moonrepo.dev/docs/commands/task-graph)\n    *   [teardown](http://moonrepo.dev/docs/commands/teardown)\n    *   [template](http://moonrepo.dev/docs/commands/template)\n    *   [templates](http://moonrepo.dev/docs/commands/templates)\n    *   [toolchain](http://moonrepo.dev/docs/commands/toolchain) \n    *   [upgrade](http://moonrepo.dev/docs/commands/upgrade)\n\n*   [Migrations](http://moonrepo.dev/docs/commands/clean#) \n*   [Cheat sheet](http://moonrepo.dev/docs/cheat-sheet)\n*   [Feature comparison](http://moonrepo.dev/docs/comparison)\n*   [Terminology](http://moonrepo.dev/docs/terminology)\n*   [FAQ](http://moonrepo.dev/docs/faq)\n*   [Changelog](https://github.com/moonrepo/moon/releases)\n\n1.   [Home](http://moonrepo.dev/)\n2.   [Commands](http://moonrepo.dev/docs/commands) \n3.   [clean](http://moonrepo.dev/docs/commands/clean) \n\nwarning\n\nDocumentation is currently for [moon v2](http://moonrepo.dev/blog/moon-v2-alpha) and latest proto. Documentation for moon v1 has been frozen and can be[found here](https://moonrepo.github.io/website-v1/).\n\nOn this page\n\nclean\n=====\n\nThe `moon clean` command will clean the current workspace by deleting stale cache. For the most part, the action pipeline will clean automatically, but this command can be used to reset the workspace entirely.\n\n`$ moon clean# Delete cache with a custom lifetime$ moon clean --lifetime '24 hours'`\n\n### Options[‚Äã](http://moonrepo.dev/docs/commands/clean#options \"Direct link to Options\")\n\n*   `--lifetime` - The maximum lifetime of cached artifacts before being marked as stale. Defaults to \"7 days\".\n\n[Edit this page](https://github.com/moonrepo/moon/tree/master/website/docs/commands/clean.mdx)\n\n[ci](http://moonrepo.dev/docs/commands/ci)\n\n[completions](http://moonrepo.dev/docs/commands/completions)\n\n*   [Options](http://moonrepo.dev/docs/commands/clean#options)\n\nFooter\n------\n\n###### Learn\n\n*   [Docs](http://moonrepo.dev/docs)\n*   [Guides](http://moonrepo.dev/docs/guides/ci)\n*   [Blog](http://moonrepo.dev/blog)\n\n###### Ecosystem\n\n*   [Releases](https://github.com/moonrepo/moon/releases)\n*   [Shared configs](https://github.com/moonrepo/moon-configs)\n*   [Developer tools](https://github.com/moonrepo/dev)\n*   [Examples repository](https://github.com/moonrepo/examples)\n\n###### Support\n\n*   [GitHub](https://github.com/moonrepo)\n*   [Discord](https://discord.gg/qCh9MEynv2)\n*   [Twitter](https://twitter.com/tothemoonrepo)\n\n###### Contact us\n\nWant to learn more about moonrepo? Have questions?\n\nSubject \n\nNext\n\nBacked by\n\nCopyright ¬© 2026, moonrepo, Inc.\n\n[GitHub](https://github.com/moonrepo)[Discord](https://discord.gg/qCh9MEynv2)[Twitter](https://twitter.com/tothemoonrepo)\n\n## /docs/commands/completions\n\nSource: https://moonrepo.dev/docs/commands/completions\n\ncompletions | moonrepo\n===============\n\n[Skip to main content](http://moonrepo.dev/docs/commands/completions#__docusaurus_skipToContent_fallback)\n\n[![Image 1: moon](http://moonrepo.dev/img/logo.svg)](http://moonrepo.dev/)\n\n[Products](http://moonrepo.dev/docs/commands/completions#)\n*   [**moon**Build system for managing codebases](http://moonrepo.dev/moon)\n*   [**proto**Multi-language version manager](http://moonrepo.dev/proto)\n\n[Docs](http://moonrepo.dev/docs/commands/completions#)\n*   [**moon**](http://moonrepo.dev/docs)\n*   [**proto**](http://moonrepo.dev/docs/proto)\n\n[Guides](http://moonrepo.dev/docs/guides/ci)[Blog](http://moonrepo.dev/blog)[GitHub](https://github.com/moonrepo)\n\nSearch\n\n*   [Introduction](http://moonrepo.dev/docs)\n*   [Install moon](http://moonrepo.dev/docs/install)\n*   [How it works](http://moonrepo.dev/docs/how-it-works) \n*   [Getting started](http://moonrepo.dev/docs/commands/completions#) \n    *   [Setup workspace](http://moonrepo.dev/docs/setup-workspace)\n    *   [Create a project](http://moonrepo.dev/docs/create-project)\n    *   [Setup toolchain](http://moonrepo.dev/docs/setup-toolchain)\n    *   [Create a task](http://moonrepo.dev/docs/create-task)\n    *   [Run a task](http://moonrepo.dev/docs/run-task)\n    *   [Migrate to moon](http://moonrepo.dev/docs/migrate-to-moon)\n\n*   [Concepts](http://moonrepo.dev/docs/concepts) \n*   [Config files](http://moonrepo.dev/docs/config) \n*   [Editors](http://moonrepo.dev/docs/editors) \n*   [Commands](http://moonrepo.dev/docs/commands) \n    *   [Overview](http://moonrepo.dev/docs/commands/overview)\n    *   [action-graph](http://moonrepo.dev/docs/commands/action-graph)\n    *   [bin](http://moonrepo.dev/docs/commands/bin)\n    *   [check](http://moonrepo.dev/docs/commands/check)\n    *   [ci](http://moonrepo.dev/docs/commands/ci)\n    *   [clean](http://moonrepo.dev/docs/commands/clean)\n    *   [completions](http://moonrepo.dev/docs/commands/completions)\n    *   [docker](http://moonrepo.dev/docs/commands/docker) \n    *   [exec](http://moonrepo.dev/docs/commands/exec)\n    *   [ext](http://moonrepo.dev/docs/commands/ext)\n    *   [extension](http://moonrepo.dev/docs/commands/extension) \n    *   [generate](http://moonrepo.dev/docs/commands/generate)\n    *   [hash](http://moonrepo.dev/docs/commands/hash)\n    *   [init](http://moonrepo.dev/docs/commands/init)\n    *   [mcp](http://moonrepo.dev/docs/commands/mcp)\n    *   [project](http://moonrepo.dev/docs/commands/project)\n    *   [projects](http://moonrepo.dev/docs/commands/projects)\n    *   [project-graph](http://moonrepo.dev/docs/commands/project-graph)\n    *   [query](http://moonrepo.dev/docs/commands/query) \n    *   [run](http://moonrepo.dev/docs/commands/run)\n    *   [setup](http://moonrepo.dev/docs/commands/setup)\n    *   [sync](http://moonrepo.dev/docs/commands/sync) \n    *   [task](http://moonrepo.dev/docs/commands/task)\n    *   [tasks](http://moonrepo.dev/docs/commands/tasks)\n    *   [task-graph](http://moonrepo.dev/docs/commands/task-graph)\n    *   [teardown](http://moonrepo.dev/docs/commands/teardown)\n    *   [template](http://moonrepo.dev/docs/commands/template)\n    *   [templates](http://moonrepo.dev/docs/commands/templates)\n    *   [toolchain](http://moonrepo.dev/docs/commands/toolchain) \n    *   [upgrade](http://moonrepo.dev/docs/commands/upgrade)\n\n*   [Migrations](http://moonrepo.dev/docs/commands/completions#) \n*   [Cheat sheet](http://moonrepo.dev/docs/cheat-sheet)\n*   [Feature comparison](http://moonrepo.dev/docs/comparison)\n*   [Terminology](http://moonrepo.dev/docs/terminology)\n*   [FAQ](http://moonrepo.dev/docs/faq)\n*   [Changelog](https://github.com/moonrepo/moon/releases)\n\n1.   [Home](http://moonrepo.dev/)\n2.   [Commands](http://moonrepo.dev/docs/commands) \n3.   [completions](http://moonrepo.dev/docs/commands/completions) \n\nwarning\n\nDocumentation is currently for [moon v2](http://moonrepo.dev/blog/moon-v2-alpha) and latest proto. Documentation for moon v1 has been frozen and can be[found here](https://moonrepo.github.io/website-v1/).\n\nOn this page\n\ncompletions\n===========\n\nThe `moon completions` command will generate moon command and argument completions for your current shell. This command will write to stdout, which can then be redirected to a file of your choice.\n\n`$ moon completions > ./path/to/write/to`\n\n### Options[‚Äã](http://moonrepo.dev/docs/commands/completions#options \"Direct link to Options\")\n\n*   `--shell` - Shell to explicitly generate for.\n\n### Examples[‚Äã](http://moonrepo.dev/docs/commands/completions#examples \"Direct link to Examples\")\n\n*   Bash\n*   Fish\n*   Zsh\n\nIf using [bash-completion](https://github.com/scop/bash-completion).\n\n`mkdir -p ~/.bash_completion.dmoon completions > ~/.bash_completion.d/moon.sh`\n\nOtherwise write the file to a common location, and source it in your profile.\n\n`mkdir -p ~/.bash_completionsmoon completions > ~/.bash_completions/moon.sh# In your profilesource ~/.bash_completions/moon.sh`\n\nWrite the file to Fish's completions directory.\n\n`mkdir -p ~/.config/fish/completionsmoon completions > ~/.config/fish/completions/moon.fish`\n\nIf using [oh-my-zsh](https://ohmyz.sh/) (the `_` prefix is required).\n\n`mkdir -p ~/.oh-my-zsh/completionsmoon completions > ~/.oh-my-zsh/completions/_moon# Reload shell (or restart terminal)omz reload`\n\n[Edit this page](https://github.com/moonrepo/moon/tree/master/website/docs/commands/completions.mdx)\n\n[clean](http://moonrepo.dev/docs/commands/clean)\n\n[docker](http://moonrepo.dev/docs/commands/docker)\n\n*   [Options](http://moonrepo.dev/docs/commands/completions#options)\n*   [Examples](http://moonrepo.dev/docs/commands/completions#examples)\n\nFooter\n------\n\n###### Learn\n\n*   [Docs](http://moonrepo.dev/docs)\n*   [Guides](http://moonrepo.dev/docs/guides/ci)\n*   [Blog](http://moonrepo.dev/blog)\n\n###### Ecosystem\n\n*   [Releases](https://github.com/moonrepo/moon/releases)\n*   [Shared configs](https://github.com/moonrepo/moon-configs)\n*   [Developer tools](https://github.com/moonrepo/dev)\n*   [Examples repository](https://github.com/moonrepo/examples)\n\n###### Support\n\n*   [GitHub](https://github.com/moonrepo)\n*   [Discord](https://discord.gg/qCh9MEynv2)\n*   [Twitter](https://twitter.com/tothemoonrepo)\n\n###### Contact us\n\nWant to learn more about moonrepo? Have questions?\n\nSubject \n\nNext\n\nBacked by\n\nCopyright ¬© 2026, moonrepo, Inc.\n\n[GitHub](https://github.com/moonrepo)[Discord](https://discord.gg/qCh9MEynv2)[Twitter](https://twitter.com/tothemoonrepo)\n\n## /docs/commands/docker\n\nSource: https://moonrepo.dev/docs/commands/docker\n\ndocker | moonrepo\n===============\n\n[Skip to main content](http://moonrepo.dev/docs/commands/docker#__docusaurus_skipToContent_fallback)\n\n[![Image 2: moon](http://moonrepo.dev/img/logo.svg)](http://moonrepo.dev/)\n\n[Products](http://moonrepo.dev/docs/commands/docker#)\n*   [**moon**Build system for managing codebases](http://moonrepo.dev/moon)\n*   [**proto**Multi-language version manager](http://moonrepo.dev/proto)\n\n[Docs](http://moonrepo.dev/docs/commands/docker#)\n*   [**moon**](http://moonrepo.dev/docs)\n*   [**proto**](http://moonrepo.dev/docs/proto)\n\n[Guides](http://moonrepo.dev/docs/guides/ci)[Blog](http://moonrepo.dev/blog)[GitHub](https://github.com/moonrepo)\n\nSearch\n\n*   [Introduction](http://moonrepo.dev/docs)\n*   [Install moon](http://moonrepo.dev/docs/install)\n*   [How it works](http://moonrepo.dev/docs/how-it-works) \n*   [Getting started](http://moonrepo.dev/docs/commands/docker#) \n    *   [Setup workspace](http://moonrepo.dev/docs/setup-workspace)\n    *   [Create a project](http://moonrepo.dev/docs/create-project)\n    *   [Setup toolchain](http://moonrepo.dev/docs/setup-toolchain)\n    *   [Create a task](http://moonrepo.dev/docs/create-task)\n    *   [Run a task](http://moonrepo.dev/docs/run-task)\n    *   [Migrate to moon](http://moonrepo.dev/docs/migrate-to-moon)\n\n*   [Concepts](http://moonrepo.dev/docs/concepts) \n*   [Config files](http://moonrepo.dev/docs/config) \n*   [Editors](http://moonrepo.dev/docs/editors) \n*   [Commands](http://moonrepo.dev/docs/commands) \n    *   [Overview](http://moonrepo.dev/docs/commands/overview)\n    *   [action-graph](http://moonrepo.dev/docs/commands/action-graph)\n    *   [bin](http://moonrepo.dev/docs/commands/bin)\n    *   [check](http://moonrepo.dev/docs/commands/check)\n    *   [ci](http://moonrepo.dev/docs/commands/ci)\n    *   [clean](http://moonrepo.dev/docs/commands/clean)\n    *   [completions](http://moonrepo.dev/docs/commands/completions)\n    *   [docker](http://moonrepo.dev/docs/commands/docker) \n        *   [file](http://moonrepo.dev/docs/commands/docker/file)\n        *   [prune](http://moonrepo.dev/docs/commands/docker/prune)\n        *   [scaffold](http://moonrepo.dev/docs/commands/docker/scaffold)\n        *   [setup](http://moonrepo.dev/docs/commands/docker/setup)\n\n    *   [exec](http://moonrepo.dev/docs/commands/exec)\n    *   [ext](http://moonrepo.dev/docs/commands/ext)\n    *   [extension](http://moonrepo.dev/docs/commands/extension) \n    *   [generate](http://moonrepo.dev/docs/commands/generate)\n    *   [hash](http://moonrepo.dev/docs/commands/hash)\n    *   [init](http://moonrepo.dev/docs/commands/init)\n    *   [mcp](http://moonrepo.dev/docs/commands/mcp)\n    *   [project](http://moonrepo.dev/docs/commands/project)\n    *   [projects](http://moonrepo.dev/docs/commands/projects)\n    *   [project-graph](http://moonrepo.dev/docs/commands/project-graph)\n    *   [query](http://moonrepo.dev/docs/commands/query) \n    *   [run](http://moonrepo.dev/docs/commands/run)\n    *   [setup](http://moonrepo.dev/docs/commands/setup)\n    *   [sync](http://moonrepo.dev/docs/commands/sync) \n    *   [task](http://moonrepo.dev/docs/commands/task)\n    *   [tasks](http://moonrepo.dev/docs/commands/tasks)\n    *   [task-graph](http://moonrepo.dev/docs/commands/task-graph)\n    *   [teardown](http://moonrepo.dev/docs/commands/teardown)\n    *   [template](http://moonrepo.dev/docs/commands/template)\n    *   [templates](http://moonrepo.dev/docs/commands/templates)\n    *   [toolchain](http://moonrepo.dev/docs/commands/toolchain) \n    *   [upgrade](http://moonrepo.dev/docs/commands/upgrade)\n\n*   [Migrations](http://moonrepo.dev/docs/commands/docker#) \n*   [Cheat sheet](http://moonrepo.dev/docs/cheat-sheet)\n*   [Feature comparison](http://moonrepo.dev/docs/comparison)\n*   [Terminology](http://moonrepo.dev/docs/terminology)\n*   [FAQ](http://moonrepo.dev/docs/faq)\n*   [Changelog](https://github.com/moonrepo/moon/releases)\n\n1.   [Home](http://moonrepo.dev/)\n2.   [Commands](http://moonrepo.dev/docs/commands) \n3.   [docker](http://moonrepo.dev/docs/commands/docker) \n\nwarning\n\nDocumentation is currently for [moon v2](http://moonrepo.dev/blog/moon-v2-alpha) and latest proto. Documentation for moon v1 has been frozen and can be[found here](https://moonrepo.github.io/website-v1/).\n\ndocker\n======\n\nOperations for integrating with Docker and Dockerfiles.\n\n[üìÑÔ∏èfile ------- The moon docker file command can be used to generate a multi-staged Dockerfile for a](http://moonrepo.dev/docs/commands/docker/file)[üìÑÔ∏èprune -------- The moon docker prune command will reduce the overall filesize of the Docker environment by](http://moonrepo.dev/docs/commands/docker/prune)[üìÑÔ∏èscaffold ----------- The moon docker scaffold command creates multiple repository skeletons for use](http://moonrepo.dev/docs/commands/docker/scaffold)[üìÑÔ∏èsetup -------- The moon docker setup command will efficiently install dependencies for focused projects. This is](http://moonrepo.dev/docs/commands/docker/setup)\n\n[completions](http://moonrepo.dev/docs/commands/completions)\n\n[file](http://moonrepo.dev/docs/commands/docker/file)\n\nFooter\n------\n\n###### Learn\n\n*   [Docs](http://moonrepo.dev/docs)\n*   [Guides](http://moonrepo.dev/docs/guides/ci)\n*   [Blog](http://moonrepo.dev/blog)\n\n###### Ecosystem\n\n*   [Releases](https://github.com/moonrepo/moon/releases)\n*   [Shared configs](https://github.com/moonrepo/moon-configs)\n*   [Developer tools](https://github.com/moonrepo/dev)\n*   [Examples repository](https://github.com/moonrepo/examples)\n\n###### Support\n\n*   [GitHub](https://github.com/moonrepo)\n*   [Discord](https://discord.gg/qCh9MEynv2)\n*   [Twitter](https://twitter.com/tothemoonrepo)\n\n###### Contact us\n\nWant to learn more about moonrepo? Have questions?\n\nSubject \n\nNext\n\nBacked by\n\nCopyright ¬© 2026, moonrepo, Inc.\n\n[GitHub](https://github.com/moonrepo)[Discord](https://discord.gg/qCh9MEynv2)[Twitter](https://twitter.com/tothemoonrepo)\n\n## /docs/commands/docker/file\n\nSource: https://moonrepo.dev/docs/commands/docker/file\n\n1.   [Home](https://moonrepo.dev/)\n\nwarning\n\nDocumentation is currently for [moon v2](https://moonrepo.dev/blog/moon-v2-alpha) and latest proto. Documentation for moon v1 has been frozen and can be[found here](https://moonrepo.github.io/website-v1/).\n\nv1.27.0\n\nThe `moon docker file <project>` command can be used to generate a multi-staged `Dockerfile` for a project, that takes full advantage of Docker's layer caching, and is primarily for production deploys (this should not be used for development).\n\n`$ moon docker file <project>`\n\nAs mentioned above, the generated `Dockerfile` uses a multi-stage approach, where each stage is broken up into the following:\n\n*   `base` - The base stage, which simply installs moon for a chosen Docker image. This stage requires Bash.\n*   `skeleton` - Scaffolds workspace and sources repository skeletons using [`moon docker scaffold`](https://moonrepo.dev/docs/commands/docker/scaffold).\n*   `build` - Copies required sources, installs the toolchain using [`moon docker setup`](https://moonrepo.dev/docs/commands/docker/setup), optionally builds the project, and optionally prunes the image using [`moon docker prune`](https://moonrepo.dev/docs/commands/docker/prune).\n*   `start` - Runs the project after it has been built. This is typically starting an HTTP server, or executing a binary.\n\ninfo\n\nView the official [Docker usage guide](https://moonrepo.dev/docs/guides/docker) for a more in-depth example of how to utilize this command.\n\n### Arguments[‚Äã](http://moonrepo.dev/docs/commands/docker/file#arguments \"Direct link to Arguments\")\n\n*   `<name>` - Name or alias of a project, as defined in [`projects`](https://moonrepo.dev/docs/config/workspace#projects).\n*   `[dest]` - Destination to write the file, relative from the project root. Defaults to `Dockerfile`.\n\n### Options[‚Äã](http://moonrepo.dev/docs/commands/docker/file#options \"Direct link to Options\")\n\n*   `--defaults` - Use default options instead of prompting in the terminal.\n*   `--build-task` - Name of a task to build the project. Defaults to the [`docker.file.buildTask`](https://moonrepo.dev/docs/config/project#buildtask) setting, or prompts in the terminal.\n*   `--image` - Base Docker image to use. Defaults to an image derived from the toolchain, or prompts in the terminal.\n*   `--no-prune` - Do not prune the workspace in the build stage.\n*   `--no-toolchain` - Do not use the toolchain and instead use system binaries.\n*   `--start-task` - Name of a task to start the project. Defaults to the [`docker.file.startTask`](https://moonrepo.dev/docs/config/project#starttask) setting, or prompts in the terminal.\n\n### Configuration[‚Äã](http://moonrepo.dev/docs/commands/docker/file#configuration \"Direct link to Configuration\")\n\n*   [`docker.file`](https://moonrepo.dev/docs/config/project#file) in `moon.yml`\n\n## /docs/commands/docker/prune\n\nSource: https://moonrepo.dev/docs/commands/docker/prune\n\ndocker prune | moonrepo\n===============\n\n[Skip to main content](http://moonrepo.dev/docs/commands/docker/prune#__docusaurus_skipToContent_fallback)\n\n[![Image 1: moon](http://moonrepo.dev/img/logo.svg)](http://moonrepo.dev/)\n\n[Products](http://moonrepo.dev/docs/commands/docker/prune#)\n*   [**moon**Build system for managing codebases](http://moonrepo.dev/moon)\n*   [**proto**Multi-language version manager](http://moonrepo.dev/proto)\n\n[Docs](http://moonrepo.dev/docs/commands/docker/prune#)\n*   [**moon**](http://moonrepo.dev/docs)\n*   [**proto**](http://moonrepo.dev/docs/proto)\n\n[Guides](http://moonrepo.dev/docs/guides/ci)[Blog](http://moonrepo.dev/blog)[GitHub](https://github.com/moonrepo)\n\nSearch\n\n*   [Introduction](http://moonrepo.dev/docs)\n*   [Install moon](http://moonrepo.dev/docs/install)\n*   [How it works](http://moonrepo.dev/docs/how-it-works) \n*   [Getting started](http://moonrepo.dev/docs/commands/docker/prune#) \n    *   [Setup workspace](http://moonrepo.dev/docs/setup-workspace)\n    *   [Create a project](http://moonrepo.dev/docs/create-project)\n    *   [Setup toolchain](http://moonrepo.dev/docs/setup-toolchain)\n    *   [Create a task](http://moonrepo.dev/docs/create-task)\n    *   [Run a task](http://moonrepo.dev/docs/run-task)\n    *   [Migrate to moon](http://moonrepo.dev/docs/migrate-to-moon)\n\n*   [Concepts](http://moonrepo.dev/docs/concepts) \n*   [Config files](http://moonrepo.dev/docs/config) \n*   [Editors](http://moonrepo.dev/docs/editors) \n*   [Commands](http://moonrepo.dev/docs/commands) \n    *   [Overview](http://moonrepo.dev/docs/commands/overview)\n    *   [action-graph](http://moonrepo.dev/docs/commands/action-graph)\n    *   [bin](http://moonrepo.dev/docs/commands/bin)\n    *   [check](http://moonrepo.dev/docs/commands/check)\n    *   [ci](http://moonrepo.dev/docs/commands/ci)\n    *   [clean](http://moonrepo.dev/docs/commands/clean)\n    *   [completions](http://moonrepo.dev/docs/commands/completions)\n    *   [docker](http://moonrepo.dev/docs/commands/docker) \n        *   [file](http://moonrepo.dev/docs/commands/docker/file)\n        *   [prune](http://moonrepo.dev/docs/commands/docker/prune)\n        *   [scaffold](http://moonrepo.dev/docs/commands/docker/scaffold)\n        *   [setup](http://moonrepo.dev/docs/commands/docker/setup)\n\n    *   [exec](http://moonrepo.dev/docs/commands/exec)\n    *   [ext](http://moonrepo.dev/docs/commands/ext)\n    *   [extension](http://moonrepo.dev/docs/commands/extension) \n    *   [generate](http://moonrepo.dev/docs/commands/generate)\n    *   [hash](http://moonrepo.dev/docs/commands/hash)\n    *   [init](http://moonrepo.dev/docs/commands/init)\n    *   [mcp](http://moonrepo.dev/docs/commands/mcp)\n    *   [project](http://moonrepo.dev/docs/commands/project)\n    *   [projects](http://moonrepo.dev/docs/commands/projects)\n    *   [project-graph](http://moonrepo.dev/docs/commands/project-graph)\n    *   [query](http://moonrepo.dev/docs/commands/query) \n    *   [run](http://moonrepo.dev/docs/commands/run)\n    *   [setup](http://moonrepo.dev/docs/commands/setup)\n    *   [sync](http://moonrepo.dev/docs/commands/sync) \n    *   [task](http://moonrepo.dev/docs/commands/task)\n    *   [tasks](http://moonrepo.dev/docs/commands/tasks)\n    *   [task-graph](http://moonrepo.dev/docs/commands/task-graph)\n    *   [teardown](http://moonrepo.dev/docs/commands/teardown)\n    *   [template](http://moonrepo.dev/docs/commands/template)\n    *   [templates](http://moonrepo.dev/docs/commands/templates)\n    *   [toolchain](http://moonrepo.dev/docs/commands/toolchain) \n    *   [upgrade](http://moonrepo.dev/docs/commands/upgrade)\n\n*   [Migrations](http://moonrepo.dev/docs/commands/docker/prune#) \n*   [Cheat sheet](http://moonrepo.dev/docs/cheat-sheet)\n*   [Feature comparison](http://moonrepo.dev/docs/comparison)\n*   [Terminology](http://moonrepo.dev/docs/terminology)\n*   [FAQ](http://moonrepo.dev/docs/faq)\n*   [Changelog](https://github.com/moonrepo/moon/releases)\n\n1.   [Home](http://moonrepo.dev/)\n2.   [Commands](http://moonrepo.dev/docs/commands) \n3.   [docker](http://moonrepo.dev/docs/commands/docker) \n4.   [prune](http://moonrepo.dev/docs/commands/docker/prune) \n\nwarning\n\nDocumentation is currently for [moon v2](http://moonrepo.dev/blog/moon-v2-alpha) and latest proto. Documentation for moon v1 has been frozen and can be[found here](https://moonrepo.github.io/website-v1/).\n\nOn this page\n\ndocker prune\n============\n\nThe `moon docker prune` command will reduce the overall filesize of the Docker environment by installing production only dependencies for projects that were scaffolded, and removing any applicable extraneous files.\n\n`$ moon docker prune`\n\ninfo\n\nView the official [Docker usage guide](http://moonrepo.dev/docs/guides/docker) for a more in-depth example of how to utilize this command.\n\ncaution\n\nThis command _must be_ ran after [`moon docker scaffold`](http://moonrepo.dev/docs/commands/docker/scaffold) and is typically ran within a `Dockerfile`! The [`moon docker file`](http://moonrepo.dev/docs/commands/docker/file) command can be used to generate a `Dockerfile`.\n\n### Configuration[‚Äã](http://moonrepo.dev/docs/commands/docker/prune#configuration \"Direct link to Configuration\")\n\n*   [`docker.prune`](http://moonrepo.dev/docs/config/workspace#prune) in `.moon/workspace.yml`\n\n[Edit this page](https://github.com/moonrepo/moon/tree/master/website/docs/commands/docker/prune.mdx)\n\n[file](http://moonrepo.dev/docs/commands/docker/file)\n\n[scaffold](http://moonrepo.dev/docs/commands/docker/scaffold)\n\n*   [Configuration](http://moonrepo.dev/docs/commands/docker/prune#configuration)\n\nFooter\n------\n\n###### Learn\n\n*   [Docs](http://moonrepo.dev/docs)\n*   [Guides](http://moonrepo.dev/docs/guides/ci)\n*   [Blog](http://moonrepo.dev/blog)\n\n###### Ecosystem\n\n*   [Releases](https://github.com/moonrepo/moon/releases)\n*   [Shared configs](https://github.com/moonrepo/moon-configs)\n*   [Developer tools](https://github.com/moonrepo/dev)\n*   [Examples repository](https://github.com/moonrepo/examples)\n\n###### Support\n\n*   [GitHub](https://github.com/moonrepo)\n*   [Discord](https://discord.gg/qCh9MEynv2)\n*   [Twitter](https://twitter.com/tothemoonrepo)\n\n###### Contact us\n\nWant to learn more about moonrepo? Have questions?\n\nSubject \n\nNext\n\nBacked by\n\nCopyright ¬© 2026, moonrepo, Inc.\n\n[GitHub](https://github.com/moonrepo)[Discord](https://discord.gg/qCh9MEynv2)[Twitter](https://twitter.com/tothemoonrepo)\n\n## /docs/commands/docker/scaffold\n\nSource: https://moonrepo.dev/docs/commands/docker/scaffold\n\nThe `moon docker scaffold <...projects>` command creates multiple repository skeletons for use within `Dockerfile`s, to effectively take advantage of Docker's layer caching. It utilizes the [project graph](https://moonrepo.dev/docs/config/workspace#projects) to copy only critical files, like manifests, lockfiles, and configuration.\n\n`# Scaffold a skeleton to .moon/docker$ moon docker scaffold <project>`\n\ninfo\n\nView the official [Docker usage guide](https://moonrepo.dev/docs/guides/docker) for a more in-depth example of how to utilize this command.\n\n### Arguments[‚Äã](http://moonrepo.dev/docs/commands/docker/scaffold#arguments \"Direct link to Arguments\")\n\n*   `<...projects>` - List of project names or aliases to scaffold sources for, as defined in [`projects`](https://moonrepo.dev/docs/config/workspace#projects).\n\n### Configuration[‚Äã](http://moonrepo.dev/docs/commands/docker/scaffold#configuration \"Direct link to Configuration\")\n\n*   [`docker.scaffold`](https://moonrepo.dev/docs/config/workspace#scaffold) in `.moon/workspace.yml` (entire workspace)\n*   [`docker.scaffold`](https://moonrepo.dev/docs/config/project#scaffold) in `moon.yml` (per project)\n\nHow it works[‚Äã](http://moonrepo.dev/docs/commands/docker/scaffold#how-it-works \"Direct link to How it works\")\n-------------------------------------------------------------------------------------------------------------\n\nThis command may seem like magic, but it's relative simple thanks to moon's infrastructure and its project graph. When the command is ran, we generate 2 skeleton structures in `.moon/docker` (be sure to gitignore this). One for the workspace, and the other for sources.\n\nwarning\n\nBecause scaffolding uses the project graph, it requires all projects with a `package.json` to be [configured in moon](https://moonrepo.dev/docs/config/workspace#projects). Otherwise, moon will fail to copy all required files and builds may fail.\n\n### Workspace[‚Äã](http://moonrepo.dev/docs/commands/docker/scaffold#workspace \"Direct link to Workspace\")\n\nThe workspace skeleton mirrors the project folder structure of the repository 1:1, and only copies files required for dependencies to install. This is typically manifests (`package.json`), lockfiles (`yarn.lock`, etc), other critical configs, and `.moon` itself. This is necessary for package managers to install dependencies (otherwise they will fail), and for dependencies to be layer cached in Docker.\n\nAn example of this skeleton using Yarn may look like the following:\n\n`.moon/docker/workspace/‚îú‚îÄ‚îÄ .moon/‚îú‚îÄ‚îÄ .yarn/‚îú‚îÄ‚îÄ apps/‚îÇ   ‚îú‚îÄ‚îÄ client/‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ package.json‚îÇ   ‚îî‚îÄ‚îÄ server/‚îÇ       ‚îî‚îÄ‚îÄ package.json‚îú‚îÄ‚îÄ packages/‚îÇ   ‚îú‚îÄ‚îÄ foo/‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ package.json‚îÇ   ‚îú‚îÄ‚îÄ bar/‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ package.json‚îÇ   ‚îî‚îÄ‚îÄ baz/‚îÇ       ‚îî‚îÄ‚îÄ package.json‚îú‚îÄ‚îÄ .yarnrc.yml‚îú‚îÄ‚îÄ package.json‚îî‚îÄ‚îÄ yarn.lock`\n\n### Sources[‚Äã](http://moonrepo.dev/docs/commands/docker/scaffold#sources \"Direct link to Sources\")\n\nThe sources skeleton is not a 1:1 mirror of the repository, and instead is the source files of a project (passed as an argument to the command), and all of its dependencies. This allows [`moon run`](https://moonrepo.dev/docs/commands/run) and other commands to work within the `Dockerfile`, and avoid having to `COPY . .` the entire repository.\n\nUsing our example workspace above, our sources skeleton would look like the following, assuming our `client` project is passed as an argument, and this project depends on the `foo` and `baz` projects.\n\n`.moon/docker/sources/‚îú‚îÄ‚îÄ apps/‚îÇ   ‚îî‚îÄ‚îÄ client/|       ‚îú‚îÄ‚îÄ src/|       ‚îú‚îÄ‚îÄ tests/|       ‚îú‚îÄ‚îÄ public/|       ‚îú‚îÄ‚îÄ package.json|       ‚îú‚îÄ‚îÄ tsconfig.json‚îÇ       ‚îî‚îÄ‚îÄ (anything else)‚îî‚îÄ‚îÄ packages/    ‚îú‚îÄ‚îÄ foo/    ‚îÇ   ‚îú‚îÄ‚îÄ lib/    ‚îÇ   ‚îú‚îÄ‚îÄ src/    ‚îÇ   ‚îú‚îÄ‚îÄ package.json    ‚îÇ   ‚îú‚îÄ‚îÄ tsconfig.json    ‚îÇ   ‚îî‚îÄ‚îÄ (anything else)    ‚îî‚îÄ‚îÄ baz/        ‚îú‚îÄ‚îÄ lib/        ‚îú‚îÄ‚îÄ src/        ‚îú‚îÄ‚îÄ package.json        ‚îú‚îÄ‚îÄ tsconfig.json        ‚îî‚îÄ‚îÄ (anything else)`\n\n## /docs/commands/docker/setup\n\nSource: https://moonrepo.dev/docs/commands/docker/setup\n\ndocker setup | moonrepo\n===============\n\n[Skip to main content](http://moonrepo.dev/docs/commands/docker/setup#__docusaurus_skipToContent_fallback)\n\n[![Image 1: moon](http://moonrepo.dev/img/logo.svg)](http://moonrepo.dev/)\n\n[Products](http://moonrepo.dev/docs/commands/docker/setup#)\n*   [**moon**Build system for managing codebases](http://moonrepo.dev/moon)\n*   [**proto**Multi-language version manager](http://moonrepo.dev/proto)\n\n[Docs](http://moonrepo.dev/docs/commands/docker/setup#)\n*   [**moon**](http://moonrepo.dev/docs)\n*   [**proto**](http://moonrepo.dev/docs/proto)\n\n[Guides](http://moonrepo.dev/docs/guides/ci)[Blog](http://moonrepo.dev/blog)[GitHub](https://github.com/moonrepo)\n\nSearch\n\n*   [Introduction](http://moonrepo.dev/docs)\n*   [Install moon](http://moonrepo.dev/docs/install)\n*   [How it works](http://moonrepo.dev/docs/how-it-works) \n*   [Getting started](http://moonrepo.dev/docs/commands/docker/setup#) \n    *   [Setup workspace](http://moonrepo.dev/docs/setup-workspace)\n    *   [Create a project](http://moonrepo.dev/docs/create-project)\n    *   [Setup toolchain](http://moonrepo.dev/docs/setup-toolchain)\n    *   [Create a task](http://moonrepo.dev/docs/create-task)\n    *   [Run a task](http://moonrepo.dev/docs/run-task)\n    *   [Migrate to moon](http://moonrepo.dev/docs/migrate-to-moon)\n\n*   [Concepts](http://moonrepo.dev/docs/concepts) \n*   [Config files](http://moonrepo.dev/docs/config) \n*   [Editors](http://moonrepo.dev/docs/editors) \n*   [Commands](http://moonrepo.dev/docs/commands) \n    *   [Overview](http://moonrepo.dev/docs/commands/overview)\n    *   [action-graph](http://moonrepo.dev/docs/commands/action-graph)\n    *   [bin](http://moonrepo.dev/docs/commands/bin)\n    *   [check](http://moonrepo.dev/docs/commands/check)\n    *   [ci](http://moonrepo.dev/docs/commands/ci)\n    *   [clean](http://moonrepo.dev/docs/commands/clean)\n    *   [completions](http://moonrepo.dev/docs/commands/completions)\n    *   [docker](http://moonrepo.dev/docs/commands/docker) \n        *   [file](http://moonrepo.dev/docs/commands/docker/file)\n        *   [prune](http://moonrepo.dev/docs/commands/docker/prune)\n        *   [scaffold](http://moonrepo.dev/docs/commands/docker/scaffold)\n        *   [setup](http://moonrepo.dev/docs/commands/docker/setup)\n\n    *   [exec](http://moonrepo.dev/docs/commands/exec)\n    *   [ext](http://moonrepo.dev/docs/commands/ext)\n    *   [extension](http://moonrepo.dev/docs/commands/extension) \n    *   [generate](http://moonrepo.dev/docs/commands/generate)\n    *   [hash](http://moonrepo.dev/docs/commands/hash)\n    *   [init](http://moonrepo.dev/docs/commands/init)\n    *   [mcp](http://moonrepo.dev/docs/commands/mcp)\n    *   [project](http://moonrepo.dev/docs/commands/project)\n    *   [projects](http://moonrepo.dev/docs/commands/projects)\n    *   [project-graph](http://moonrepo.dev/docs/commands/project-graph)\n    *   [query](http://moonrepo.dev/docs/commands/query) \n    *   [run](http://moonrepo.dev/docs/commands/run)\n    *   [setup](http://moonrepo.dev/docs/commands/setup)\n    *   [sync](http://moonrepo.dev/docs/commands/sync) \n    *   [task](http://moonrepo.dev/docs/commands/task)\n    *   [tasks](http://moonrepo.dev/docs/commands/tasks)\n    *   [task-graph](http://moonrepo.dev/docs/commands/task-graph)\n    *   [teardown](http://moonrepo.dev/docs/commands/teardown)\n    *   [template](http://moonrepo.dev/docs/commands/template)\n    *   [templates](http://moonrepo.dev/docs/commands/templates)\n    *   [toolchain](http://moonrepo.dev/docs/commands/toolchain) \n    *   [upgrade](http://moonrepo.dev/docs/commands/upgrade)\n\n*   [Migrations](http://moonrepo.dev/docs/commands/docker/setup#) \n*   [Cheat sheet](http://moonrepo.dev/docs/cheat-sheet)\n*   [Feature comparison](http://moonrepo.dev/docs/comparison)\n*   [Terminology](http://moonrepo.dev/docs/terminology)\n*   [FAQ](http://moonrepo.dev/docs/faq)\n*   [Changelog](https://github.com/moonrepo/moon/releases)\n\n1.   [Home](http://moonrepo.dev/)\n2.   [Commands](http://moonrepo.dev/docs/commands) \n3.   [docker](http://moonrepo.dev/docs/commands/docker) \n4.   [setup](http://moonrepo.dev/docs/commands/docker/setup) \n\nwarning\n\nDocumentation is currently for [moon v2](http://moonrepo.dev/blog/moon-v2-alpha) and latest proto. Documentation for moon v1 has been frozen and can be[found here](https://moonrepo.github.io/website-v1/).\n\nOn this page\n\ndocker setup\n============\n\nThe `moon docker setup` command will efficiently install dependencies for focused projects. This is an all-in-one command for tool and dependency installations, and should replace `npm install` and other commands.\n\n`$ moon docker setup`\n\ninfo\n\nView the official [Docker usage guide](http://moonrepo.dev/docs/guides/docker) for a more in-depth example of how to utilize this command.\n\ncaution\n\nThis command _must be_ ran after [`moon docker scaffold`](http://moonrepo.dev/docs/commands/docker/scaffold) and is typically ran within a `Dockerfile`! The [`moon docker file`](http://moonrepo.dev/docs/commands/docker/file) command can be used to generate a `Dockerfile`.\n\n### Configuration[‚Äã](http://moonrepo.dev/docs/commands/docker/setup#configuration \"Direct link to Configuration\")\n\n*   [`*`](http://moonrepo.dev/docs/config/toolchain) in `.moon/toolchains.yml`\n\n[Edit this page](https://github.com/moonrepo/moon/tree/master/website/docs/commands/docker/setup.mdx)\n\n[scaffold](http://moonrepo.dev/docs/commands/docker/scaffold)\n\n[exec](http://moonrepo.dev/docs/commands/exec)\n\n*   [Configuration](http://moonrepo.dev/docs/commands/docker/setup#configuration)\n\nFooter\n------\n\n###### Learn\n\n*   [Docs](http://moonrepo.dev/docs)\n*   [Guides](http://moonrepo.dev/docs/guides/ci)\n*   [Blog](http://moonrepo.dev/blog)\n\n###### Ecosystem\n\n*   [Releases](https://github.com/moonrepo/moon/releases)\n*   [Shared configs](https://github.com/moonrepo/moon-configs)\n*   [Developer tools](https://github.com/moonrepo/dev)\n*   [Examples repository](https://github.com/moonrepo/examples)\n\n###### Support\n\n*   [GitHub](https://github.com/moonrepo)\n*   [Discord](https://discord.gg/qCh9MEynv2)\n*   [Twitter](https://twitter.com/tothemoonrepo)\n\n###### Contact us\n\nWant to learn more about moonrepo? Have questions?\n\nSubject \n\nNext\n\nBacked by\n\nCopyright ¬© 2026, moonrepo, Inc.\n\n[GitHub](https://github.com/moonrepo)[Discord](https://discord.gg/qCh9MEynv2)[Twitter](https://twitter.com/tothemoonrepo)\n\n## /docs/commands/exec\n\nSource: https://moonrepo.dev/docs/commands/exec\n\nexec | moonrepo\n===============\n\n[Skip to main content](http://moonrepo.dev/docs/commands/exec#__docusaurus_skipToContent_fallback)\n\n[![Image 1: moon](http://moonrepo.dev/img/logo.svg)](http://moonrepo.dev/)\n\n[Products](http://moonrepo.dev/docs/commands/exec#)\n*   [**moon**Build system for managing codebases](http://moonrepo.dev/moon)\n*   [**proto**Multi-language version manager](http://moonrepo.dev/proto)\n\n[Docs](http://moonrepo.dev/docs/commands/exec#)\n*   [**moon**](http://moonrepo.dev/docs)\n*   [**proto**](http://moonrepo.dev/docs/proto)\n\n[Guides](http://moonrepo.dev/docs/guides/ci)[Blog](http://moonrepo.dev/blog)[GitHub](https://github.com/moonrepo)\n\nSearch\n\n*   [Introduction](http://moonrepo.dev/docs)\n*   [Install moon](http://moonrepo.dev/docs/install)\n*   [How it works](http://moonrepo.dev/docs/how-it-works) \n*   [Getting started](http://moonrepo.dev/docs/commands/exec#) \n    *   [Setup workspace](http://moonrepo.dev/docs/setup-workspace)\n    *   [Create a project](http://moonrepo.dev/docs/create-project)\n    *   [Setup toolchain](http://moonrepo.dev/docs/setup-toolchain)\n    *   [Create a task](http://moonrepo.dev/docs/create-task)\n    *   [Run a task](http://moonrepo.dev/docs/run-task)\n    *   [Migrate to moon](http://moonrepo.dev/docs/migrate-to-moon)\n\n*   [Concepts](http://moonrepo.dev/docs/concepts) \n*   [Config files](http://moonrepo.dev/docs/config) \n*   [Editors](http://moonrepo.dev/docs/editors) \n*   [Commands](http://moonrepo.dev/docs/commands) \n    *   [Overview](http://moonrepo.dev/docs/commands/overview)\n    *   [action-graph](http://moonrepo.dev/docs/commands/action-graph)\n    *   [bin](http://moonrepo.dev/docs/commands/bin)\n    *   [check](http://moonrepo.dev/docs/commands/check)\n    *   [ci](http://moonrepo.dev/docs/commands/ci)\n    *   [clean](http://moonrepo.dev/docs/commands/clean)\n    *   [completions](http://moonrepo.dev/docs/commands/completions)\n    *   [docker](http://moonrepo.dev/docs/commands/docker) \n    *   [exec](http://moonrepo.dev/docs/commands/exec)\n    *   [ext](http://moonrepo.dev/docs/commands/ext)\n    *   [extension](http://moonrepo.dev/docs/commands/extension) \n    *   [generate](http://moonrepo.dev/docs/commands/generate)\n    *   [hash](http://moonrepo.dev/docs/commands/hash)\n    *   [init](http://moonrepo.dev/docs/commands/init)\n    *   [mcp](http://moonrepo.dev/docs/commands/mcp)\n    *   [project](http://moonrepo.dev/docs/commands/project)\n    *   [projects](http://moonrepo.dev/docs/commands/projects)\n    *   [project-graph](http://moonrepo.dev/docs/commands/project-graph)\n    *   [query](http://moonrepo.dev/docs/commands/query) \n    *   [run](http://moonrepo.dev/docs/commands/run)\n    *   [setup](http://moonrepo.dev/docs/commands/setup)\n    *   [sync](http://moonrepo.dev/docs/commands/sync) \n    *   [task](http://moonrepo.dev/docs/commands/task)\n    *   [tasks](http://moonrepo.dev/docs/commands/tasks)\n    *   [task-graph](http://moonrepo.dev/docs/commands/task-graph)\n    *   [teardown](http://moonrepo.dev/docs/commands/teardown)\n    *   [template](http://moonrepo.dev/docs/commands/template)\n    *   [templates](http://moonrepo.dev/docs/commands/templates)\n    *   [toolchain](http://moonrepo.dev/docs/commands/toolchain) \n    *   [upgrade](http://moonrepo.dev/docs/commands/upgrade)\n\n*   [Migrations](http://moonrepo.dev/docs/commands/exec#) \n*   [Cheat sheet](http://moonrepo.dev/docs/cheat-sheet)\n*   [Feature comparison](http://moonrepo.dev/docs/comparison)\n*   [Terminology](http://moonrepo.dev/docs/terminology)\n*   [FAQ](http://moonrepo.dev/docs/faq)\n*   [Changelog](https://github.com/moonrepo/moon/releases)\n\n1.   [Home](http://moonrepo.dev/)\n2.   [Commands](http://moonrepo.dev/docs/commands) \n3.   [exec](http://moonrepo.dev/docs/commands/exec) \n\nwarning\n\nDocumentation is currently for [moon v2](http://moonrepo.dev/blog/moon-v2-alpha) and latest proto. Documentation for moon v1 has been frozen and can be[found here](https://moonrepo.github.io/website-v1/).\n\nOn this page\n\nexec\n====\n\nv2.0.0\nThe `moon exec` (or `moon x`, or `moonx`) command is a low-level command for executing tasks in the action pipeline. It provides fine-grained control over how tasks are selected and executed, through command line options, making it ideal for custom workflows and advanced use cases.\n\nThe [`moon check`](http://moonrepo.dev/docs/commands/check), [`moon ci`](http://moonrepo.dev/docs/commands/ci), and [`moon run`](http://moonrepo.dev/docs/commands/run) commands are all built on top of `moon exec`, so be sure to check those out for more user-friendly abstractions!\n\n`# Run `lint` in project `app`$ moon exec app:lint$ moonx app:lint# Run `dev` in project `client` and `server`$ moon exec client:dev server:dev$ moonx client:dev server:dev# Run `test` in all projects$ moon exec :test$ moonx :test# Run `test` in all projects with tag `frontend`$ moon exec '#frontend:test'$ moonx '#frontend:test'# Run `format` in the default project$ moon exec format$ moonx format# Run `build` in projects matching the query$ moon exec :build --query \"language=javascript && projectLayer=library\"`\n\nArguments[‚Äã](http://moonrepo.dev/docs/commands/exec#arguments \"Direct link to Arguments\")\n-----------------------------------------------------------------------------------------\n\n*   `...<target>` - [Targets](http://moonrepo.dev/docs/concepts/target) or project relative tasks to run.\n*   `[-- <args>]` - Additional arguments to [pass to the underlying command](http://moonrepo.dev/docs/run-task#passing-arguments-to-the-underlying-command).\n\nOptions[‚Äã](http://moonrepo.dev/docs/commands/exec#options \"Direct link to Options\")\n-----------------------------------------------------------------------------------\n\n*   `-f`, `--force` - Force run and bypass cache, ignore changed files, and skip affected checks.\n*   `-i`, `--interactive` - Run the pipeline and tasks interactively.\n*   `-s`, `--summary [LEVEL]` - Print a summary of all actions that were ran in the pipeline.\n\n### Workflow[‚Äã](http://moonrepo.dev/docs/commands/exec#workflow \"Direct link to Workflow\")\n\n*   `--on-failure <ON>` - When a task fails, either bail the pipeline, or continue executing.\n*   `--only-ci-tasks` - Filter tasks to those that only run in CI.\n*   `--query <QUERY>` - Filter tasks based on the result of a query.\n*   `--no-actions` - Run the pipeline without sync and setup related actions.\n\n### Affected[‚Äã](http://moonrepo.dev/docs/commands/exec#affected \"Direct link to Affected\")\n\n*   `--affected [BY]` - Only run tasks if affected by changed files. Optionally accepts \"local\" or \"remote\".\n*   `--base <BASE>` - Base branch, commit, or revision to compare against.\n*   `--head <HEAD>` - Current branch, commit, or revision to compare with.\n*   `--status <STATUS>` - Filter changed files based on a changed status.\n*   `--stdin` - Accept changed files from stdin for affected checks.\n\n### Graph[‚Äã](http://moonrepo.dev/docs/commands/exec#graph \"Direct link to Graph\")\n\n*   `--downstream <DEPTH>`, `--dependents <DEPTH>` - Control the depth of downstream dependents.\n*   `--upstream <DEPTH>`, `--dependencies <DEPTH>` - Control the depth of upstream dependencies.\n\n### Parallelism[‚Äã](http://moonrepo.dev/docs/commands/exec#parallelism \"Direct link to Parallelism\")\n\n*   `--job <INDEX>` - Index of the current job (0 based).\n*   `--job-total <TOTAL>` - Total amount of jobs to run.\n\n[Edit this page](https://github.com/moonrepo/moon/tree/master/website/docs/commands/exec.mdx)\n\n[setup](http://moonrepo.dev/docs/commands/docker/setup)\n\n[ext](http://moonrepo.dev/docs/commands/ext)\n\n*   [Arguments](http://moonrepo.dev/docs/commands/exec#arguments)\n*   [Options](http://moonrepo.dev/docs/commands/exec#options)\n    *   [Workflow](http://moonrepo.dev/docs/commands/exec#workflow)\n    *   [Affected](http://moonrepo.dev/docs/commands/exec#affected)\n    *   [Graph](http://moonrepo.dev/docs/commands/exec#graph)\n    *   [Parallelism](http://moonrepo.dev/docs/commands/exec#parallelism)\n\nFooter\n------\n\n###### Learn\n\n*   [Docs](http://moonrepo.dev/docs)\n*   [Guides](http://moonrepo.dev/docs/guides/ci)\n*   [Blog](http://moonrepo.dev/blog)\n\n###### Ecosystem\n\n*   [Releases](https://github.com/moonrepo/moon/releases)\n*   [Shared configs](https://github.com/moonrepo/moon-configs)\n*   [Developer tools](https://github.com/moonrepo/dev)\n*   [Examples repository](https://github.com/moonrepo/examples)\n\n###### Support\n\n*   [GitHub](https://github.com/moonrepo)\n*   [Discord](https://discord.gg/qCh9MEynv2)\n*   [Twitter](https://twitter.com/tothemoonrepo)\n\n###### Contact us\n\nWant to learn more about moonrepo? Have questions?\n\nSubject \n\nNext\n\nBacked by\n\nCopyright ¬© 2026, moonrepo, Inc.\n\n[GitHub](https://github.com/moonrepo)[Discord](https://discord.gg/qCh9MEynv2)[Twitter](https://twitter.com/tothemoonrepo)\n\n## /docs/commands/ext\n\nSource: https://moonrepo.dev/docs/commands/ext\n\next | moonrepo\n===============\n\n[Skip to main content](http://moonrepo.dev/docs/commands/ext#__docusaurus_skipToContent_fallback)\n\n[![Image 1: moon](http://moonrepo.dev/img/logo.svg)](http://moonrepo.dev/)\n\n[Products](http://moonrepo.dev/docs/commands/ext#)\n*   [**moon**Build system for managing codebases](http://moonrepo.dev/moon)\n*   [**proto**Multi-language version manager](http://moonrepo.dev/proto)\n\n[Docs](http://moonrepo.dev/docs/commands/ext#)\n*   [**moon**](http://moonrepo.dev/docs)\n*   [**proto**](http://moonrepo.dev/docs/proto)\n\n[Guides](http://moonrepo.dev/docs/guides/ci)[Blog](http://moonrepo.dev/blog)[GitHub](https://github.com/moonrepo)\n\nSearch\n\n*   [Introduction](http://moonrepo.dev/docs)\n*   [Install moon](http://moonrepo.dev/docs/install)\n*   [How it works](http://moonrepo.dev/docs/how-it-works) \n*   [Getting started](http://moonrepo.dev/docs/commands/ext#) \n    *   [Setup workspace](http://moonrepo.dev/docs/setup-workspace)\n    *   [Create a project](http://moonrepo.dev/docs/create-project)\n    *   [Setup toolchain](http://moonrepo.dev/docs/setup-toolchain)\n    *   [Create a task](http://moonrepo.dev/docs/create-task)\n    *   [Run a task](http://moonrepo.dev/docs/run-task)\n    *   [Migrate to moon](http://moonrepo.dev/docs/migrate-to-moon)\n\n*   [Concepts](http://moonrepo.dev/docs/concepts) \n*   [Config files](http://moonrepo.dev/docs/config) \n*   [Editors](http://moonrepo.dev/docs/editors) \n*   [Commands](http://moonrepo.dev/docs/commands) \n    *   [Overview](http://moonrepo.dev/docs/commands/overview)\n    *   [action-graph](http://moonrepo.dev/docs/commands/action-graph)\n    *   [bin](http://moonrepo.dev/docs/commands/bin)\n    *   [check](http://moonrepo.dev/docs/commands/check)\n    *   [ci](http://moonrepo.dev/docs/commands/ci)\n    *   [clean](http://moonrepo.dev/docs/commands/clean)\n    *   [completions](http://moonrepo.dev/docs/commands/completions)\n    *   [docker](http://moonrepo.dev/docs/commands/docker) \n    *   [exec](http://moonrepo.dev/docs/commands/exec)\n    *   [ext](http://moonrepo.dev/docs/commands/ext)\n    *   [extension](http://moonrepo.dev/docs/commands/extension) \n    *   [generate](http://moonrepo.dev/docs/commands/generate)\n    *   [hash](http://moonrepo.dev/docs/commands/hash)\n    *   [init](http://moonrepo.dev/docs/commands/init)\n    *   [mcp](http://moonrepo.dev/docs/commands/mcp)\n    *   [project](http://moonrepo.dev/docs/commands/project)\n    *   [projects](http://moonrepo.dev/docs/commands/projects)\n    *   [project-graph](http://moonrepo.dev/docs/commands/project-graph)\n    *   [query](http://moonrepo.dev/docs/commands/query) \n    *   [run](http://moonrepo.dev/docs/commands/run)\n    *   [setup](http://moonrepo.dev/docs/commands/setup)\n    *   [sync](http://moonrepo.dev/docs/commands/sync) \n    *   [task](http://moonrepo.dev/docs/commands/task)\n    *   [tasks](http://moonrepo.dev/docs/commands/tasks)\n    *   [task-graph](http://moonrepo.dev/docs/commands/task-graph)\n    *   [teardown](http://moonrepo.dev/docs/commands/teardown)\n    *   [template](http://moonrepo.dev/docs/commands/template)\n    *   [templates](http://moonrepo.dev/docs/commands/templates)\n    *   [toolchain](http://moonrepo.dev/docs/commands/toolchain) \n    *   [upgrade](http://moonrepo.dev/docs/commands/upgrade)\n\n*   [Migrations](http://moonrepo.dev/docs/commands/ext#) \n*   [Cheat sheet](http://moonrepo.dev/docs/cheat-sheet)\n*   [Feature comparison](http://moonrepo.dev/docs/comparison)\n*   [Terminology](http://moonrepo.dev/docs/terminology)\n*   [FAQ](http://moonrepo.dev/docs/faq)\n*   [Changelog](https://github.com/moonrepo/moon/releases)\n\n1.   [Home](http://moonrepo.dev/)\n2.   [Commands](http://moonrepo.dev/docs/commands) \n3.   [ext](http://moonrepo.dev/docs/commands/ext) \n\nwarning\n\nDocumentation is currently for [moon v2](http://moonrepo.dev/blog/moon-v2-alpha) and latest proto. Documentation for moon v1 has been frozen and can be[found here](https://moonrepo.github.io/website-v1/).\n\nOn this page\n\next\n===\n\nv1.20.0\nThe `moon ext <id>` command will execute an extension (a WASM plugin) that has been configured with the [`extensions`](http://moonrepo.dev/docs/config/workspace#extensions) setting in [`.moon/workspace.yml`](http://moonrepo.dev/docs/config). View our official [extensions guide](http://moonrepo.dev/docs/guides/extensions) for more information.\n\n`$ moon ext download -- --url https://github.com/moonrepo/moon/archive/refs/tags/v1.19.3.zip`\n\nExtensions typically support command line arguments, which _must_ be passed after a `--` separator (as seen above). Any arguments before the separator will be passed to the `moon ext` command itself.\n\ncaution\n\nThis command requires an internet connection if the extension's `.wasm` file must be downloaded from a URL, and it hasn't been cached locally.\n\n### Arguments[‚Äã](http://moonrepo.dev/docs/commands/ext#arguments \"Direct link to Arguments\")\n\n*   `<id>` - Name of the extension to execute.\n*   `[-- <args>]` - Arguments to pass to the extension.\n\n### Configuration[‚Äã](http://moonrepo.dev/docs/commands/ext#configuration \"Direct link to Configuration\")\n\n*   [`extensions`](http://moonrepo.dev/docs/config/workspace#extensions) in `.moon/workspace.yml`\n\n[Edit this page](https://github.com/moonrepo/moon/tree/master/website/docs/commands/ext.mdx)\n\n[exec](http://moonrepo.dev/docs/commands/exec)\n\n[extension](http://moonrepo.dev/docs/commands/extension)\n\n*   [Arguments](http://moonrepo.dev/docs/commands/ext#arguments)\n*   [Configuration](http://moonrepo.dev/docs/commands/ext#configuration)\n\nFooter\n------\n\n###### Learn\n\n*   [Docs](http://moonrepo.dev/docs)\n*   [Guides](http://moonrepo.dev/docs/guides/ci)\n*   [Blog](http://moonrepo.dev/blog)\n\n###### Ecosystem\n\n*   [Releases](https://github.com/moonrepo/moon/releases)\n*   [Shared configs](https://github.com/moonrepo/moon-configs)\n*   [Developer tools](https://github.com/moonrepo/dev)\n*   [Examples repository](https://github.com/moonrepo/examples)\n\n###### Support\n\n*   [GitHub](https://github.com/moonrepo)\n*   [Discord](https://discord.gg/qCh9MEynv2)\n*   [Twitter](https://twitter.com/tothemoonrepo)\n\n###### Contact us\n\nWant to learn more about moonrepo? Have questions?\n\nSubject \n\nNext\n\nBacked by\n\nCopyright ¬© 2026, moonrepo, Inc.\n\n[GitHub](https://github.com/moonrepo)[Discord](https://discord.gg/qCh9MEynv2)[Twitter](https://twitter.com/tothemoonrepo)\n\n## /docs/commands/extension\n\nSource: https://moonrepo.dev/docs/commands/extension\n\nextension | moonrepo\n===============\n\n[Skip to main content](http://moonrepo.dev/docs/commands/extension#__docusaurus_skipToContent_fallback)\n\n[![Image 2: moon](http://moonrepo.dev/img/logo.svg)](http://moonrepo.dev/)\n\n[Products](http://moonrepo.dev/docs/commands/extension#)\n*   [**moon**Build system for managing codebases](http://moonrepo.dev/moon)\n*   [**proto**Multi-language version manager](http://moonrepo.dev/proto)\n\n[Docs](http://moonrepo.dev/docs/commands/extension#)\n*   [**moon**](http://moonrepo.dev/docs)\n*   [**proto**](http://moonrepo.dev/docs/proto)\n\n[Guides](http://moonrepo.dev/docs/guides/ci)[Blog](http://moonrepo.dev/blog)[GitHub](https://github.com/moonrepo)\n\nSearch\n\n*   [Introduction](http://moonrepo.dev/docs)\n*   [Install moon](http://moonrepo.dev/docs/install)\n*   [How it works](http://moonrepo.dev/docs/how-it-works) \n*   [Getting started](http://moonrepo.dev/docs/commands/extension#) \n    *   [Setup workspace](http://moonrepo.dev/docs/setup-workspace)\n    *   [Create a project](http://moonrepo.dev/docs/create-project)\n    *   [Setup toolchain](http://moonrepo.dev/docs/setup-toolchain)\n    *   [Create a task](http://moonrepo.dev/docs/create-task)\n    *   [Run a task](http://moonrepo.dev/docs/run-task)\n    *   [Migrate to moon](http://moonrepo.dev/docs/migrate-to-moon)\n\n*   [Concepts](http://moonrepo.dev/docs/concepts) \n*   [Config files](http://moonrepo.dev/docs/config) \n*   [Editors](http://moonrepo.dev/docs/editors) \n*   [Commands](http://moonrepo.dev/docs/commands) \n    *   [Overview](http://moonrepo.dev/docs/commands/overview)\n    *   [action-graph](http://moonrepo.dev/docs/commands/action-graph)\n    *   [bin](http://moonrepo.dev/docs/commands/bin)\n    *   [check](http://moonrepo.dev/docs/commands/check)\n    *   [ci](http://moonrepo.dev/docs/commands/ci)\n    *   [clean](http://moonrepo.dev/docs/commands/clean)\n    *   [completions](http://moonrepo.dev/docs/commands/completions)\n    *   [docker](http://moonrepo.dev/docs/commands/docker) \n    *   [exec](http://moonrepo.dev/docs/commands/exec)\n    *   [ext](http://moonrepo.dev/docs/commands/ext)\n    *   [extension](http://moonrepo.dev/docs/commands/extension) \n        *   [add](http://moonrepo.dev/docs/commands/extension/add)\n        *   [info](http://moonrepo.dev/docs/commands/extension/info)\n\n    *   [generate](http://moonrepo.dev/docs/commands/generate)\n    *   [hash](http://moonrepo.dev/docs/commands/hash)\n    *   [init](http://moonrepo.dev/docs/commands/init)\n    *   [mcp](http://moonrepo.dev/docs/commands/mcp)\n    *   [project](http://moonrepo.dev/docs/commands/project)\n    *   [projects](http://moonrepo.dev/docs/commands/projects)\n    *   [project-graph](http://moonrepo.dev/docs/commands/project-graph)\n    *   [query](http://moonrepo.dev/docs/commands/query) \n    *   [run](http://moonrepo.dev/docs/commands/run)\n    *   [setup](http://moonrepo.dev/docs/commands/setup)\n    *   [sync](http://moonrepo.dev/docs/commands/sync) \n    *   [task](http://moonrepo.dev/docs/commands/task)\n    *   [tasks](http://moonrepo.dev/docs/commands/tasks)\n    *   [task-graph](http://moonrepo.dev/docs/commands/task-graph)\n    *   [teardown](http://moonrepo.dev/docs/commands/teardown)\n    *   [template](http://moonrepo.dev/docs/commands/template)\n    *   [templates](http://moonrepo.dev/docs/commands/templates)\n    *   [toolchain](http://moonrepo.dev/docs/commands/toolchain) \n    *   [upgrade](http://moonrepo.dev/docs/commands/upgrade)\n\n*   [Migrations](http://moonrepo.dev/docs/commands/extension#) \n*   [Cheat sheet](http://moonrepo.dev/docs/cheat-sheet)\n*   [Feature comparison](http://moonrepo.dev/docs/comparison)\n*   [Terminology](http://moonrepo.dev/docs/terminology)\n*   [FAQ](http://moonrepo.dev/docs/faq)\n*   [Changelog](https://github.com/moonrepo/moon/releases)\n\n1.   [Home](http://moonrepo.dev/)\n2.   [Commands](http://moonrepo.dev/docs/commands) \n3.   [extension](http://moonrepo.dev/docs/commands/extension) \n\nwarning\n\nDocumentation is currently for [moon v2](http://moonrepo.dev/blog/moon-v2-alpha) and latest proto. Documentation for moon v1 has been frozen and can be[found here](https://moonrepo.github.io/website-v1/).\n\nextension\n=========\n\nManage extension plugins.\n\n[üìÑÔ∏èadd ------ The moon extension add [plugin] command will add a extension to the workspace by injecting a](http://moonrepo.dev/docs/commands/extension/add)[üìÑÔ∏èinfo ------- The moon extension info [plugin] command will display detailed information about a extension.](http://moonrepo.dev/docs/commands/extension/info)\n\n[ext](http://moonrepo.dev/docs/commands/ext)\n\n[add](http://moonrepo.dev/docs/commands/extension/add)\n\nFooter\n------\n\n###### Learn\n\n*   [Docs](http://moonrepo.dev/docs)\n*   [Guides](http://moonrepo.dev/docs/guides/ci)\n*   [Blog](http://moonrepo.dev/blog)\n\n###### Ecosystem\n\n*   [Releases](https://github.com/moonrepo/moon/releases)\n*   [Shared configs](https://github.com/moonrepo/moon-configs)\n*   [Developer tools](https://github.com/moonrepo/dev)\n*   [Examples repository](https://github.com/moonrepo/examples)\n\n###### Support\n\n*   [GitHub](https://github.com/moonrepo)\n*   [Discord](https://discord.gg/qCh9MEynv2)\n*   [Twitter](https://twitter.com/tothemoonrepo)\n\n###### Contact us\n\nWant to learn more about moonrepo? Have questions?\n\nSubject \n\nNext\n\nBacked by\n\nCopyright ¬© 2026, moonrepo, Inc.\n\n[GitHub](https://github.com/moonrepo)[Discord](https://discord.gg/qCh9MEynv2)[Twitter](https://twitter.com/tothemoonrepo)\n\n## /docs/commands/extension/add\n\nSource: https://moonrepo.dev/docs/commands/extension/add\n\nextension add | moonrepo\n===============\n\n[Skip to main content](http://moonrepo.dev/docs/commands/extension/add#__docusaurus_skipToContent_fallback)\n\n[![Image 1: moon](http://moonrepo.dev/img/logo.svg)](http://moonrepo.dev/)\n\n[Products](http://moonrepo.dev/docs/commands/extension/add#)\n*   [**moon**Build system for managing codebases](http://moonrepo.dev/moon)\n*   [**proto**Multi-language version manager](http://moonrepo.dev/proto)\n\n[Docs](http://moonrepo.dev/docs/commands/extension/add#)\n*   [**moon**](http://moonrepo.dev/docs)\n*   [**proto**](http://moonrepo.dev/docs/proto)\n\n[Guides](http://moonrepo.dev/docs/guides/ci)[Blog](http://moonrepo.dev/blog)[GitHub](https://github.com/moonrepo)\n\nSearch\n\n*   [Introduction](http://moonrepo.dev/docs)\n*   [Install moon](http://moonrepo.dev/docs/install)\n*   [How it works](http://moonrepo.dev/docs/how-it-works) \n*   [Getting started](http://moonrepo.dev/docs/commands/extension/add#) \n    *   [Setup workspace](http://moonrepo.dev/docs/setup-workspace)\n    *   [Create a project](http://moonrepo.dev/docs/create-project)\n    *   [Setup toolchain](http://moonrepo.dev/docs/setup-toolchain)\n    *   [Create a task](http://moonrepo.dev/docs/create-task)\n    *   [Run a task](http://moonrepo.dev/docs/run-task)\n    *   [Migrate to moon](http://moonrepo.dev/docs/migrate-to-moon)\n\n*   [Concepts](http://moonrepo.dev/docs/concepts) \n*   [Config files](http://moonrepo.dev/docs/config) \n*   [Editors](http://moonrepo.dev/docs/editors) \n*   [Commands](http://moonrepo.dev/docs/commands) \n    *   [Overview](http://moonrepo.dev/docs/commands/overview)\n    *   [action-graph](http://moonrepo.dev/docs/commands/action-graph)\n    *   [bin](http://moonrepo.dev/docs/commands/bin)\n    *   [check](http://moonrepo.dev/docs/commands/check)\n    *   [ci](http://moonrepo.dev/docs/commands/ci)\n    *   [clean](http://moonrepo.dev/docs/commands/clean)\n    *   [completions](http://moonrepo.dev/docs/commands/completions)\n    *   [docker](http://moonrepo.dev/docs/commands/docker) \n    *   [exec](http://moonrepo.dev/docs/commands/exec)\n    *   [ext](http://moonrepo.dev/docs/commands/ext)\n    *   [extension](http://moonrepo.dev/docs/commands/extension) \n        *   [add](http://moonrepo.dev/docs/commands/extension/add)\n        *   [info](http://moonrepo.dev/docs/commands/extension/info)\n\n    *   [generate](http://moonrepo.dev/docs/commands/generate)\n    *   [hash](http://moonrepo.dev/docs/commands/hash)\n    *   [init](http://moonrepo.dev/docs/commands/init)\n    *   [mcp](http://moonrepo.dev/docs/commands/mcp)\n    *   [project](http://moonrepo.dev/docs/commands/project)\n    *   [projects](http://moonrepo.dev/docs/commands/projects)\n    *   [project-graph](http://moonrepo.dev/docs/commands/project-graph)\n    *   [query](http://moonrepo.dev/docs/commands/query) \n    *   [run](http://moonrepo.dev/docs/commands/run)\n    *   [setup](http://moonrepo.dev/docs/commands/setup)\n    *   [sync](http://moonrepo.dev/docs/commands/sync) \n    *   [task](http://moonrepo.dev/docs/commands/task)\n    *   [tasks](http://moonrepo.dev/docs/commands/tasks)\n    *   [task-graph](http://moonrepo.dev/docs/commands/task-graph)\n    *   [teardown](http://moonrepo.dev/docs/commands/teardown)\n    *   [template](http://moonrepo.dev/docs/commands/template)\n    *   [templates](http://moonrepo.dev/docs/commands/templates)\n    *   [toolchain](http://moonrepo.dev/docs/commands/toolchain) \n    *   [upgrade](http://moonrepo.dev/docs/commands/upgrade)\n\n*   [Migrations](http://moonrepo.dev/docs/commands/extension/add#) \n*   [Cheat sheet](http://moonrepo.dev/docs/cheat-sheet)\n*   [Feature comparison](http://moonrepo.dev/docs/comparison)\n*   [Terminology](http://moonrepo.dev/docs/terminology)\n*   [FAQ](http://moonrepo.dev/docs/faq)\n*   [Changelog](https://github.com/moonrepo/moon/releases)\n\n1.   [Home](http://moonrepo.dev/)\n2.   [Commands](http://moonrepo.dev/docs/commands) \n3.   [extension](http://moonrepo.dev/docs/commands/extension) \n4.   [add](http://moonrepo.dev/docs/commands/extension/add) \n\nwarning\n\nDocumentation is currently for [moon v2](http://moonrepo.dev/blog/moon-v2-alpha) and latest proto. Documentation for moon v1 has been frozen and can be[found here](https://moonrepo.github.io/website-v1/).\n\nOn this page\n\nextension add\n=============\n\nv2.0.0\nThe `moon extension add <id> [plugin]` command will add a extension to the workspace by injecting a configuration block into `.moon/extensions.yml`. To do this, the command will download the WASM plugin, extract information, and call initialize functions.\n\nFor built-in extensions, the [plugin locator](http://moonrepo.dev/docs/guides/wasm-plugins#configuring-plugin-locations) argument is optional, and will be derived from the identifier.\n\n`$ moon extension add download`\n\nFor third-party extensions, the [plugin locator](http://moonrepo.dev/docs/guides/wasm-plugins#configuring-plugin-locations) argument is required, and must point to the WASM plugin.\n\n`$ moon extension add custom https://example.com/path/to/plugin.wasm`\n\n### Arguments[‚Äã](http://moonrepo.dev/docs/commands/extension/add#arguments \"Direct link to Arguments\")\n\n*   `<id>` - ID of the extension to use.\n*   `[plugin]` - Optional [plugin locator](http://moonrepo.dev/docs/guides/wasm-plugins#configuring-plugin-locations) for third-party extensions.\n\n### Options[‚Äã](http://moonrepo.dev/docs/commands/extension/add#options \"Direct link to Options\")\n\n*   `--minimal` - Generate minimal configurations and sane defaults.\n*   `--yes` - Skip all prompts and enables tools based on file detection.\n\n[Edit this page](https://github.com/moonrepo/moon/tree/master/website/docs/commands/extension/add.mdx)\n\n[extension](http://moonrepo.dev/docs/commands/extension)\n\n[info](http://moonrepo.dev/docs/commands/extension/info)\n\n*   [Arguments](http://moonrepo.dev/docs/commands/extension/add#arguments)\n*   [Options](http://moonrepo.dev/docs/commands/extension/add#options)\n\nFooter\n------\n\n###### Learn\n\n*   [Docs](http://moonrepo.dev/docs)\n*   [Guides](http://moonrepo.dev/docs/guides/ci)\n*   [Blog](http://moonrepo.dev/blog)\n\n###### Ecosystem\n\n*   [Releases](https://github.com/moonrepo/moon/releases)\n*   [Shared configs](https://github.com/moonrepo/moon-configs)\n*   [Developer tools](https://github.com/moonrepo/dev)\n*   [Examples repository](https://github.com/moonrepo/examples)\n\n###### Support\n\n*   [GitHub](https://github.com/moonrepo)\n*   [Discord](https://discord.gg/qCh9MEynv2)\n*   [Twitter](https://twitter.com/tothemoonrepo)\n\n###### Contact us\n\nWant to learn more about moonrepo? Have questions?\n\nSubject \n\nNext\n\nBacked by\n\nCopyright ¬© 2026, moonrepo, Inc.\n\n[GitHub](https://github.com/moonrepo)[Discord](https://discord.gg/qCh9MEynv2)[Twitter](https://twitter.com/tothemoonrepo)\n\n## /docs/commands/extension/info\n\nSource: https://moonrepo.dev/docs/commands/extension/info\n\nextension info | moonrepo\n===============\n\n[Skip to main content](http://moonrepo.dev/docs/commands/extension/info#__docusaurus_skipToContent_fallback)\n\n[![Image 1: moon](http://moonrepo.dev/img/logo.svg)](http://moonrepo.dev/)\n\n[Products](http://moonrepo.dev/docs/commands/extension/info#)\n*   [**moon**Build system for managing codebases](http://moonrepo.dev/moon)\n*   [**proto**Multi-language version manager](http://moonrepo.dev/proto)\n\n[Docs](http://moonrepo.dev/docs/commands/extension/info#)\n*   [**moon**](http://moonrepo.dev/docs)\n*   [**proto**](http://moonrepo.dev/docs/proto)\n\n[Guides](http://moonrepo.dev/docs/guides/ci)[Blog](http://moonrepo.dev/blog)[GitHub](https://github.com/moonrepo)\n\nSearch\n\n*   [Introduction](http://moonrepo.dev/docs)\n*   [Install moon](http://moonrepo.dev/docs/install)\n*   [How it works](http://moonrepo.dev/docs/how-it-works) \n*   [Getting started](http://moonrepo.dev/docs/commands/extension/info#) \n    *   [Setup workspace](http://moonrepo.dev/docs/setup-workspace)\n    *   [Create a project](http://moonrepo.dev/docs/create-project)\n    *   [Setup toolchain](http://moonrepo.dev/docs/setup-toolchain)\n    *   [Create a task](http://moonrepo.dev/docs/create-task)\n    *   [Run a task](http://moonrepo.dev/docs/run-task)\n    *   [Migrate to moon](http://moonrepo.dev/docs/migrate-to-moon)\n\n*   [Concepts](http://moonrepo.dev/docs/concepts) \n*   [Config files](http://moonrepo.dev/docs/config) \n*   [Editors](http://moonrepo.dev/docs/editors) \n*   [Commands](http://moonrepo.dev/docs/commands) \n    *   [Overview](http://moonrepo.dev/docs/commands/overview)\n    *   [action-graph](http://moonrepo.dev/docs/commands/action-graph)\n    *   [bin](http://moonrepo.dev/docs/commands/bin)\n    *   [check](http://moonrepo.dev/docs/commands/check)\n    *   [ci](http://moonrepo.dev/docs/commands/ci)\n    *   [clean](http://moonrepo.dev/docs/commands/clean)\n    *   [completions](http://moonrepo.dev/docs/commands/completions)\n    *   [docker](http://moonrepo.dev/docs/commands/docker) \n    *   [exec](http://moonrepo.dev/docs/commands/exec)\n    *   [ext](http://moonrepo.dev/docs/commands/ext)\n    *   [extension](http://moonrepo.dev/docs/commands/extension) \n        *   [add](http://moonrepo.dev/docs/commands/extension/add)\n        *   [info](http://moonrepo.dev/docs/commands/extension/info)\n\n    *   [generate](http://moonrepo.dev/docs/commands/generate)\n    *   [hash](http://moonrepo.dev/docs/commands/hash)\n    *   [init](http://moonrepo.dev/docs/commands/init)\n    *   [mcp](http://moonrepo.dev/docs/commands/mcp)\n    *   [project](http://moonrepo.dev/docs/commands/project)\n    *   [projects](http://moonrepo.dev/docs/commands/projects)\n    *   [project-graph](http://moonrepo.dev/docs/commands/project-graph)\n    *   [query](http://moonrepo.dev/docs/commands/query) \n    *   [run](http://moonrepo.dev/docs/commands/run)\n    *   [setup](http://moonrepo.dev/docs/commands/setup)\n    *   [sync](http://moonrepo.dev/docs/commands/sync) \n    *   [task](http://moonrepo.dev/docs/commands/task)\n    *   [tasks](http://moonrepo.dev/docs/commands/tasks)\n    *   [task-graph](http://moonrepo.dev/docs/commands/task-graph)\n    *   [teardown](http://moonrepo.dev/docs/commands/teardown)\n    *   [template](http://moonrepo.dev/docs/commands/template)\n    *   [templates](http://moonrepo.dev/docs/commands/templates)\n    *   [toolchain](http://moonrepo.dev/docs/commands/toolchain) \n    *   [upgrade](http://moonrepo.dev/docs/commands/upgrade)\n\n*   [Migrations](http://moonrepo.dev/docs/commands/extension/info#) \n*   [Cheat sheet](http://moonrepo.dev/docs/cheat-sheet)\n*   [Feature comparison](http://moonrepo.dev/docs/comparison)\n*   [Terminology](http://moonrepo.dev/docs/terminology)\n*   [FAQ](http://moonrepo.dev/docs/faq)\n*   [Changelog](https://github.com/moonrepo/moon/releases)\n\n1.   [Home](http://moonrepo.dev/)\n2.   [Commands](http://moonrepo.dev/docs/commands) \n3.   [extension](http://moonrepo.dev/docs/commands/extension) \n4.   [info](http://moonrepo.dev/docs/commands/extension/info) \n\nwarning\n\nDocumentation is currently for [moon v2](http://moonrepo.dev/blog/moon-v2-alpha) and latest proto. Documentation for moon v1 has been frozen and can be[found here](https://moonrepo.github.io/website-v1/).\n\nOn this page\n\nextension info\n==============\n\nv2.0.0\nThe `moon extension info <id> [plugin]` command will display detailed information about a extension. To do this, the command will download the WASM plugin, extract information, and call specific functions.\n\nFor built-in extensions, the [plugin locator][locator] argument is optional, and will be derived from the identifier.\n\n`$ moon extension info download`\n\nFor third-party extensions, the [plugin locator][locator] argument is required, and must point to the WASM plugin.\n\n`$ moon extension info custom https://example.com/path/to/plugin.wasm`\n\n### Arguments[‚Äã](http://moonrepo.dev/docs/commands/extension/info#arguments \"Direct link to Arguments\")\n\n*   `<id>` - ID of the extension to view.\n*   `[plugin]` - Optional [plugin locator][locator] for third-party extensions.\n\nExample output[‚Äã](http://moonrepo.dev/docs/commands/extension/info#example-output \"Direct link to Example output\")\n------------------------------------------------------------------------------------------------------------------\n\n`Extension ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  Download a file from a URL into the current working directory.  ID: download  Title: Download  Version: 1.0.0APIs ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚ö´Ô∏è define_extension_config  üü¢ execute_extension  ‚ö´Ô∏è extend_command  ‚ö´Ô∏è extend_project_graph  ‚ö´Ô∏è extend_task_command  ‚ö´Ô∏è extend_task_script  ‚ö´Ô∏è initialize_extension  üü¢ register_extension (required)  ‚ö´Ô∏è sync_project  ‚ö´Ô∏è sync_workspace`\n\n[Edit this page](https://github.com/moonrepo/moon/tree/master/website/docs/commands/extension/info.mdx)\n\n[add](http://moonrepo.dev/docs/commands/extension/add)\n\n[generate](http://moonrepo.dev/docs/commands/generate)\n\n*   [Arguments](http://moonrepo.dev/docs/commands/extension/info#arguments)\n*   [Example output](http://moonrepo.dev/docs/commands/extension/info#example-output)\n\nFooter\n------\n\n###### Learn\n\n*   [Docs](http://moonrepo.dev/docs)\n*   [Guides](http://moonrepo.dev/docs/guides/ci)\n*   [Blog](http://moonrepo.dev/blog)\n\n###### Ecosystem\n\n*   [Releases](https://github.com/moonrepo/moon/releases)\n*   [Shared configs](https://github.com/moonrepo/moon-configs)\n*   [Developer tools](https://github.com/moonrepo/dev)\n*   [Examples repository](https://github.com/moonrepo/examples)\n\n###### Support\n\n*   [GitHub](https://github.com/moonrepo)\n*   [Discord](https://discord.gg/qCh9MEynv2)\n*   [Twitter](https://twitter.com/tothemoonrepo)\n\n###### Contact us\n\nWant to learn more about moonrepo? Have questions?\n\nSubject \n\nNext\n\nBacked by\n\nCopyright ¬© 2026, moonrepo, Inc.\n\n[GitHub](https://github.com/moonrepo)[Discord](https://discord.gg/qCh9MEynv2)[Twitter](https://twitter.com/tothemoonrepo)\n\n## /docs/commands/generate\n\nSource: https://moonrepo.dev/docs/commands/generate\n\ngenerate | moonrepo\n===============\n\n[Skip to main content](http://moonrepo.dev/docs/commands/generate#__docusaurus_skipToContent_fallback)\n\n[![Image 1: moon](http://moonrepo.dev/img/logo.svg)](http://moonrepo.dev/)\n\n[Products](http://moonrepo.dev/docs/commands/generate#)\n*   [**moon**Build system for managing codebases](http://moonrepo.dev/moon)\n*   [**proto**Multi-language version manager](http://moonrepo.dev/proto)\n\n[Docs](http://moonrepo.dev/docs/commands/generate#)\n*   [**moon**](http://moonrepo.dev/docs)\n*   [**proto**](http://moonrepo.dev/docs/proto)\n\n[Guides](http://moonrepo.dev/docs/guides/ci)[Blog](http://moonrepo.dev/blog)[GitHub](https://github.com/moonrepo)\n\nSearch\n\n*   [Introduction](http://moonrepo.dev/docs)\n*   [Install moon](http://moonrepo.dev/docs/install)\n*   [How it works](http://moonrepo.dev/docs/how-it-works) \n*   [Getting started](http://moonrepo.dev/docs/commands/generate#) \n    *   [Setup workspace](http://moonrepo.dev/docs/setup-workspace)\n    *   [Create a project](http://moonrepo.dev/docs/create-project)\n    *   [Setup toolchain](http://moonrepo.dev/docs/setup-toolchain)\n    *   [Create a task](http://moonrepo.dev/docs/create-task)\n    *   [Run a task](http://moonrepo.dev/docs/run-task)\n    *   [Migrate to moon](http://moonrepo.dev/docs/migrate-to-moon)\n\n*   [Concepts](http://moonrepo.dev/docs/concepts) \n*   [Config files](http://moonrepo.dev/docs/config) \n*   [Editors](http://moonrepo.dev/docs/editors) \n*   [Commands](http://moonrepo.dev/docs/commands) \n    *   [Overview](http://moonrepo.dev/docs/commands/overview)\n    *   [action-graph](http://moonrepo.dev/docs/commands/action-graph)\n    *   [bin](http://moonrepo.dev/docs/commands/bin)\n    *   [check](http://moonrepo.dev/docs/commands/check)\n    *   [ci](http://moonrepo.dev/docs/commands/ci)\n    *   [clean](http://moonrepo.dev/docs/commands/clean)\n    *   [completions](http://moonrepo.dev/docs/commands/completions)\n    *   [docker](http://moonrepo.dev/docs/commands/docker) \n    *   [exec](http://moonrepo.dev/docs/commands/exec)\n    *   [ext](http://moonrepo.dev/docs/commands/ext)\n    *   [extension](http://moonrepo.dev/docs/commands/extension) \n    *   [generate](http://moonrepo.dev/docs/commands/generate)\n    *   [hash](http://moonrepo.dev/docs/commands/hash)\n    *   [init](http://moonrepo.dev/docs/commands/init)\n    *   [mcp](http://moonrepo.dev/docs/commands/mcp)\n    *   [project](http://moonrepo.dev/docs/commands/project)\n    *   [projects](http://moonrepo.dev/docs/commands/projects)\n    *   [project-graph](http://moonrepo.dev/docs/commands/project-graph)\n    *   [query](http://moonrepo.dev/docs/commands/query) \n    *   [run](http://moonrepo.dev/docs/commands/run)\n    *   [setup](http://moonrepo.dev/docs/commands/setup)\n    *   [sync](http://moonrepo.dev/docs/commands/sync) \n    *   [task](http://moonrepo.dev/docs/commands/task)\n    *   [tasks](http://moonrepo.dev/docs/commands/tasks)\n    *   [task-graph](http://moonrepo.dev/docs/commands/task-graph)\n    *   [teardown](http://moonrepo.dev/docs/commands/teardown)\n    *   [template](http://moonrepo.dev/docs/commands/template)\n    *   [templates](http://moonrepo.dev/docs/commands/templates)\n    *   [toolchain](http://moonrepo.dev/docs/commands/toolchain) \n    *   [upgrade](http://moonrepo.dev/docs/commands/upgrade)\n\n*   [Migrations](http://moonrepo.dev/docs/commands/generate#) \n*   [Cheat sheet](http://moonrepo.dev/docs/cheat-sheet)\n*   [Feature comparison](http://moonrepo.dev/docs/comparison)\n*   [Terminology](http://moonrepo.dev/docs/terminology)\n*   [FAQ](http://moonrepo.dev/docs/faq)\n*   [Changelog](https://github.com/moonrepo/moon/releases)\n\n1.   [Home](http://moonrepo.dev/)\n2.   [Commands](http://moonrepo.dev/docs/commands) \n3.   [generate](http://moonrepo.dev/docs/commands/generate) \n\nwarning\n\nDocumentation is currently for [moon v2](http://moonrepo.dev/blog/moon-v2-alpha) and latest proto. Documentation for moon v1 has been frozen and can be[found here](https://moonrepo.github.io/website-v1/).\n\nOn this page\n\ngenerate\n========\n\nThe `moon generate <id>` (or `moon g`) command will generate code (files and folders) from a pre-defined template of the same name, using an interactive series of prompts. Templates are located based on the [`generator.templates`](http://moonrepo.dev/docs/config/workspace#templates) setting.\n\n`# Generate code from a template$ moon generate npm-package# Generate code from a template to a target directory$ moon generate npm-package --to ./packages/example# Generate code while declaring custom variable values$ moon generate npm-package --to ./packages/example -- --name \"@company/example\"# Create a new template$ moon generate react-app --template`\n\n> View the official [code generation guide](http://moonrepo.dev/docs/guides/codegen) for a more in-depth example of how to utilize this command.\n\n### Arguments[‚Äã](http://moonrepo.dev/docs/commands/generate#arguments \"Direct link to Arguments\")\n\n*   `<id>` - ID of the template to generate.\n*   `[-- <vars>]` - Additional arguments to override default variable values.\n\n### Options[‚Äã](http://moonrepo.dev/docs/commands/generate#options \"Direct link to Options\")\n\n*   `--defaults` - Use the default value of all variables instead of prompting the user.\n*   `--dry-run` - Run entire generator process without writing files.\n*   `--force` - Force overwrite any existing files at the destination.\n*   `--template` - Create a new template with the provided name.\n*   `--to` - Destination to write files to, relative from the current working directory. If not defined, will be prompted during generation.\n\n### Configuration[‚Äã](http://moonrepo.dev/docs/commands/generate#configuration \"Direct link to Configuration\")\n\n*   [`generator`](http://moonrepo.dev/docs/config/workspace#generator) in `.moon/workspace.yml`\n\n[Edit this page](https://github.com/moonrepo/moon/tree/master/website/docs/commands/generate.mdx)\n\n[info](http://moonrepo.dev/docs/commands/extension/info)\n\n[hash](http://moonrepo.dev/docs/commands/hash)\n\n*   [Arguments](http://moonrepo.dev/docs/commands/generate#arguments)\n*   [Options](http://moonrepo.dev/docs/commands/generate#options)\n*   [Configuration](http://moonrepo.dev/docs/commands/generate#configuration)\n\nFooter\n------\n\n###### Learn\n\n*   [Docs](http://moonrepo.dev/docs)\n*   [Guides](http://moonrepo.dev/docs/guides/ci)\n*   [Blog](http://moonrepo.dev/blog)\n\n###### Ecosystem\n\n*   [Releases](https://github.com/moonrepo/moon/releases)\n*   [Shared configs](https://github.com/moonrepo/moon-configs)\n*   [Developer tools](https://github.com/moonrepo/dev)\n*   [Examples repository](https://github.com/moonrepo/examples)\n\n###### Support\n\n*   [GitHub](https://github.com/moonrepo)\n*   [Discord](https://discord.gg/qCh9MEynv2)\n*   [Twitter](https://twitter.com/tothemoonrepo)\n\n###### Contact us\n\nWant to learn more about moonrepo? Have questions?\n\nSubject \n\nNext\n\nBacked by\n\nCopyright ¬© 2026, moonrepo, Inc.\n\n[GitHub](https://github.com/moonrepo)[Discord](https://discord.gg/qCh9MEynv2)[Twitter](https://twitter.com/tothemoonrepo)\n\n## /docs/commands/hash\n\nSource: https://moonrepo.dev/docs/commands/hash\n\nhash | moonrepo\n===============\n\n[Skip to main content](http://moonrepo.dev/docs/commands/hash#__docusaurus_skipToContent_fallback)\n\n[![Image 1: moon](http://moonrepo.dev/img/logo.svg)](http://moonrepo.dev/)\n\n[Products](http://moonrepo.dev/docs/commands/hash#)\n*   [**moon**Build system for managing codebases](http://moonrepo.dev/moon)\n*   [**proto**Multi-language version manager](http://moonrepo.dev/proto)\n\n[Docs](http://moonrepo.dev/docs/commands/hash#)\n*   [**moon**](http://moonrepo.dev/docs)\n*   [**proto**](http://moonrepo.dev/docs/proto)\n\n[Guides](http://moonrepo.dev/docs/guides/ci)[Blog](http://moonrepo.dev/blog)[GitHub](https://github.com/moonrepo)\n\nSearch\n\n*   [Introduction](http://moonrepo.dev/docs)\n*   [Install moon](http://moonrepo.dev/docs/install)\n*   [How it works](http://moonrepo.dev/docs/how-it-works) \n*   [Getting started](http://moonrepo.dev/docs/commands/hash#) \n    *   [Setup workspace](http://moonrepo.dev/docs/setup-workspace)\n    *   [Create a project](http://moonrepo.dev/docs/create-project)\n    *   [Setup toolchain](http://moonrepo.dev/docs/setup-toolchain)\n    *   [Create a task](http://moonrepo.dev/docs/create-task)\n    *   [Run a task](http://moonrepo.dev/docs/run-task)\n    *   [Migrate to moon](http://moonrepo.dev/docs/migrate-to-moon)\n\n*   [Concepts](http://moonrepo.dev/docs/concepts) \n*   [Config files](http://moonrepo.dev/docs/config) \n*   [Editors](http://moonrepo.dev/docs/editors) \n*   [Commands](http://moonrepo.dev/docs/commands) \n    *   [Overview](http://moonrepo.dev/docs/commands/overview)\n    *   [action-graph](http://moonrepo.dev/docs/commands/action-graph)\n    *   [bin](http://moonrepo.dev/docs/commands/bin)\n    *   [check](http://moonrepo.dev/docs/commands/check)\n    *   [ci](http://moonrepo.dev/docs/commands/ci)\n    *   [clean](http://moonrepo.dev/docs/commands/clean)\n    *   [completions](http://moonrepo.dev/docs/commands/completions)\n    *   [docker](http://moonrepo.dev/docs/commands/docker) \n    *   [exec](http://moonrepo.dev/docs/commands/exec)\n    *   [ext](http://moonrepo.dev/docs/commands/ext)\n    *   [extension](http://moonrepo.dev/docs/commands/extension) \n    *   [generate](http://moonrepo.dev/docs/commands/generate)\n    *   [hash](http://moonrepo.dev/docs/commands/hash)\n    *   [init](http://moonrepo.dev/docs/commands/init)\n    *   [mcp](http://moonrepo.dev/docs/commands/mcp)\n    *   [project](http://moonrepo.dev/docs/commands/project)\n    *   [projects](http://moonrepo.dev/docs/commands/projects)\n    *   [project-graph](http://moonrepo.dev/docs/commands/project-graph)\n    *   [query](http://moonrepo.dev/docs/commands/query) \n    *   [run](http://moonrepo.dev/docs/commands/run)\n    *   [setup](http://moonrepo.dev/docs/commands/setup)\n    *   [sync](http://moonrepo.dev/docs/commands/sync) \n    *   [task](http://moonrepo.dev/docs/commands/task)\n    *   [tasks](http://moonrepo.dev/docs/commands/tasks)\n    *   [task-graph](http://moonrepo.dev/docs/commands/task-graph)\n    *   [teardown](http://moonrepo.dev/docs/commands/teardown)\n    *   [template](http://moonrepo.dev/docs/commands/template)\n    *   [templates](http://moonrepo.dev/docs/commands/templates)\n    *   [toolchain](http://moonrepo.dev/docs/commands/toolchain) \n    *   [upgrade](http://moonrepo.dev/docs/commands/upgrade)\n\n*   [Migrations](http://moonrepo.dev/docs/commands/hash#) \n*   [Cheat sheet](http://moonrepo.dev/docs/cheat-sheet)\n*   [Feature comparison](http://moonrepo.dev/docs/comparison)\n*   [Terminology](http://moonrepo.dev/docs/terminology)\n*   [FAQ](http://moonrepo.dev/docs/faq)\n*   [Changelog](https://github.com/moonrepo/moon/releases)\n\n1.   [Home](http://moonrepo.dev/)\n2.   [Commands](http://moonrepo.dev/docs/commands) \n3.   [hash](http://moonrepo.dev/docs/commands/hash) \n\nwarning\n\nDocumentation is currently for [moon v2](http://moonrepo.dev/blog/moon-v2-alpha) and latest proto. Documentation for moon v1 has been frozen and can be[found here](https://moonrepo.github.io/website-v1/).\n\nOn this page\n\nhash\n====\n\nv2.0.0\nUse the `moon hash` command to inspect the contents and sources of a generated hash, also known as the hash manifest. This is extremely useful in debugging task inputs.\n\n`$ moon hash 0b55b234f1018581c45b00241d7340dc648c63e639fbafdaf85a4cd7e718fdde# Query hash using short form$ moon hash 0b55b234`\n\nBy default, this will output the contents of the hash manifest (which is JSON), and the fully qualified resolved hash.\n\n`Hash: 0b55b234f1018581c45b00241d7340dc648c63e639fbafdaf85a4cd7e718fdde{  \"command\": \"build\",  \"args\": [\"./build\"]  // ...}`\n\nThe command can also be output raw JSON by passing the `--json` flag.\n\n### Comparing hashes[‚Äã](http://moonrepo.dev/docs/commands/hash#comparing-hashes \"Direct link to Comparing hashes\")\n\nThe command can also be used to compare two hashes by diffing their contents. Simply pass two hashes as arguments.\n\n`# Diff between 2 hashes$ moon hash 0b55b234f1018581c45b00241d7340dc648c63e639fbafdaf85a4cd7e718fdde 2388552fee5a02062d0ef402bdc7232f0a447458b058c80ce9c3d0d4d7cfe171# Diff between 2 hashes using short form$ moon hash 0b55b234 2388552f`\n\nBy default, this will output the contents of a hash file (which is JSON), highlighting the differences between the left and right hashes. Lines that match will be printed in white, while the left differences printed in green, and right differences printed in red. If you use `git diff`, this will feel familiar to you.\n\n`Left:  0b55b234f1018581c45b00241d7340dc648c63e639fbafdaf85a4cd7e718fddeRight: 2388552fee5a02062d0ef402bdc7232f0a447458b058c80ce9c3d0d4d7cfe171{\t\"command\": \"build\",\t\"args\": [+\t\t\"./dist\"-\t\t\"./build\"\t],\t...}`\n\nThe differences can also be output in JSON by passing the `--json` flag. The output has the following structure:\n\n`{\tleft: string,\tleft_hash: string,\tleft_diffs: string[],\tright: string,\tright_hash: string,\tright_diffs: string[],}`\n\n### Options[‚Äã](http://moonrepo.dev/docs/commands/hash#options \"Direct link to Options\")\n\n*   `--json` - Display the diff in JSON format.\n\n### Configuration[‚Äã](http://moonrepo.dev/docs/commands/hash#configuration \"Direct link to Configuration\")\n\n*   [`hasher`](http://moonrepo.dev/docs/config/workspace#hasher) in `.moon/workspace.yml`\n\n[Edit this page](https://github.com/moonrepo/moon/tree/master/website/docs/commands/hash.mdx)\n\n[generate](http://moonrepo.dev/docs/commands/generate)\n\n[init](http://moonrepo.dev/docs/commands/init)\n\n*   [Comparing hashes](http://moonrepo.dev/docs/commands/hash#comparing-hashes)\n*   [Options](http://moonrepo.dev/docs/commands/hash#options)\n*   [Configuration](http://moonrepo.dev/docs/commands/hash#configuration)\n\nFooter\n------\n\n###### Learn\n\n*   [Docs](http://moonrepo.dev/docs)\n*   [Guides](http://moonrepo.dev/docs/guides/ci)\n*   [Blog](http://moonrepo.dev/blog)\n\n###### Ecosystem\n\n*   [Releases](https://github.com/moonrepo/moon/releases)\n*   [Shared configs](https://github.com/moonrepo/moon-configs)\n*   [Developer tools](https://github.com/moonrepo/dev)\n*   [Examples repository](https://github.com/moonrepo/examples)\n\n###### Support\n\n*   [GitHub](https://github.com/moonrepo)\n*   [Discord](https://discord.gg/qCh9MEynv2)\n*   [Twitter](https://twitter.com/tothemoonrepo)\n\n###### Contact us\n\nWant to learn more about moonrepo? Have questions?\n\nSubject \n\nNext\n\nBacked by\n\nCopyright ¬© 2026, moonrepo, Inc.\n\n[GitHub](https://github.com/moonrepo)[Discord](https://discord.gg/qCh9MEynv2)[Twitter](https://twitter.com/tothemoonrepo)\n\n## /docs/commands/init\n\nSource: https://moonrepo.dev/docs/commands/init\n\n# init\n\nThe `moon init` command will initialize moon into a repository and scaffold necessary config files\nby creating a `.moon` folder.\n\n```\n$ moon init# In another directory$ moon init ./app\n```\n\n### Arguments\n\n- `[dest]` - Destination to initialize and scaffold into. Defaults to `.` (current working directory).\n\n### Options\n\n- `--force` - Overwrite existing config files if they exist.\n\n- `--minimal` - Generate minimal configurations and sane defaults.\n\n- `--yes` - Skip all prompts and enables tools based on file detection.\n\n## /docs/commands/mcp\n\nSource: https://moonrepo.dev/docs/commands/mcp\n\n# mcp\n\nv1.37.0\n\nThe `moon mcp` command will start an [MCP](https://modelcontextprotocol.io) server that listens for\nrequests from AI assistants. This allows for agentic workflows in your favorite editor.\n\n```\n$ moon mcp\n```\n\ninfo\n\nThis command should not be ran manually and instead should be integrated into your editor. View the\n[MCP guide](/docs/guides/mcp) for more information.\n\n## /docs/commands/overview\n\nSource: https://moonrepo.dev/docs/commands/overview\n\n# Overview\n\nThe following options are available for all moon commands.\n\n- `--cache ` - The mode for [cache operations](#caching).\n\n- `--color` - Force [colored output](#colors) for moon (not tasks).\n\n- `--concurrency`, `-c` - Maximum number of threads to utilize.\n\n- `--dump` - Dump a [trace profile](#profiling) to the working directory.\n\n- `--help` - Display the help menu for the current command.\n\n- `--log ` - The lowest [log level to output](#logging).\n\n- `--log-file ` - Write logs to the defined file.\n\n- `--quiet`, `-q` - Hide all non-important moon specific terminal output.\n\n- `--theme` - Terminal theme to write output in. v1.35.0\n\n- `--version` - Display the version of the CLI.\n\n## Caching\n\nWe provide a powerful [caching layer](/docs/concepts/cache), but sometimes you need to debug failing or\nbroken tasks, and this cache may get in the way. To circumvent this, we support the `--cache` global\noption, or the `MOON_CACHE` environment variable, both of which accept one of the following values.\n\n- `off` - Turn off caching entirely. Every task will run fresh, including dependency installs.\n\n- `read` - Read existing items from the cache, but do not write to them.\n\n- `read-write` (default) - Read and write items to the cache.\n\n- `write` - Do not read existing cache items, but write new items to the cache.\n\n```\n$ moon run app:build --cache off# Or$ MOON_CACHE=off moon run app:build\n```\n\n## Colors\n\nColored output is a complicated subject, with differing implementations and standards across tooling\nand operating systems. moon aims to normalize this as much as possible, by doing the following:\n\n- By default, moon colors are inherited from your terminal settings (`TERM` and `COLORTERM` environment variables).\n\n- Colors can be force enabled by passing the `--color` option (preferred), or `MOON_COLOR` or `FORCE_COLOR` environment variables.\n\n```\n$ moon app:build --color run# Or$ MOON_COLOR=2 moon run app:build\n```\n\nWhen forcing colors with `MOON_COLOR` or `FORCE_COLOR`, you may set it to one of the following\nnumerical values for the desired level of color support. This is automatically inferred if you use\n`--color`.\n\n- `0` - No colors\n\n- `1` - 16 colors (standard terminal colors)\n\n- `2` - 256 colors\n\n- `3` - 16 million colors (truecolor)\n\n### Themesv1.35.0\n\nBy default, moon assumes a dark themed terminal is being used, and will output colors accordingly.\nHowever, if you use a light theme, these colors are hard to read. To mitigate this, we support\nchanging the theme with the `--theme` global option, or the `MOON_THEME` environment variable.\n\n```\n$ moon run app:build --theme light# Or$ MOON_THEME=light moon run app:build\n```\n\n### Piped output\n\nWhen tasks (child processes) are piped, colors and ANSI escape sequences are lost, since the target\nis not a TTY and we do not implement a PTY. This is a common pattern this is quite annoying.\nHowever, many tools and CLIs support a `--color` option to work around this limitation and to always\nforce colors, even when not a TTY.\n\nTo mitigate this problem as a whole, and to avoid requiring `--color` for every task, moon supports\nthe [`pipeline.inheritColorsForPipedTasks`](/docs/config/workspace#inheritcolorsforpipedtasks)\nconfiguration setting. When enabled, all piped child processes will inherit the color settings of\nthe currently running terminal.\n\n## Concurrency\n\nThe `--concurrency` option or `MOON_CONCURRENCY` environment variable can be used to control the\nmaximum amount of threads to utilize in our thread pool. If not defined, defaults to the number of\noperating system cores.\n\n```\n$ moon run app:build --concurrency 1# Or$ MOON_CONCURRENCY=1 moon run app:build\n```\n\n## Debugging\n\nAt minimum, most debugging can be done by passing [`--log trace`](#logging) on the command line and\nsifting through the logs. We also provide the following environment variables to toggle output.\n\n- `MOON_DEBUG_PROCESS_ENV` - By default moon hides the environment variables (except for `MOON_`) passed to processes to avoid leaking sensitive information. However, knowing what environment variables are passed around is helpful in debugging. Declare this variable to reveal the entire environment.\n\n- `MOON_DEBUG_PROCESS_INPUT` - By default moon truncates the stdin passed to processes to avoid thrashing the console with a large input string. However, knowing what input is passed around is helpful in debugging. Declare this variable to reveal the entire input.\n\n- `MOON_DEBUG_PROTO_INSTALL` - Debug the proto installation process.\n\n- `MOON_DEBUG_REMOTE` - Debug our remote caching implementation by including additional logging output, and printing internal connection errors.\n\n- `MOON_DEBUG_WASM` - Debug our WASM plugins by including additional logging output, and optionally dumping memory/core profiles.\n\n## Logging\n\nBy default, moon aims to output as little as possible, as we want to preserve the original output of\nthe command's being ran, excluding warnings and errors. This is managed through log levels, which\ncan be defined with the `--log` global option, or the `MOON_LOG` environment variable. The following\nlevels are supported, in priority order.\n\n- `off` - Turn off logging entirely.\n\n- `error` - Only show error logs.\n\n- `warn` - Only show warning logs and above.\n\n- `info` (default) - Only show info logs and above.\n\n- `debug` - Only show debug logs and above.\n\n- `trace` - Show all logs, including network requests and child processes.\n\n- `verbose` - Like `trace` but also includes span information. v1.35.0\n\n```\n$ moon run app:build --log trace# Or$ MOON_LOG=trace moon run app:build\n```\n\n### Writing logs to a file\n\nmoon can dump the logs from a command to a file using the `--logFile` option, or the `MOON_LOG_FILE`\nenvironment variable. The dumped logs will respect the `--log` option and filter the logs piped to\nthe output file.\n\n```\n$ moon run app:build --logFile=output.log# Or$ MOON_LOG_FILE=output.log moon run app:build\n```\n\n## Profilingv1.26.0\n\nWhen the `--dump` option or `MOON_DUMP` environment variable is set, moon will generate a trace\nprofile and dump it to the current working directory. This profile can be opened with Chrome (via\n`chrome://tracing`) or [Perfetto](https://ui.perfetto.dev/).\n\nThis profile will display many of the operations within moon as a flame chart, allowing you to\ninspect and debug slow operations.\n\n## /docs/commands/project\n\nSource: https://moonrepo.dev/docs/commands/project\n\n# project\n\nThe `moon project [id]` (or `moon p`) command will display all available information about a project\nthat has been configured and exists within the graph. If a project does not exist, the program will\nreturn with a 1 exit code.\n\n```\n$ moon project web\n```\n\n### Arguments\n\n- `[id]` - ID or alias of a project, as defined in [`projects`](/docs/config/workspace#projects).\n\n### Options\n\n- `--json` - Print the project and its configuration as JSON.\n\n- `--no-tasks` - Do not list tasks for the project.\n\n## Example output\n\nThe following output is an example of what this command prints, using our very own\n`@moonrepo/runtime` package.\n\n```\nRUNTIMEProject: runtimeAlias: @moonrepo/runtimeSource: packages/runtimeRoot: ~/Projects/moon/packages/runtimeToolchain: nodeLanguage: typescriptStack: unknownType: libraryDEPENDS ON  - types (implicit, production)INHERITS FROM  - .moon/tasks/node.ymlTASKSbuild:  ‚Ä∫ packemon build --addFiles --addExports --declarationformat:  ‚Ä∫ prettier --check --config ../../prettier.config.js --ignore-path ../../.prettierignore --no-error-on-unmatched-pattern .lint:  ‚Ä∫ eslint --cache --cache-location ./.eslintcache --color --ext .js,.ts,.tsx --ignore-path ../../.eslintignore --exit-on-fatal-error --no-error-on-unmatched-pattern --report-unused-disable-directives .lint-fix:  ‚Ä∫ eslint --cache --cache-location ./.eslintcache --color --ext .js,.ts,.tsx --ignore-path ../../.eslintignore --exit-on-fatal-error --no-error-on-unmatched-pattern --report-unused-disable-directives . --fixtest:  ‚Ä∫ jest --cache --color --preset jest-preset-moon --passWithNoTeststypecheck:  ‚Ä∫ tsc --buildFILE GROUPSconfigs:  - packages/runtime/*.{js,json}sources:  - packages/runtime/src/**/*  - packages/runtime/types/**/*tests:  - packages/runtime/tests/**/*\n```\n\n### Configuration\n\n- [`projects`](/docs/config/workspace#projects) in `.moon/workspace.yml`\n\n- [`project`](/docs/config/project#project) in `moon.yml`\n\n## /docs/commands/project-graph\n\nSource: https://moonrepo.dev/docs/commands/project-graph\n\n# project-graph\n\nThe `moon project-graph [id]` (or `moon pg`) command will generate and serve a visual graph of all\nconfigured projects as nodes, with dependencies between as edges, and can also output the graph in\n[Graphviz DOT format](https://graphviz.org/doc/info/lang.html).\n\n```\n# Run the visualizer locally$ moon project-graph# Export to DOT format$ moon project-graph --dot > graph.dot\n```\n\nA project name can be passed to focus the graph to only that project and its dependencies. For\nexample, `moon project-graph app`.\n\n### Arguments\n\n- `[id]` - Optional ID or alias of a project to focus, as defined in [`projects`](/docs/config/workspace#projects).\n\n### Options\n\n- `--dependents` - Include direct dependents of the focused project.\n\n- `--dot` - Print the graph in DOT format.\n\n- `--host` - The host address. Defaults to `127.0.0.1`. v1.36.0\n\n- `--json` - Print the graph in JSON format.\n\n- `--port` - The port to bind to. Defaults to a random port. v1.36.0\n\n### Configuration\n\n- [`projects`](/docs/config/workspace#projects) in `.moon/workspace.yml`\n\n## Example output\n\nThe following output is an example of the graph in DOT format.\n\n```\ndigraph {    0 [ label=\"(workspace)\" style=filled, shape=circle, fillcolor=black, fontcolor=white]    1 [ label=\"runtime\" style=filled, shape=circle, fillcolor=gray, fontcolor=black]    2 [ label=\"website\" style=filled, shape=circle, fillcolor=gray, fontcolor=black]    0 -> 1 [ arrowhead=none]    0 -> 2 [ arrowhead=none]}\n```\n\n## /docs/commands/projects\n\nSource: https://moonrepo.dev/docs/commands/projects\n\n# projects\n\nv2.0.0\n\nThe `moon projects` command will list all projects configured in the workspace as a table of\ninformation.\n\n```\n‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ‚îÇProject          Source                    Stack             Layer             Toolchains                                Description                                                   ‚îÇ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ‚îÇtypes            packages/types            frontend          library           javascript, node, typescript, yarn                                                                      ‚îÇ‚îÇwebsite          website                   frontend          application       javascript, node, typescript, yarn        A static website powered by Docusaurus.                       ‚îÇ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\n```\n\ninfo\n\nUse [`moon query projects`](/docs/commands/query/projects) for advanced querying and filtering of projects.\n\n### Options\n\n- `--json` - Print the projects as JSON.\n\n## /docs/commands/query\n\nSource: https://moonrepo.dev/docs/commands/query\n\n- [Home](/)\n- [Commands](/docs/commands)\n- [query](/docs/commands/query)\n\nwarning\n\nDocumentation is currently for [moon v2](/blog/moon-v2-alpha) and latest proto. Documentation for moon v1 has been frozen and can be [found here](https://moonrepo.github.io/website-v1/).\n\n# query\n\nQuery information about moon, its projects, their tasks, the environment, the pipeline, and many other aspects of the workspace.\n\n[üìÑÔ∏è affectedUse the moon query affected sub-command to query for all affected projects and tasks based on the](/docs/commands/query/affected)\n\n[üìÑÔ∏è changed-filesUse the moon query changed-files sub-command to query for a list of changed files (added,](/docs/commands/query/changed-files)\n\n[üìÑÔ∏è projectsUse the moon query projects sub-command to query information about all projects in the project](/docs/commands/query/projects)\n\n[üìÑÔ∏è tasksUse the moon query tasks sub-command to query task information for all projects in the project](/docs/commands/query/tasks)\n\n[project-graph](/docs/commands/project-graph)\n\n[affected](/docs/commands/query/affected)\n\n## /docs/commands/query/affected\n\nSource: https://moonrepo.dev/docs/commands/query/affected\n\n# query affected\n\nv2.0.0\n\nUse the `moon query affected` sub-command to query for all affected projects and tasks based on the\nstate of the workspace and VCS.\n\n```\n# Return affected$ moon query affected# Return affected including dependency relationships$ moon query affected --upstream deep\n```\n\nThis will output a map of projects and tasks as JSON. The output has the following structure:\n\n```\n{\tprojects: Record,\ttasks: Record,}\n```\n\n### Options\n\n- `--downstream` - Include downstream dependents. Supports \"none\" (default), \"direct\", \"deep\".\n\n- `--upstream` - Include upstream dependencies. Supports \"none\", \"direct\", \"deep\" (default).\n\n## /docs/commands/query/changed-files\n\nSource: https://moonrepo.dev/docs/commands/query/changed-files\n\n# query changed-files\n\nUse the `moon query changed-files` sub-command to query for a list of changed files (added,\nmodified, deleted, etc) using the current VCS state. These are the same queries that\n[`moon ci`](/docs/commands/ci) and [`moon run`](/docs/commands/run) use under the hood.\n\nTouches files are determined using the following logic:\n\n- If `--defaultBranch` is provided, and the current branch is the [`vcs.defaultBranch`](/docs/config/workspace#defaultbranch), then compare against the previous revision of the default branch (`HEAD~1`). This is what [continuous integration](/docs/guides/ci) uses.\n\n- If `--local` is provided, changed files are based on your local index only (`git status`).\n\n- Otherwise, then compare the defined base (`--base`) against head (`--head`).\n\n```\n# Return all files$ moon query changed-files# Return deleted files$ moon query changed-files --status deleted# Return all files between 2 revisions$ moon query changed-files --base  --head\n```\n\nThis will output a list of workspace relative files as JSON. The output has the following structure:\n\n```\n{\tfiles: string[],\toptions: QueryOptions,}\n```\n\n### Options\n\n- `--default-branch` - When on the default branch, compare against the previous revision.\n\n- `--base ` - Base branch, commit, or revision to compare against. Defaults to [`vcs.defaultBranch`](/docs/config/workspace#defaultbranch).\n\n- `--head ` - Current branch, commit, or revision to compare with. Defaults to `HEAD`.\n\n- `--local` - Gather files from the local state instead of remote.\n\n- `--remote` - Gather files from the remote state instead of local.\n\n- `--status ` - Filter files based on a changed status. Can be passed multiple times. Types: `all` (default), `added`, `deleted`, `modified`, `staged`, `unstaged`, `untracked`\n\n### Configuration\n\n- [`vcs`](/docs/config/workspace#vcs) in `.moon/workspace.yml`\n\n## /docs/commands/query/projects\n\nSource: https://moonrepo.dev/docs/commands/query/projects\n\n# query projects\n\nUse the `moon query projects` sub-command to query information about all projects in the project\ngraph. The project list can be filtered by passing a [query statement](/docs/concepts/query-lang) as\nan argument, or by using [options](#options) arguments.\n\n```\n# Find all projects$ moon query projects# Find all projects with an id that matches \"react\"$ moon query projects --id react$ moon query projects \"project~react\"# Find all projects with a `lint` or `build` task$ moon query projects --tasks \"lint|build\"$ moon query projects \"task=[lint,build]\"\n```\n\nThis will output a list of projects as JSON. The output has the following structure:\n\n```\n{\tprojects: Project[],\toptions: QueryOptions,}\n```\n\n### Affected projects\n\nThis command can also be used to query for affected projects, based on the state of the VCS working\ntree. For advanced control, you can also pass the results of `moon query changed-files` to stdin.\n\n```\n# Find all affected projects$ moon query projects --affected# Find all affected projects using the results of another query$ moon query changed-files | moon query projects --affected\n```\n\n### Arguments\n\n- `[query]` - An optional [query statement](/docs/concepts/query-lang) to filter projects with. When provided, all [filter options](#filters) are ignored. v1.4.0\n\n### Options\n\n#### Affected\n\n- `--affected` - Filter projects that have been affected by touched files.\n\n- `--downstream` - Include downstream dependents of queried projects. Supports \"none\" (default), \"direct\", \"deep\". v1.29.0\n\n- `--upstream` - Include upstream dependencies of queried projects. Supports \"none\", \"direct\", \"deep\" (default). v1.29.0\n\n#### Filters\n\nAll option values are case-insensitive regex patterns.\n\n- `--alias ` - Filter projects that match this alias.\n\n- `--id ` - Filter projects that match this ID/name.\n\n- `--language ` - Filter projects of this programming language.\n\n- `--layer ` - Filter project of this layer.\n\n- `--source ` - Filter projects that match this source path.\n\n- `--stack ` - Filter projects of the tech stack.\n\n- `--tags ` - Filter projects that have the following tags.\n\n- `--tasks ` - Filter projects that have the following tasks.\n\n### Configuration\n\n- [`projects`](/docs/config/workspace#projects) in `.moon/workspace.yml`\n\n## /docs/commands/query/tasks\n\nSource: https://moonrepo.dev/docs/commands/query/tasks\n\n# query tasks\n\nUse the `moon query tasks` sub-command to query task information for all projects in the project\ngraph. The tasks list can be filtered by passing a [query statement](/docs/concepts/query-lang) as\nan argument, or by using [options](#options) arguments.\n\n```\n# Find all tasks grouped by project$ moon query tasks# Find all tasks from projects with an id that matches \"react\"$ moon query tasks --id react$ moon query tasks \"task~react\"\n```\n\nThis will output a list of projects as JSON. The output has the following structure:\n\n```\n{\ttasks: Record>,\toptions: QueryOptions,}\n```\n\n### Arguments\n\n- `[query]` - An optional [query statement](/docs/concepts/query-lang) to filter projects with. When provided, all [filter options](#filters) are ignored. v1.4.0\n\n### Options\n\n#### Affected\n\n- `--affected` - Filter tasks that have been affected by touched files.\n\n- `--downstream` - Include downstream dependents of queried tasks. Supports \"none\" (default), \"direct\", \"deep\". v1.30.0\n\n- `--upstream` - Include upstream dependencies of queried tasks. Supports \"none\", \"direct\", \"deep\" (default). v1.30.0\n\n#### Filtersv1.30.0\n\nAll option values are case-insensitive regex patterns.\n\n- `--command ` - Filter tasks that match this command.\n\n- `--id ` - Filter tasks that match this ID.\n\n- `--project ` - Filter tasks that belong to this project.\n\n- `--script ` - Filter tasks that match this script.\n\n- `--toolchain ` - Filter tasks of this toolchain. v1.31.0\n\n- `--type ` - Filter tasks of this type.\n\n### Configuration\n\n- [`projects`](/docs/config/workspace#projects) in `.moon/workspace.yml`\n\n- [`tasks`](/docs/config/project#tasks) in `moon.yml`\n\n## /docs/commands/run\n\nSource: https://moonrepo.dev/docs/commands/run\n\n# run\n\nThe `moon run` (or `moon r`) command will run one or many [targets](/docs/concepts/target) and all of\nits dependencies in topological order. Each run will incrementally cache each task, improving speed\nand development times... over time. View the official [Run a task](/docs/run-task) and\n[Cheat sheet](/docs/cheat-sheet#tasks) articles for more information!\n\n```\n# Run `lint` in project `app`$ moon run app:lint# Run `dev` in project `client` and `server`$ moon run client:dev server:dev# Run `test` in all projects$ moon run :test# Run `test` in all projects with tag `frontend`$ moon run '#frontend:test'# Run `format` in default project$ moon run format# Run `build` in projects matching the query$ moon run :build --query \"language=javascript && projectLayer=library\"\n```\n\ninfo\n\nThe default behavior for `moon run` is to \"fail fast\", meaning that any failed task will immediately\nabort execution of the entire action graph. Use `moon exec --on-failure continue` for alternative\nbehavior.\n\n### Arguments\n\n- `...` - [Targets](/docs/concepts/target) or project relative tasks to run.\n\n- `[-- ]` - Additional arguments to [pass to the underlying command](/docs/run-task#passing-arguments-to-the-underlying-command).\n\n### Options\n\nInherits all options from [`moon exec`](/docs/commands/exec) except for `--on-failure`.\n\n### Configuration\n\n- [`projects`](/docs/config/workspace#projects) in `.moon/workspace.yml`\n\n- [`tasks`](/docs/config/tasks#tasks) in `.moon/tasks/all.yml`\n\n- [`tasks`](/docs/config/project#tasks) in `moon.yml`\n\n## /docs/commands/setup\n\nSource: https://moonrepo.dev/docs/commands/setup\n\n# setup\n\nThe `moon setup` command can be used to setup the developer and pipeline environments. It achieves\nthis by downloading and installing all configured tools into the toolchain.\n\n```\n$ moon setup\n```\n\ninfo\n\nThis command should rarely be used, as the environment is automatically setup when running other\ncommands, like detecting affected projects, running a task, or generating a build artifact.\n\n### Configuration\n\n- [`*`](/docs/config/toolchain) in `.moon/toolchains.yml`\n\n## /docs/commands/sync\n\nSource: https://moonrepo.dev/docs/commands/sync\n\n- [Home](/)\n- [Commands](/docs/commands)\n- [sync](/docs/commands/sync)\n\nwarning\n\nDocumentation is currently for [moon v2](/blog/moon-v2-alpha) and latest proto. Documentation for moon v1 has been frozen and can be [found here](https://moonrepo.github.io/website-v1/).\n\n# sync\n\nOperations for syncing the workspace to a healthy state.\n\n[üìÑÔ∏è code-ownersThe moon sync code-owners command will manually sync code owners, by aggregating all owners from](/docs/commands/sync/code-owners)\n\n[üìÑÔ∏è config-schemasThe moon sync config-schemas command will manually generate JSON schemas to .moon/cache/schemas](/docs/commands/sync/config-schemas)\n\n[üìÑÔ∏è projectsThe moon sync projects command will force sync all projects in the workspace to help achieve a](/docs/commands/sync/projects)\n\n[üìÑÔ∏è vcs-hooksThe moon sync vcs-hooks command will manually sync hooks for the configured](/docs/commands/sync/vcs-hooks)\n\n[setup](/docs/commands/setup)\n\n[code-owners](/docs/commands/sync/code-owners)\n\n## /docs/commands/sync/code-owners\n\nSource: https://moonrepo.dev/docs/commands/sync/code-owners\n\n# sync code-owners\n\nv1.8.0\n\nThe `moon sync code-owners` command will manually sync code owners, by aggregating all owners from\nprojects, and generating a single `CODEOWNERS` file. Refer to the official\n[code owners](/docs/guides/codeowners) guide for more information.\n\n```\n$ moon sync code-owners\n```\n\n### Options\n\n- `--clean` - Clean and remove previously generated file.\n\n- `--force` - Bypass cache and force create file.\n\n### Configuration\n\n- [`codeowners`](/docs/config/workspace#codeowners) in `.moon/workspace.yml`\n\n- [`owners`](/docs/config/project#owners) in `moon.yml`\n\n## /docs/commands/sync/config-schemas\n\nSource: https://moonrepo.dev/docs/commands/sync/config-schemas\n\n# sync config-schemas\n\nv1.27.0\n\nThe `moon sync config-schemas` command will manually generate JSON schemas to `.moon/cache/schemas`\nfor all our different configuration files.\n\n```\n$ moon sync config-schemas\n```\n\n### Options\n\n- `--force` - Bypass cache and force create files.\n\n## /docs/commands/sync/projects\n\nSource: https://moonrepo.dev/docs/commands/sync/projects\n\n# sync projects\n\nv1.8.0\n\nThe `moon sync projects` command will force sync all projects in the workspace to help achieve a\n[healthy repository state](/docs/faq#what-should-be-considered-the-source-of-truth). This applies\nthe following:\n\n- Ensures cross-project dependencies are linked based on [`dependsOn`](/docs/config/project#dependson).\n\n- Ensures language specific configuration files are present and accurate (`package.json`, `tsconfig.json`, etc).\n\n- Ensures root configuration and project configuration are in sync.\n\n- Any additional language specific semantics that may be required.\n\n```\n$ moon sync projects\n```\n\nThis command should rarely be ran, as [`moon run`](/docs/commands/run) will sync affected projects\nautomatically! However, when migrating or refactoring, manual syncing may be necessary.\n\n### Configuration\n\n- [`projects`](/docs/config/workspace#projects) in `.moon/workspace.yml`\n\n## /docs/commands/sync/vcs-hooks\n\nSource: https://moonrepo.dev/docs/commands/sync/vcs-hooks\n\n# sync vcs-hooks\n\nv1.9.0\n\nThe `moon sync vcs-hooks` command will manually sync hooks for the configured\n[VCS](/docs/config/workspace#vcs), by generating and referencing hook scripts from the\n[`vcs.hooks`](/docs/config/workspace#hooks) setting. Refer to the official\n[VCS hooks](/docs/guides/vcs-hooks) guide for more information.\n\n```\n$ moon sync vcs-hooks\n```\n\n### Options\n\n- `--clean` - Clean and remove previously generated hooks.\n\n- `--force` - Bypass cache and force create hooks.\n\n### Configuration\n\n- [`vcs.hooks`](/docs/config/workspace#hooks) in `.moon/workspace.yml`\n\n## /docs/commands/task\n\nSource: https://moonrepo.dev/docs/commands/task\n\n# task\n\nv1.1.0\n\nThe `moon task [target]` (or `moon t`) command will display information about a task that has been\nconfigured and exists within a project. If a task does not exist, the program will return with a 1\nexit code.\n\n```\n$ moon task web:build\n```\n\n### Arguments\n\n- `[target]` - Fully qualified project + task target.\n\n### Options\n\n- `--json` - Print the task and its configuration as JSON.\n\n## Example output\n\nThe following output is an example of what this command prints, using our very own\n`@moonrepo/runtime` package.\n\n```\nRUNTIME:BUILDTask: buildProject: runtimeToolchain: nodeType: buildPROCESSCommand: packemon build --addFiles --addExports --declarationEnvironment variables:  - NODE_ENV = productionWorking directory: ~/Projects/moon/packages/runtimeRuns dependencies: ConcurrentlyRuns in CI: YesDEPENDS ON  - types:buildINHERITS FROM  - .moon/tasks/node.ymlINPUTS  - .moon/*.yml  - .moon/tasks/node.yml  - packages/runtime/package.json  - packages/runtime/src/**/*  - packages/runtime/tsconfig.*.json  - packages/runtime/tsconfig.json  - packages/runtime/types/**/*  - tsconfig.options.jsonOUTPUTS  - packages/runtime/cjs\n```\n\n### Configuration\n\n- [`tasks`](/docs/config/tasks#tasks) in `.moon/tasks/all.yml`\n\n- [`tasks`](/docs/config/project#tasks) in `moon.yml`\n\n## /docs/commands/task-graph\n\nSource: https://moonrepo.dev/docs/commands/task-graph\n\n# task-graph\n\nv1.30.0\n\nThe `moon task-graph [target]` (or `moon tg`) command will generate and serve a visual graph of all\nconfigured tasks as nodes, with dependencies between as edges, and can also output the graph in\n[Graphviz DOT format](https://graphviz.org/doc/info/lang.html).\n\n```\n# Run the visualizer locally$ moon task-graph# Export to DOT format$ moon task-graph --dot > graph.dot\n```\n\nA task target can be passed to focus the graph to only that task and its dependencies. For\nexample, `moon task-graph app:build`.\n\n### Arguments\n\n- `[target]` - Optional target of task to focus.\n\n### Options\n\n- `--dependents` - Include direct dependents of the focused task.\n\n- `--dot` - Print the graph in DOT format.\n\n- `--host` - The host address. Defaults to `127.0.0.1`. v1.36.0\n\n- `--json` - Print the graph in JSON format.\n\n- `--port` - The port to bind to. Defaults to a random port. v1.36.0\n\n## Example output\n\nThe following output is an example of the graph in DOT format.\n\n```\ndigraph {    0 [ label=\"types:build\" style=filled, shape=oval, fillcolor=gray, fontcolor=black]    1 [ label=\"runtime:build\" style=filled, shape=oval, fillcolor=gray, fontcolor=black]    2 [ label=\"website:build\" style=filled, shape=oval, fillcolor=gray, fontcolor=black]    1 -> 0 [ label=\"required\" arrowhead=box, arrowtail=box]    2 -> 1 [ label=\"required\" arrowhead=box, arrowtail=box]    2 -> 0 [ label=\"required\" arrowhead=box, arrowtail=box]}\n```\n\n## /docs/commands/tasks\n\nSource: https://moonrepo.dev/docs/commands/tasks\n\n# tasks\n\nv2.0.0\n\nThe `moon tasks` command will list all tasks available in the workspace as a table of information.\n\n```\n‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ‚îÇTask                          Command          Type        Preset      Toolchains                                Description                                                           ‚îÇ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ‚îÇwebsite:build                 docusaurus       build                   typescript, javascript, node, yarn        Builds the Docusaurus app.                                            ‚îÇ‚îÇwebsite:format                prettier         test                    javascript, node, yarn                                                                                          ‚îÇ‚îÇwebsite:format-write          prettier         test                    javascript, node, yarn                                                                                          ‚îÇ‚îÇwebsite:lint                  eslint           test                    javascript, node, yarn                                                                                          ‚îÇ‚îÇwebsite:lint-fix              eslint           test                    javascript, node, yarn                                                                                          ‚îÇ‚îÇwebsite:start                 docusaurus       run         server      typescript, javascript, node, yarn                                                                              ‚îÇ‚îÇwebsite:test                  jest             test                    javascript, node, yarn                                                                                          ‚îÇ‚îÇwebsite:typecheck             tsc              test                    typescript, javascript, node, yarn                                                                              ‚îÇ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\n```\n\ninfo\n\nUse [`moon query tasks`](/docs/commands/query/tasks) for advanced querying and filtering of tasks.\n\n### Arguments\n\n- `[id]` - Filter tasks to a specific project ID.\n\n### Options\n\n- `--json` - Print the projects as JSON.\n\n## /docs/commands/teardown\n\nSource: https://moonrepo.dev/docs/commands/teardown\n\n# teardown\n\nThe `moon teardown` command, as its name infers, will teardown and clean the current environment,\nopposite the [`setup`](/docs/commands/setup) command. It achieves this by doing the following:\n\n- Uninstalling all configured tools in the toolchain.\n\n- Removing any download or temporary files/folders.\n\n```\n$ moon teardown\n```\n\n### Configuration\n\n- [`*`](/docs/config/toolchain) in `.moon/toolchains.yml`\n\n## /docs/commands/template\n\nSource: https://moonrepo.dev/docs/commands/template\n\n# template\n\nv2.0.0\n\nThe `moon template [id]` command will display information about a template, its files, and\nvariables.\n\n```\nTemplate title ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  Some description of the template and its files.About ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  Template: package  Location: /templates/package  Destination: packages/[name | kebab_case]  Extends: ‚Äî  Assets: ‚Äî  Files:    - package.jsonVariables ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  name: string\n```\n\n### Arguments\n\n- `[id]` - The template ID.\n\n### Options\n\n- `--json` - Print the template as JSON.\n\n## /docs/commands/templates\n\nSource: https://moonrepo.dev/docs/commands/templates\n\n# templates\n\nv1.24.0\n\nThe `moon templates` command will list all templates available for [code generation](/docs/commands/generate).\nThis list will include the template title, description, default destination, where it's source files\nare located, and more.\n\n```\n$ moon templates\n```\n\n### Options\n\n- `--filter` - Filter templates by a search term.\n\n- `--json` - Print templates in JSON format.\n\n### Configuration\n\n- [`generator`](/docs/config/workspace#generator) in `.moon/workspace.yml`\n\n## /docs/commands/toolchain\n\nSource: https://moonrepo.dev/docs/commands/toolchain\n\n- [Home](/)\n- [Commands](/docs/commands)\n- [toolchain](/docs/commands/toolchain)\n\nwarning\n\nDocumentation is currently for [moon v2](/blog/moon-v2-alpha) and latest proto. Documentation for moon v1 has been frozen and can be [found here](https://moonrepo.github.io/website-v1/).\n\n# toolchain\n\nManage toolchain plugins.\n\n[üìÑÔ∏è addThe moon toolchain add [plugin] command will add a toolchain to the workspace by injecting a](/docs/commands/toolchain/add)\n\n[üìÑÔ∏è infoThe moon toolchain info [plugin] command will display detailed information about a toolchain,](/docs/commands/toolchain/info)\n\n[templates](/docs/commands/templates)\n\n[add](/docs/commands/toolchain/add)\n\n## /docs/commands/toolchain/add\n\nSource: https://moonrepo.dev/docs/commands/toolchain/add\n\n# toolchain add\n\nv1.38.0\n\nThe `moon toolchain add  [plugin]` command will add a toolchain to the workspace by injecting a\nconfiguration block into `.moon/toolchains.yml`. To do this, the command will download the WASM\nplugin, extract information, and call initialize functions.\n\nFor built-in toolchains, the [plugin locator](/docs/guides/wasm-plugins#configuring-plugin-locations) argument is optional, and will be derived\nfrom the identifier.\n\n```\n$ moon toolchain add typescript\n```\n\nFor third-party toolchains, the [plugin locator](/docs/guides/wasm-plugins#configuring-plugin-locations) argument is required, and must point to\nthe WASM plugin.\n\n```\n$ moon toolchain add custom https://example.com/path/to/plugin.wasm\n```\n\n### Arguments\n\n- `` - ID of the toolchain to use.\n\n- `[plugin]` - Optional [plugin locator](/docs/guides/wasm-plugins#configuring-plugin-locations) for third-party toolchains.\n\n### Options\n\n- `--minimal` - Generate minimal configurations and sane defaults.\n\n- `--yes` - Skip all prompts and enables tools based on file detection.\n\n## /docs/commands/toolchain/info\n\nSource: https://moonrepo.dev/docs/commands/toolchain/info\n\n# toolchain info\n\nv1.38.0\n\nThe `moon toolchain info  [plugin]` command will display detailed information about a toolchain,\nlike what files are scanned, what configuration settings are available, and what tier APIs are\nsupported. To do this, the command will download the WASM plugin, extract information, and call\nspecific functions.\n\nFor built-in toolchains, the [plugin locator][locator] argument is optional, and will be derived\nfrom the identifier.\n\n```\n$ moon toolchain info typescript\n```\n\nFor third-party toolchains, the [plugin locator][locator] argument is required, and must point to\nthe WASM plugin.\n\n```\n$ moon toolchain info custom https://example.com/path/to/plugin.wasm\n```\n\n### Arguments\n\n- `` - ID of the toolchain to view.\n\n- `[plugin]` - Optional [plugin locator][locator] for third-party toolchains.\n\n## Example output\n\n```\nToolchain ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  Provides sync operations that keep tsconfig.json's in a healthy state.  ID: typescript  Name: TypeScript  Version: 0.2.0Configuration ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  createMissingConfig: bool  When `syncProjectReferences` is enabled, will create a `tsconfig.json`  in referenced projects if it does not exist.  includeProjectReferenceSources: bool  Appends sources of project reference to `include` in `tsconfig.json`,  for each project.  includeSharedTypes: bool  Appends shared types to `include` in `tsconfig.json`, for each project.  projectConfigFileName: string  Name of the `tsconfig.json` file within each project.  root: string  The relative root to the TypeScript root. Primarily used for  resolving project references.  rootConfigFileName: string  Name of the `tsconfig.json` file at the workspace root.  rootOptionsConfigFileName: string  Name of the shared compiler options `tsconfig.json` file  at the workspace root.  routeOutDirToCache: bool  Updates and routes `outDir` in `tsconfig.json` to moon's cache,  for each project.  syncProjectReferences: bool  Syncs all project dependencies as `references` in `tsconfig.json`,  for each project.  syncProjectReferencesToPaths: bool  Syncs all project dependencies as `paths` in `tsconfig.json`,  for each project.Tier 1 - Usage detection ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  Config files: tsconfig.json, tsconfig.*.json, *.tsconfig.json, .tsbuildinfo, *.tsbuildinfo  Executable names: tsc, tsserver  APIs:    üü¢ register_toolchain (required)    üü¢ define_toolchain_config    üü¢ initialize_toolchain    ‚ö´Ô∏è detect_version_files    ‚ö´Ô∏è parse_version_file    üü¢ define_docker_metadata    ‚ö´Ô∏è scaffold_docker    ‚ö´Ô∏è prune_docker    üü¢ sync_project    ‚ö´Ô∏è sync_workspaceTier 2 - Ecosystem integration ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  APIs:    ‚ö´Ô∏è extend_project_graph    ‚ö´Ô∏è extend_task_command    ‚ö´Ô∏è extend_task_script    ‚ö´Ô∏è locate_dependencies_root    ‚ö´Ô∏è install_dependencies    üü¢ hash_task_contents    ‚ö´Ô∏è parse_lock    ‚ö´Ô∏è parse_manifest    ‚ö´Ô∏è setup_environmentTier 3 - Tool management ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  APIs:    ‚ö´Ô∏è register_tool (required)    ‚ö´Ô∏è load_versions    ‚ö´Ô∏è resolve_version    ‚ö´Ô∏è download_prebuilt (required)    ‚ö´Ô∏è unpack_archive    ‚ö´Ô∏è locate_executables (required)    ‚ö´Ô∏è setup_toolchain    ‚ö´Ô∏è teardown_toolchain\n```\n\n## /docs/commands/upgrade\n\nSource: https://moonrepo.dev/docs/commands/upgrade\n\n# upgrade\n\nThe `moon upgrade` command can be used to upgrade your current moon binary (if installed globally)\nto the latest version.\n\n```\n$ moon upgrade\n```\n\ncaution\n\nThis command will only work if moon was installed in the `~/.moon` directory, using our official\n[installation script](/docs/install). If installed through Node.js, you'll need to upgrade manually.\n\n## /docs/comparison\n\nSource: https://moonrepo.dev/docs/comparison\n\n# Feature comparison\n\nThe following comparisons are not an exhaustive list of features, and may be inaccurate or out of\ndate, but represent a good starting point for investigation. If something is not correct, please\n[create an issue](https://github.com/moonrepo/moon/issues) or\n[submit a patch](https://github.com/moonrepo/moon/blob/master/website/src/components/ComparisonTable.tsx).\n\nBefore diving into our comparisons below, we highly suggest reading\n[monorepo.tools](https://monorepo.tools/) for a deeper insight into monorepos and available tooling.\nIt's a great resource for learning about the current state of things and the ecosystem.\n\ninfo\n\nLooking to migrate from Nx or Turborepo to moon? Use our\n[`moon ext migrate-nx`](/docs/guides/extensions#migrate-nx) or\n[`moon ext migrate-turborepo`](/docs/guides/extensions#migrate-turborepo) commands for a (somewhat)\nseamless migration!\n\n## Unique features\n\nAlthough moon is still in its infancy, we provide an array of powerful features that other frontend\ncentric task runners do not, such as...\n\n- [Integrated toolchain](/docs/concepts/toolchain) - moon manages its own version of programming languages and dependency managers behind the scenes, so that every task is executed with the exact same version, across all machines.\n\n- [Task inheritance](/docs/concepts/task-inheritance) - Instead of defining the same tasks (lint, test, etc) over and over again for every project in the monorepo, moon supports a task inheritance model where it only needs to be defined once at the top-level. Projects can then merge with, exclude, or override if need be.\n\n- [Continuous integration](/docs/guides/ci) - By default, all moon tasks will run in CI, as we want to encourage every facet of a project or repository to be continually tested and verified. This can be turned off on a per-task basis.\n\nCurious to learn more? Check out the \"[Why use moon?](/docs/)\" or \"[Features](/docs/)\" sections for more\ninformation, or these wonderful articles provided by the community:\n\n- [A review of moon + Packemon](https://azu.github.io/slide/2022/moa/moon-packemon.html) by [azu](https://twitter.com/azu_re)\n\n- [Improve repo management with moon](https://blog.logrocket.com/improve-repo-management-moon/) by [James Sinkala](https://jamesinkala.com/)\n\n## Comparison\n\n### Turborepo\n\nAt a high-level, Turborepo and moon seem very similar as they both claim to be task runners. They\nboth support incremental builds, content/smart hashing, local and remote caching1,\nparallel execution, and everything else you'd expect from a task runner. But that's where the\nsimilarities stop, because in the end, Turborepo is nothing more than a `package.json` scripts\norchestrator with a caching layer. While moon also supports this, it\n[aims to be far more](#unique-features) with a heavy focus on the developer experience.\n\nIn the next section, we'll be talking about a few key areas that we deem important to consumers. If\nyou'd prefer a more granular comparison, jump down to the [comparison tables](#comparison-tables).\n\n#### Configuration\n\nTurborepo only supports the Node.js ecosystem, so implicitly uses a conventions based approach. It provides very little to no configuration for customizing Turborepo to your needs.\n\nmoon is language agnostic, with initial support for Node.js and its ecosystem. Because of this, moon provides a ton of configuration for customizing moon to your needs. It prefers a configuration over conventions approach, as every repository is different.\n\n#### Projects\n\nTurborepo infers projects from `package.json` workspaces, and does not support non-JavaScript based projects.\n\nmoon requires projects to be defined in `.moon/workspace.yml`, and supports any programming language2.\n\n#### Tasks\n\nTurborepo requires `package.json` scripts to be defined for every project. This results in the same scripts being repeated constantly.\n\nmoon avoids this overhead by using [task inheritance](#unique-features). No more repetition.\n\n#### CI\n\nEach pipeline in `turbo.json` must be individually ran as a step in CI. Scripts not configured as pipeline tasks are never ran.\n\nmoon runs every task automatically using `moon ci`, which also supports parallelism/sharding.\n\n#### Long-term\n\nTurborepo is in the process of being rewritten in Rust, with its codebase being shared and coupled with the new Turbopack library, a Rust based bundler. Outside of this, there are no publicly available plans for Turborepo's future.\n\nmoon plans to be so much more than a task runner, with one such facet being a repository management tool. This includes code ownership, dependency management and auditing, repository linting, in-repo secrets, and anything else we deem viable. We also plan to support additional languages as first-class citizens within our toolchain.\n\n- Turborepo remote caching is powered by Vercel. moon provides its own paid service.\n\n- moon projects may run commands for any language, but not all languages are supported in the toolchain.\n\n### Lerna\n\nLerna was a fantastic tool that helped the JavaScript ecosystem grow and excelled at package\nversioning and publishing (and still does), but it offered a very rudimentary task runner. While\nLerna was able to run scripts in parallel, it wasn't the most efficient, as it did not support\ncaching, hashing, or performant scheduling.\n\nHowever, the reason Lerna is not compared in-depth, is that Lerna was unowned and unmaintained for\nquite some time, and has recently fallen under the Nx umbrella. Lerna is basically Nx lite now.\n\n## Comparison tables\n\nüü© Supported üü® Partially supported üü¶ Similarly supported üü• Not supported\n\n### Workspace\n\nmoon (11) nx (11) turborepo (8)\n\nCore/CLI written in Rust Node.js & Rust (for hot paths) Rust / Go\n\nPlugins written in WASM (any compatible language) TypeScript üü•\n\nWorkspace configured with `.moon/workspace.yml` `nx.json` `turbo.json`\n\nProject list configured in `.moon/workspace.yml` `workspace.json` / `package.json` workspaces `package.json` workspaces\n\nRepo / folder structure loose loose loose\n\nIgnore file support üü© via `hasher.ignorePatterns` üü© .nxignore üü© via `--ignore`\n\nSupports dependencies inherited by all tasks üü© via `implicitDeps` üü© via `targetDefaults` üü•\n\nSupports inputs inherited by all tasks üü© via `implicitInputs` üü© via `implicitDependencies` üü© via `globalDependencies`\n\nSupports tasks inherited by all projects üü© üü© via `plugins` üü•\n\nIntegrates with a version control system üü© git üü© git üü© git\n\nSupports scaffolding / generators üü© üü© üü©\n\n### Toolchain\n\nmoon (6) nx (2) turborepo (2)\n\nSupported languages in task runner All languages available on `PATH` All languages via plugins. OOTB TS/JS, existing plugins for Rust, Go, Dotnet and more JavaScriptTypeScript via `package.json` scripts\n\nSupported dependency managers npm, pnpm, yarn, bun npm, pnpm, yarn npm, pnpm, yarn\n\nSupported toolchain languages (automatic dev envs) Bun, Deno, Node.js, Rust üü• üü•\n\nHas a built-in toolchain üü© üü• üü•\n\nDownloads and installs languages (when applicable) üü© üü• üü•\n\nConfigures explicit language/dependency manager versions üü© üü• üü•\n\n### Projects\n\nmoon (8) nx (5) turborepo (2)\n\nDependencies on other projects üü© implicit from `package.json` or explicit in `moon.yml` üü© implicit from `package.json` or explicit in `project.json` and code imports/exports üü© implicit from `package.json`\n\nOwnership metadata üü© üü• üü•\n\nPrimary programming language üü© üü• üü•\n\nProject type (app, lib, etc) üü© app, lib, tool, automation, config, scaffold üü© app, lib üü•\n\nProject tech stack üü© frontend, backend, infra, systems üü• üü•\n\nProject-level file groups üü© üü© via `namedInputs` üü•\n\nProject-level tasks üü© üü© üü©\n\nTags and scopes (boundaries) üü© native for all languages üü© boundaries via ESLint (TS and JS), tags for filtering for all languages üü•\n\n### Tasks\n\nmoon (24) nx (24) turborepo (17)\n\nKnown as tasks targets tasks\n\nDefines tasks in `moon.yml` or `package.json` scripts `nx.json`, `project.json` or `package.json` scripts `package.json` scripts\n\nRun a single task with `moon run project:task` `nx target project` or `nx run project:target` `turbo run task --filter=project`\n\nRun multiple tasks with `moon run :task` or `moon run a:task b:task` or `moon check` `nx run-many -t task1 task2 task3` `turbo run task` or `turbo run a b c`\n\nRun tasks based on a query/filter `moon run :task --query \"...\"` `nx run-many -t task -p \"tag:..\" -p \"dir/*\" -p \"name*\" -p \"!negation\"` üü•\n\nCan define tasks globally üü© with `.moon/tasks/all.yml` üü® with `targetDefaults` üü•\n\nMerges or overrides global tasks üü© üü© üü•\n\nRuns a command with args üü© üü© üü® within the script\n\nRuns commands from project or workspace root current working directory, or wherever desired via config project root\n\nSupports pipes, redirects, etc, in configured tasks üü® encapsulated in a file üü® within the executor or script üü® within the script\n\nDependencies on other tasks üü© via `deps` üü© via `dependsOn` üü© via `dependsOn`\n\nCan provide extra params for task dependencies üü© üü© üü•\n\nCan mark a task dependency as optional üü© via `optional` üü• üü•\n\nCan depend on arbitrary or unrelated tasks üü© üü© üü• dependent projects only\n\nRuns task dependencies in parallel üü© üü© üü©\n\nCan run task dependencies in serial üü© üü© via `parallel=1` üü© via `concurrency=1`\n\nFile groups üü© üü© via `namedInputs` üü•\n\nEnvironment variables üü© via `env`, `envFile` üü© automatically via `.env` files and/or inherited from shell üü® within the script\n\nInputs üü© files, globs, env vars üü© files, globs, env vars, runtime üü© files, globs\n\nOutputs üü© files, globs üü© files, globs üü© files, globs\n\nOutput logging style üü© via `outputStyle` üü© via `--output-style` üü© via `outputMode`\n\nCustom hash inputs üü• üü© via `runtime` inputs üü© via `globalDependencies`\n\nToken substitution üü© token functions and variable syntax üü© `{workspaceRoot}`, `{projectRoot}`, `{projectName}`, arbitrary patterns `namedInputs` üü•\n\nConfiguration presets üü© via task `extends` üü© via `configurations` üü•\n\nConfigurable options üü© üü© üü©\n\n### Task runner\n\nmoon (9) nx (11) turborepo (7)\n\nKnown as action pipeline task runner pipeline\n\nGenerates a dependency graph üü© üü© üü©\n\nRuns in topological order üü© üü© üü©\n\nAutomatically retries failed tasks üü© üü© when flakiness detected on Nx Cloud üü•\n\nCaches task outputs via a unique hash üü© üü© üü©\n\nCan customize the underlying runner üü• üü© üü•\n\nCan profile running tasks üü© cpu, heap üü© cpu üü© cpu\n\nCan generate run reports üü© üü© free in Nx Cloud & GitHub App Comment üü©\n\nContinuous integration (CI) support üü© üü© üü®\n\nContinuous deployment (CD) support üü• üü® via `nx release` üü•\n\nRemote / cloud caching and syncing üü© with Bazel REAPI (free / paid) üü© with nx.app Nx Cloud (free / paid) üü© requires a Vercel account (free)\n\n### Generator\n\nmoon (14) nx (14) turborepo (11)\n\nKnown as generator generator generator\n\nTemplates are configured with a schema üü© via `template.yml` üü© üü•\n\nTemplate file extensions (optional) üü© .tera, .twig üü© fully under user control, built in utility for .ejs templates üü© .hbs\n\nTemplate files support frontmatter üü© üü© fully under user control üü•\n\nCreates/copies files to destination üü© üü© üü©\n\nUpdates/merges with existing files üü© JSON/YAML only üü© via TypeScript/JavaScript plugins üü©\n\nRenders with a template engine üü© via Tera üü© fully under user control, built in utility for .ejs templates üü© via Handlebars\n\nVariable interpolation in file content üü© üü© üü©\n\nVariable interpolation in file paths üü© üü© üü©\n\nCan define variable values via interactive prompts üü© üü© using JSON schema üü©\n\nCan define variable values via command line args üü© üü© using JSON schema üü©\n\nSupports dry runs üü© üü© üü•\n\nSupports render helpers, filters, and built-ins üü© üü© üü©\n\nGenerators can compose other generators üü© via `extends` üü© fully under user control, author in TypeScript/JavaScript üü© using JavaScript\n\n### Other systems\n\nmoon (6) nx (0) turborepo (1)\n\nCan send webhooks for critical pipeline events üü© üü• üü•\n\nGenerates run reports with granular stats/metrics üü© üü• üü©\n\nCan define and manage code owners üü© üü• üü•\n\nCan generate a `CODEOWNERS` file üü© üü• üü•\n\nCan define and manage VCS (git) hooks üü© üü• üü•\n\nSupports git worktrees üü© üü• üü•\n\n### JavaScript ecosystem\n\nmoon (10) nx (1) turborepo (0)\n\nWill automatically install node modules when lockfile changes üü© üü• üü•\n\nCan automatically dedupe when lockfile changes üü© üü• üü•\n\nCan alias `package.json` names for projects üü© üü© üü•\n\nCan add `engines` constraint to root `package.json` üü© üü• üü•\n\nCan sync version manager configs (`.nvmrc`, etc) üü© üü• üü•\n\nCan sync cross-project dependencies to `package.json` üü© üü• üü•\n\nCan sync project references to applicable `tsconfig.json` üü© üü• üü•\n\nCan auto-create missing `tsconfig.json` üü© üü• üü•\n\nCan sync dependencies as `paths` to `tsconfig.json` üü© üü• üü•\n\nCan route `outDir` to a shared cached in `tsconfig.json` üü© üü• üü•\n\n### Docker integration\n\nmoon (3) nx (2) turborepo (2)\n\nEfficient scaffolding for Dockerfile layer caching üü© üü¶ via custom generator üü©\n\nAutomatic production-only dependency installation üü© üü® generated automatically by first party plugin üü•\n\nEnvironment pruning to reduce image/container sizes üü© üü• üü©\n\n## /docs/concepts\n\nSource: https://moonrepo.dev/docs/concepts\n\n- [Home](/)\n- [Concepts](/docs/concepts)\n\nwarning\n\nDocumentation is currently for [moon v2](/blog/moon-v2-alpha) and latest proto. Documentation for moon v1 has been frozen and can be [found here](https://moonrepo.github.io/website-v1/).\n\n# Concepts\n\n[üìÑÔ∏è Cachemoon's able to achieve high performance and blazing speeds by implementing a cache that's powered by](/docs/concepts/cache)\n\n[üìÑÔ∏è File groupsFile groups are a mechanism for grouping similar types of files and environment variables within a](/docs/concepts/file-group)\n\n[üìÑÔ∏è File patternsGlobs](/docs/concepts/file-pattern)\n\n[üìÑÔ∏è Query languagemoon supports an integrated query language, known as MQL, that can be used to filter and select](/docs/concepts/query-lang)\n\n[üìÑÔ∏è ProjectsA project is a library, application, package, binary, tool, etc, that contains source files, test](/docs/concepts/project)\n\n[üìÑÔ∏è TargetsA target is a compound identifier that pairs a scope to a task,](/docs/concepts/target)\n\n[üìÑÔ∏è TasksTasks are commands that are ran in the context of a project. Underneath the hood, a](/docs/concepts/task)\n\n[üìÑÔ∏è Task inheritanceUnlike other task runners that require the same tasks to be repeatedly defined for every project,](/docs/concepts/task-inheritance)\n\n[üìÑÔ∏è TokensTokens are variables and functions that can be used by command,](/docs/concepts/token)\n\n[üìÑÔ∏è ToolchainThe toolchain is an internal layer for downloading, installing, and managing tools (languages,](/docs/concepts/toolchain)\n\n[üìÑÔ∏è WorkspaceA workspace is a directory that contains projects, manages a toolchain,](/docs/concepts/workspace)\n\n[Migrate to moon](/docs/migrate-to-moon)\n\n[Cache](/docs/concepts/cache)\n\n## /docs/concepts/cache\n\nSource: https://moonrepo.dev/docs/concepts/cache\n\n# Cache\n\nmoon's able to achieve high performance and blazing speeds by implementing a cache that's powered by\nour own unique smart hashing layer. All cache is stored in `.moon/cache`, relative from the\nworkspace root (be sure to git ignore this folder).\n\n## Hashing\n\nIncremental builds are possible through a concept known as hashing, where in multiple sources are\naggregated to generate a unique hash. In the context of moon, each time a target is ran we generate\na hash, and if this hash already exists we abort early (cache hit), otherwise we continue the run\n(cache miss).\n\nThe tiniest change may trigger a different hash, for example, changing a line of code (when an\ninput), or updating a package version, so don't worry if you see a lot of hashes.\n\nOur smart hashing currently takes the following sources into account:\n\n- Command (`command`) being ran and its arguments (`args`).\n\n- Input sources (`inputs`).\n\n- Output targets (`outputs`).\n\n- Environment variables (`env`).\n\n- Dependencies between projects (`dependsOn`) and tasks (`deps`).\n\n- For Deno tasks: Deno version.\n\n- `deno.json`/`deps.ts` imports, import maps, and scopes.\n\n- `tsconfig.json` compiler options (when applicable).\n\n- For Bun and Node.js tasks: Bun/Node.js version.\n\n- `package.json` dependencies (including development and peer).\n\n- `tsconfig.json` compiler options (when applicable).\n\ncaution\n\nBe aware that greedy inputs (`**/*`, the default) will include everything in the target directory\nas a source. We do our best to filter out VCS ignored files, and `outputs` for the current task, but\nfiles may slip through that you don't expect. We suggest using explicit `inputs` and routinely\nauditing the hash files for accuracy!\n\n## Archiving & hydration\n\nOn top of our hashing layer, we have another concept known as archiving, where in we create a\ntarball archive of a task's outputs and store it in `.moon/cache/outputs`. These are akin to build\nartifacts.\n\nWhen we encounter a cache hit on a hash, we trigger a mechanism known as hydration, where we\nefficiently unpack an existing tarball archive into a task's outputs. This can be understood as a\ntimeline, where every point in time will have its own hash + archive that moon can play back.\n\nFurthermore, if we receive a cache hit on the hash, and the hash is the same as the last run, and\noutputs exist, we exit early without hydrating and assume the project is already hydrated. In the\nterminal, you'll see a message for \"cached\".\n\n## File structure\n\nThe following diagram outlines our cache folder structure and why each piece exists.\n\n```\n.moon/cache/\t# Stores hash manifests of every ran task. Exists purely for debugging purposes.\thashes/\t\t# Contents includes all sources used to generate the hash.\t\t.json\t# Stores `tar.gz` archives of a task's outputs based on its generated hash.\toutputs/\t\t.tar.gz\t# State information about anything and everything within moon. Toolchain,\t# dependencies, projects, running targets, etc.\tstates/\t\t# Files at the root pertain to the entire workspace.\t\t.json\t\t# Files for a project are nested within a folder by the project name.\n/\t\t\t# Informational snapshot of the project, its tasks, and its configs.\t\t\t# Can be used at runtime by tasks that require this information.\t\t\tsnapshot.json\t\t\t/\t\t\t\t# Contents of the child process, including the exit code and\t\t\t\t# unique hash that is referenced above.\t\t\t\tlastRun.json\t\t\t\t# Outputs of last run target.\t\t\t\tstderr.log\t\t\t\tstdout.log\n```\n\n## /docs/concepts/file-group\n\nSource: https://moonrepo.dev/docs/concepts/file-group\n\n# File groups\n\nFile groups are a mechanism for grouping similar types of files and environment variables within a\nproject using [file glob patterns or literal file paths](/docs/concepts/file-pattern). These groups are then used\nby [tasks](/docs/concepts/task) to calculate functionality like cache computation, affected files since last\nchange, deterministic builds, and more.\n\n## Configuration\n\nFile groups can be configured per project through [`moon.yml`](/docs/config/project), or for many\nprojects through [`.moon/tasks/all.yml`](/docs/config/tasks).\n\n### Token functions\n\nFile groups can be referenced in [tasks](/docs/concepts/task) using [token functions](/docs/concepts/token). For example, the\n`@group(name)` token will expand to all paths configured in the `sources` file group.\n\nmoon.yml\n\n```\ntasks:  build:    command: 'vite build'    inputs:      - '@group(sources)'\n```\n\n## Inheritance and merging\n\nWhen a file group of the same name exists in both [configuration files](#configuration), the\nproject-level group will override the workspace-level group, and all other workspace-level groups\nwill be inherited as-is.\n\nA primary scenario in which to define file groups at the project-level is when you want to\noverride file groups defined at the workspace-level. For example, say we want to override the\n`sources` file group because our source folder is named \"lib\" and not \"src\", we would define our\nfile groups as followed.\n\n.moon/tasks/all.yml\n\n```\nfileGroups:  sources:    - 'src/**/*'    - 'types/**/*'  tests:    - 'tests/**/*.test.*'    - '**/__tests__/**/*'\n```\n\nmoon.yml\n\n```\nfileGroups:  # Overrides global  sources:    - 'lib/**/*'    - 'types/**/*'  # Inherited as-is  tests:    - 'tests/**/*.test.*'    - '**/__tests__/**/*'\n```\n\n## /docs/concepts/file-pattern\n\nSource: https://moonrepo.dev/docs/concepts/file-pattern\n\n# File patterns\n\n## Globs\n\nGlobs in moon are [Rust-based globs](https://github.com/olson-sean-k/wax), not JavaScript-based.\nThis may result in different or unexpected results. The following guidelines must be met when using\nglobs:\n\n- Must use forward slashes (`/`) for path separators, even on Windows.\n\n- Must not start with or use any relative path parts, `.` or `..`.\n\n### Supported syntax\n\n- `*` - Matches zero or more characters, but does not match the `/` character. Will attempt to match the longest possible text (eager).\n\n- `$` - Like `*`, but will attempt to match the shortest possible text (lazy).\n\n- `**` - Matches zero or more directories.\n\n- `?` - Matches exactly one character, but not `/`.\n\n- `[abc]` - Matches one case-sensitive character listed in the brackets.\n\n- `[!xyz]` - Like the above, but will match any character not listed.\n\n- `[a-z]` - Matches one case-sensitive character in range in the brackets.\n\n- `[!x-z]` - Like the above, but will match any character not in range.\n\n- `{glob,glob}` - Matches one or more comma separated list of sub-glob patterns.\n\n- `` - Matches a sub-glob within a defined bounds.\n\n- `!` - At the start of a pattern, will negate previous positive patterns.\n\n### Examples\n\n```\nREADME.{md,mdx,txt}src/**/*tests/**/*.?js!**/__tests__/**/*logs/--.log\n```\n\n## Project relative\n\nWhen configuring [`fileGroups`](/docs/config/project#filegroups), [`inputs`](/docs/config/project#inputs),\nand [`outputs`](/docs/config/project#outputs), all listed file paths and globs are relative from the\nproject root they will be ran in. They must not traverse upwards with `..`.\n\n```\n# Validsrc/**/*./src/**/*package.json# Invalid../utils\n```\n\n## Workspace relative\n\nWhen configuring [`fileGroups`](/docs/config/project#filegroups), [`inputs`](/docs/config/project#inputs),\nand [`outputs`](/docs/config/project#outputs), a listed file path or glob can be prefixed with `/` to\nresolve relative from the workspace root, and not the project root.\n\n```\n# In projectpackage.json# In workspace/package.json\n```\n\n## /docs/concepts/project\n\nSource: https://moonrepo.dev/docs/concepts/project\n\n# Projects\n\nA project is a library, application, package, binary, tool, etc, that contains source files, test\nfiles, assets, resources, and more. A project must exist and be configured within a\n[workspace](/docs/concepts/workspace).\n\n## IDs\n\nA project identifier (or name) is a unique resource for locating a project. The ID is explicitly\nconfigured within [`.moon/workspace.yml`](/docs/config/workspace), as a key within the\n[`projects`](/docs/config/workspace#projects) setting, and can be written in camel/kebab/snake case.\nIDs support alphabetic unicode characters, `0-9`, `_`, `-`, `/`, `.`, and must start with a\ncharacter.\n\nIDs are used heavily by configuration and the command line to link and reference everything. They're\nalso a much easier concept for remembering projects than file system paths, and they typically can\nbe written with less key strokes.\n\nLastly, a project ID can be paired with a task ID to create a [target](/docs/concepts/target).\n\n## Aliases\n\nAliases are a secondary approach for naming projects, and can be used as a drop-in replacement for\nstandard names. What this means is that an alias can also be used when configuring dependencies, or\ndefining [targets](/docs/concepts/target).\n\nHowever, the difference between aliases and names is that aliases can not be explicit configured\nin moon. Instead, they are specific to a project's primary programming language, and are inferred\nbased on that context (when enabled in settings). For example, a JavaScript or TypeScript project\nwill use the `name` field from its `package.json` as the alias.\n\nBecause of this, a project can either be referenced by its name or alias, or both. Choose the\npattern that makes the most sense for your company or team!\n\n## Dependencies\n\nProjects can depend on other projects within the [workspace](/docs/concepts/workspace) to build a\n[project graph](/docs/how-it-works/action-graph), and in turn, an action graph for executing\n[tasks](/docs/concepts/task). Project dependencies are divided into 2 categories:\n\n- Explicit dependencies - These are dependencies that are explicitly defined in a project's [`moon.yml`](/docs/config/project) config file, using the [`dependsOn`](/docs/config/project#dependson) setting.\n\n- Implicit dependencies - These are dependencies that are implicitly discovered by moon when scanning the repository. How an implicit dependency is discovered is based on the project's [`language`](/docs/config/project#language) setting, and how that language's ecosystem functions.\n\n## Configuration\n\nProjects can be configured with an optional [`moon.yml`](/docs/config/project) in the project root, or\nthrough the optional workspace-level [`.moon/tasks/all.yml`](/docs/config/tasks).\n\n## /docs/concepts/query-lang\n\nSource: https://moonrepo.dev/docs/concepts/query-lang\n\n# Query language\n\nv1.3.0\n\nmoon supports an integrated query language, known as MQL, that can be used to filter and select\nprojects from the project graph, using an SQL-like syntax. MQL is primarily used by\n[`moon run`](/docs/commands/run) with the `--query` option.\n\n## Syntax\n\n### Comparisons\n\nA comparison (also known as an assignment) is an expression that defines a piece of criteria, and is\na building block of a query. This criteria maps a [field](#fields) to a value, with an explicit\ncomparison operator.\n\n#### Equals, Not equals\n\nThe equals (`=`) and not equals (`!=`) comparison operators can be used for exact value matching.\n\n```\nprojectLayer=library && language!=javascript\n```\n\nYou can also define a list of values using square bracket syntax, that will match against one of the\nvalues.\n\n```\nlanguage=[javascript, typescript]\n```\n\n#### Like, Not like\n\nThe like (`~`) and not like (`!~`) comparison operators can be used for wildcard value matching,\nusing [glob syntax](/docs/concepts/file-pattern#globs).\n\n```\nprojectSource~packages/* && tag!~*-app\n```\n\nLike comparisons can only be used on non-enum fields.\n\n### Conditions\n\nThe `&&` and `||` logical operators can be used to combine multiple comparisons into a condition.\nThe `&&` operator is used to combine comparisons into a logical AND, and the `||` operator is used\nfor logical OR.\n\n```\ntaskToolchain=system || taskToolchain=node\n```\n\nFor readability concerns, you can also use `AND` or `OR`.\n\n```\ntaskToolchain=system OR taskToolchain=node\n```\n\nMixing both operators in the same condition is not supported.\n\n### Grouping\n\nFor advanced queries and complex conditions, you can group comparisons using parentheses to create\nlogical groupings. Groups can also be nested within other groups.\n\n```\nlanguage=javascript && (taskType=test || taskType=build)\n```\n\n## Fields\n\nThe following fields can be used as criteria, and are related to [task tokens](/docs/concepts/token#variables).\n\n### `language`\n\nProgramming language the project is written in, as defined in\n[`moon.yml`](/docs/config/project#language).\n\n```\nlanguage=rust\n```\n\n### `project`\n\nName OR alias of the project.\n\n```\nproject=server\n```\n\n### `projectAlias`\n\nAlias of the project. For example, the `package.json` name.\n\n```\nprojectAlias~@scope/*\n```\n\n### `projectLayer`v1.39.0\n\nThe project layer, as defined in [`moon.yml`](/docs/config/project#layer).\n\n```\nprojectLayer=application\n```\n\n### `projectId`\n\nName of the project, as defined in [`.moon/workspace.yml`](/docs/config/workspace), or `id` in\n[`moon.yml`](/docs/config/project#id).\n\n```\nprojectId=server\n```\n\n### `projectSource`\n\nRelative file path from the workspace root to the project root, as defined in\n[`.moon/workspace.yml`](/docs/config/workspace).\n\n```\nprojectSource~packages/*\n```\n\n### `projectStack`v1.22.0\n\nThe project stack, as defined in [`moon.yml`](/docs/config/project#stack).\n\n```\nprojectStack=frontend\n```\n\n### `tag`\n\nA tag within the project, as defined in [`moon.yml`](/docs/config/project#tags).\n\n```\ntag~react-*\n```\n\n### `task`\n\nID/name of a task within the project.\n\n```\ntask=[build,test]\n```\n\n### `taskToolchain`v1.31.0\n\nThe toolchain a task will run against, as defined in [`moon.yml`](/docs/config/project).\n\n```\ntaskToolchain=node\n```\n\n### `taskType`\n\nThe [type of task](/docs/concepts/task#types), based on its configured settings.\n\n```\ntaskType=build\n```\n\n## /docs/concepts/target\n\nSource: https://moonrepo.dev/docs/concepts/target\n\n# Targets\n\nA target is a compound identifier that pairs a [scope](#common-scopes) to a [task](/docs/concepts/task),\nseparated by a `:`, in the format of `scope:task`.\n\nTargets are used by terminal commands...\n\n```\n$ moon run designSystem:build\n```\n\nAnd configurations for declaring cross-project or cross-task dependencies.\n\n```\ntasks:  build:    command: 'webpack'    deps:      - 'designSystem:build'\n```\n\n## Common scopes\n\nThese scopes are available for both running targets and configuring them.\n\n### By project\n\nThe most common scope is the project scope, which requires the name of a project, as defined in\n[`.moon/workspace.yml`](/docs/config/workspace). When paired with a task name, it will run a specific\ntask from that project.\n\n```\n# Run `lint` in project `app`$ moon run app:lint\n```\n\n### By tagv1.4.0\n\nAnother way to target projects is with the tag scope, which requires the name of a tag prefixed with\n`#`, and will run a specific task in all projects with that tag.\n\n```\n# Run `lint` in projects with the tag `frontend`$ moon run '#frontend:lint'\n```\n\ncaution\n\nBecause `#` is a special character in the terminal (is considered a comment), you'll need to wrap\nthe target in quotes, or escape it like so `\\#`.\n\n## Run scopes\n\nThese scopes are only available on the command line when running tasks with `moon run` or `moon ci`.\n\n### All projects\n\nFor situations where you want to run a specific target in all projects, for example `lint`ing, you\ncan utilize the all projects scope by omitting the project name from the target: `:lint`.\n\n```\n# Run `lint` in all projects$ moon run :lint\n```\n\n### Closest project `~`v1.33.0\n\nIf you are within a project folder, or an arbitrarily nested folder, and want to run a task in the\nclosest project (traversing upwards), the `~` scope can be used.\n\n```\n# Run `lint` in the closest project$ moon run ~:lint\n```\n\n## Config scopes\n\nThese scopes are only available when configuring a task.\n\n### Dependencies `^`\n\nWhen you want to include a reference for each project [that's depended on](/docs/concepts/project#dependencies),\nyou can utilize the `^` scope. This will be expanded to all depended on projects. If you do not\nwant all projects, then you'll need to explicitly define them.\n\nmoon.yml\n\n```\ndependsOn:  - 'apiClients'  - 'designSystem'# Configured astasks:  build:    command: 'webpack'    deps:      - '^:build'# Resolves totasks:  build:    command: 'webpack'    deps:      - 'apiClients:build'      - 'designSystem:build'\n```\n\n### Self `~`\n\nWhen referring to another task within the current project, you can utilize the `~` scope, or omit\nthe `~:` prefix altogether, which will be expanded to the current project's name. This is useful for\nsituations where the name is unknown, for example, when configuring\n[`.moon/tasks/all.yml`](/docs/config/tasks), or if you just want a shortcut!\n\n.moon/tasks/all.yml\n\n```\n# Configured astasks:  lint:    command: 'eslint'    deps:      - '~:typecheck'      # OR      - 'typecheck'  typecheck:    command: 'tsc'# Resolves to (assuming project is \"foo\")tasks:  lint:    command: 'eslint'    deps:      - 'foo:typecheck'  typecheck:    command: 'tsc'\n```\n\n## /docs/concepts/task\n\nSource: https://moonrepo.dev/docs/concepts/task\n\n# Tasks\n\nTasks are commands that are ran in the context of a [project](/docs/concepts/project). Underneath the hood, a\ntask is simply a binary or system command that is ran as a child process.\n\n## IDs\n\nA task identifier (or name) is a unique resource for locating a task within a project. The ID is\nexplicitly configured as a key within the [`tasks`](/docs/config/project#tasks) setting, and can be\nwritten in camel/kebab/snake case. IDs support alphabetic unicode characters, `0-9`, `_`, `-`, `/`,\n`.`, and must start with a character.\n\nA task ID can be paired with a scope to create a [target](/docs/concepts/target).\n\n## Types\n\nTasks are grouped into 1 of the following types based on their configured parameters.\n\n- Build - Task generates one or many artifacts, and is derived from the [`outputs`](/docs/config/project#outputs) setting.\n\n- Run - Task runs a one-off, long-running, or never-ending process, and is derived from the [`local`](/docs/config/project#local) setting.\n\n- Test - Task asserts code is correct and behaves as expected. This includes linting, typechecking, unit tests, and any other form of testing. Is the default.\n\n## Modes\n\nAlongside types, tasks can also grouped into a special mode that provides unique handling within the\naction graph and pipelines.\n\n### Local only\n\nTasks either run locally, in CI (continuous integration pipelines), or both. For tasks that should\nonly be ran locally, for example, development servers and watchers, we provide a mechanism for\nmarking a task as local only. When enabled, caching is turned off, the task will not run in CI,\nterminal output is not captured, and the task is marked as [persistent](#persistent).\n\nTo mark a task as local only, enable the [`local`](/docs/config/project#local) setting.\n\nmoon.yml\n\n```\ntasks:  dev:    command: 'start-dev-server'    preset: 'server'\n```\n\n### Internal onlyv1.23.0\n\nInternal tasks are tasks that are not meant to be ran explicitly by the user (via\n[`moon check`](/docs/commands/check) or [`moon run`](/docs/commands/run)), but are used internally as\ndependencies of other tasks. Additionally, internal tasks are not displayed in a project's tasks\nlist, but can be inspected with [`moon task`](/docs/commands/task).\n\nTo mark a task as internal, enable the [`options.internal`](/docs/config/project#internal) setting.\n\nmoon.yml\n\n```\ntasks:  prepare:    command: 'intermediate-step'    options:      internal: true\n```\n\n### Interactivev1.12.0\n\nTasks that need to interact with the user via terminal prompts are known as interactive tasks.\nBecause interactive tasks require stdin, and it's not possible to have multiple parallel running\ntasks interact with stdin, we isolate interactive tasks from other tasks in the action graph. This\nensures that only 1 interactive task is ran at a time.\n\nTo mark a task as interactive, enable the [`options.interactive`](/docs/config/project#interactive)\nsetting.\n\nmoon.yml\n\n```\ntasks:  init:    command: 'init-app'    options:      interactive: true\n```\n\n### Persistentv1.6.0\n\nTasks that never complete, like servers and watchers, are known as persistent tasks. Persistent\ntasks are typically problematic when it comes to dependency graphs, because if they run in the\nmiddle of the graph, subsequent tasks will never run because the persistent task never completes!\n\nHowever in moon, this is a non-issue, as we collect all persistent tasks within the action graph and\nrun them last as a batch. This is perfect for a few reasons:\n\n- All persistent tasks are ran in parallel, so they don't block each other.\n\n- Running both the backend API and frontend webapp in parallel is a breeze.\n\n- Dependencies of persistent tasks are guaranteed to have ran and completed.\n\nTo mark a task as persistent, enable the [`local`](/docs/config/project#local) or\n[`options.persistent`](/docs/config/project#persistent) settings.\n\nmoon.yml\n\n```\ntasks:  dev:    command: 'start-dev-server'    preset: 'server'    # OR    options:      persistent: true\n```\n\n## Configuration\n\nTasks can be configured per project through [`moon.yml`](/docs/config/project), or for many projects\nthrough [`.moon/tasks/all.yml`](/docs/config/tasks).\n\n### Commands vs Scripts\n\nA task is either a command or script, but not both. So what's the difference exactly? In the context\nof a moon task, a command is a single binary execution with optional arguments, configured with the\n[`command`](/docs/config/project#command) and [`args`](/docs/config/project#args) settings (which both\nsupport a string or array). While a script is one or many binary executions, with support for pipes\nand redirects, and configured with the [`script`](/docs/config/project#script) setting (which is only a\nstring).\n\nA command also supports merging during task inheritance, while a script does not and will always\nreplace values. Refer to the table below for more differences between the 2.\n\nCommand Script\n\nConfigured as string, array string\n\nInheritance merging ‚úÖ via `mergeArgs` option ‚ö†Ô∏è always replaces\n\nAdditional args ‚úÖ via `args` setting ‚ùå\n\nPassthrough args (from CLI) ‚úÖ ‚ùå\n\nMultiple commands (with `&&` or `;`) ‚ùå ‚úÖ\n\nPipes, redirects, etc ‚ùå ‚úÖ\n\nAlways ran in a shell ‚ùå ‚úÖ\n\nCustom platform/toolchain ‚úÖ ‚úÖ\n\n[Token](/docs/concepts/token) functions and variables ‚úÖ ‚úÖ\n\n### Inheritance\n\nView the official documentation on [task inheritance](/docs/concepts/task-inheritance).\n\n## /docs/concepts/task-inheritance\n\nSource: https://moonrepo.dev/docs/concepts/task-inheritance\n\n# Task inheritance\n\nUnlike other task runners that require the same tasks to be repeatedly defined for every project,\nmoon uses an inheritance model where tasks can be defined once at the workspace-level, and are then\ninherited by many or all projects.\n\nWorkspace-level tasks (also known as global tasks) are defined in [`.moon/tasks/**/*.yml`](/docs/config/tasks),\nand are inherited by based on conditions. However, projects are able to include, exclude, or rename\ninherited tasks using the [`workspace.inheritedTasks`](/docs/config/project#inheritedtasks) in\n[`moon.yml`](/docs/config/project).\n\n## Conditional inheritance\n\nTask inheritance is powered by the [`inheritedBy`](/docs/config/tasks#inheritedby) setting in global\ntask configurations (those in [`.moon/tasks/**/*`](/docs/config/tasks)). This setting defines conditions that a\nproject must meet in order for inheritance to occur. If the setting is not defined, or no conditions\nare defined, the configuration is inherited by all projects.\n\nThe following conditions are supported:\n\n- `file`, `files` - Inherit for projects that contain specific files.\n\n- `language`, `languages` - Inherit for projects that belong to specific [`language`](/docs/config/project#language)s.\n\n- `layer`, `layers` - Inherit for projects that belong to specific [`layer`](/docs/config/project#layer)s.\n\n- `stack`, `stacks` - Inherit for projects that belong to specific [`stack`](/docs/config/project#stack)s.\n\n- `tag`, `tags` - Inherit for projects that have specific [`tags`](/docs/config/project#tags).\n\n- `toolchain`, `toolchains` - Inherit for projects that belong to specific [`toolchains`](/docs/config/project#toolchains).\n\nOne or many conditions can be defined, and all conditions must be met for inheritance to occur. For\nexample, the following configuration will only be inherited by Node.js frontend libraries.\n\n.moon/tasks/node-frontend-library.yml\n\n```\ninheritedBy:  toolchain: 'node'  stack: 'frontend'  layer: 'library'\n```\n\nEach condition supports a single value or an array of values. For example, the previous example\ncould be rewritten to inherit for both Node.js or Deno frontend libraries.\n\n.moon/tasks/js-frontend-library.yml\n\n```\ninheritedBy:  toolchains: ['node', 'deno']  stack: 'frontend'  layer: 'library'\n```\n\n### Clauses\n\nThe `tags` and `toolchains` conditions support special clauses `and`, `or` (the default), and `not`\nfor matching more complex scenarios.\n\n```\ninheritedBy:  toolchains:    or: ['javascript', 'typescript']    not: ['ruby']  layer: 'library'\n```\n\n## Merge strategies\n\nWhen a [global task](/docs/config/tasks#tasks) and [local task](/docs/config/project#tasks) of the same\nname exist, they are merged into a single task. To accomplish this, one of many\n[merge strategies](/docs/config/project#options) can be used.\n\nMerging is applied to the parameters [`args`](/docs/config/project#args),\n[`deps`](/docs/config/project#deps), [`env`](/docs/config/project#env-1),\n[`inputs`](/docs/config/project#inputs), [`outputs`](/docs/config/project#outputs), and\n[`toolchains`](/docs/config/project#toolchains), using the [`merge`](/docs/config/project#merge),\n[`mergeArgs`](/docs/config/project#mergeargs), [`mergeDeps`](/docs/config/project#mergedeps),\n[`mergeEnv`](/docs/config/project#mergeenv), [`mergeInputs`](/docs/config/project#mergeinputs),\n[`mergeOutputs`](/docs/config/project#mergeoutputs) and\n[`mergeToolchains`](/docs/config/project#mergetoolchains) options respectively. Each of these options\nsupport one of the following strategy values.\n\n- `append` (default) - Values found in the local task are merged after the values found in the global task. For example, this strategy is useful for toggling flag arguments.\n\n- `prepend` - Values found in the local task are merged before the values found in the global task. For example, this strategy is useful for applying option arguments that must come before positional arguments.\n\n- `preserve` - Preserve the original global task values. This should rarely be used, but exists for situations where an inheritance chain is super long and complex, but we simply want to the base values. v1.29.0\n\n- `replace` - Values found in the local task entirely replaces the values in the global task. This strategy is useful when you need full control.\n\nAll 3 of these strategies are demonstrated below, with a somewhat contrived example, but you get the\npoint.\n\n```\n# Globaltasks:  build:    command:      - 'webpack'      - '--mode'      - 'production'      - '--color'    deps:      - 'designSystem:build'    inputs:      - '/webpack.config.js'    outputs:      - 'build/'# Localtasks:  build:    args: '--no-color --no-stats'    deps:      - 'reactHooks:build'    inputs:      - 'webpack.config.js'    options:      mergeArgs: 'append'      mergeDeps: 'prepend'      mergeInputs: 'replace'# Merged resulttasks:  build:    command:      - 'webpack'      - '--mode'      - 'production'      - '--color'      - '--no-color'      - '--no-stats'    deps:      - 'reactHooks:build'      - 'designSystem:build'    inputs:      - 'webpack.config.js'    outputs:      - 'build/'    options:      mergeArgs: 'append'      mergeDeps: 'prepend'      mergeInputs: 'replace'\n```\n\n## /docs/concepts/token\n\nSource: https://moonrepo.dev/docs/concepts/token\n\n# Tokens\n\nTokens are variables and functions that can be used by [`command`](/docs/config/project#command),\n[`args`](/docs/config/project#args), [`env`](/docs/config/project#env) (>= v1.12),\n[`inputs`](/docs/config/project#inputs), and [`outputs`](/docs/config/project#outputs) when configuring a\ntask. They provide a way of accessing file group paths, referencing values from other task fields,\nand referencing metadata about the project and task itself.\n\n## Functions\n\nA token function is labeled as such as it takes a single argument, starts with an `@`, and is\nformatted as `@name(arg)`. The following token functions are available, grouped by their\nfunctionality.\n\ncaution\n\nToken functions must be the only content within a value, as they expand to multiple files. When\nused in an `env` value, multiple files are joined with a comma (`,`).\n\n### File groups\n\nThese functions reference file groups by name, where the name is passed as the argument.\n\n### `@group`\n\nUsable in `args`, `env`, `inputs`, and `outputs`.\n\nThe `@group(file_group)` token is a standard token that will be replaced with the file group items\nas-is, for both file paths and globs. This token merely exists for reusability purposes.\n\n```\nfileGroups:  storybook:    - '.storybook/**/*'    - 'src/**/*'    - '**/*.stories.*'# Configured astasks:  build:    command: 'build-storybook'    inputs:      - '@group(storybook)'  start:    command: 'start-storybook'    inputs:      - '@group(storybook)'# Resolves totasks:  build:    command: 'build-storybook'    inputs:      - '/path/to/project/.storybook/**/*'      - '/path/to/project/src/**/*'      - '/path/to/project/**/*.stories.*'  start:    command: 'start-storybook'    inputs:      - '/path/to/project/.storybook/**/*'      - '/path/to/project/src/**/*'      - '/path/to/project/**/*.stories.*'\n```\n\n### `@dirs`\n\nUsable in `args`, `env`, `inputs`, and `outputs`.\n\nThe `@dirs(file_group)` token will be replaced with an expanded list of directory paths, derived\nfrom the file group of the same name. If a glob pattern is detected within the file group, it will\naggregate all directories found.\n\nwarning\n\nThis token walks the file system to verify each directory exists, and filters out those that don't.\nIf using within `outputs`, you're better off using [`@group`](#group) instead.\n\n```\nfileGroups:  lintable:    - 'src'    - 'tests'    - 'scripts'    - '*.config.js'# Configured astasks:  lint:    command: 'eslint @dirs(lintable) --color'    inputs:      - '@dirs(lintable)'# Resolves totasks:  lint:    command:      - 'eslint'      - 'src'      - 'tests'      - 'scripts'      - '--color'    inputs:      - '/path/to/project/src'      - '/path/to/project/tests'      - '/path/to/project/scripts'\n```\n\n### `@files`\n\nUsable in `args`, `env`, `inputs`, and `outputs`.\n\nThe `@files(file_group)` token will be replaced with an expanded list of file paths, derived from\nthe file group of the same name. If a glob pattern is detected within the file group, it will\naggregate all files found.\n\nwarning\n\nThis token walks the file system to verify each file exists, and filters out those that don't. If\nusing within `outputs`, you're better off using [`@group`](#group) instead.\n\n```\nfileGroups:  config:    - '*.config.js'    - 'package.json'# Configured astasks:  build:    command: 'webpack build @files(config)'    inputs:      - '@files(config)'# Resolves totasks:  build:    command:      - 'webpack'      - 'build'      - 'babel.config.js'      - 'webpack.config.js'      - 'package.json'    inputs:      - '/path/to/project/babel.config.js'      - '/path/to/project/webpack.config.js'      - '/path/to/project/package.json'\n```\n\n### `@globs`\n\nUsable in `args`, `env`, `inputs`, and `outputs`.\n\nThe `@globs(file_group)` token will be replaced with the list of glob patterns as-is, derived from\nthe file group of the same name. If a non-glob pattern is detected within the file group, it will be\nignored.\n\n```\nfileGroups:  tests:    - 'tests/**/*'    - '**/__tests__/**/*'# Configured astasks:  test:    command: 'jest --testMatch @globs(tests)'    inputs:      - '@globs(tests)'# Resolves totasks:  test:    command:      - 'jest'      - '--testMatch'      - 'tests/**/*'      - '**/__tests__/**/*'    inputs:      - '/path/to/project/tests/**/*'      - '/path/to/project/**/__tests__/**/*'\n```\n\n### `@root`\n\nUsable in `args`, `env`, `inputs`, and `outputs`.\n\nThe `@root(file_group)` token will be replaced with the lowest common directory, derived from the\nfile group of the same name. If a glob pattern is detected within the file group, it will walk the\nfile system and aggregate all directories found before reducing.\n\n```\nfileGroups:  sources:    - 'src/app'    - 'src/packages'    - 'src/scripts'# Configured astasks:  format:    command: 'prettier --write @root(sources)'    inputs:      - '@root(sources)'# Resolves totasks:  format:    command:      - 'prettier'      - '--write'      - 'src'    inputs:      - '/path/to/project/src'\n```\n\nWhen there's no directies, or too many directories, this function will return the project root\nusing `.`.\n\n### `@envs`v1.21.0\n\nUsable in `inputs`.\n\nThe `@envs(file_group)` token will be replaced with all environment variables that have been\nconfigured in the group of the provided name.\n\n```\nfileGroups:  sources:    - 'src/**/*'    - '$NODE_ENV'# Configured astasks:  build:    command: 'vite build'    inputs:      - '@envs(sources)'# Resolves totasks:  build:    command: 'vite build'    inputs:      - '$NODE_ENV'\n```\n\n### Inputs & outputs\n\n### `@in`\n\nUsable in `script` and `args` only.\n\nThe `@in(index)` token will be replaced with a single path, derived from\n[`inputs`](/docs/config/project#inputs) by numerical index. If a glob pattern is referenced by index,\nthe glob will be used as-is, instead of returning the expanded list of files.\n\n```\n# Configured astasks:  build:    command:      - 'babel'      - '--copy-files'      - '--config-file'      - '@in(1)'      - '@in(0)'    inputs:      - 'src'      - 'babel.config.js'# Resolves totasks:  build:    command:      - 'babel'      - '--copy-files'      - '--config-file'      - 'babel.config.js'      - 'src'    inputs:      - '/path/to/project/src'      - '/path/to/project/babel.config.js'\n```\n\n### `@out`\n\nUsable in `script` and `args` only.\n\nThe `@out(index)` token will be replaced with a single path, derived from\n[`outputs`](/docs/config/project#outputs) by numerical index.\n\n```\n# Configured astasks:  build:    command:      - 'babel'      - '.'      - '--out-dir'      - '@out(0)'    outputs:      - 'lib'# Resolves totasks:  build:    command:      - 'babel'      - '.'      - '--out-dir'      - 'lib'    outputs:      - '/path/to/project/lib'\n```\n\n### Miscellaneous\n\n### `@meta`v1.28.0\n\nUsable in `command`, `script`, `args`, `env`, `inputs`, and `outputs` only.\n\nThe `@meta(key)` token can be used to access project metadata and will be replaced with a value\nderived from [`project`](/docs/config/project#project) in [`moon.yml`](/docs/config/project).\n\nThe top-level fields (like `name` and `description`) will be used as-is (no quotes). If the setting\nis not defined, it will default to nothing or an empty string. For lists of values, they will be\njoined with `,`.\n\nCustom metadata defined in [`project`](/docs/config/project#project) can also be accessed by key, but\nwill return a JSON stringified value. For example, a custom string value of `example` will be\nstringified to `\"example\"` (with quotes).\n\n```\nproject:  title: 'example'  index: 123# Configured astasks:  build:    script: 'build --name @meta(title) --index @meta(index)'# Resolves totasks:  build:    script: 'build --name example --index 123'\n```\n\n## Variables\n\nA token variable is a value that starts with `$` and is substituted to a value derived from the\ncurrent workspace, project, and task. And unlike token functions, token variables can be placed\nwithin content when necessary, and supports multiple variables within the same content.\n\n### Environmentv1.30.0\n\n- `$arch` - The current host architecture, derived from the Rust [`ARCH` constant](https://doc.rust-lang.org/std/env/consts/constant.ARCH.html).\n\n- `$os` - The current operating system, derived from the Rust [`OS` constant](https://doc.rust-lang.org/std/env/consts/constant.OS.html).\n\n- `$osFamily` - The current operating system family, either `unix` or `windows`.\n\n```\n# Configured astasks:  build:    command: 'example --arch $arch'# Resolves totasks:  build:    command:      - 'example'      - '--arch'      - 'aarch64'\n```\n\n### Workspace\n\n- `$workingDir` - The current working directory.\n\n- `$workspaceRoot` - Absolute file path to the workspace root.\n\n```\n# Configured astasks:  build:    command:      - 'example'      - '--cwd'      - '$workspaceRoot'# Resolves totasks:  build:    command:      - 'example'      - '--cwd'      - '/path/to/repo'\n```\n\n### Project\n\nMost values are derived from settings in [`moon.yml`](/docs/config/project). When a setting is not\ndefined, or does not have a config, the variable defaults to \"unknown\" (for enums) or an empty\nstring.\n\n- `$language` Programming language the project is written in, as defined with [`language`](/docs/config/project#language).\n\n- `$project` - ID of the project that owns the currently running task, as defined in [`.moon/workspace.yml`](/docs/config/workspace).\n\n- `$projectAlias` - Alias of the project that owns the currently running task.\n\n- `$projectChannel` - The discussion channel for the project, as defined with [`project.channel`](/docs/config/project#channel). v1.28.0\n\n- `$projectLayer` - The project layer, as defined with [`layer`](/docs/config/project#layer). v1.39.0\n\n- `$projectTitle` - The human-readable name of the project, as defined with [`project.title`](/docs/config/project#title). v1.28.0\n\n- `$projectOwner` - The owner of the project, as defined with [`project.owner`](/docs/config/project#name). v1.28.0\n\n- `$projectRoot` - Absolute file path to the project root.\n\n- `$projectSource` - Relative file path from the workspace root to the project root, as defined in [`.moon/workspace.yml`](/docs/config/workspace).\n\n- `$projectStack` - The stack of the project, as defined with [`stack`](/docs/config/project#stack). v1.22.0\n\n```\n# Configured astasks:  build:    command: 'example debug $language'# Resolves totasks:  build:    command:      - 'example'      - 'debug'      - 'node'\n```\n\n### Task\n\n- `$target` - Fully-qualified target that is currently running.\n\n- `$task` - ID of the task that is currently running. Does not include the project ID.\n\n- `$taskToolchain` - The toolchain that task will run against, as defined in [`moon.yml`](/docs/config/project). v1.31.0\n\n- `$taskType` - The [type of task](/docs/concepts/task#types), based on its configured settings.\n\n```\n# Configured astasks:  build:    command: 'example $target'# Resolves totasks:  build:    command:      - 'example'      - 'web:build'\n```\n\n### Date/Time\n\n- `$date` - The current date in the format of `YYYY-MM-DD`.\n\n- `$datetime` - The current date and time in the format of `YYYY-MM-DD_HH:MM:SS`.\n\n- `$time` - The current time in the format of `HH:MM:SS`.\n\n- `$timestamp` - The current date and time as a UNIX timestamp in seconds.\n\n```\n# Configured astasks:  build:    command: 'example --date $date'# Resolves totasks:  build:    command:      - 'example'      - '--date'      - '2023-03-17'\n```\n\n### VCSv1.30.0\n\n- `$vcsBranch` - The current branch.\n\n- `$vcsRepository` - The repository slug, in the format of `owner/repo`.\n\n- `$vcsRevision` - The current revision (commit, etc).\n\n```\n# Configured astasks:  build:    command: 'example --branch $vcsBranch'# Resolves totasks:  build:    command:      - 'example'      - '--branch'      - 'master'\n```\n\n## /docs/concepts/toolchain\n\nSource: https://moonrepo.dev/docs/concepts/toolchain\n\n# Toolchain\n\nThe toolchain is an internal layer for downloading, installing, and managing tools (languages,\ndependency managers, libraries, and binaries) that are required at runtime. We embrace this approach\nover relying on these tools \"existing\" in the current environment, as it ensures the following\nacross any environment or machine:\n\n- The version and enabled features of a tool are identical.\n\n- Tools are isolated and unaffected by external sources.\n\n- Builds are consistent, reproducible, and hopefully deterministic.\n\nFurthermore, this avoids a developer, pipeline, machine, etc, having to pre-install all the\nnecessary tools, and to keep them in sync as time passes.\n\n## How it works\n\nThe toolchain is built around [proto](/proto), our stand-alone multi-language version manager. moon\nwill piggyback of proto's toolchain found at `~/.proto` and reuse any tools available, or download\nand install them if they're missing.\n\n### Force disabling\n\nThe `MOON_TOOLCHAIN_FORCE_GLOBALS` environment variable can be set to `true` to force moon to use\ntool binaries available on `PATH`, instead of downloading and installing them. This is useful for\npre-configured environments, like CI and Docker.\n\n```\nMOON_TOOLCHAIN_FORCE_GLOBALS=true\n```\n\nAdditionally, the name of one or many tools can be passed to this variable to only force globals for\nthose tools, and use the toolchain for the remaining tools.\n\n```\nMOON_TOOLCHAIN_FORCE_GLOBALS=node,yarn\n```\n\n## Configuration\n\nThe tools that are managed by the toolchain are configured through the\n[`.moon/toolchains.yml`](/docs/config/toolchain) file, but can be overridden in each project with\n[`moon.yml`](/docs/config/project#toolchain).\n\n### Version specification\n\nAs mentioned above, tools within the toolchain are managed by version for consistency across\nmachines. These versions are configured on a per-tool basis in\n[`.moon/toolchains.yml`](/docs/config/toolchain). So what kinds of versions are allowed?\n\n- Full versions - A full version is a semantic version that is fully specified, such as `1.2.3` or `2.0.0-rc.1`. This is the most common way to specify a version, and is preferred to avoid subtle deviations.\n\n- Partial versions - A partial version is a version that is either missing a patch number, minor number, or both, such as `1.2` or `1`. These can also be represented with requirement syntax, such as `^1.2` or `~1`. If using partials, we suggest having a major and minor number to reduce the deviation of versions across machines.\n\n- Aliases - An alias is a human-readable word that maps to a specific version. For example, `latest` or `stable` maps to the latest version of a tool, or `canary` which maps to applicable canary release, or even a completely custom alias like `berry`. Aliases are language specific, are not managed by moon, and are not suggested for use since they can change at any time (or even daily!).\n\nThis sounds great, but how exactly does this work? For full versions and aliases, it's straight\nforward, as the resolved version is used as-is (assuming it's a legitimate version), and can be\nfound at `~/.proto/tools//`.\n\nFor partial versions, we first check locally installed versions for a match, by scanning\n`~/.proto/tools/`. For example, if the requested version is `1.2` and we have `1.2.10`\ninstalled locally, we'll use that version instead of downloading the latest `1.2.*` version.\nOtherwise, we'll download the latest version that matches the partial version, and install it\nlocally.\n\n## /docs/concepts/workspace\n\nSource: https://moonrepo.dev/docs/concepts/workspace\n\n# Workspace\n\nA workspace is a directory that contains [projects](/docs/concepts/project), manages a [toolchain](/docs/concepts/toolchain),\nruns [tasks](/docs/concepts/task), and is coupled with a VCS repository. The root of a workspace is denoted by a\n`.moon` folder.\n\nBy default moon has been designed for monorepos, but can also be used for polyrepos.\n\n## Configuration\n\nConfiguration that's applied to the entire workspace is defined in\n[`.moon/workspace.yml`](/docs/config/workspace).\n\n## /docs/config\n\nSource: https://moonrepo.dev/docs/config\n\n- [Home](/)\n- [Config files](/docs/config)\n\nwarning\n\nDocumentation is currently for [moon v2](/blog/moon-v2-alpha) and latest proto. Documentation for moon v1 has been frozen and can be [found here](https://moonrepo.github.io/website-v1/).\n\n# Config files\n\n[üìÑÔ∏è OverviewSupported formats](/docs/config/overview)\n\n[üìÑÔ∏è .moon/workspaceThe .moon/workspace.yml file configures projects and services in the workspace. This file is](/docs/config/workspace)\n\n[üìÑÔ∏è .moon/extensionsThe .moon/extensions.yml file configures extensions that can hook into pipeline events, or be](/docs/config/extensions)\n\n[üìÑÔ∏è .moon/toolchainsThe .moon/toolchains.yml file configures the toolchain and the workspace development environment.](/docs/config/toolchain)\n\n[üìÑÔ∏è .moon/tasksThe .moon/tasks//* files configures file groups and tasks that are inherited by every project](/docs/config/tasks)\n\n[üìÑÔ∏è moonThe moon.yml configuration file is not required but can be used to define additional metadata](/docs/config/project)\n\n[üìÑÔ∏è templateThe template.yml file configures metadata and variables for a template,](/docs/config/template)\n\n[Workspace](/docs/concepts/workspace)\n\n[Overview](/docs/config/overview)\n\n## /docs/config/extensions\n\nSource: https://moonrepo.dev/docs/config/extensions\n\n# .moon/extensions\n\nv2.0.0\n\nThe `.moon/extensions.yml` file configures extensions that can hook into pipeline events, or be\nexecuted directly. This file is optional.\n\n## `extends`\n\nDefines one or many external `.moon/extensions.yml`'s to extend and inherit settings from. Perfect\nfor reusability and sharing configuration across repositories and projects. When defined, this\nsetting must be an HTTPS URL or relative file system path that points to a valid YAML document!\n\n.moon/extensions.yml\n\n```\nextends: 'https://raw.githubusercontent.com/organization/repository/master/.moon/extensions.yml'\n```\n\ncaution\n\nSettings will be merged recursively for blocks, with values defined in the local configuration\ntaking precedence over those defined in the extended configuration.\n\n## How it works\n\nA mapping of extensions that can be downloaded and executed with the [`moon ext`](/docs/commands/ext)\ncommand. An extension is a WASM plugin, and the location of the WASM file must be defined with the\n`plugin` field, which requires a\n[plugin locator string](/docs/guides/wasm-plugins#configuring-plugin-locations).\n\n.moon/extensions.yml\n\n```\nexample:  plugin: 'file://./path/to/example.wasm'  # or  plugin: 'https://example.com/path/to/example.wasm'\n```\n\nAdditionally, extensions support custom configuration that is passed to the WASM runtime when the\nplugin is instantiated. This configuration is defined by inserting additional fields under the\nextension name, relative to the `plugin` field. Each extension may have its own settings, so refer\nto their documentation for more information.\n\n.moon/extensions.yml\n\n```\nexample:  plugin: 'file://./path/to/example.wasm'  setting1: true  setting2: 'abc'\n```\n\n## Supported extensions\n\nView the [official guide](/docs/guides/extensions) for all built-in extensions.\n\n## /docs/config/overview\n\nSource: https://moonrepo.dev/docs/config/overview\n\n# Overview\n\n## Supported formatsv2.0.0\n\nIn moon, you can define configuration files in a variety of formats. We currently support the\nfollowing:\n\n- JSON (`.json`)\n\n- JSON with comments (`.jsonc`)\n\n- [HCL](https://github.com/hashicorp/hcl) (`.hcl`)\n\n- [Pkl](https://pkl-lang.org/) (`.pkl`)\n\n- [TOML](https://toml.io/en/) (`.toml`)\n\n- YAML (`.yml`, `.yaml`)\n\ninfo\n\nIn moon v1, only YAML (`.yml`) and Pkl (`.pkl`) configuration files were supported.\n\n## Schema validationv1.33.0\n\nWe support schema validation for all configuration files through\n[JSON Schema](https://json-schema.org/), even for formats that are not JSON (depends on tool/editor\nsupport). To reference the schema for a specific configuration file, configure the `$schema`\nproperty at the top of the file with the appropriate schema found at `.moon/cache/schemas`.\n\n- .moon/workspace\n- .moon/extensions\n- .moon/toolchains\n- .moon/tasks\n- moon\n- template\n\n.moon/workspace.yml\n\n```\n$schema: './cache/schemas/workspace.json'\n```\n\n.moon/extensions.yml\n\n```\n$schema: './cache/schemas/extensions.json'\n```\n\n.moon/toolchains.yml\n\n```\n$schema: './cache/schemas/toolchains.json'\n```\n\n.moon/tasks/all.yml\n\n```\n$schema: '../cache/schemas/tasks.json'\n```\n\nmoon.yml\n\n```\n$schema: '../path/to/.moon/cache/schemas/project.json'\n```\n\ntemplate.yml\n\n```\n$schema: '../path/to/.moon/cache/schemas/template.json'\n```\n\ninfo\n\nThe schemas are automatically created when running a task. If they do not exist yet, you can run\n[`moon sync config-schemas`](/docs/commands/sync/config-schemas) to generate them manually.\n\ndanger\n\nIn older versions of moon, the schema files were located at `https://moonrepo.dev/schemas`. These\nURLs are now deprecated, as they do not support dynamic settings. Please update your `$schema`\nreferences to point to the local schema files in `.moon/cache/schemas`.\n\n## /docs/config/project\n\nSource: https://moonrepo.dev/docs/config/project\n\n# moon\n\nThe `moon.yml` configuration file is not required but can be used to define additional metadata\nfor a project, override inherited tasks, and more at the project-level. When used, this file must\nexist in a project's root, as configured in [`projects`](/docs/config/workspace#projects).\n\n## `dependsOn`\n\nExplicitly defines other projects that this project depends on, primarily when generating the\nproject and task graphs. The most common use case for this is building those projects before\nbuilding this one. When defined, this setting requires an array of project names, which are the keys\nfound in the [`projects`](/docs/config/workspace#projects) map.\n\nmoon.yml\n\n```\ndependsOn:  - 'apiClients'  - 'designSystem'\n```\n\nA dependency object can also be defined, where a specific `scope` can be assigned, which accepts\n\"production\" (default), \"development\", \"build\", or \"peer\".\n\nmoon.yml\n\n```\ndependsOn:  - id: 'apiClients'    scope: 'production'  - id: 'designSystem'    scope: 'peer'\n```\n\nLearn more about [implicit and explicit dependencies](/docs/concepts/project#dependencies).\n\n## Metadata\n\n## `id`v1.18.0\n\nOverrides the name (identifier) of the project, which was configured in or derived from the\n[`projects`](/docs/config/workspace#projects) setting in [`.moon/workspace.yml`](/docs/config/workspace). This setting is\nuseful when using glob based project location, and want to avoid using the folder name as the\nproject name.\n\nmoon.yml\n\n```\nid: 'custom-id'\n```\n\ninfo\n\nAll references to the project must use the new identifier, including project and task dependencies.\n\n## `language`\n\nThe primary programming language the project is written in. This setting is required for\n[task inheritance](/docs/config/tasks), editor extensions, and more. Supports the following values:\n\n- `bash` - A [Bash](https://en.wikipedia.org/wiki/Bash_(Unix_shell)) based project (Unix only).\n\n- `batch` - A [Batch](https://en.wikibooks.org/wiki/Windows_Batch_Scripting)/PowerShell based project (Windows only).\n\n- `go` - A [Go](https://go.dev/) based project.\n\n- `javascript` - A [JavaScript](https://developer.mozilla.org/en-US/docs/Web/JavaScript) based project.\n\n- `php` - A [PHP](https://www.php.net) based project.\n\n- `python` - A [Python](https://www.python.org/) based project.\n\n- `ruby` - A [Ruby](https://www.ruby-lang.org/en/) based project.\n\n- `rust` - A [Rust](https://www.rust-lang.org/) based project.\n\n- `typescript` - A [TypeScript](https://www.typescriptlang.org/) based project.\n\n- `unknown` (default) - When not configured or inferred.\n\n- `*` - A custom language. Values will be converted to kebab-case.\n\nmoon.yml\n\n```\nlanguage: 'javascript'# Customlanguage: 'kotlin'\n```\n\nFor convenience, when this setting is not defined, moon will attempt to detect the language based\non configuration files found in the project root. This only applies to non-custom languages!\n\n## `owners`v1.8.0\n\nDefines ownership of source code within the current project, by mapping file system paths to owners.\nAn owner is either a user, team, or group.\n\nCurrently supports\n[GitHub](https://docs.github.com/en/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/about-code-owners),\n[GitLab](https://docs.gitlab.com/ee/user/project/codeowners/reference.html), and\n[Bitbucket](https://marketplace.atlassian.com/apps/1218598/code-owners-for-bitbucket?tab=overview&hosting=cloud)\n(via app).\n\n### `customGroups`Bitbucket\n\nWhen using the\n[Code Owners for Bitbucket](https://marketplace.atlassian.com/apps/1218598/code-owners-for-bitbucket?tab=overview&hosting=cloud)\napp, this setting provides a way to define custom groups that will be injected at the top of the\n`CODEOWNERS` file. These groups must be unique across all projects.\n\nmoon.yml\n\n```\nowners:  customGroups:    '@@@backend': ['@\"user name\"', '@@team']\n```\n\n### `defaultOwner`\n\nThe default owner for all [`paths`](#paths). This setting is optional in some cases but helps to\navoid unnecessary repetition.\n\nmoon.yml\n\n```\nowners:  defaultOwner: '@frontend'\n```\n\n### `optional`GitLab\n\nFor GitLab, marks the project's\n[code owners section](https://docs.gitlab.com/ee/user/project/codeowners/reference.html#optional-sections)\nas optional. Defaults to `false`.\n\nmoon.yml\n\n```\nowners:  optional: true\n```\n\n### `paths`\n\nThe primary setting for defining ownership of source code within the current project. This setting\nsupports 2 formats, the first being a list of file paths relative from the current project. This\nformat requires [`defaultOwner`](#defaultowner) to be defined, and only supports 1 owner for every\npath (the default owner).\n\nmoon.yml\n\n```\nowners:  defaultOwner: '@frontend'  paths:    - '**/*.ts'    - '**/*.tsx'    - '*.config.js'\n```\n\nThe second format provides far more granularity, allowing for multiple owners per path. This format\nrequires a map, where the key is a file path relative from the current project, and the value is a\nlist of owners. Paths with an empty list of owners will fallback to [`defaultOwner`](#defaultowner).\n\nmoon.yml\n\n```\nowners:  defaultOwner: '@frontend'  paths:    '**/*.rs': ['@backend']    '**/*.js': []    '*.config.js': ['@frontend', '@frontend-infra']\n```\n\nThe syntax for owners is dependent on the provider you are using for version control (GitHub,\nGitLab, Bitbucket). moon provides no validation or guarantees that these are correct.\n\n### `requiredApprovals`Bitbucket / GitLab\n\nRequires a specific number of approvals for a pull/merge request to be satisfied. Defaults to `1`.\n\n- For Bitbucket, defines the [`Check()` condition](https://docs.mibexsoftware.com/codeowners/merge-checks#MergeChecks-2.MergeChecks:HowmanyoftheseCodeOwnersneedtoapprovebeforeapullrequestcanbemerged?) when using a [`defaultOwner`](#defaultowner).\n\n- For GitLab, defines a requirement on the [code owners section](https://docs.gitlab.com/ee/user/project/codeowners/reference.html#sections-requiring-multiple-approvals).\n\nmoon.yml\n\n```\nowners:  requiredApprovals: 2\n```\n\n## `layer`\n\nThe layer within a [stack](#stack). Supports the following values:\n\n- `application` - An application of any kind.\n\n- `automation` - An automated testing suite, like E2E, integration, or visual tests. v1.16.0\n\n- `configuration` - Configuration files or infrastructure. v1.22.0\n\n- `library` - A self-contained, shareable, and publishable set of code.\n\n- `scaffolding` - Templates or generators for scaffolding. v1.22.0\n\n- `tool` - An internal tool, CLI, one-off script, etc.\n\n- `unknown` (default) - When not configured.\n\nmoon.yml\n\n```\nlayer: 'application'\n```\n\ninfo\n\nThe project layer is used in [task inheritance](/docs/concepts/task-inheritance),\n[constraints and boundaries](/docs/config/workspace#constraints), editor extensions, and more!\n\n## `project`\n\nThe `project` setting defines metadata about the project itself.\n\nmoon.yml\n\n```\nproject:  title: 'moon'  description: 'A monorepo management tool.'  channel: '#moon'  owner: 'infra.platform'  maintainers: ['miles.johnson']\n```\n\nThe information listed within `project` is purely informational and primarily displayed within the\nCLI. However, this setting exists for you, your team, and your company, as a means to identify and\norganize all projects. Feel free to build your own tooling around these settings!\n\n### `channel`\n\nThe Slack, Discord, Teams, IRC, etc channel name (with leading #) in which to discuss the project.\n\n### `description`Required\n\nA description of what the project does and aims to achieve. Be as descriptive as possible, as this\nis the kind of information search engines would index on.\n\n### `maintainers`\n\nA list of people/developers that maintain the project, review code changes, and can provide support.\nCan be a name, email, LDAP name, GitHub username, etc, the choice is yours.\n\n### `title`\n\nA human readable name of the project. This is different from the unique project name configured in\n[`projects`](/docs/config/workspace#projects).\n\n### `owner`\n\nThe team or organization that owns the project. Can be a title, LDAP name, GitHub team, etc. We\nsuggest not listing people/developers as the owner, use [maintainers](#maintainers) instead.\n\n### Custom fieldsv2.0.0\n\nAdditional fields can be configured as custom metadata to associate to this project. Supports all\nvalue types that are valid JSON.\n\nmoon.yml\n\n```\nproject:  # ...  deprecated: true\n```\n\n## `stack`v1.22.0\n\nThe technology stack this project belongs to, primarily for categorization. Supports the following\nvalues:\n\n- `backend` - Server-side APIs, etc.\n\n- `data` - Data sources, database layers, etc. v2.0.0\n\n- `frontend` - Client-side user interfaces, etc.\n\n- `infrastructure` - Cloud/server infrastructure, Docker, etc.\n\n- `systems` - Low-level systems programming.\n\n- `unknown` (default) - When not configured.\n\nmoon.yml\n\n```\nstack: 'frontend'\n```\n\ninfo\n\nThe project stack is also used in [constraints and boundaries](/docs/config/workspace#constraints)!\n\n## `tags`\n\nTags are a simple mechanism for categorizing projects. They can be used to group projects together\nfor [easier querying](/docs/commands/query/projects), enforcing of\n[project boundaries and constraints](/docs/config/workspace#constraints),\n[task inheritance](/docs/concepts/task-inheritance), and more.\n\nmoon.yml\n\n```\ntags:  - 'react'  - 'prisma'\n```\n\n## Integrations\n\n## `docker`v1.27.0\n\nConfigures Docker integration for the current project.\n\n### `file`\n\nConfigures the `Dockerfile` generation process when [`moon docker file`](/docs/commands/docker/file) is\nexecuted.\n\n#### `buildTask`\n\nThe name of a task within the current project that will be used for building the project before\nrunning it. If not defined, does nothing.\n\nmoon.yml\n\n```\ndocker:  file:    buildTask: 'build'\n```\n\n#### `image`\n\nThe Docker image to use in the base stage. Defaults to an image based on the project's toolchain, as\noutlined below.\n\n- `oven/bun:latest` for Bun\n\n- `denoland/deno:latest` for Deno\n\n- `node:latest` for Node.js\n\n- `python:latest` for Python\n\n- `rust:latest` for Rust\n\n- `scratch` for everything else\n\nmoon.yml\n\n```\ndocker:  file:    image: 'node:latest'\n```\n\n#### `startTask`\n\nThe name of a task within the current project that will run the project after it has been built (if\nrequired). This task will be used as `CMD` within the `Dockerfile`.\n\nmoon.yml\n\n```\ndocker:  file:    startTask: 'start'\n```\n\n### `scaffold`\n\nConfigures aspects of the Docker scaffolding process when\n[`moon docker scaffold`](/docs/commands/docker/scaffold) is executed. Only applies to the\n[sources skeleton](/docs/commands/docker/scaffold#sources).\n\n#### `sourcesPhaseGlobs`\n\nList of globs in which to copy project-relative files into the `.moon/docker/sources` skeleton. When\nnot defined, defaults to `**/*`.\n\nmoon.yml\n\n```\ndocker:  scaffold:    sourcesPhaseGlobs:      - 'src/**/*'\n```\n\n## Tasks\n\n## `env`\n\nThe `env` field is map of strings that are passed as environment variables to all tasks within the\ncurrent project. Project-level variables will not override task-level variables of the same name.\n\nmoon.yml\n\n```\nenv:  NODE_ENV: 'production'\n```\n\nView the task [`env`](#env-1) setting for more usage examples and information.\n\n## `fileGroups`\n\nDefines [file groups](/docs/concepts/file-group) to be used by local tasks. By default, this setting\nis not required for the following reasons:\n\n- File groups are an optional feature, and are designed for advanced use cases.\n\n- File groups defined in [`.moon/tasks/all.yml`](/docs/config/tasks) will be inherited by all projects.\n\nWhen defined this setting requires a map, where the key is the file group name, and the value is a\nlist of [globs or file paths](/docs/concepts/file-pattern), or environment variables. Globs and paths\nare [relative to a project](/docs/concepts/file-pattern#project-relative) (even when defined\n[globally](/docs/config/tasks)).\n\nmoon.yml\n\n```\n# Example groupsfileGroups:  configs:    - '*.config.{js,cjs,mjs}'    - '*.json'  sources:    - 'src/**/*'    - 'types/**/*'  tests:    - 'tests/**/*'    - '**/__tests__/**/*'  assets:    - 'assets/**/*'    - 'images/**/*'    - 'static/**/*'    - '**/*.{scss,css}'\n```\n\nOnce your groups have been defined, you can reference them within [`args`](#args),\n[`inputs`](#inputs), [`outputs`](#outputs), and more, using\n[token functions and variables](/docs/concepts/token).\n\nmoon.yml\n\n```\ntasks:  build:    command: 'vite build'    inputs:      - '@group(configs)'      - '@group(sources)'\n```\n\n## `tasks`\n\nTasks are actions that are ran within the context of a [project](/docs/concepts/project), and commonly\nwrap an npm binary or system command. This setting requires a map, where the key is a unique name\nfor the task, and the value is an object of task parameters.\n\nmoon.yml\n\n```\ntasks:  format:    command: 'prettier'  lint:    command: 'eslint'  test:    command: 'jest'  typecheck:    command: 'tsc'\n```\n\n### `extends`v1.12.0\n\nThe `extends` field can be used to extend the settings from a sibling task within the same project,\nor [inherited from the global scope](/docs/concepts/task-inheritance). This is useful for composing\nsimilar tasks with different arguments or options.\n\nWhen extending another task, the same\n[merge strategies](/docs/concepts/task-inheritance#merge-strategies) used for inheritance are applied.\n\nmoon.yml\n\n```\ntasks:  lint:    command: 'eslint .'    inputs:      - 'src/**/*'  lint-fix:    extends: 'lint'    args: '--fix'    preset: 'utility'\n```\n\n### `description`v1.22.0\n\nA human-readable description of what the task does. This information is displayed within the\n[`moon project`](/docs/commands/project) and [`moon task`](/docs/commands/task) commands.\n\nmoon.yml\n\n```\ntasks:  build:    description: 'Builds the project using Vite'    command: 'vite build'\n```\n\n### `command`\n\nThe `command` field is a single command to execute for the task, including the command binary/name\n(must be first) and any optional [arguments](#args). This field supports task inheritance and\nmerging of arguments.\n\nThis setting can be defined using a string, or an array of strings. We suggest using arrays when\ndealing with many args, or the args string cannot be parsed easily.\n\nmoon.yml\n\n```\ntasks:  format:    # Using a string    command: 'prettier --check .'    # Using an array    command:      - 'prettier'      - '--check'      - '.'\n```\n\ninfo\n\nIf you need to support pipes, redirects, or multiple commands, use [`script`](#script) instead.\nLearn more about [commands vs scripts](/docs/concepts/task#commands-vs-scripts).\n\n#### Special commands\n\nFor interoperability reasons, the following command names have special handling.\n\n- `noop`, `no-op`, `nop` - Marks the task as a \"no operation\". Will not execute a command in the action pipeline but can define dependencies.\n\n- When `toolchain` is \"bun\": `bun`, `bunx` - Uses the binaries from the toolchain.\n\n- When `toolchain` is \"deno\": Will execute with `deno` binary.\n\n- When `toolchain` is \"node\": `node`, `npm`, `pnpm`, `yarn` - Uses the binaries from the toolchain.\n\n- When `toolchain` is \"rust\": Will execute with `cargo` binary.\n\n### `args`\n\nThe `args` field is a collection of additional arguments to append to the [`command`](#command)\nwhen executing the task. This field exists purely to provide arguments for\n[inherited tasks](/docs/config/tasks#tasks).\n\nThis setting can be defined using a string, or an array of strings. We suggest using arrays when\ndealing with many args, or the args string cannot be parsed easily.\n\nmoon.yml\n\n```\ntasks:  test:    command: 'jest'    # Using a string    args: '--color --maxWorkers 3'    # Using an array    args:      - '--color'      - '--maxWorkers'      - '3'\n```\n\nHowever, for the array approach to work correctly, each argument must be its own distinct item,\nincluding argument values. For example:\n\nmoon.yml\n\n```\ntasks:  test:    command: 'jest'    args:      # Valid      - '--maxWorkers'      - '3'      # Also valid      - '--maxWorkers=3'      # Invalid      - '--maxWorkers 3'\n```\n\n### `deps`\n\nThe `deps` field is a list of other tasks (known as [targets](/docs/concepts/target)), either within\nthis project or found in another project, that will be executed before this task. It achieves this\nby generating a directed task graph based on the project graph.\n\nmoon.yml\n\n```\ntasks:  build:    command: 'webpack'    deps:      - 'apiClients:build'      - 'designSystem:build'      # A task within the current project      - 'codegen'\n```\n\n#### Args & env\n\nFurthermore, for each dependency target, you can configure additional command line arguments and\nenvironment variables that'll be passed to the dependent task when it is ran. The `args` field\nsupports a list of strings, while `env` is an object of key-value pairs.\n\nmoon.yml\n\n```\ntasks:  build:    command: 'webpack'    deps:      - target: 'apiClients:build'        args: ['--env', 'production']        env:          NODE_ENV: 'production'\n```\n\nDependencies of inherited tasks will be excluded and renamed according to the\n[`workspace.inheritedTasks`](#inheritedtasks) setting. This process only uses filters from the\ncurrent project, and not filters from dependent projects. Furthermore, `args` and `env` are not\ndeeply merged.\n\n#### Optional\n\nBy default, all dependencies are required to exist when tasks are being built and expanded, but this\nisn't always true when dealing with composition and inheritance. For dependencies that may not exist\nbased on what's inherited, you can mark it as `optional`.\n\nmoon.yml\n\n```\ntasks:  build:    command: 'webpack'    deps:      - target: 'apiClients:build'        optional: true\n```\n\n### `env`\n\nThe `env` field is map of strings that are passed as environment variables when running the command.\nVariables defined here will take precedence over those loaded with [`envFile`](#envfile).\n\nmoon.yml\n\n```\ntasks:  build:    command: 'webpack'    env:      NODE_ENV: 'production'\n```\n\nVariables also support substitution using the syntax `${VAR_NAME}`. When using substitution, only\nvariables in the current process can be referenced, and not those currently defined in `env`.\n\nmoon.yml\n\n```\ntasks:  build:    command: 'webpack'    env:      APP_TARGET: '${REGION}-${ENVIRONMENT}'\n```\n\n### `inputs`\n\nThe `inputs` field is a list of sources that calculate whether to execute this task based on the\nenvironment and files that have been touched since the last time the task has been ran. If not\ndefined or inherited, then all files within a project are considered an input (`**/*`), excluding\nroot-level tasks.\n\nInputs support the following source types:\n\n- Environment variables\n\n- Environment variable wildcards v1.22.0\n\n- Files, folders, and globs\n\n- [Token functions and variables](/docs/concepts/token)\n\nmoon.yml\n\n```\ntasks:  lint:    command: 'eslint'    inputs:      # Config files anywhere within the project      - '**/.eslintignore'      - '**/.eslintrc.js'      # Config files at the workspace root      - '/.eslintignore'      - '/.eslintrc.js'      # Tokens      - '$projectRoot'      - '@group(sources)'\n```\n\n#### Environment variables\n\nEnvironment variables can be used as inputs and must start with a `$`. Wildcard variables can use\n`*` to match any character.\n\nmoon.yml\n\n```\ntasks:  example:    inputs:      - '$FOO_CACHE'      - '$FOO_*'\n```\n\ncaution\n\nWhen using an environment variable, we assume it's not defined by default, and will trigger an\naffected state when it is defined. If the environment variable always exists, then the task will\nalways run and bypass the cache.\n\n#### File paths\n\nFile paths support\n[project and workspace relative file/folder patterns](/docs/concepts/file-pattern#project-relative).\nThey can be defined as a literal path, or a `file://` URI v1.39.0,\nor as an object with a `file` property v1.39.0. Additionally, the\nfollowing parameters are supported as a URI query or as object fields:\n\n- `content`, `match`, `matches` (`string`) - When determining affected state, will match against the file's content using the defined regex pattern, instead of relying on file existence.\n\n- `optional` (`boolean`) - When hashing and set to `true` and the file is missing, will not log a warning. When set to `false` and the file is missing, will fail with an error. Defaults to logging a warning.\n\nmoon.yml\n\n```\ntasks:  example:    inputs:      # Literal paths      - 'project/relative/file.js'      - '/workspace/relative/file.js'      # Using file protocol      - 'file://project/relative/file.js?optional'      - 'file:///workspace/relative/file.js?content=a|b|c'      # Using an object      - file: 'project/relative/file.js'        optional: true      - file: '/workspace/relative/file.js'        content: 'a|b|c'\n```\n\n#### File groupsv1.41.0\n\nA file group input will reference the defined files/globs within from a file group in the current\nproject. It can be defined with a `group://` URI, or as an object with a `group` property.\nAdditionally, the following parameters are supported as a URI query or as object fields:\n\n- `format`, `as` (`string`) - The format in which to gather the file group results. Supported values are `static` (default), `files`, `dirs`, `globs`, `envs`, and `root`.\n\nmoon.yml\n\n```\nfileGroups:  sources:    - 'src/**/*'tasks:  build:    # ...    inputs:      # Using group protocol      - 'group://sources?format=dirs'      # Using an object      - group: 'sources'        format: 'dirs'\n```\n\n#### Glob patterns\n\nGlob patterns support\n[project and workspace relative file/folder patterns](/docs/concepts/file-pattern#project-relative).\nThey can be defined as a literal path, or a `glob://` URI v1.39.0,\nor as an object with a `glob` property v1.39.0. Additionally, the\nfollowing parameters are supported as a URI query or as object fields:\n\n- `cache` (`boolean`) - When gathering inputs for hashing, defines whether the glob results should be cached for the duration of the moon process. Defaults to `true`.\n\nmoon.yml\n\n```\ntasks:  example:    inputs:      # Literal paths      - 'project/relative/file.*'      - '/workspace/relative/**/*'      # Using glob protocol      - 'glob://project/relative/file.*?cache=false'      - 'glob:///workspace/relative/**/*?cache'      # Using an object      - glob: 'project/relative/file.*'        cache: false      - glob: '/workspace/relative/**/*'\n```\n\nGlobs can also be negated by prefixing the path with `!`, which will exclude all files that match\nthe glob.\n\nmoon.yml\n\n```\ntasks:  example:    inputs:      - '!**/*.md'      - 'glob://!/workspace/relative/**/*'      - glob: '!/workspace/relative/**/*'\n```\n\nwarning\n\nGlob patterns that contain `?`, for example `*.tsx?`, cannot be used in URI format, as it conflicts\nwith the query string syntax. Use the path or object format instead.\n\ndanger\n\nBe aware that files that match the glob, but are ignored via `.gitignore` (or similar), will not\nbe considered an input. To work around this, use explicit file inputs.\n\n#### External projectsv1.41.0\n\nTasks can also depend on files and globs from other projects within the same workspace. This is\nuseful for handling cross-project relationships without needing to define explicit task\ndependencies.\n\nExternal projects can be defined as a `project://` URI, or as an object with a `project` property,\nboth of which require a project identifier, or `^` for all dependent projects. Additionally, the\nfollowing parameters are supported as a URI query or as object fields:\n\n- `group`, `fileGroup` (`id`) - The name of a file group within the external project in which file and glob patterns will be used for matching. Takes precedence over `filter`.\n\n- `filter` (`string[]`) - A list of [project relative glob patterns](/docs/concepts/file-pattern#project-relative) that will be used for matching.\n\nIf neither `group` nor `filter` are defined, all files within the external project are considered a\nmatch (`**/*`).\n\nmoon.yml\n\n```\ntasks:  example:    inputs:      # Using project protocol      - 'project://foo'      - 'project://bar?group=sources'      - 'project://baz?filter=src/**/*'      # Using an object      - project: 'foo'      - project: 'bar'        group: 'sources'      - project: 'baz'        filter: ['src/**/*']\n```\n\n### `outputs`\n\nThe `outputs` field is a list of [files and folders](/docs/concepts/file-pattern#project-relative) that\nare created as a result of executing this task, typically from a build or compilation related\ntask. Outputs are necessary for [incremental caching and hydration](/docs/concepts/cache). If you'd\nprefer to avoid that functionality, omit this field.\n\n#### File paths\n\nFile paths support\n[project and workspace relative file/folder patterns](/docs/concepts/file-pattern#project-relative).\nThey can be defined as a literal path, or a `file://` URI v1.41.0,\nor as an object with a `file` property v1.41.0. Additionally, the\nfollowing parameters are supported as a URI query or as object fields:\n\n- `optional` (`boolean`) - When archiving and set to `true` and the file is missing, will not fail with a missing output error. Defaults to `false`.\n\nmoon.yml\n\n```\ntasks:  example:    inputs:      # Literal paths      - 'build/'      # Using file protocol      - 'file://build/'      # Using an object      - file: 'build/'        optional: true\n```\n\n#### Glob patterns\n\nGlob patterns support\n[project and workspace relative file/folder patterns](/docs/concepts/file-pattern#project-relative).\nThey can be defined as a literal path, or a `glob://` URI v1.41.0,\nor as an object with a `glob` property v1.41.0. Additionally, the\nfollowing parameters are supported as a URI query or as object fields:\n\n- `optional` (`boolean`) - When archiving and set to `true` and the glob produced no results, will not fail with a missing output error. Defaults to `false`.\n\nmoon.yml\n\n```\ntasks:  example:    inputs:      # Literal paths      - 'build/**/*.js'      - '!build/internal.js'      # Using glob protocol      - 'glob://build/**/*.js'      # Using an object      - glob: 'build/**/*.js'\n```\n\nwarning\n\nGlob patterns that contain `?`, for example `*.tsx?`, cannot be used in URI format, as it conflicts\nwith the query string syntax. Use the path or object format instead.\n\ndanger\n\nWhen using globs and moon hydrates an output (a cache hit), all files not matching the glob will be\ndeleted. Ensure that all files critical for the build to function correctly are included.\n\n### `preset`v1.28.0\n\nApplies the chosen preset to the task. A preset defines a collection of task options that will be\ninherited as the default, and can then be overridden within the task itself. The following presets\nare available:\n\n- `server` [`cache`](#cache) -> Turned off\n\n- [`outputStyle`](#outputstyle) -> Set to \"stream\"\n\n- [`persistent`](#persistent) -> Turned on\n\n- [`runInCI`](#runinci) -> Turned off\n\n- `utility` v2.0.0 [`cache`](#cache) -> Turned off\n\n- [`interactive`](#interactive) -> Turned on\n\n- [`outputStyle`](#outputstyle) -> Set to \"stream\"\n\n- [`persistent`](#persistent) -> Turned off\n\n- [`runInCI`](#runinci) -> Skipped\n\nTasks named \"dev\", \"start\", or \"serve\" are marked as `server` automatically.\n\nmoon.yml\n\n```\ntasks:  dev:    command: 'webpack server'    preset: 'server'\n```\n\n### `script`v1.27.0\n\nThe `script` field is one or many commands to execute for the task, with support for pipes,\nredirects, and more. This field does not support task inheritance merging, and can only be defined\nwith a string.\n\nIf defined, will supersede [`command`](#command) and [`args`](#args).\n\nmoon.yml\n\n```\ntasks:  exec:    # Single command    script: 'cp ./in ./out'    # Multiple commands    script: 'rm -rf ./out && cp ./in ./out'    # Pipes    script: 'ps aux | grep 3000'    # Redirects    script: './gen.sh > out.json'\n```\n\ninfo\n\nIf you need to support merging during task inheritance, use [`command`](#command) instead. Learn\nmore about [commands vs scripts](/docs/concepts/task#commands-vs-scripts).\n\n### `toolchains`v1.31.0\n\nThe `toolchain` field defines additional [toolchain(s)](/docs/concepts/toolchain) the command runs on,\nwhere to locate its executable, and more. By default, moon will set to a value based on the\nproject's [`language`](#language), default [`toolchain.default`](#toolchain-1), or via detection.\n\nmoon.yml\n\n```\ntasks:  env:    command: 'printenv'    toolchains: 'system'\n```\n\nThis setting also supports multiple values.\n\nmoon.yml\n\n```\ntasks:  build:    command: 'npm run build'    toolchains: ['javascript', 'node', 'npm']\n```\n\n### `options`\n\nThe `options` field is an object of configurable options that can be used to modify the task and its\nexecution. The following fields can be provided, with merge related fields supporting all\n[merge strategies](/docs/concepts/task-inheritance#merge-strategies).\n\nmoon.yml\n\n```\ntasks:  typecheck:    command: 'tsc --noEmit'    options:      mergeArgs: 'replace'      runFromWorkspaceRoot: true\n```\n\n#### `affectedFiles`\n\nWhen enabled and the [`--affected` option](/docs/run-task#running-based-on-affected-files-only) is\nprovided, all affected files that match this task's [`inputs`](#inputs) will be passed as relative\nfile paths as command line arguments, and as a `MOON_AFFECTED_FILES` environment variable.\n\nIf there are no affected files, `.` (current directory) will be passed instead for arguments, and an\nempty value for the environment variable. This functionality can be changed with the\n[`affectedPassInputs`](#affectedpassinputs) setting.\n\nmoon.yml\n\n```\ntasks:  lint:    command: 'eslint'    options:      affectedFiles: true      # Only pass args      affectedFiles: 'args'      # Only set env var      affectedFiles: 'env'\n```\n\ncaution\n\nWhen using this option, ensure that explicit files or `.` are not present in the [`args`](#args)\nlist. Furthermore, this functionality will only work if the task's command supports an arbitrary\nlist of files being passed as arguments.\n\nThis setting also supports an object format with additional parameters. The `pass` field is\nrequired, which accepts a value described above.\n\nmoon.yml\n\n```\ntasks:  lint:    command: 'eslint'    options:      affectedFiles:        pass: 'args'\n```\n\nThe following additional parameters are supported:\n\n- `passInputsWhenNoMatch` (`boolean`) - When no affected files are found, and `pass` includes `args`, will pass all configured [`inputs`](#inputs) as relative file paths instead of `.`. Defaults to `false`.\n\n#### `allowFailure`v1.13.0\n\nAllows a task to fail without failing the entire pipeline. When enabled, the following changes\noccur:\n\n- Other tasks cannot depend on this task, as we can't ensure it's side-effect free.\n\n- For [`moon run`](/docs/commands/run), the process will not bail early and will run to completion.\n\n- For [`moon ci`](/docs/commands/ci), the process will not exit with a non-zero exit code, if the only failing tasks are allowed to fail.\n\nmoon.yml\n\n```\ntasks:  lint:    command: 'eslint'    options:      allowFailure: true\n```\n\n#### `cache`\n\nWhether to cache the task's execution result using our [smart hashing](/docs/concepts/cache#hashing)\nsystem. If disabled, will not create a cache hash, and will not persist a task's\n[outputs](#outputs). Supports the following values:\n\n- `true` (default) - Cache the task's output.\n\n- `false` - Do not cache the task's output.\n\n- `local` - Only cache locally. v1.40.0\n\n- `remote` - Only cache [remotely](/docs/guides/remote-cache). v1.40.0\n\nWe suggest disabling caching when defining cleanup tasks, one-off scripts, or file system heavy\noperations.\n\nmoon.yml\n\n```\ntasks:  clean:    command: 'rm -rf ./temp'    options:      cache: false\n```\n\n#### `cacheKey`v1.35.0\n\nA custom key to include in the cache and task hashing process. Can be used to invalidate local and\nremote caches.\n\nmoon.yml\n\n```\ntasks:  build:    command: 'some-costly-build'    options:      cacheKey: 'v1'\n```\n\n#### `cacheLifetime`v1.29.0\n\nThe lifetime in which a [cached task](#cache) will live before being marked as stale and re-running.\nThis applies to a task even if it does not produce [outputs](#outputs).\n\nThe lifetime can be configured in a human-readable string format, for example, `1 day`, `3 hr`,\n`1m`, etc. If the lifetime is not defined, the cache will live forever, or until the task inputs are\ntouched.\n\nmoon.yml\n\n```\ntasks:  build:    command: 'some-costly-build'    options:      cacheLifetime: '1 day'\n```\n\nString formats are powered by the\n[humantime](https://docs.rs/humantime/2.1.0/humantime/fn.parse_duration.html) crate.\n\n#### `envFile`\n\nA boolean or path to a `.env` file (also know as dotenv file) that defines a collection of\n[environment variables](#env-1) for the current task. Variables will be loaded on project creation,\nbut will not override those defined in [`env`](#env-1).\n\nVariables defined in the file support value substitution/expansion by wrapping the variable name in\ncurly brackets, such as `${VAR_NAME}`.\n\nmoon.yml\n\n```\ntasks:  build:    command: 'webpack'    options:      # Defaults to .env      envFile: true      # Or      envFile: '.env.production'      # Or from the workspace root      envFile: '/.env.shared'\n```\n\nWhen set to `true`, moon will load the following files in order, with later files taking precedence\nover earlier ones:\n\n- `/.env`\n\n- `/.env.local`\n\n- `.env`\n\n- `.env.local`\n\n- `.env.`\n\n- `.env..local`\n\nAdditionally, a list of file paths can also be provided. When using a list, the order of the files\nis important, as environment variables from all files will be aggregated into a single map, with\nsubsequent files taking precedence over previous ones. Once aggregated, the variables will be passed\nto the task, but will not override those defined in [`env`](#env-1).\n\nmoon.yml\n\n```\ntasks:  build:    command: 'webpack'    options:      envFile:        - '.env'        - '.env.production'\n```\n\n#### `inferInputs`v1.31.0\n\nAutomatically infer [inputs](#inputs) based on the following parameters configured within the task's\n`command`, `script`, `args`, or `env`. Defaults to `false`.\n\n- File/glob paths derived from [file group based token functions](/docs/concepts/token#file-groups).\n\n- Environment variables being substituted within a command or script.\n\nmoon.yml\n\n```\ntasks:  build:    # ...    options:      inferInputs: false\n```\n\n#### `internal`v1.23.0\n\nMarks the task as internal only. [Internal tasks](/docs/concepts/task#internal-only) can not be\nexplicitly ran on the command line, but can be depended on by other tasks.\n\nmoon.yml\n\n```\ntasks:  prepare:    # ...    options:      internal: true\n```\n\n#### `interactive`v1.12.0\n\nMarks the task as interactive. [Interactive tasks](/docs/concepts/task#interactive) run in isolation so\nthat they can interact with stdin.\n\nThis setting also disables caching, turns of CI, and other functionality, similar to the\n[`preset`](#preset) setting.\n\nmoon.yml\n\n```\ntasks:  init:    # ...    options:      interactive: true\n```\n\n#### `merge`v1.29.0\n\nThe [strategy](/docs/concepts/task-inheritance#merge-strategies) to use when merging [`args`](#args),\n[`deps`](#deps), [`env`](#env-1), [`inputs`](#inputs), and [`outputs`](#outputs) with an inherited\ntask. This option can be overridden with the field specific merge options below.\n\n#### `mergeArgs`\n\nThe [strategy](/docs/concepts/task-inheritance#merge-strategies) to use when merging the\n[`args`](#args) list with an inherited task. Defaults to \"append\".\n\n#### `mergeDeps`\n\nThe [strategy](/docs/concepts/task-inheritance#merge-strategies) to use when merging the\n[`deps`](#deps) list with an inherited task. Defaults to \"append\".\n\n#### `mergeEnv`\n\nThe [strategy](/docs/concepts/task-inheritance#merge-strategies) to use when merging the\n[`env`](#env-1) map with an inherited task. Defaults to \"append\".\n\n#### `mergeInputs`\n\nThe [strategy](/docs/concepts/task-inheritance#merge-strategies) to use when merging the\n[`inputs`](#inputs) list with an inherited task. Defaults to \"append\".\n\n#### `mergeOutputs`\n\nThe [strategy](/docs/concepts/task-inheritance#merge-strategies) to use when merging the\n[`outputs`](#outputs) list with an inherited task. Defaults to \"append\".\n\n#### `mergeToolchains`\n\nThe [strategy](/docs/concepts/task-inheritance#merge-strategies) to use when merging the\n[`toolchains`](#toolchains) list with an inherited task. Defaults to \"append\".\n\n#### `mutex`v1.24.0\n\nCreates an exclusive lock on a \"virtual resource\", preventing other tasks using the same \"virtual\nresource\" from running concurrently.\n\nIf you have many tasks that require exclusive access to a resource that can't be tracked by moon\n(like a database, an ignored file, a file that's not part of the project, or a remote resource) you\ncan use the `mutex` option to prevent them from running at the same time.\n\nmoon.yml\n\n```\ntasks:  a:    # ...    options:      mutex: 'virtual_resource_name'  # b doesn't necessarily have to be in the same project  b:    # ...    options:      mutex: 'virtual_resource_name'\n```\n\n#### `os`v1.28.0\n\nWhen defined, the task will only run on the configured operating system. For other operating\nsystems, the task becomes a no-operation. Supports the values `linux`, `macos`, and `windows`.\n\nCan be defined as a single value, or a list of values.\n\nmoon.yml\n\n```\ntasks:  build-unix:    # ...    options:      os: ['linux', 'macos']  build-windows:    # ...    options:      os: 'windows'\n```\n\n#### `outputStyle`\n\nControls how stdout/stderr is displayed when the task is ran as a transitive target. By default,\nthis setting is not defined and defers to the action pipeline, but can be overridden with one of the\nfollowing values:\n\n- `buffer` - Buffers output and displays after the task has exited (either success or failure).\n\n- `buffer-only-failure` - Like `buffer`, but only displays on failures.\n\n- `hash` - Ignores output and only displays the generated [hash](/docs/concepts/cache#hashing).\n\n- `none` - Ignores output.\n\n- `stream` - Streams output directly to the terminal. Will prefix each line of output with the target.\n\nmoon.yml\n\n```\ntasks:  test:    # ...    options:      outputStyle: 'stream'\n```\n\n#### `persistent`v1.6.0\n\nMarks the task as persistent (continuously running). [Persistent tasks](/docs/concepts/task#persistent)\nare handled differently than non-persistent tasks in the action graph. When running a target, all\npersistent tasks are ran last and in parallel, after all their dependencies have completed.\n\nThis is extremely useful for running a server (or a watcher) in the background while other tasks are\nrunning.\n\nmoon.yml\n\n```\ntasks:  dev:    # ...    options:      persistent: true\n```\n\nWe suggest using the [`preset`](#preset) setting instead, which enables this setting, amongst\nother useful settings.\n\n#### `priority`v1.35.0\n\nThe priority level determines the position of the task within the action pipeline queue. A task with\na higher priority will run sooner rather than later, while still respecting the topological order.\nSupports the following levels:\n\n- `critical`\n\n- `high`\n\n- `normal` (default)\n\n- `low`\n\nmoon.yml\n\n```\ntasks:  build:    # ...    options:      priority: 'high'\n```\n\n#### `retryCount`\n\nThe number of attempts the task will retry execution before returning a failure. This is especially\nuseful for flaky tasks. Defaults to `0`.\n\nmoon.yml\n\n```\ntasks:  test:    # ...    options:      retryCount: 3\n```\n\n#### `runDepsInParallel`\n\nWhether to run the task's direct [`deps`](#deps) in parallel or serial (in order). Defaults to\n`true`.\n\nWhen disabled, this does not run dependencies of dependencies in serial, only direct dependencies.\n\nmoon.yml\n\n```\ntasks:  start:    # ...    deps:      - '~:clean'      - '~:build'    options:      runDepsInParallel: false\n```\n\n#### `runInCI`\n\nWhether to run the task automatically in a CI (continuous integration) environment when affected by\ntouched files using the [`moon ci`](/docs/commands/ci) command. Supports the following values:\n\n- `always` - Always run in CI, regardless if affected or not. v1.31.0\n\n- `affected`, `true` (default) - Only run in CI if affected by touched files.\n\n- `false` - Never run in CI.\n\n- `only` - Only run in CI, and not locally, if affected by touched files. v1.41.0\n\n- `skip` - Skip running in CI but run locally and allow task relationships to be valid. v1.41.0\n\nmoon.yml\n\n```\ntasks:  build:    # ...    options:      runInCI: false\n```\n\n#### `runFromWorkspaceRoot`\n\nWhether to use the workspace root as the working directory when executing a task. Defaults to\n`false` and runs from the task's project root.\n\nmoon.yml\n\n```\ntasks:  typecheck:    # ...    options:      runFromWorkspaceRoot: true\n```\n\n#### `shell`\n\nWhether to run the command within a shell or not. Defaults to `true` for system toolchain or\nWindows, and `false` otherwise. The shell to run is determined by the [`unixShell`](#unixshell) and\n[`windowsShell`](#windowsshell) options respectively.\n\nmoon.yml\n\n```\ntasks:  native:    command: 'echo $SHELL'    options:      shell: true\n```\n\nHowever, if you'd like to use a different shell, or customize the shell's arguments, or have\ngranular control, you can set `shell` to false and configure a fully qualified command.\n\nmoon.yml\n\n```\ntasks:  native:    command: '/bin/zsh -c \"echo $SHELL\"'    options:      shell: false\n```\n\n#### `timeout`v1.26.0\n\nThe maximum time in seconds that the task is allowed to run, before it is force cancelled. If not\ndefined, will run indefinitely.\n\nmoon.yml\n\n```\ntasks:  build:    # ...    options:      timeout: 120\n```\n\n#### `unixShell`v1.21.0\n\nCustomize the shell to run with when on a Unix operating system. Accepts `bash`, `elvish`, `fish`,\n`ion`, `murex`, `nu`, `pwsh`, `xonsh`, or `zsh`. If not defined, will derive the shell from the\n`SHELL` environment variable, or defaults to `bash`.\n\nmoon.yml\n\n```\ntasks:  native:    command: 'echo $SHELL'    options:      unixShell: 'fish'\n```\n\n#### `windowsShell`v1.21.0\n\nCustomize the shell to run with when on a Windows operating system. Accepts `bash` (typically via\nGit), `elvish`, `fish`, `murex`, `nu`, `pwsh`, or `xonsh`. If not defined, defaults to `pwsh`.\n\nmoon.yml\n\n```\ntasks:  native:    command: 'echo $SHELL'    options:      windowsShell: 'bash'\n```\n\n## Overrides\n\nDictates how a project interacts with settings defined at the top-level.\n\n## `toolchains`\n\n### `default`v1.31.0\n\nThe default [`toolchain`](#toolchain-1) for all task's within the current project. When a task's\n`toolchain` has not been explicitly configured, the toolchain will fallback to this configured\nvalue, otherwise the toolchain will be detected from the project's environment.\n\nmoon.yml\n\n```\ntoolchains:  default: 'node'\n```\n\n### `bun`\n\nConfigures Bun for this project and overrides the top-level [`bun`](/docs/config/toolchain#bun) setting.\n\n#### `version`\n\nDefines the explicit Bun [version specification](/docs/concepts/toolchain#version-specification) to use\nwhen running tasks for this project.\n\nmoon.yml\n\n```\ntoolchains:  bun:    version: '1.0.0'\n```\n\n### `deno`\n\nConfigures Deno for this project and overrides the top-level [`deno`](/docs/config/toolchain#deno) setting.\n\n#### `version`\n\nDefines the explicit Deno [version specification](/docs/concepts/toolchain#version-specification) to\nuse when running tasks for this project.\n\nmoon.yml\n\n```\ntoolchains:  deno:    version: '1.40.0'\n```\n\n### `node`\n\nConfigures Node.js for this project and overrides the top-level [`node`](/docs/config/toolchain#node) setting.\nCurrently, only the Node.js version can be overridden per-project, not the package manager.\n\n#### `version`\n\nDefines the explicit Node.js [version specification](/docs/concepts/toolchain#version-specification) to\nuse when running tasks for this project.\n\nmoon.yml\n\n```\ntoolchains:  node:    version: '12.12.0'\n```\n\n### `python`\n\nConfigures Python for this project and overrides the top-level [`python`](/docs/config/toolchain#python)\nsetting.\n\n#### `version`\n\nDefines the explicit Python\n[version/channel specification](/docs/concepts/toolchain#version-specification) to use when running\ntasks for this project.\n\nmoon.yml\n\n```\ntoolchains:  python:    version: '3.12.0'\n```\n\n### `rust`\n\nConfigures Rust for this project and overrides the top-level [`rust`](/docs/config/toolchain#rust) setting.\n\n#### `version`\n\nDefines the explicit Rust\n[version/channel specification](/docs/concepts/toolchain#version-specification) to use when running\ntasks for this project.\n\nmoon.yml\n\n```\ntoolchains:  rust:    version: '1.68.0'\n```\n\n### `typescript`\n\n#### `includeProjectReferenceSources`v1.17.0\n\nOverrides the workspace-level\n[`includeProjectReferenceSources`](/docs/config/toolchain#includeprojectreferencesources) setting. Defaults to\nundefined.\n\nmoon.yml\n\n```\ntoolchains:  typescript:    includeProjectReferenceSources: false\n```\n\n#### `includeSharedTypes`v1.17.0\n\nOverrides the workspace-level [`includeSharedTypes`](/docs/config/toolchain#includesharedtypes) setting.\nDefaults to undefined.\n\nmoon.yml\n\n```\ntoolchains:  typescript:    includeSharedTypes: false\n```\n\n#### `routeOutDirToCache`\n\nOverrides the workspace-level [`routeOutDirToCache`](/docs/config/toolchain#routeoutdirtocache) setting.\nDefaults to undefined.\n\nmoon.yml\n\n```\ntoolchains:  typescript:    routeOutDirToCache: false\n```\n\n#### `syncProjectReferences`\n\nOverrides the workspace-level [`syncProjectReferences`](/docs/config/toolchain#syncprojectreferences) setting.\nDefaults to undefined.\n\nmoon.yml\n\n```\ntoolchains:  typescript:    syncProjectReferences: false\n```\n\n#### `syncProjectReferencesToPaths`\n\nOverrides the workspace-level\n[`syncProjectReferencesToPaths`](/docs/config/toolchain#syncprojectreferencestopaths) setting. Defaults to\nundefined.\n\nmoon.yml\n\n```\ntoolchains:  typescript:    syncProjectReferencesToPaths: false\n```\n\n## `workspace`\n\n### `inheritedTasks`\n\nProvides a layer of control when inheriting tasks from [`.moon/tasks/all.yml`](/docs/config/tasks).\n\n#### `exclude`\n\nThe optional `exclude` setting permits a project to exclude specific tasks from being inherited. It\naccepts a list of strings, where each string is the name of a global task to exclude.\n\nmoon.yml\n\n```\nworkspace:  inheritedTasks:    # Exclude the inherited `test` task for this project    exclude: ['test']\n```\n\nExclusion is applied after inclusion and before renaming.\n\n#### `include`\n\nThe optional `include` setting permits a project to only include specific inherited tasks (works\nlike an allow/white list). It accepts a list of strings, where each string is the name of a global\ntask to include.\n\nWhen this field is not defined, the project will inherit all tasks from the global project config.\n\nmoon.yml\n\n```\nworkspace:  inheritedTasks:    # Include *no* tasks (works like a full exclude)    include: []    # Only include the `lint` and `test` tasks for this project    include:      - 'lint'      - 'test'\n```\n\nInclusion is applied before exclusion and renaming.\n\n#### `rename`\n\nThe optional `rename` setting permits a project to rename the inherited task within the current\nproject. It accepts a map of strings, where the key is the original name (found in the global\nproject config), and the value is the new name to use.\n\nFor example, say we have 2 tasks in the global project config called `buildPackage` and\n`buildApplication`, but we only need 1, and since we're an application, we should omit and rename.\n\nmoon.yml\n\n```\nworkspace:  inheritedTasks:    exclude: ['buildPackage']    rename:      buildApplication: 'build'\n```\n\nRenaming occurs after inclusion and exclusion.\n\n## /docs/config/tasks\n\nSource: https://moonrepo.dev/docs/config/tasks\n\n# .moon/tasks\n\nThe `.moon/tasks/**/*` files configures file groups and tasks that are inherited by every project\nin the workspace based on inheritance conditions.\n[Learn more about task inheritance!](/docs/concepts/task-inheritance)\n\nProjects can override or merge with these settings within their respective [`moon.yml`](/docs/config/project).\n\n## `extends`\n\nDefines one or many external `.moon/tasks/all.yml`'s to extend and inherit settings from. Perfect\nfor reusability and sharing configuration across repositories and projects. When defined, this\nsetting must be an HTTPS URL or relative file system path that points to a valid YAML document!\n\n.moon/tasks/all.yml\n\n```\nextends: 'https://raw.githubusercontent.com/organization/repository/master/.moon/tasks/all.yml'\n```\n\ncaution\n\nFor map-based settings, `fileGroups` and `tasks`, entries from both the extended configuration and\nlocal configuration are merged into a new map, with the values of the local taking precedence. Map\nvalues are not deep merged!\n\n## `fileGroups`\n\nFor more information on file group configuration, refer to the\n[`fileGroups`](/docs/config/project#filegroups) section in the [`moon.yml`](/docs/config/project) doc.\n\nDefines [file groups](/docs/concepts/file-group) that will be inherited by projects, and also enables\nenforcement of organizational patterns and file locations. For example, encourage projects to place\nsource files in a `src` folder, and all test files in `tests`.\n\n.moon/tasks/all.yml\n\n```\nfileGroups:  configs:    - '*.config.{js,cjs,mjs}'    - '*.json'  sources:    - 'src/**/*'    - 'types/**/*'  tests:    - 'tests/**/*'    - '**/__tests__/**/*'  assets:    - 'assets/**/*'    - 'images/**/*'    - 'static/**/*'    - '**/*.{scss,css}'\n```\n\ninfo\n\nFile paths and globs used within a file group are relative from the inherited project's root, and\nnot the workspace root.\n\n## `implicitDeps`\n\nDefines task [`deps`](/docs/config/project#deps) that are implicitly inserted into all inherited tasks within\na project. This is extremely useful for pre-building projects that are used extensively throughout\nthe repo, or always building project dependencies. Defaults to an empty list.\n\n.moon/tasks/all.yml\n\n```\nimplicitDeps:  - '^:build'\n```\n\ninfo\n\nImplicit dependencies are always inherited, regardless of the [`mergeDeps`](/docs/config/project#mergedeps)\noption.\n\n## `implicitInputs`\n\nDefines task [`inputs`](/docs/config/project#inputs) that are implicitly inserted into all inherited tasks\nwithin a project. This is extremely useful for the \"changes to these files should always trigger a\ntask\" scenario.\n\nLike `inputs`, file paths/globs defined here are relative from the inheriting project.\n[Project and workspace relative file patterns](/docs/concepts/file-pattern#project-relative) are\nsupported and encouraged.\n\n.moon/tasks/node.yml\n\n```\nimplicitInputs:  - 'package.json'\n```\n\ninfo\n\nImplicit inputs are always inherited, regardless of the [`mergeInputs`](/docs/config/project#mergeinputs)\noption.\n\n## `inheritedBy`v2.0.0\n\nA map of conditions that must be met for the configuration within the file to be inherited by a\nproject. When this field is not defined, or is an empty map, the configuration will be inherited by\nall projects.\n\n.moon/tasks/custom.yml\n\n```\ninheritedBy:  # Project belongs to either javascript or typescript toolchain, but not the ruby toolchain  toolchains:    or: ['javascript', 'typescript']    not: ['ruby']  # And project is either a frontend or backend stack  stacks: ['frontend', 'backend']  # And project is either a library or tool layer  layers: ['library', 'tool']\n```\n\ninfo\n\nView the [official task inheritance guide](/docs/concepts/task-inheritance) for more information!\n\n## `tasks`\n\nFor more information on task configuration, refer to the [`tasks`](/docs/config/project#tasks) section in the\n[`moon.yml`](/docs/config/project) doc.\n\nAs mentioned in the link above, [tasks](/docs/concepts/task) are actions that are ran within the\ncontext of a project, and commonly wrap a command. For most workspaces, every project should have\nlinting, typechecking, testing, code formatting, so on and so forth. To reduce the amount of\nboilerplate that every project would require, this setting offers the ability to define tasks that\nare inherited by many projects within the workspace, but can also be overridden per project.\n\n.moon/tasks/all.yml\n\n```\ntasks:  format:    command: 'prettier --check .'  lint:    command: 'eslint --no-error-on-unmatched-pattern .'  test:    command: 'jest --passWithNoTests'  typecheck:    command: 'tsc --build'\n```\n\ninfo\n\nRelative file paths and globs used within a task are relative from the inherited project's root, and\nnot the workspace root.\n\n## `taskOptions`v1.20.0\n\nFor more information on task options, refer to the [`options`](/docs/config/project#options) section in the\n[`moon.yml`](/docs/config/project) doc.\n\nLike [tasks](#tasks), this setting allows you to define task options that will be inherited by all\ntasks within the configured file, and by all project-level inherited tasks. This setting is the 1st\nlink in the inheritance chain, and can be overridden within each task.\n\n.moon/tasks/all.yml\n\n```\ntaskOptions:  # Never cache builds  cache: false  # Always re-run flaky tests  retryCount: 2tasks:  build:    # ...    options:      # Override the default cache setting      cache: true\n```\n\n## /docs/config/template\n\nSource: https://moonrepo.dev/docs/config/template\n\n# template\n\nThe `template.yml` file configures metadata and variables for a template,\n[used by the generator](/docs/guides/codegen), and must exist at the root of a named template folder.\n\n## `id`v1.23.0\n\nOverrides the name (identifier) of the template, instead of inferring the name from the template\nfolder. Be aware that template names must be unique across the workspace, and across all template\nlocations that have been configured in [`generator.templates`](/docs/config/workspace#templates).\n\ntemplate.yml\n\n```\nid: 'npm-package'\n```\n\n## `title`Required\n\nA human readable title that will be displayed during the [`moon generate`](/docs/commands/generate)\nprocess.\n\ntemplate.yml\n\n```\ntitle: 'npm package'\n```\n\n## `description`Required\n\nA description of why the template exists, what its purpose is, and any other relevant information.\n\ntemplate.yml\n\n```\ndescription: |  Scaffolds the initial structure for an npm package,  including source and test folders, a package.json, and more.\n```\n\n## `destination`v1.19.0\n\nAn optional file path in which this template should be generated into. This provides a mechanism for\nstandardizing a destination location, and avoids having to manually pass a destination to\n[`moon generate`](/docs/commands/generate).\n\nIf the destination is prefixed with `/`, it will be relative from the workspace root, otherwise it\nis relative from the current working directory.\n\ntemplate.yml\n\n```\ndestination: 'packages/[name]'\n```\n\nThis setting supports [template variables](#variables) through `[varName]` syntax. Learn more in\nthe [code generation documentation](/docs/guides/codegen#interpolation).\n\n## `extends`v1.19.0\n\nOne or many other templates that this template should extend. Will deeply inherit all template files\nand variables.\n\ntemplate.yml\n\n```\nextends: ['base', 'configs']\n```\n\n## `variables`\n\nA mapping of variables that will be interpolated into all template files and file system paths when\n[rendering with Tera](https://tera.netlify.app/docs/#variables). The map key is the variable name\n(in camelCase or snake_case), while the value is a configuration object, as described with the\nsettings below.\n\ntemplate.yml\n\n```\nvariables:  name:    type: 'string'    default: ''    required: true    prompt: 'Package name?'\n```\n\n### `type`Required\n\nThe type of value for the variable. Accepts `array`, `boolean`, `string`, `object`, `number`, or\n`enum`. Floats are not supported, use strings instead.\n\nFor arrays and objects, the value of each member must be a JSON compatible type.\n\n### `internal`v1.23.0\n\nMarks a variable as internal only, which avoids the variable value being overwritten by command line\narguments.\n\n### `order`v1.23.0\n\nThe order in which the variable will be prompted to the user. By default, variables are prompted in\nthe order they are defined in the `template.yml` file.\n\n### Primitives & collections\n\nYour basic primitives: boolean, numbers, strings, and collections: arrays, objects.\n\n- array\n- boolean\n- number\n- object\n- string\n\ntemplate.yml\n\n```\nvariables:  type:    type: 'array'    prompt: 'Type?'    default: ['app', 'lib']\n```\n\ntemplate.yml\n\n```\nvariables:  private:    type: 'boolean'    prompt: 'Private?'    default: false\n```\n\ntemplate.yml\n\n```\nvariables:  age:    type: 'number'    prompt: 'Age?'    default: 0    required: true\n```\n\ntemplate.yml\n\n```\nvariables:  metadata:    type: 'object'    prompt: 'Metadata?'    default:      type: 'lib'      dev: true\n```\n\ntemplate.yml\n\n```\nvariables:  name:    type: 'string'    prompt: 'Name?'    required: true\n```\n\n### `default`Required\n\nThe default value of the variable. When `--defaults` is passed to\n[`moon generate`](/docs/commands/generate) or [`prompt`](#prompt) is not defined, the default value\nwill be used, otherwise the user will be prompted to enter a custom value.\n\n### `prompt`\n\nWhen defined, will prompt the user with a message in the terminal to input a custom value, otherwise\n[`default`](#default) will be used.\n\nFor arrays and objects, a valid JSON string must be provided as the value.\n\n### `required`\n\nMarks the variable as required during prompting only. For arrays, strings, and objects, will error\nfor empty values (`''`). For numbers, will error for zero's (`0`).\n\n### Enums\n\nAn enum is an explicit list of string values that a user can choose from.\n\ntemplate.yml\n\n```\nvariables:  color:    type: 'enum'    values: ['red', 'green', 'blue', 'purple']    default: 'purple'    prompt: 'Favorite color?'\n```\n\n### `default`\n\nThe default value of the variable. When `--defaults` is passed to\n[`moon generate`](/docs/commands/generate) or [`prompt`](#prompt) is not defined, the default value\nwill be used, otherwise the user will be prompted to enter a custom value.\n\nFor enums, the default value can be a string when [`multiple`](#multiple) is false, or a string or\nan array of strings when `multiple` is true. Furthermore, each default value must exist in the\n[`values`](#values) list.\n\ntemplate.yml\n\n```\n# Singlevariables:  color:    type: 'enum'    values: ['red', 'green', 'blue', 'purple']    default: 'purple'    prompt: 'Favorite color?'# Multiplevariables:  color:    type: 'enum'    values: ['red', 'green', 'blue', 'purple']    default: ['red', 'purple']    multiple: true    prompt: 'Favorite color?'\n```\n\n### `prompt`\n\nWhen defined, will prompt the user with a message in the terminal to input a custom value, otherwise\n[`default`](#default) will be used.\n\n### `multiple`\n\nAllows multiple values to be chosen during prompting. In the template, an array or strings will be\nrendered, otherwise when not-multiple, a single string will be.\n\n### `values`Required\n\nList of explicit values to choose from. Can either be defined with a string, which acts as a value\nand label, or as an object, which defines an explicit value and label.\n\ntemplate.yml\n\n```\nvariables:  color:    type: 'enum'    values:      - 'red'      # OR      - value: 'red'        label: 'Red üî¥'    # ...\n```\n\n## Frontmatter\n\nThe following settings are not available in `template.yml`, but can be defined as frontmatter at\nthe top of a template file. View the [code generation guide](/docs/guides/codegen#frontmatter) for more\ninformation.\n\n### `force`\n\nWhen enabled, will always overwrite a file of the same name at the destination path, and will bypass\nany prompting in the terminal.\n\n```\n---force: true---Some template content!\n```\n\n### `to`\n\nDefines a custom file path, relative from the destination root, in which to create the file. This\nwill override the file path within the template folder, and allow for conditional rendering and\nengine filters to be used.\n\n```\n{% set component_name = name | pascal_case %}---to: components/{{ component_name }}.tsx---export function {{ component_name }}() {  return\n;}\n```\n\n### `skip`\n\nWhen enabled, the template file will be skipped while writing to the destination path. This setting\ncan be used to conditionally render a file.\n\n```\n---skip: {{ name == \"someCondition\" }}---Some template content!\n```\n\n## /docs/config/toolchain\n\nSource: https://moonrepo.dev/docs/config/toolchain\n\n# .moon/toolchains\n\nThe `.moon/toolchains.yml` file configures the toolchain and the workspace development environment.\nThis file is optional.\n\nManaging tool version's within the toolchain ensures a deterministic environment across any machine\n(whether a developer, CI, or production machine).\n\n## `extends`\n\nDefines one or many external `.moon/toolchains.yml`'s to extend and inherit settings from. Perfect\nfor reusability and sharing configuration across repositories and projects. When defined, this\nsetting must be an HTTPS URL or relative file system path that points to a valid YAML document!\n\n.moon/toolchains.yml\n\n```\nextends: 'https://raw.githubusercontent.com/organization/repository/master/.moon/toolchains.yml'\n```\n\ncaution\n\nSettings will be merged recursively for blocks, with values defined in the local configuration\ntaking precedence over those defined in the extended configuration.\n\n## `moon`v1.29.0\n\nConfigures how moon will receive information about latest releases and download locations.\n\n### `manifestUrl`\n\nDefines an HTTPS URL in which to fetch the current version information from.\n\n.moon/toolchains.yml\n\n```\nmoon:  manifestUrl: 'https://proxy.corp.net/moon/version'\n```\n\n### `downloadUrl`\n\nDefines an HTTPS URL in which the moon binary can be downloaded from. The download file name is\nhard-coded and will be appended to the provided URL.\n\nDefaults to downloading from GitHub: [https://github.com/moonrepo/moon/releases](https://github.com/moonrepo/moon/releases)\n\n.moon/toolchains.yml\n\n```\nmoon:  downloadUrl: 'https://github.com/moonrepo/moon/releases/latest/download'\n```\n\n## `proto`v1.39.0\n\nConfigures how moon integrates with and utilizes [proto](/proto).\n\n### `version`\n\nThe version of proto to install and run toolchains with. If proto or this version of proto has not\nbeen installed yet, it will be installed automatically when running a task.\n\n.moon/toolchains.yml\n\n```\nproto:  version: '0.51.0'\n```\n\n## Go\n\n## `go`v1.38.0\n\nRun `moon toolchain info go` for all available settings.\n\n## JavaScript\n\n## `javascript`v1.40.0\n\nRun `moon toolchain info javascript` for all available settings.\n\n## `bun`v1.40.0\n\nRun `moon toolchain info bun` for all available settings.\n\ninfo\n\nThis toolchain requires the [`javascript`](#javascript) toolchain to also be enabled.\n\n## `deno`v1.41.0\n\nRun `moon toolchain info deno` for all available settings.\n\ninfo\n\nThis toolchain requires the [`javascript`](#javascript) toolchain to also be enabled.\n\n## `node`v1.40.0\n\nRun `moon toolchain info node` for all available settings.\n\ninfo\n\nThis toolchain requires the [`javascript`](#javascript) toolchain to also be enabled.\n\n## `npm`v1.40.0\n\nRun `moon toolchain info npm` for all available settings.\n\ninfo\n\nThis toolchain requires the [`node`](#node) toolchain to also be enabled.\n\n## `pnpm`v1.40.0\n\nRun `moon toolchain info pnpm` for all available settings.\n\ninfo\n\nThis toolchain requires the [`node`](#node) toolchain to also be enabled.\n\n## `yarn`v1.40.0\n\nRun `moon toolchain info yarn` for all available settings.\n\ninfo\n\nThis toolchain requires the [`node`](#node) toolchain to also be enabled.\n\n## `typescript`\n\nRun `moon toolchain info typescript` for all available settings.\n\n## Pythonv1.30.0\n\ncaution\n\nPython support is currently a work in progress for v2!\n\n## `python`\n\nRun `moon toolchain info python` for all available settings.\n\n## Rust\n\n## `rust`v1.37.0\n\nRun `moon toolchain info rust` for all available settings.\n\n## /docs/config/workspace\n\nSource: https://moonrepo.dev/docs/config/workspace\n\n# .moon/workspace\n\nThe `.moon/workspace.yml` file configures projects and services in the workspace. This file is\nrequired.\n\n## `extends`\n\nDefines one or many external `.moon/workspace.yml`'s to extend and inherit settings from. Perfect\nfor reusability and sharing configuration across repositories and projects. When defined, this\nsetting must be an HTTPS URL or relative file system path that points to a valid YAML document!\n\n.moon/workspace.yml\n\n```\nextends: 'https://raw.githubusercontent.com/organization/repository/master/.moon/workspace.yml'\n```\n\ninfo\n\nSettings will be merged recursively for blocks, with values defined in the local configuration\ntaking precedence over those defined in the extended configuration. However, the `projects` setting\ndoes not merge!\n\n## `projects`Required\n\nDefines the location of all [projects](/docs/concepts/project) within the workspace. Supports either a\nmanual map of projects (default), a list of globs in which to automatically locate projects, or\nboth.\n\ncaution\n\nProjects that depend on each other and form a cycle must be avoided! While we do our best to avoid\nan infinite loop and disconnect nodes from each other, there's no guarantee that tasks will run in\nthe correct order.\n\n### Using a map\n\nWhen using a map, each project must be manually configured and requires a unique\n[name](/docs/concepts/project#names) as the map key, where this name is used heavily on the command\nline and within the project graph for uniquely identifying the project amongst all projects. The map\nvalue (known as the project source) is a file system path to the project folder, relative from the\nworkspace root, and must be contained within the workspace boundary.\n\n.moon/workspace.yml\n\n```\nprojects:  admin: 'apps/admin'  apiClients: 'packages/api-clients'  designSystem: 'packages/design-system'  web: 'apps/web'\n```\n\n### Using globs\n\nIf manually mapping projects is too tedious or cumbersome, you may provide a list of\n[globs](/docs/concepts/file-pattern#globs) to automatically locate all project folders, relative from\nthe workspace root.\n\nWhen using this approach, the project name is derived from the project folder name, and is cleaned\nto our [supported characters](/docs/concepts/project#names), but can be customized with the\n[`id`](/docs/config/project#id) setting in [`moon.yml`](/docs/config/project). Furthermore, globbing does risk the\nchance of collision, and when that happens, we log a warning and skip the conflicting project from\nbeing configured in the project graph.\n\n.moon/workspace.yml\n\n```\nprojects:  - 'apps/*'  - 'packages/*'  # Only shared folders with a moon configuration  - 'shared/*/moon.yml'\n```\n\n### Using a map and globs\n\nFor those situations where you want to use both patterns, you can! The list of globs can be\ndefined under a `globs` field, while the map of projects under a `sources` field.\n\n.moon/workspace.yml\n\n```\nprojects:  globs:    - 'apps/*'    - 'packages/*'  sources:    www: 'www'\n```\n\nAdditionally, you can customize the format of project IDs for glob discovered projects. By default\nit inherits the fodler name, but this has a high chance of collision. Instead you can configure\n`globFormat` to use a different format, for example, using the full workspace relative path as the\nproject ID.\n\n.moon/workspace.yml\n\n```\nprojects:  globFormat: 'source-path'  globs:    - 'packages/**/moon.yml'\n```\n\n## `defaultProject`v2.0.0\n\nDefines the default project to focus on when no project scope is specified on the command line for\ntask targets.\n\n.moon/workspace.yml\n\n```\ndefaultProject: 'web'\n```\n\n## `codeowners`v1.8.0\n\nConfigures code owners (`CODEOWNERS`) integration across the entire workspace.\n\n### `globalPaths`\n\nThis setting defines file patterns and their owners at the workspace-level, and are applied to any\nmatching path, at any depth, within the entire workspace. This is useful for defining global or\nfallback owners when a granular [project-level path](/docs/config/project#paths) does not match or exist.\n\n.moon/workspace.yml\n\n```\ncodeowners:  globalPaths:    '*': ['@admins']    'config/': ['@infra']    '/.github/': ['@infra']\n```\n\n### `orderBy`\n\nThe order in which code owners, grouped by project, are listed in the `CODEOWNERS` file. Accepts\n\"file-source\" (default) or \"project-id\".\n\n.moon/workspace.yml\n\n```\ncodeowners:  orderBy: 'project-id'\n```\n\n### `sync`\n\nWill automatically generate a `CODEOWNERS` file by aggregating and syncing all project\n[`owners`](/docs/config/project#owners) in the workspace when a [target is run](/docs/concepts/target). The format\nand location of the `CODEOWNERS` file is based on the [`vcs.provider`](#provider) setting. Defaults\nto `false`.\n\n.moon/workspace.yml\n\n```\ncodeowners:  sync: true\n```\n\n## `constraints`\n\nConfigures constraints between projects that are enforced during project graph generation. This is\nalso known as project boundaries.\n\n### `enforceLayerRelationships`\n\nEnforces allowed relationships between a project and its dependencies based on the project's\n[`layer`](/docs/config/project#layer) and [`stack`](/docs/config/project#stack) settings. When a project depends on\nanother project of an invalid layer, a layering violation error will be thrown when attempting to\nrun a task.\n\nLayers are allowed to depend on lower layers in the same stack, but not higher layers. Additionally,\nlayers may depend on itself, excluding automations and applications. The following layers are\nstacked as such:\n\nLayer Description\n\n`automation` An automated testing suite, like E2E, integration, or visual tests.\n\n`application` An application of any kind.\n\n`tool` An internal tool, CLI, one-off script, etc.\n\n`library` A self-contained, shareable, and publishable set of code.\n\n`scaffolding` Templates or generators for scaffolding.\n\n`configuration` Configuration files or infrastructure.\n\n`unknown` When not configured.\n\nWhen the project `stack` setting is defined, it alters these rules to allow these kinds of\nrelationships. For example, a frontend application can depend on a backend application, but not\nanother frontend application.\n\n.moon/workspace.yml\n\n```\nconstraints:  enforceLayerRelationships: false\n```\n\nProjects with an unconfigured or unknown layer are ignored during enforcement.\n\n### `tagRelationships`\n\nEnforces allowed relationships between a project and its dependencies based on the project's\n[`tags`](/docs/config/project#tags) setting. This works in a similar fashion to `enforceLayerRelationships`,\nbut gives you far more control over what these relationships look like.\n\nFor example, let's enforce that Next.js projects using the `next` tag can only depend on React\nprojects using the `react` tag. If a dependency does not have one of the configured required tags,\nin this case `react`, an error will occur.\n\n.moon/workspace.yml\n\n```\nconstraints:  tagRelationships:    next: ['react']\n```\n\nOn the project side, we would configure [`moon.yml`](/docs/config/project#tags) like so:\n\napp/moon.yml\n\n```\ntags: ['next']dependsOn: ['components']\n```\n\npackages/components/moon.yml\n\n```\ntags: ['react']\n```\n\n## `docker`v1.27.0\n\nConfigures Docker integration for the entire workspace.\n\n### `prune`\n\nConfigures aspects of the Docker pruning process when\n[`moon docker prune`](/docs/commands/docker/prune) is executed.\n\n#### `deleteVendorDirectories`\n\nAutomatically delete vendor directories (package manager dependencies, build targets, etc) while\npruning. For example, `node_modules` for JavaScript, or `target` for Rust. Defaults to `true`.\n\n.moon/workspace.yml\n\n```\ndocker:  prune:    deleteVendorDirectories: false\n```\n\nThis process happens before toolchain dependencies are installed.\n\n#### `installToolchainDependencies`\n\nAutomatically install production dependencies for all required toolchain's of the focused projects\nwithin the Docker build. For example, `node_modules` for JavaScript. Defaults to `true`.\n\n.moon/workspace.yml\n\n```\ndocker:  prune:    installToolchainDependencies: false\n```\n\nThis process happens after vendor directories are deleted.\n\n### `scaffold`\n\nConfigures aspects of the Docker scaffolding process when\n[`moon docker scaffold`](/docs/commands/docker/scaffold) is executed. Only applies to the\n[workspace skeleton](/docs/commands/docker/scaffold#workspace).\n\n#### `configsPhaseGlobs`\n\nList of globs in which to copy additional workspace-relative files into the `.moon/docker/workspace`\nskeleton. When not defined, does nothing.\n\n.moon/workspace.yml\n\n```\ndocker:  scaffold:    configsPhaseGlobs:      - '**/package.json'\n```\n\n## `experiments`v1.11.0\n\nEnable or disable experiments that alter core functionality.\n\nwarning\n\nExperiments are a work in progress and may be buggy. Please report any issues you encounter!\n\n### `fasterGlobWalk`v1.34.0\n\nUtilizes a new concurrent glob walking implementation that is on average, 1.5-2x faster than the\ncurrent implementation. Additionally, common globs are now cached for the duration of the process.\nDefaults to `true`.\n\n.moon/workspace.yml\n\n```\nexperiments:  fasterGlobWalk: true\n```\n\n### `gitV2`v1.34.0\n\nUtilizes a Git implementation, that has better support for submodules, subtrees, and workspaces.\nAdditionally, processes are parallized when applicable. Defaults to `true`.\n\n.moon/workspace.yml\n\n```\nexperiments:  gitV2: true\n```\n\n## `generator`\n\nConfigures aspects of the template generator.\n\n### `templates`\n\nA list of paths in which templates can be located. Supports the following types of paths, and\ndefaults to `./templates`.\n\n- File system paths, relative from the workspace root.\n\n- Git repositories and a revision, prefixed with `git://`. v1.23.0\n\n- npm packages and a version, prefixed with `npm://`. v1.23.0\n\n.moon/workspace.yml\n\n```\ngenerator:  templates:    - './templates'    - 'file://./other/templates'    - 'git://github.com/moonrepo/templates#master'    - 'npm://@moonrepo/templates#1.2.3'\n```\n\nLearn more about this in the official\n[code generation guide](/docs/guides/codegen#configuring-template-locations)!\n\n## `hasher`\n\nConfigures aspects of the smart hashing layer.\n\n### `ignoreMissingPatterns`v1.10.0\n\nWhen [`hasher.warnOnMissingInputs`](#warnonmissinginputs) is enabled, moon will log a warning to the\nterminal that an input is missing. This is useful for uncovering misconfigurations, but can be quite\nnoisy when inputs are truly optional.\n\nTo ignore warnings for missing inputs, a list of [glob patterns](/docs/concepts/file-pattern#globs) can\nbe configured to filter and ignore files. Files are matched against workspace relative paths, so\nprefixing patterns with `**/` is suggested.\n\n.moon/workspace.yml\n\n```\nhasher:  ignoreMissingPatterns:    - '**/.eslintrc.*'    - '**/*.config.*'\n```\n\n### `ignorePatterns`v1.10.0\n\nA list of [glob patterns](/docs/concepts/file-pattern#globs) used to filter and ignore files during the\ninputs hashing process. Files are matched against workspace relative paths, so prefixing patterns\nwith `**/` is suggested.\n\n.moon/workspace.yml\n\n```\nhasher:  ignorePatterns:    - '**/*.png'\n```\n\n### `optimization`\n\nDetermines the optimization level to utilize when hashing content before running targets.\n\n- `accuracy` (default) - When hashing dependency versions, utilize the resolved value in the lockfile. This requires parsing the lockfile, which may reduce performance.\n\n- `performance` - When hashing dependency versions, utilize the value defined in the manifest. This is typically a version range or requirement.\n\n.moon/workspace.yml\n\n```\nhasher:  optimization: 'performance'\n```\n\n### `walkStrategy`\n\nDefines the file system walking strategy to utilize when discovering inputs to hash.\n\n- `glob` - Walks the file system using glob patterns.\n\n- `vcs` (default) - Calls out to the [VCS](#vcs) to extract files from its working tree.\n\n.moon/workspace.yml\n\n```\nhasher:  walkStrategy: 'glob'\n```\n\n### `warnOnMissingInputs`\n\nWhen enabled, will log warnings to the console when attempting to hash an input that does not exist.\nThis is useful in uncovering misconfigured tasks. Defaults to `true`.\n\n.moon/workspace.yml\n\n```\nhasher:  warnOnMissingInputs: false\n```\n\n## `notifier`\n\nConfigures how moon notifies and interacts with a developer or an external system.\n\n### `terminalNotifications`v1.38.0\n\nWhen defined, will display OS notifications for action pipeline events when running commands from a\nterminal. Supports the following values:\n\n- `always` - Display on pipeline success and failure.\n\n- `failure` - Display on pipeline failure only.\n\n- `success` - Display on pipeline success only.\n\n- `task-failure` - Display for each task failure.\n\n.moon/workspace.yml\n\n```\nnotifier:  terminalNotifications: 'always'\n```\n\n### `webhookUrl`\n\nDefines an HTTPS URL that all pipeline events will be posted to. View the\n[webhooks guide for more information](/docs/guides/webhooks) on available events.\n\n.moon/workspace.yml\n\n```\nnotifier:  webhookUrl: 'https://api.company.com/some/endpoint'\n```\n\n### `acknowledge`\n\nWhen enabled, webhook notifier will wait for request result and validates the return code for 2xx.\nDefaults to `false`.\n\nwarning\n\nActivating this setting will slow down your pipeline, because every webhook request will be\nevaluated!\n\n.moon/workspace.yml\n\n```\nnotifier:  webhookUrl: 'https://api.company.com/some/endpoint'  webhookAcknowledge: true\n```\n\n## `pipeline`\n\nConfigures aspects of task running and the action pipeline.\n\n### `autoCleanCache`v1.24.0\n\nAutomatically cleans cached artifacts older than [`cacheLifetime`](#cachelifetime) from the cache\ndirectory (`.moon/cache`) after every run. This is useful for keeping the cache directory lean.\nDefaults to `true`.\n\n.moon/workspace.yml\n\n```\npipeline:  autoCleanCache: false\n```\n\n### `cacheLifetime`\n\nThe maximum lifetime of cached artifacts before they're marked as stale and automatically removed by\nthe action pipeline. Defaults to \"7 days\". This field requires an integer and a timeframe unit that\ncan be [parsed as a duration](https://docs.rs/humantime/2.1.0/humantime/fn.parse_duration.html).\n\n.moon/workspace.yml\n\n```\npipeline:  cacheLifetime: '24 hours'\n```\n\n### `inheritColorsForPipedTasks`\n\nForce colors to be inherited from the current terminal for all tasks that are ran as a child process\nand their output is piped to the action pipeline. Defaults to `true`.\n[View more about color handling in moon](/docs/commands/overview#colors).\n\n.moon/workspace.yml\n\n```\npipeline:  inheritColorsForPipedTasks: true\n```\n\n### `installDependencies`v1.34.0\n\nWhen enabled, runs the\n[`InstallWorkspaceDeps` and `InstallProjectDeps` actions](/docs/how-it-works/action-graph#install-dependencies)\nwithin the pipeline before running an applicable task. Installation is determined based on changed\nmanifests and lockfiles. Defaults to `true`.\n\n.moon/workspace.yml\n\n```\npipeline:  installDependencies: false\n```\n\nInstead of a boolean, a list of toolchain IDs can be provided to only allow those toolchains to\ninstall dependencies.\n\n.moon/workspace.yml\n\n```\npipeline:  installDependencies: ['node']\n```\n\n### `killProcessThreshold`v1.32.1\n\nThreshold in milliseconds in which to force kill running child processes after the pipeline receives\nan external signal (like `SIGINT` or `SIGTERM`). A value of 0 will not kill the process and let them\nrun to completion. Defaults to `2000` (2 seconds).\n\n.moon/workspace.yml\n\n```\npipeline:  killProcessThreshold: 5000\n```\n\n### `logRunningCommand`\n\nWhen enabled, will log the task's command, resolved arguments, and working directory when a target\nis ran. Defaults to `false`.\n\n.moon/workspace.yml\n\n```\npipeline:  logRunningCommand: true\n```\n\n### `syncProjects`v1.34.0\n\nWhen enabled, runs the [`SyncProject` action](/docs/how-it-works/action-graph#sync-project) within the\npipeline before running an applicable task. Defaults to `true`.\n\n.moon/workspace.yml\n\n```\npipeline:  syncProjects: false\n```\n\nInstead of a boolean, a list of project IDs can be provided to only sync those projects.\n\n.moon/workspace.yml\n\n```\npipeline:  syncProjects: ['app']\n```\n\nThe [`moon sync projects`](/docs/commands/sync/projects) command can be executed to manually sync\nprojects.\n\n### `syncWorkspace`v1.34.0\n\nWhen enabled, runs the [`SyncWorkspace` action](/docs/how-it-works/action-graph#sync-workspace) within\nthe pipeline before all other actions. This syncing includes operations such as codeowners, VCS\nhooks, and more. Defaults to `true`.\n\n.moon/workspace.yml\n\n```\npipeline:  syncWorkspace: false\n```\n\nThe [`moon sync ...`](/docs/commands/sync) sub-commands can be executed to manually sync features.\n\n## `remote`v1.30.0\n\nConfigures a remote service, primarily for cloud-based caching of artifacts. Learn more about this\nin the [remote caching](/docs/guides/remote-cache) guide.\n\n### `api`v1.32.0\n\nThe API format of the remote server. This format dictates which type of client moon uses for\ncommunicating with. Supports the following:\n\n- `grpc` (default) - Uses the gRPC API: [https://github.com/bazelbuild/remote-apis](https://github.com/bazelbuild/remote-apis)\n\n- `http` - Uses the HTTP API: [https://bazel.build/remote/caching#http-caching](https://bazel.build/remote/caching#http-caching)\n\n.moon/workspace.yml\n\n```\nremote:  api: 'grpc'\n```\n\n### `auth`v1.32.0\n\nConfigures authorization and authentication level features of our remote clients.\n\n#### `headers`v1.32.0\n\nA mapping of HTTP headers to include in all requests to the remote server. These headers are applied\nto all [API formats and protocols](#api), not just HTTP.\n\n.moon/workspace.yml\n\n```\nremote:  auth:    headers:      'X-Custom-Header': 'value'\n```\n\n#### `token`v1.32.0\n\nThe name of an environment variable in which to extract a token for\n[Bearer HTTP authorization](https://swagger.io/docs/specification/v3_0/authentication/bearer-authentication/).\nAn `Authorization` HTTP header will be included in all requests to the remote server.\n\nIf the token does not exist, or is not enabled, remote caching will be disabled.\n\n.moon/workspace.yml\n\n```\nremote:  auth:    token: 'ENV_VAR_NAME'\n```\n\n### `cache`\n\nConfigures aspects of the caching layer, primarily the action cache (AC) and content addressable\ncache (CAS).\n\n#### `compression`v1.31.0\n\nThe compression format to use when uploading/downloading blobs. Supports `none` and `zstd`, and\ndefaults to no compression (`identity` format in RE API).\n\n.moon/workspace.yml\n\n```\nremote:  cache:    compression: 'zstd'\n```\n\ninfo\n\nCompression is only applied to gRPC based APIs, not HTTP.\n\n#### `instanceName`\n\nA\n[unique identifier](https://github.com/bazelbuild/remote-apis/blob/main/build/bazel/remote/execution/v2/remote_execution.proto#L223)\nused to distinguish between the various instances on the host. This allows the same remote service\nto serve and partition multiple moon repositories. Defaults to `moon-outputs`.\n\n.moon/workspace.yml\n\n```\nremote:  cache:    instanceName: 'custom-dir-name'\n```\n\nWe suggest changing the instance name to the name of your repository!\n\n#### `localReadOnly`v1.40.0\n\nWhen enabled and developing locally, existing remote blobs will only be downloaded, but new local\nblobs will not be uploaded. Blobs will only be uploaded in CI environments.\n\n.moon/workspace.yml\n\n```\nremote:  cache:    localReadOnly: true\n```\n\n#### `verifyIntegrity`v1.36.0\n\nWhen downloading blobs, verify the digests/hashes in the response match the associated blob\ncontents. This will reduce performance but ensure partial or corrupted blobs won't cause failures.\nDefaults to `false`.\n\n.moon/workspace.yml\n\n```\nremote:  cache:    verifyIntegrity: true\n```\n\n### `host`\n\nThe host URL to communicate with when uploading and downloading artifacts. Supports both\n`grpc(s)://` and `http(s)://` protocols. This field is required!\n\n.moon/workspace.yml\n\n```\nremote:  host: 'grpcs://your-host.com:9092'\n```\n\n### `mtls`\n\nConnect to the host using server and client authentication with mTLS. This takes precedence over\nnormal TLS.\n\n.moon/workspace.yml\n\n```\nremote:  # ...  mtls:    caCert: 'certs/ca.pem'    clientCert: 'certs/client.pem'    clientKey: 'certs/client.key'    domain: 'your-host.com'\n```\n\n#### `assumeHttp2`\n\nIf true, assume that the host supports HTTP/2, even if it doesn't provide protocol negotiation via\nALPN.\n\n#### `caCert`\n\nA file path, relative from the workspace root, to the certificate authority PEM encoded X509\ncertificate (typically `ca.pem`).\n\n#### `clientCert`\n\nA file path, relative from the workspace root, to the client's PEM encoded X509 certificate\n(typically `client.pem`).\n\n#### `clientKey`\n\nA file path, relative from the workspace root, to the client's PEM encoded X509 private key\n(typically `client.key`).\n\n#### `domain`\n\nThe domain name in which to verify the TLS certificate.\n\n### `tls`\n\nConnect to the host using server-only authentication with TLS.\n\n.moon/workspace.yml\n\n```\nremote:  # ...  tls:    cert: 'certs/ca.pem'    domain: 'your-host.com'\n```\n\n#### `assumeHttp2`\n\nIf true, assume that the host supports HTTP/2, even if it doesn't provide protocol negotiation via\nALPN.\n\n#### `cert`\n\nA file path, relative from the workspace root, to the certificate authority PEM encoded X509\ncertificate (typically `ca.pem`).\n\n#### `domain`\n\nThe domain name in which to verify the TLS certificate.\n\n## `telemetry`\n\nWhen enabled, will check for a newer moon version and send anonymous usage data to the moonrepo\nteam. This data is used to improve the quality and reliability of the tool. Defaults to `true`.\n\n.moon/workspace.yml\n\n```\ntelemetry: false\n```\n\n## `vcs`\n\nConfigures the version control system to utilize within the workspace (and repository). A VCS is\nrequired for determining touched (added, modified, etc) files, calculating file hashes, computing\naffected files, and much more.\n\n### `defaultBranch`\n\nDefines the default branch in the repository for comparing differences against. For git, this is\ntypically \"master\" (default) or \"main\".\n\n.moon/workspace.yml\n\n```\nvcs:  defaultBranch: 'master'\n```\n\n### `hooks`v1.9.0\n\nDefines a mapping of hooks to a list of commands to run when that event is triggered. There are no\nrestrictions to what commands can be run, but the binaries for each command must exist on each\nmachine that will be running hooks.\n\nFor Git, each [hook name](https://git-scm.com/docs/githooks#_hooks) must be a valid kebab-cased\nname. [Learn more about Git hooks](https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks).\n\n.moon/workspace.yml\n\n```\nvcs:  hooks:    pre-commit:      - 'moon run :lint :format --affected --status=staged --no-bail'      - 'another-command'\n```\n\ninfo\n\nIf running `moon` commands directly, the `moon` binary must be installed globally!\n\n### `hookFormat`v1.29.0\n\nThe shell and file type in which generated hook files are formatted with. Supports the following:\n\n- `native` (default) - The format native to the current operating system. Bash on Unix, and PowerShell on Windows.\n\n- `bash` - Forces the format to Bash for all operating systems.\n\n.moon/workspace.yml\n\n```\nvcs:  hookFormat: 'bash'\n```\n\n### `client`\n\nDefines the VCS tool/binary that is being used for managing the repository. Accepts \"git\" (default).\nExpect more version control systems in the future!\n\n.moon/workspace.yml\n\n```\nvcs:  client: 'git'\n```\n\n### `provider`v1.8.0\n\nDefines the service provider that the repository is hosted on. Accepts \"github\" (default), \"gitlab\",\n\"bitbucket\", or \"other\".\n\n.moon/workspace.yml\n\n```\nvcs:  provider: 'github'\n```\n\n### `remoteCandidates`\n\n(Git only) Defines a list of remote candidates to query against to determine merge bases. Defaults\nto \"origin\" and \"upstream\".\n\n.moon/workspace.yml\n\n```\nvcs:  remoteCandidates:    - 'origin'    - 'upstream'\n```\n\n### `sync`v1.9.0\n\nWill automatically generate [hook scripts](#hooks) to `.moon/hooks` and sync the scripts to the\nlocal VCS checkout. The hooks format and location is based on the [`vcs.client`](#client) setting.\nDefaults to `false`.\n\n.moon/workspace.yml\n\n```\nvcs:  hooks:    # ...  sync: true\n```\n\ncaution\n\nWhen enabled, this will sync hooks for all users of the repository. For personal or small\nprojects, this may be fine, but for larger projects, this may be undesirable and disruptive!\n\n## `versionConstraint`\n\nDefines a version requirement for the currently running moon binary. This provides a mechanism for\nenforcing that the globally installed moon on every developers machine is using an applicable\nversion.\n\n.moon/workspace.yml\n\n```\nversionConstraint: '>=0.20.0'\n```\n\n## /docs/create-project\n\nSource: https://moonrepo.dev/docs/create-project\n\n# Create a project\n\n3 min\n\nWith a [workspace](/docs/setup-workspace), we can now house one or many [projects](/docs/concepts/project),\nwith a project being an application, library, or tool. In the end, each project will have its own\nbuild layer, personal tasks, and custom configuration.\n\n## Declaring a project in the workspace\n\nAlthough a project may exist in your repository, it's not accessible from moon until it's been\nmapped in the [`projects`](/docs/config/workspace#projects) setting found in\n[`.moon/workspace.yml`](/docs/config/workspace). When mapping a project, we require a unique name for\nthe project, and a project source location (path relative from the workspace root).\n\nLet's say we have a frontend web application called \"client\", and a backend application called\n\"server\", our `projects` setting would look like the following.\n\n.moon/workspace.yml\n\n```\nprojects:  client: 'apps/client'  server: 'apps/server'\n```\n\nWe can now run [`moon project client`](/docs/commands/project) and\n[`moon project server`](/docs/commands/project) to display information about each project. If these\nprojects were not mapped, or were pointing to an invalid source, the command would throw an error.\n\nsuccess\n\nThe [`projects`](/docs/config/workspace#projects) setting also supports a list of globs, if you'd prefer\nto not manually curate the projects list!\n\n## Configuring a project\n\nA project can be configured in 1 of 2 ways:\n\n- Through the [`.moon/tasks/all.yml`](/docs/config/tasks) config file, which defines file groups and tasks that are inherited by all projects within the workspace. Perfect for standardizing common tasks like linting, typechecking, and code formatting.\n\n- Through the [`moon.yml`](/docs/config/project) config file, found at the root of each project, which defines files groups, tasks, dependencies, and more that are unique to that project.\n\nBoth config files are optional, and can be used separately or together, the choice is yours!\n\nNow let's continue with our client and server example above. If we wanted to configure both\nprojects, and define config that's also shared between the 2, we could do something like the\nfollowing:\n\n- Client\n- Server\n- Both (inherited)\n\napps/client/moon.yml\n\n```\ntasks:  build:    command: 'vite dev'    inputs:      - 'src/**/*'    outputs:      - 'dist'\n```\n\napps/server/moon.yml\n\n```\ntasks:  build:    command: 'babel src --out-dir build'    inputs:      - 'src/**/*'    outputs:      - 'build'\n```\n\n.moon/tasks/all.yml\n\n```\ntasks:  format:    command: 'prettier --check .'  lint:    command: 'eslint --no-error-on-unmatched-pattern .'  test:    command: 'jest --passWithNoTests .'  typecheck:    command: 'tsc --build'\n```\n\n### Adding optional metadata\n\nWhen utilizing moon in a large monorepo or organization, ownership becomes very important, but also\ndifficult to maintain. To combat this problem, moon supports the\n[`project`](/docs/config/project#project) field within a project's [`moon.yml`](/docs/config/project)\nconfig.\n\nThis field is optional by default, but when defined it provides metadata about the project,\nspecifically around team ownership, which developers maintain the project, where to discuss it, and\nmore!\n\nFurthermore, we also support the [`layer`](/docs/config/project#layer) and\n[`language`](/docs/config/project#language) settings for a more granular breakdown of what exists in the\nrepository.\n\n/moon.yml\n\n```\nlayer: 'tool'language: 'typescript'project:  name: 'moon'  description: 'A repo management tool.'  channel: '#moon'  owner: 'infra.platform'  maintainers: ['miles.johnson']\n```\n\n## Next steps\n\n[Setup toolchain](/docs/setup-toolchain)[Configure `.moon/workspace.yml` further](/docs/config/workspace)[Configure `.moon/tasks/all.yml` further](/docs/config/tasks)[Configure `moon.yml` further](/docs/config/project)[Learn about projects](/docs/concepts/project)\n\n## /docs/create-task\n\nSource: https://moonrepo.dev/docs/create-task\n\n# Create a task\n\n6 min\n\nThe primary focus of moon is a task runner, and for it to operate in any capacity, it requires tasks\nto run. In moon, a task is a binary or system command that is ran as a child process within the\ncontext of a project (is the current working directory). Tasks are defined per project with\n[`moon.yml`](/docs/config/project), or inherited by many projects with\n[`.moon/tasks/all.yml`](/docs/config/tasks), but can also be inferred from a language's ecosystem\n([we'll talk about this later](/docs/migrate-to-moon)).\n\ntip\n\nChange the language dropdown at the top right to switch the examples!\n\n## Configuring a task\n\nMost ‚Äî if not all projects ‚Äî utilize the same core tasks: linting, testing, code formatting,\ntypechecking, and building. Because these are so universal, let's implement the build task within\na project using [`moon.yml`](/docs/config/project).\n\nBegin by creating the `moon.yml` file at the root of a project and add `build` to the\n[`tasks`](/docs/config/project#tasks) field, with a [`command`](/docs/config/project#command) parameter.\n\n/moon.yml\n\n```\nlanguage: 'javascript'tasks:  build:    command: 'webpack build'\n```\n\nBy itself, this isn't doing much, so let's add some arguments. Arguments can also be defined with\nthe [`args`](/docs/config/project#args) setting.\n\n/moon.yml\n\n```\nlanguage: 'javascript'tasks:  build:    command: 'webpack build --mode production --no-stats'\n```\n\nWith this, the task can be ran from the command line with\n[`moon run :build`](/docs/commands/run)! This is tasks in its most simplest form, but continue\nreading on how to take full advantage of our task runner.\n\n### Inputs\n\nOur task above works, but isn't very efficient as it always runs, regardless of what has changed\nsince the last time it has ran. This becomes problematic in continuous integration environments, not\njust locally.\n\nTo mitigate this problem, moon provides a system known as inputs, which are file paths, globs, and\nenvironment variables that are used by the task when it's ran. moon will use and compare these\ninputs to calculate whether to run, or to return the previous run state from the cache.\n\nIf you're a bit confused, let's demonstrate this by expanding the task with the\n[`inputs`](/docs/config/project#inputs) setting.\n\n/moon.yml\n\n```\nlanguage: 'javascript'tasks:  build:    command: 'webpack build --mode production --no-stats'    inputs:      - 'src/**/*'      - 'webpack.config.js'      - '/webpack-shared.config.js'\n```\n\nThis list of inputs may look complicated, but they are merely run checks. For example, when moon\ndetects a change in...\n\n- Any files within the `src` folder, relative from the project's root.\n\n- A config file in the project's root.\n\n- A shared config file in the workspace root (denoted by the leading `/`).\n\n...the task will be ran! If the change occurs outside of the project or outside the list of\ninputs, the task will not be ran.\n\ntip\n\nInputs are a powerful feature that can be fine-tuned to your project's need. Be as granular or open\nas you want, the choice is yours!\n\n### Outputs\n\nOutputs are the opposite of [inputs](#inputs), as they are files and folders that are created as a\nresult of running the task. With that being said, outputs are optional, as not all tasks require\nthem, and the ones that do are typically build related.\n\nNow why is declaring outputs important? For incremental builds and smart caching! When moon\nencounters a build that has already been built, it hydrates all necessary outputs from the cache,\nthen immediately exits. No more waiting for long builds!\n\nContinuing our example, let's route the built files and expand our task with the\n[`outputs`](/docs/config/project#outputs) setting.\n\n/moon.yml\n\n```\nlanguage: 'javascript'tasks:  build:    command: 'webpack build --mode production --no-stats --output-path @out(0)'    inputs:      - 'src/**/*'      - 'webpack.config.js'      - '/webpack-shared.config.js'    outputs:      - 'build'\n```\n\n## Depending on other tasks\n\nFor scenarios where you need run a task before another task, as you're expecting some repository\nstate or artifact to exist, can be achieved with the [`deps`](/docs/config/project#deps) setting, which\nrequires a list of [targets](/docs/concepts/target):\n\n- `:` - Full canonical target.\n\n- `~:` or `` - A task within the current project.\n\n- `^:` - A task from all [depended on projects](/docs/concepts/project#dependencies).\n\n/moon.yml\n\n```\ndependsOn:  # ...tasks:  build:    # ...    deps:      - '^:build'\n```\n\n## Using file groups\n\nOnce you're familiar with configuring tasks, you may notice certain inputs being repeated\nconstantly, like source files, test files, and configuration. To reduce the amount of boilerplate\nrequired, moon provides a feature known as [file groups](/docs/concepts/file-group), which enables\ngrouping of similar file types within a project using\n[file glob patterns or literal file paths](/docs/concepts/file-pattern).\n\nFile groups are defined with the [`fileGroups`](/docs/config/project#filegroups) setting, which maps a\nlist of file paths/globs to a group, like so.\n\n/moon.yml\n\n```\nfileGroups:  configs:    - '*.config.js'  sources:    - 'src/**/*'    - 'types/**/*'  tests:    - 'tests/**/*'\n```\n\nWe can then replace the inputs in our task above with these new file groups using a syntax known as\n[tokens](/docs/concepts/token), specifically the [`@globs`](/docs/concepts/token#globs) and\n[`@files`](/docs/concepts/token#files) token functions. Tokens are an advanced feature, so please refer\nto their documentation for more information!\n\n/moon.yml\n\n```\nlanguage: 'javascript'fileGroups:  # ...tasks:  build:    command: 'webpack build --mode production --no-stats --output-path @out(0)'    inputs:      - '@globs(sources)'      - 'webpack.config.js'      - '/webpack-shared.config.js'    outputs:      - 'build'\n```\n\nWith file groups (and tokens), you're able to reduce the amount of configuration required and\nencourage certain file structures for consuming projects!\n\n## Next steps\n\n[Run a task](/docs/run-task)[Configure `.moon/tasks/all.yml` further](/docs/config/tasks)[Configure `moon.yml` further](/docs/config/project)[Learn about tasks](/docs/concepts/task)[Learn about tokens](/docs/concepts/token)\n\n## /docs/editors\n\nSource: https://moonrepo.dev/docs/editors\n\n- [Home](/)\n- [Editors](/docs/editors)\n\nwarning\n\nDocumentation is currently for [moon v2](/blog/moon-v2-alpha) and latest proto. Documentation for moon v1 has been frozen and can be [found here](https://moonrepo.github.io/website-v1/).\n\n# Editors\n\n[üìÑÔ∏è VS CodeEnhance your VS Code experience with our integrated moon console! Whether you're a fan of the](/docs/editors/vscode)\n\n[template](/docs/config/template)\n\n[VS Code](/docs/editors/vscode)\n\n## /docs/editors/vscode\n\nSource: https://moonrepo.dev/docs/editors/vscode\n\n# VS Code extension\n\nEnhance your VS Code experience with our integrated moon console! Whether you're a fan of the\ncommand line, or prefer interactive interfaces, our console will be a welcome experience.\n\nThis extension is in its early stages. Expect more advanced features in the future, like\nautocompletion, config validation, and more!\n\n## Views\n\nAll views are available within the moon sidebar. Simply click the moon icon in the left activity\nbar!\n\n### Projects\n\nThe backbone of moon is the projects view. In this view, all moon configured projects will be\nlisted, categorized by their [`layer`](/docs/config/project#layer), [`stack`](/docs/config/project#stack),\nand designated with their [`language`](/docs/config/project#language).\n\nEach project can then be expanded to view all available tasks. Tasks can be ran by clicking the `‚ñ∂`\nicon, or using the command palette.\n\nThis view is available in both the \"Explorer\" and \"moon\" sidebars.\n\n### Tags\n\nSimilar to the projects view, the tags view displays projects grouped by their\n[`tags`](/docs/config/project#tags).\n\nThis view is only available in the \"moon\" sidebar.\n\n### Last run\n\nInformation about the last ran task will be displayed in a beautiful table with detailed stats.\n\nThis table displays all actions that were ran alongside the primary target(s). They are ordered\ntopologically via the action graph.\n\n## Features\n\n### YAML validation\n\nTo enable accurate validation of our YAML configuration files, you'll need to update the\n`yaml.schemas` setting in `.vscode/settings.json` to point to the local schemas at\n`.moon/cache/schemas`.\n\nThis can be automated by running the \"moon: Append YAML schemas configuration to settings\" in the\ncommand palette, after the extension has been installed.\n\n## Troubleshooting\n\nView the\n[official VS Code marketplace](https://marketplace.visualstudio.com/items?itemName=moonrepo.moon-console)\nfor more information on the extension, its commands, available settings, and more!\n\nIf you encounter a bug, or have a feature request, please submit them to the\n[moonrepo/dev](https://github.com/moonrepo/dev/tree/master/packages/vscode-extension) repository!\n\n## /docs/faq\n\nSource: https://moonrepo.dev/docs/faq\n\n# FAQ\n\n## General\n\n### Where did the name \"moon\" come from?\n\nThe first incarnation of the name was a misspelling of monorepo (= moonrepo). This is where the\ndomain moonrepo.dev came from, and our official company, moonrepo, Inc.\n\nHowever, moonrepo is quite a long name with many syllables, and as someone who prefers short 1\nsyllable words, moon was perfect. The word moon also has great symmetry, as you can see in our logo!\n\nBut that's not all... moon is also an acronym. It originally stood for monorepo,\norganization, orchestration, and notification tool. But since moon can also be used for\npolyrepos, we replaced monorepo with management (as shown on the homepage). This is a great\nacronym, as it embraces what moon is trying to solve:\n\n- Manage repos, projects, and tasks with ease.\n\n- Organize projects and the repo to scale.\n\n- Orchestrate tasks as efficiently as possible.\n\n- Notify developers and systems about important events.\n\n### Will moon support other languages?\n\nYes! Although we're focusing right now on the web ecosystem (Node.js, Rust, Go, PHP, Python, etc),\nwe've designed moon to be language agnostic and easily pluggable in the future. View our\n[supported languages for more information](/docs#supported-languages).\n\n### Will moon support continuous deployment?\n\nYes! We plan to integrate CD with the current build and CI system, but we are focusing on the latter\n2 for the time being. Why not start using moon today so that you can easily adopt CD when it's\nready?\n\n### What should be considered the \"source of truth\"?\n\nIf you're a frontend developer, you'll assume that a `package.json` is the source of truth for a\nproject, as it defines scripts, dependencies, and repo-local relations. While true, this breaks down\nwith additional tooling, like TypeScript project references, as now you must maintain\n`tsconfig.json` as well as `package.json`. The risk of these falling out of sync is high.\n\nThis problem is further exacerbated by more tooling, or additional programming languages. What if\nyour frontend project is dependent on a backend project? This isn't easily modeled in\n`package.json`. What if the backend project needs to be built and ran before running the frontend\nproject? Again, while not impossible, it's quite cumbersome to model in `package.json` scripts. So\non and so forth.\n\nmoon aims to solve this with a different approach, by standardizing all projects in the workspace on\n[`moon.yml`](/docs/config/project). With this, the `moon.yml` is the source of truth for each project,\nand provides us with the following:\n\n- The configuration is language agnostic. All projects are configured in a similar manner.\n\n- Tasks can reference other tasks easily. For example, npm scripts referencing rake tasks, and vice verse, is a non-ideal experience.\n\n- Dependencies defined with [`dependsOn`](/docs/config/project#dependson) use moon project names, and not language specific semantics. This field also easily populates the dependency/project graphs.\n\n- For JavaScript projects: `package.json` dependencies (via `dependsOn`) are kept in sync when [`node.syncProjectWorkspaceDependencies`](/docs/config/toolchain#syncprojectworkspacedependencies) is enabled.\n\n- `tsconfig.json` project references (via `dependsOn`) are kept in sync when [`typescript.syncProjectReferences`](/docs/config/toolchain#syncprojectreferences) is enabled.\n\nBy using moon as the source of truth, we can ensure a healthy repository, by accurately keeping\neverything in sync, and modifying project/language configuration to operate effectively.\n\ninfo\n\nWith all that being said, moon supports\n[implicit dependency scanning](/docs/concepts/project#dependencies), if you'd prefer to continue\nutilizing language specific functionality, instead of migrating entirely to moon.\n\n### How to stop moon formatting JSON and YAML files?\n\nTo ensure a healthy repository state, moon constantly modifies JSON and YAML files, specifically\n`package.json` and `tsconfig.json`. This may result in a different formatting style in regards to\nindentation. While there is no way to stop or turn off this functionality, we respect\n[EditorConfig](https://editorconfig.org/) during this process.\n\nCreate a root `.editorconfig` file to enforce a consistent syntax.\n\n.editorconfig\n\n```\n[*.{json,yaml,yml}]indent_style = spaceindent_size = 4\n```\n\n## Projects & tasks\n\n### How to pipe or redirect tasks?\n\nPiping (`|`) or redirecting (`>`) the output of one moon task to another moon task, whether via\nstdin or through `inputs`, is not possible within our pipeline (task runner) directly.\n\nHowever, we do support this functionality on the command line, or within a task itself, using the\n[`script`](/docs/config/project#script) setting.\n\nmoon.yml\n\n```\ntasks:  pipe:    script: 'gen-json | jq ...'\n```\n\nAlternativaly, you can wrap this script in something like a Bash file, and execute that instead.\n\nscripts/pipe.sh\n\n```\n#!/usr/bin/env bashgen-json | jq ...\n```\n\nmoon.yml\n\n```\ntasks:  pipe:    command: 'bash ./scripts/pipe.sh'\n```\n\n### How to run multiple commands within a task?\n\nOnly [`script`](/docs/config/project#script) based tasks can run multiple commands via `&&` or `;`\nsyntax. This is possible as we execute the entire script within a shell, and not directly with the\ntoolchain.\n\nmoon.yml\n\n```\ntasks:  multiple:    script: 'mkdir test && cd test && do-something'\n```\n\n### How to run tasks in a shell?\n\nBy default, all tasks run in a shell, based on the task's [`shell`](/docs/config/project#shell) option,\nas demonstrated below:\n\nmoon.yml\n\n```\ntasks:  # Runs in a shell  global:    command: 'some-command-on-path'  # Custom shells  unix:    command: 'bash -c some-command'    options:      shell: false  windows:    command: 'pwsh.exe -c some-command'    options:      shell: false\n```\n\n### Can we run other languages?\n\nYes! Although our toolchain only supports a few languages at this time, you can still run other\nlanguages within tasks by setting their [`toolchain`](/docs/config/project#toolchain) to \"system\".\nSystem tasks are an escape hatch that will use any command available on the current machine.\n\nmoon.yml\n\n```\ntasks:  # Ruby  lint:    command: 'rubocop'    toolchain: 'system'  # PHP  test:    command: 'phpunit tests'    toolchain: 'system'\n```\n\nHowever, because these languages are not supported directly within our toolchain, they will not\nreceive the benefits of the toolchain. Some of which are:\n\n- Automatic installation of the language. System tasks expect the command to already exist in the environment, which requires the user to manually install them.\n\n- Consistent language and dependency manager versions across all machines.\n\n- Built-in cpu and heap profiling (language specific).\n\n- Automatic dependency installs when the lockfile changes.\n\n- And many more.\n\n## JavaScript ecosystem\n\n### Can we use `package.json` scripts?\n\nWe encourage everyone to define tasks in a [`moon.yml`](/docs/config/project#tasks) file, as it allows\nfor additional metadata like `inputs`, `outputs`, `options`, and more. However, if you'd like to\nkeep using `package.json` scripts, enable the\n[`node.inferTasksFromScripts`](/docs/config/toolchain#infertasksfromscripts) setting.\n\nView the [official documentation](/docs/migrate-to-moon) for more information on this approach,\nincluding risks, disadvantages, and caveats.\n\n### Can moon version/publish packages?\n\nAt this time, no, as we're focusing on the build and test aspect of development. With that being\nsaid, this is something we'd like to support first-class in the future, but until then, we suggest\nthe following popular tools:\n\n- [Yarn releases](https://yarnpkg.com/features/release-workflow) (requires >= v2)\n\n- [Changesets](https://github.com/changesets/changesets)\n\n- [Lerna](https://github.com/lerna/lerna)\n\n### Why is npm/pnpm/yarn install running twice when running a task?\n\nmoon will automatically install dependencies in a project or in the workspace root (when using\npackage workspaces) when the lockfile or `package.json` has been modified since the last time the\ninstall ran. If you are running a task and multiple installs are occurring (and it's causing\nissues), it can mean 1 of 2 things:\n\n- If you are using package workspaces, then one of the projects triggering the install is not listed within the `workspaces` field in the root `package.json` (for npm and yarn), or in `pnpm-workspace.yml` (for pnpm).\n\n- If the install is triggering in a non-JavaScript related project, then this project is incorrectly listed as a package workspace.\n\n- If you don't want a package included in the workspace, but do want to install its dependencies, then it'll need its own lockfile.\n\n## Troubleshooting\n\n### How to resolve the \"version 'GLIBC_X.XX' not found\" error?\n\nThis is typically caused by running moon in an old environment, like Ubuntu 18, and the minimum\nrequired libc doesn't exist or is too old. Since moon is Rust based, we're unable to support all\nenvironments and versions perpetually, and will only support relatively modern environments.\n\nThere's not an easy fix to this problem, but there are a few potential solutions, from easiest to\nhardest:\n\n- Run moon in a Docker container/image that has the correct environment and libs. For example, the `node:latest` image.\n\n- Upgrade the environment to a newer one. For example, Ubuntu 18 -> 22.\n\n- Try and install a newer libc ([more information](https://stackoverflow.com/questions/72513993/how-install-glibc-2-29-or-higher-in-ubuntu-18-04)).\n\nFor more information on this problem as a whole,\n[refer to this in-depth article](https://kobzol.github.io/rust/ci/2021/05/07/building-rust-binaries-in-ci-that-work-with-older-glibc.html).\n\n## /docs/guides/ci\n\nSource: https://moonrepo.dev/docs/guides/ci\n\n# Continuous integration (CI)\n\nAll companies and projects rely on continuous integration (CI) to ensure high quality code and to\navoid regressions. Because this is such a critical piece of every developer's workflow, we wanted to\nsupport it as a first-class feature within moon, and we do just that with the\n[`moon ci`](/docs/commands/ci) command.\n\n## How it works\n\nThe `ci` command does all the heavy lifting necessary for effectively running jobs. It achieves this\nby automatically running the following steps:\n\n- Determines touched files by comparing the current HEAD against a base.\n\n- Determines all [targets](/docs/concepts/target) that need to run based on touched files.\n\n- Additionally runs affected [targets](/docs/concepts/target) dependencies and dependents.\n\n- Generates an action and dependency graph.\n\n- Installs the toolchain, Node.js, and npm dependencies.\n\n- Runs all actions within the graph using a thread pool.\n\n- Displays stats about all passing, failed, and invalid actions.\n\n## Configuring tasks\n\nBy default, all tasks run in CI, as you should always be building, linting, typechecking, testing,\nso on and so forth. However, this isn't always true, so this can be disabled on a per-task basis\nthrough the [`runInCI`](/docs/config/project#runinci) or [`local`](/docs/config/project#local) options.\n\n```\ntasks:  dev:    command: 'webpack server'    options:      runInCI: false    # Or    preset: 'server'\n```\n\ncaution\n\nThis option must be set to false for tasks that spawn a long-running or never-ending process, like\nHTTP or development servers. To help mitigate this, tasks named `dev`, `start`, or `serve` are false\nby default. This can be easily controlled with the [`local`](/docs/config/project#local) setting.\n\n## Integrating\n\nThe following examples can be referenced for setting up moon and its CI workflow in popular\nproviders. For GitHub, we're using our\n[`setup-toolchain` action](https://github.com/moonrepo/setup-toolchain) to install moon. For other\nproviders, we assume moon is an npm dependency and must be installed with Node.js.\n\n- GitHub\n- Buildkite\n- CircleCI\n- TravisCI\n\n.github/workflows/ci.yml\n\n```\nname: 'Pipeline'on:  push:    branches:      - 'master'  pull_request:jobs:  ci:    name: 'CI'    runs-on: 'ubuntu-latest'    steps:      - uses: 'actions/checkout@v4'        with:          fetch-depth: 0      - uses: 'moonrepo/setup-toolchain@v0'      - run: 'moon ci'\n```\n\n.buildkite/pipeline.yml\n\n```\nsteps:  - label: 'CI'    commands:      - 'yarn install --immutable'      - 'moon ci'\n```\n\n.circleci/config.yml\n\n```\nversion: 2.1orbs:  node: 'circleci/node@5.0.2'jobs:  ci:    docker:      - image: 'cimg/base:stable'    steps:      - checkout      - node/install:          install-yarn: true          node-version: '16.13'      - node/install-packages:          check-cache: 'always'          pkg-manager: 'yarn-berry'      - run: 'moon ci'workflows:  pipeline:    jobs:      - 'ci'\n```\n\n.travis.yml\n\n```\nlanguage: node_jsnode_js:  - 16cache: yarnscript: 'moon ci'\n```\n\n## Choosing targetsv1.14.0\n\nBy default `moon ci` will run all tasks from all projects that are affected by touched files and\nhave the [`runInCI`](/docs/config/project#runinci) task option enabled. This is a great catch-all\nsolution, but may not vibe with your workflow or requirements.\n\nIf you'd prefer more control, you can pass a list of targets to `moon ci`, instead of moon\nattempting to detect them. When providing targets, `moon ci` will still only run them if affected by\ntouched files, but will still filter with the `runInCI` option.\n\n```\n# Run all builds$ moon ci :build# In another job, run tests$ moon ci :test :lint\n```\n\n## Comparing revisions\n\nBy default the command will attempt to detect the base and head revisions automatically based on the\ncurrent CI provider (powered by the [`ci_env`](https://github.com/milesj/rust-cicd-env) Rust crate).\nIf nothing was detected, this will fallback to the configured\n[`vcs.defaultBranch`](/docs/config/workspace#defaultbranch) for the base revision, and `HEAD` for the\nhead revision.\n\nThese values can be customized with the `--base` and `--head` command line options, or the\n`MOON_BASE` and `MOON_HEAD` environment variables, which takes highest precedence.\n\n```\n$ moon ci --base  --head # Or$ MOON_BASE= MOON_HEAD= moon ci\n```\n\n## Parallelizing tasks\n\nIf your CI environment supports sharding across multiple jobs, then you can utilize moon's built in\nparallelism by passing `--jobTotal` and `--job` options. The `--jobTotal` option is an integer of\nthe total number of jobs available, and `--job` is the current index (0 based) amongst the total.\n\nWhen these options are passed, moon will only run affected [targets](/docs/concepts/target) based on\nthe current job slice.\n\n- GitHub\n- Buildkite\n- CircleCI\n- TravisCI\n\nGitHub Actions do not support native parallelism, but it can be emulated using it's matrix.\n\n.github/workflows/ci.yml\n\n```\n# ...jobs:  ci:    # ...    strategy:      matrix:        index: [0, 1]    steps:      # ...      - run: 'moon ci --job ${{ matrix.index }} --jobTotal 2'\n```\n\n- [Documentation](https://docs.github.com/en/actions/using-jobs/using-a-matrix-for-your-jobs)\n\n.buildkite/pipeline.yml\n\n```\n# ...steps:  - label: 'CI'    parallelism: 10    commands:      # ...      - 'moon ci --job $$BUILDKITE_PARALLEL_JOB --jobTotal $$BUILDKITE_PARALLEL_JOB_COUNT'\n```\n\n- [Documentation](https://buildkite.com/docs/tutorials/parallel-builds#parallel-jobs)\n\n.circleci/config.yml\n\n```\n# ...jobs:  ci:    # ...    parallelism: 10    steps:      # ...      - run: 'moon ci --job $CIRCLE_NODE_INDEX --jobTotal $CIRCLE_NODE_TOTAL'\n```\n\n- [Documentation](https://circleci.com/docs/2.0/parallelism-faster-jobs/)\n\nTravisCI does not support native parallelism, but it can be emulated using it's matrix.\n\n.travis.yml\n\n```\n# ...env:  global:    - TRAVIS_JOB_TOTAL=2  jobs:    - TRAVIS_JOB_INDEX=0    - TRAVIS_JOB_INDEX=1script: 'moon ci --job $TRAVIS_JOB_INDEX --jobTotal $TRAVIS_JOB_TOTAL'\n```\n\n- [Documentation](https://docs.travis-ci.com/user/speeding-up-the-build/)\n\nYour CI environment may provide environment variables for these 2 values.\n\n## Caching artifacts\n\nWhen a CI pipeline reaches a certain scale, its run times increase, tasks are unnecessarily ran, and\nbuild artifacts are not shared. To combat this, we support [remote caching](/docs/guides/remote-cache), a\nmechanism where we store build artifacts in the cloud, and sync these artifacts to machines on\ndemand.\n\n### Manual persistence\n\nIf you'd prefer to not use remote caching at this time, you can cache artifacts yourself, by\npersisting the `.moon/cache/{hashes,outputs}` directories. All other files and folders in\n`.moon/cache` should not be persisted, as they are not safe/portable across machines.\n\nHowever, because tasks can generate a different hash each run, you'll need to manually invalidate\nyour cache. Blindly storing the `hashes` and `outputs` directories without a mechanism to invalidate\nwill simply not work, as the contents will drastically change between CI runs. This is the primary\nreason why the remote caching service exists.\n\n## Reporting run results\n\nIf you're using GitHub Actions as your CI provider, we suggest using our\n[`moonrepo/run-report-action`](https://github.com/marketplace/actions/moon-ci-run-reports). This\naction will report the results of a [`moon ci`](/docs/commands/ci) run to a pull request as a comment\nand workflow summary.\n\n.github/workflows/ci.yml\n\n```\n# ...jobs:  ci:    name: 'CI'    runs-on: 'ubuntu-latest'    steps:      # ...      - run: 'moon ci'      - uses: 'moonrepo/run-report-action@v1'        if: success() || failure()        with:          access-token: ${{ secrets.GITHUB_TOKEN }}\n```\n\nThe report looks something like the following:\n\n### Community offerings\n\nThe following GitHub actions are provided by the community:\n\n- [`appthrust/moon-ci-retrospect`](https://github.com/appthrust/moon-ci-retrospect) - Displays the results of a `moon ci` run in a more readable fashion.\n\n- [`kymckay/moon-ci-booster`](https://github.com/kymckay/moon-ci-booster) - Displays failing `moon ci` tasks as comments with error logs directly on your pull request.\n\n## /docs/guides/codegen\n\nSource: https://moonrepo.dev/docs/guides/codegen\n\n# Code generation\n\nCode generation provides an easy mechanism for automating common development workflows and file\nstructures. Whether it's scaffolding a new library or application, updating configuration, or\nstandardizing patterns.\n\nTo accomplish this, we provide a generator, which is divided into two parts. The first being the\ntemplates and their files to be scaffolded. The second is our rendering engine that writes template\nfiles to a destination.\n\n## Creating a new template\n\nTo create a new template, run [`moon generate`](/docs/commands/generate) while passing the `--template` option. This\nwill create a template directory and [`template.yml`](/docs/config/template) file in the 1st file-based template\nlocation defined in [`generator.templates`](/docs/config/workspace#templates).\n\n```\n$ moon generate  --template\n```\n\n### Configuring `template.yml`\n\nEvery template requires a [`template.yml`](/docs/config/template) file in the template's directory root. This file\nacts as a schema and declares metadata and variables required by the generator.\n\ntemplate.yml\n\n```\ntitle: 'npm package'description: |  Scaffolds the initial structure for an npm package,  including source and test folders, a package.json, and more.variables:  name:    type: 'string'    default: ''    required: true    prompt: 'Package name?'\n```\n\n### Managing files\n\nFeel free to add any files and folders to the template that you'd like to be generated by consumers!\nThese files will then be scaffolded 1:1 in structure at the target destination.\n\nAn example of the templates folder structure may look something like the following:\n\n```\ntemplates/‚îú‚îÄ‚îÄ npm-package/‚îÇ   ‚îú‚îÄ‚îÄ src/‚îÇ   ‚îú‚îÄ‚îÄ tests/‚îÇ   ‚îú‚îÄ‚îÄ package.json‚îÇ   ‚îî‚îÄ‚îÄ template.yml‚îî‚îÄ‚îÄ react-app/\n```\n\n#### Interpolation\n\nVariables can be interpolated into file paths using the form `[varName]`. For example, if you had a\ntemplate file `src/[type].ts`, and a variable `type` with a value of \"bin\", then the destination\nfile path would be `src/bin.ts`.\n\nThis syntax also supports [filters](#filters), such as `[varName | camel_case]`. However, spaces may\ncause issues with file path encoding, so this functionality is primarily recommended for the\n[`destination`](/docs/config/template#destination) setting.\n\n#### File extensions\n\nTo enable syntax highlighting for template engine syntax, you may use the `.tera` (preferred) or\n`.twig` file extensions. These extensions are optional, but will be removed when the files are\ngenerated.\n\nDepending on your preferred editor, these extensions may be supported through a plugin, or can be\nconfigured based on file type.\n\n- VS Code [Tera extension](https://marketplace.visualstudio.com/items?itemName=karunamurti.tera)\n\n- [Twig extension](https://marketplace.visualstudio.com/items?itemName=mblode.twig-language-2)\n\n- Atom [Twig package](https://atom.io/packages/atom-twig)\n\n- Webstorm [Twig plugin](https://plugins.jetbrains.com/plugin/7303-twig)\n\n#### Partials\n\nPartials are special template files that are used for\n[composition](https://keats.github.io/tera/docs/#include) and\n[inheritance](https://keats.github.io/tera/docs/#inheritance). Because of this, these files should\nnot be generated into the target destination, and do not support frontmatter.\n\nTo ensure they are not generated, include the word \"partial\" anywhere in the file path. For example,\n`partials/header.tpl` or `header.partial.tpl`.\n\n#### Rawsv1.11.0\n\nRaw template files are another special type of file that bypass all Tera rendering, and are used\nas-is instead. This is useful for files that contain syntax that conflicts with Tera.\n\nTo mark a file as raw, add a `.raw` extension, for example: `file.raw.js` or `file.js.raw`. When the\nfile is generated, the `.raw` extension will be removed.\n\n#### Frontmatter\n\nFrontmatter is a well-known concept for \"per-file configuration\", and is achieved by inserting YAML\nat the top of the file, delimited by wrapping `---`. This is a very powerful feature that provides\nmore control than the alternatives, and allows for some very cool integrations.\n\nmoon's frontmatter supports functionality like file skipping, force overwriting, and destination\npath rewriting.\n[View the configuration docs for a full list of supported fields](/docs/config/template#frontmatter).\n\npackage.json\n\n```\n---force: true---{  \"name\": \"{{ name | kebab_case }}\",  \"version\": \"0.0.1\"}\n```\n\nSince frontmatter exists in the file itself, you can take advantage of the rendering engine to\npopulate the field values dynamically. For example, if you're scaffolding a React component, you can\nconvert the component name and file name to PascalCase.\n\n```\n{% set component_name = name | pascal_case %}---to: components/{{ component_name }}.tsx---export function {{ component_name }}() {  return\n;}\n```\n\n#### Assets\n\nAssets are binary files that are copied as-is to the destination, without any rendering, and no\nsupport for frontmatter. This applies to all non-text based files, like images, audio, video, etc.\n\n### Template engine & syntax\n\nRendering templates is powered by [Tera](https://keats.github.io/tera/), a Rust based template\nengine with syntax similar to Twig, Liquid, Django, and more. We highly encourage everyone to read\nTera's documentation for an in-depth understanding, but as a quick reference, Tera supports the\nfollowing:\n\n- [Variable interpolation](https://keats.github.io/tera/docs/#variables) (defined with the [`variables`](/docs/config/template#variables) setting), with [built-in filters](https://keats.github.io/tera/docs/#built-in-filters).\n\n```\n{{ varName }} -> foo{{ varName | upper }} -> FOO\n```\n\n- [Conditional blocks](https://keats.github.io/tera/docs/#if) and [loops](https://keats.github.io/tera/docs/#for).\n\n```\n{% if price  1000 and not rich %}  That's expensive!{% else %}  N/A{% endif %}\n```\n\n```\n{% for item in items %}  {{ loop.index }} - {{ item.name }}{% endfor %}\n```\n\n- And many more features, like auto-escaping, white space control, and math operators!\n\n#### Filters\n\nFilters are a mechanism for transforming values during interpolation and are written using pipes\n(`|`). Tera provides many [built-in filters](https://keats.github.io/tera/docs/#built-in-filters),\nbut we also provide the following custom filters:\n\n- Strings - `camel_case`, `pascal_case`, `snake_case`, `upper_snake_case`, `kebab_case`, `upper_kebab_case`, `lower_case`, `upper_case`\n\n```\n{{ some_value | upper_case }}\n```\n\n- Paths - `path_join`, `path_relative`\n\n```\n{{ some_path | path_join(part = \"another/folder\") }}{{ some_path | path_relative(from = other_path) }}{{ some_path | path_relative(to = other_path) }}\n```\n\n#### Functions\n\nThe following functions are available within a template:\n\n- `variables()` - Returns an object containing all variables within the current template. v1.23.0\n\n#### Variables\n\nThe following variables are always available within a template:\n\n- `dest_dir` - Absolute path to the destination folder.\n\n- `dest_rel_dir` - Relative path to the destination folder from the working directory.\n\n- `working_dir` - Current working directory.\n\n- `workspace_root` - The moon workspace root.\n\n## Generating code from a template\n\nOnce a template has been created and configured, you can generate files based on it using the\n[`moon generate`](/docs/commands/generate) command! This is also know as scaffolding or code generation.\n\nThis command requires the name of a template as the 1st argument. The template name is the folder\nname on the file system that houses all the template files, or the [`id`](/docs/config/template#id)\nsetting configured in [`template.yml`](/docs/config/template).\n\n```\n$ moon generate npm-package\n```\n\nAn optional destination path, relative from the current working directory, can be provided as the\n2nd argument. If not provided, the [`destination`](/docs/config/template#destination) setting\nconfigured in [`template.yml`](/docs/config/template) will be used, or you'll be prompted during\ngeneration to provide one.\n\n```\n$ moon generate npm-package ./packages/example\n```\n\nThis command is extremely interactive, as we'll prompt you for the destination path, variable\nvalues, whether to overwrite files, and more. If you'd prefer to avoid interactions, pass\n`--defaults`, or `--force`, or both.\n\n### Configuring template locations\n\nTemplates can be located anywhere, especially when [being shared](#sharing-templates). Because of\nthis, our generator will loop through all template paths configured in\n[`generator.templates`](/docs/config/workspace#templates), in order, until a match is found.\n\n.moon/workspace.yml\n\n```\ngenerator:  templates:    - './templates'    # Or    - 'file://other/templates'\n```\n\nWhen using literal file paths, all paths are relative from the workspace root.\n\n#### Archive URLsv1.36.0\n\nTemplate locations can reference archives (zip, tar, etc) through https URLs. These archives should\ncontain templates and will be downloaded and unpacked. The list of\n[available archive formats can be found here](https://github.com/moonrepo/starbase/blob/master/crates/archive/src/lib.rs#L76).\n\n.moon/workspace.yml\n\n```\ngenerator:  templates:    - 'https://domain.com/some/path/to/archive.zip'\n```\n\nArchives will be unpacked to `~/.moon/templates/archive/`, and will be cached for future\nuse.\n\n#### Globsv1.31.0\n\nIf you'd prefer more control over literal file paths (above), you can instead use glob paths or the\n`glob://` protocol. Globs are relative from the workspace root, and will only match directories, or\npatterns that end in `template.yml`.\n\n.moon/workspace.yml\n\n```\ngenerator:  templates:    - './templates/*'    # Or    - 'glob://projects/*/templates/*'\n```\n\n#### Git repositoriesv1.23.0\n\nTemplates locations can also reference templates in an external Git repository using the `git://`\nlocator protocol. This locator requires the Git host, repository path, and revision (branch, tag,\ncommit, etc).\n\n.moon/workspace.yml\n\n```\ngenerator:  templates:    - 'git://github.com/moonrepo/templates#master'    - 'git://gitlab.com/org/repo#v1.2.3'\n```\n\nGit repositories will be cloned to `~/.moon/templates/git/` using an HTTPS URL (not a Git\nURL), and will be cached for future use.\n\n#### npm packagesv1.23.0\n\nAdditionally, template locations can also reference npm packages using the `npm://` locator\nprotocol. This locator requires a package name and published version.\n\n.moon/workspace.yml\n\n```\ngenerator:  templates:    - 'npm://@moonrepo/templates#1.2.3'    - 'npm://other-templates#4.5.6'\n```\n\nnpm packages will be downloaded and unpacked to `~/.moon/templates/npm` and cached for future use.\n\n### Declaring variables with CLI arguments\n\nDuring generation, you'll be prompted in the terminal to provide a value for any configured\nvariables. However, you can pre-fill these variable values by passing arbitrary command line\narguments after `--` to [`moon generate`](/docs/commands/generate). Argument names must exactly match the variable\nnames.\n\nUsing the package template example above, we could pre-fill the `name` variable like so:\n\n```\n$ moon generate npm-package ./packages/example -- --name '@company/example' --private\n```\n\ninfo\n\n- Array variables support multiple options of the same name.\n\n- Boolean variables can be negated by prefixing the argument with `--no-`.\n\n- Object variables can not declare values through arguments.\n\n## Sharing templates\n\nAlthough moon is designed for a monorepo, you may be using multiple repositories and would like to\nuse the same templates across all of them. So how can we share templates across repositories? Why\nnot try...\n\n- Git submodules\n\n- Git repositories (using `git://` protocol)\n\n- File archives\n\n- Node.js modules\n\n- npm packages (using `npm://` protocol)\n\n- Another packaging system\n\nRegardless of the choice, simply configure [`generator.templates`](/docs/config/workspace#templates) to point to these\nlocations:\n\n.moon/workspace.yml\n\n```\ngenerator:  templates:    - './templates'    - 'file://./templates'    # Git    - './path/to/submodule'    - 'git://github.com/org/repo#branch'    # npm    - './node_modules/@company/shared-templates'    - 'npm://@company/shared-templates#1.2.3'\n```\n\n### Git and npm layout structure\n\nIf you plan to share templates using Git repositories (`git://`) or npm packages (`npm://`), then\nthe layout of those projects must follow these guidelines:\n\n- A project must support multiple templates\n\n- A template is denoted by a folder in the root of the project\n\n- Each template must have a [`template.yml`](/docs/config/template) file\n\n- Template names are derived from the folder name, or the `id` field in [`template.yml`](/docs/config/template)\n\nAn example of this layout structure may look something like the following:\n\n```\n‚îú‚îÄ‚îÄ template-one/‚îÇ   ‚îî‚îÄ‚îÄ template.yml‚îú‚îÄ‚îÄ template-two/‚îÇ   ‚îî‚îÄ‚îÄ template.yml‚îú‚îÄ‚îÄ template-three/‚îÇ   ‚îî‚îÄ‚îÄ template.yml‚îî‚îÄ‚îÄ package.json, etc\n```\n\nThese templates can then be referenced by name, such as [`moon generate template-one`](/docs/commands/generate).\n\n## /docs/guides/codeowners\n\nSource: https://moonrepo.dev/docs/guides/codeowners\n\n# Code owners\n\nv1.8.0\n\nCode owners enables companies to define individuals, teams, or groups that are responsible for code\nin a repository. This is useful in ensuring that pull/merge requests are reviewed and approved by a\nspecific set of contributors, before the branch is merged into the base branch.\n\nWith that being said, moon does not implement a custom code owners solution, and instead builds\nupon the popular `CODEOWNERS` integration in VCS providers, like GitHub, GitLab, and Bitbucket.\n\n## Defining owners\n\nWith moon, you do not modify a `CODEOWNERS` file directly. Instead you define owners per project\nwith [`moon.yml`](/docs/config/project), or globally with [`.moon/workspace.yml`](/docs/config/workspace).\nThese owners are then aggregated and automatically\n[synced to a `CODEOWNERS` file](#generating-codeowners).\n\ninfo\n\nAn owner is a user, team, or group unique to your VCS provider. Please refer to your provider's\ndocumentation for the correct format in which to define owners.\n\n### Project-level\n\nFor projects, we support an [`owners`](/docs/config/project#owners) setting in\n[`moon.yml`](/docs/config/project) that accepts file patterns/paths and their owners (contributors\nrequired to review), as well as operational settings for minimum required approvals, custom groups,\nand more.\n\nPaths configured here are relative from the project root, and will be prefixed with the project\nsource (path from workspace root to project root) when the file is synced.\n\npackages/components/moon.yml\n\n```\nowners:  requiredApprovals: 2  paths:    'src/': ['@frontend', '@design-system']    '*.config.js': ['@frontend-infra']    '*.json': ['@frontend-infra']\n```\n\nThe configuration above would generate the following:\n\n- GitHub\n- GitLab\n- Bitbucket\n\n.github/CODEOWNERS\n\n```\n# components/packages/components/src/ @frontend @design-system/packages/components/*.config.js @frontend-infra/packages/components/*.json @frontend-infra\n```\n\n.gitlab/CODEOWNERS\n\n```\n# components[components][2]/packages/components/src/ @frontend @design-system/packages/components/*.config.js @frontend-infra/packages/components/*.json @frontend-infra\n```\n\nCODEOWNERS\n\n```\n# components/packages/components/src/ @frontend @design-system/packages/components/*.config.js @frontend-infra/packages/components/*.json @frontend-infra\n```\n\n### Workspace-level\n\nProject scoped owners are great but sometimes you need to define owners for files that span across\nall projects, or files at any depth within the repository. With the\n[`codeowners.globalPaths`](/docs/config/workspace#globalpaths) setting in\n[`.moon/workspace.yml`](/docs/config/workspace), you can do just that.\n\nPaths configured here are used as-is, allowing for full control of what ownership is applied.\n\n.moon/workspace.yml\n\n```\ncodeowners:  globalPaths:    # All files    '*': ['@admins']    # Config folder at any depth    'config/': ['@app-platform']    # GitHub folder at the root    '/.github/': ['@infra']\n```\n\nThe configuration above would generate the following at the top of the file (is the same for all\nproviders):\n\n- GitHub\n- GitLab\n- Bitbucket\n\n.github/CODEOWNERS\n\n```\n# (workspace)* @adminsconfig/ @app-platform/.github/ @infra\n```\n\n.gitlab/CODEOWNERS\n\n```\n# (workspace)* @adminsconfig/ @app-platform/.github/ @infra\n```\n\nCODEOWNERS\n\n```\n# (workspace)* @adminsconfig/ @app-platform/.github/ @infra\n```\n\n## Generating `CODEOWNERS`\n\nCode owners is an opt-in feature, and as such, the `CODEOWNERS` file can be generated in a few ways.\nThe first is manually, with the [`moon sync codeowners`](/docs/commands/sync/code-owners) command.\n\n```\n$ moon sync codeowners\n```\n\nWhile this works, it is a manual process, and can easily be forgotten, resulting in an out-of-date\nfile.\n\nAn alternative solution is the [`codeowners.syncOnRun`](/docs/config/workspace#synconrun) setting in\n[`.moon/workspace.yml`](/docs/config/workspace#codeowners), that when enabled, moon will automatically\ngenerate a `CODEOWNERS` file when a [target](/docs/concepts/target) is ran.\n\n.moon/workspace.yml\n\n```\ncodeowners:  syncOnRun: true\n```\n\nThe format and location of the `CODEOWNERS` file is based on the\n[`vcs.provider`](/docs/config/workspace#provider) setting.\n\n## FAQ\n\n### What providers or formats are supported?\n\nThe following providers are supported, based on the [`vcs.provider`](/docs/config/workspace#provider)\nsetting.\n\n- [Bitbucket](https://marketplace.atlassian.com/apps/1218598/code-owners-for-bitbucket?tab=overview&hosting=cloud) (via a 3rd-party app)\n\n- [GitHub](https://docs.github.com/en/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/about-code-owners)\n\n- [GitLab](https://docs.gitlab.com/ee/user/project/codeowners/reference.html)\n\n- Other (very basic syntax)\n\n### Where does the `CODEOWNERS` file get created?\n\nThe location of the file is dependent on the configured provider.\n\n- GitHub -> `.github/CODEOWNERS`\n\n- GitLab -> `.gitlab/CODEOWNERS`\n\n- Everything else -> `CODEOWNERS`\n\n### Why are owners defined in `moon.yml` and not an alternative like `OWNERS`?\n\nA very popular pattern for defining owners is through an `OWNERS` file, which can appear in any\nfolder, at any depth, within the repository. All of these files are then aggregated into a single\n`CODEOWNERS` file.\n\nWhile this is useful for viewing ownership of a folder at a glance, it incurs a massive performance\nhit as we'd have to constantly glob the entire repository to find all `OWNERS` files. We found it\nbest to define owners in `moon.yml` instead for the following reasons:\n\n- No performance hit, as we're already loading and parsing these config files.\n\n- Co-locates owners with the rest of moon's configuration.\n\n- Ownership is now a part of the project graph, enabling future features.\n\n## /docs/guides/debug-task\n\nSource: https://moonrepo.dev/docs/guides/debug-task\n\n# Debugging a task\n\nRunning [tasks](/docs/concepts/task) is the most common way to interact with moon, so what do you do\nwhen your task isn't working as expected? Diagnose it of course! Diagnosing the root cause of a\nbroken task can be quite daunting, but do not fret, as the following steps will help guide you in\nthis endeavor.\n\n## Verify configuration\n\nBefore we dive into the internals of moon, we should first verify that the task is actually\nconfigured correctly. Our configuration layer is very strict, but it can't catch everything, so jump\nto the [`moon.yml`](/docs/config/project#tasks) documentation for more information.\n\nTo start, moon will create a snapshot of the project and its tasks, with all [tokens](/docs/concepts/token)\nresolved, and paths expanded. This snapshot is located at\n`.moon/cache/states/\n/snapshot.json`. With the snapshot open, inspect the root `tasks`\nobject for any inconsistencies or inaccuracies.\n\nSome issues to look out for:\n\n- Have `command` and `args` been parsed correctly?\n\n- Have [tokens](/docs/concepts/token) resolved correctly? If not, verify syntax or try another token type.\n\n- Have `inputFiles`, `inputGlobs`, and `inputVars` expanded correctly from [`inputs`](/docs/config/project#inputs)?\n\n- Have `outputFiles` and `outputGlobs` expanded correctly from [`outputs`](/docs/config/project#outputs)?\n\n- Is the `toolchain` (formerly `platform`) correct for the command? If incorrect, explicitly set the [`toolchain`](/docs/config/project#toolchain).\n\n- Are `options` and `flags` correct?\n\ninfo\n\nResolved information can also be inspected with the [`moon task --json`](/docs/commands/task)\ncommand.\n\n### Verify inherited configuration\n\nIf the configuration from the previous step looks correct, you can skip this step, otherwise let's\nverify that the inherited configuration is also correct. In the `snapshot.json` file, inspect the\nroot `inherited` object, which is structured as follows:\n\n- `order` - The order in which configuration files from `.moon` are loaded, from lowest to highest priority, and the order files are merged. The `*` entry is `.moon/tasks/all.yml`, while other entries map to `.moon/tasks/**/*.yml`.\n\n- `layers` - A mapping of configuration files that were loaded, derived from the `order`. Each layer represents a partial object (not expanded or resolved). Only files that exist will be mapped here.\n\n- `config` - A partial configuration object representing the state of all merged layers. This is what is merged with the project's `moon.yml` file.\n\nSome issues to look out for:\n\n- Is the order correct? If not, verify the project's [`language`](/docs/config/project#language) and the task's [`toolchain`](/docs/config/project#toolchain).\n\n- Does `config` correctly represent the merged state of all `layers`? Do note that tasks are shallow merged (by name), not deep merged.\n\n- Have the root `tasks` properly inherited [`implicitDeps`](/docs/config/tasks#implicitdeps), [`implicitInputs`](/docs/config/tasks#implicitinputs), and `fileGroups`?\n\n## Inspect trace logs\n\nIf configuration looks good, let's move on to inspecting the trace logs, which can be a non-trivial\namount of effort. Run the task to generate the logs, bypass the cache, and include debug\ninformation:\n\n```\nMOON_DEBUG_PROCESS_ENV=true MOON_DEBUG_PROCESS_INPUT=true moon run  --log trace --force\n```\n\nOnce ran, a large amount of information will be logged to the terminal. However, most of it can be\nignored, as we're only interested in the \"is this task affected by changes\" logs. This breaks down\nas follows:\n\n- First, we gather touched files from the local checkout, which is typically `git status --porcelain --untracked-files` (from the `moon_process::command_inspector` module). The logs do not output the list of files that are touched, but you can run this command locally to verify the output.\n\n- Secondly, we gather all files from the project directory, using the `git ls-files --full-name --cached --modified --others --exclude-standard --deduplicate` command (also from the `moon_process::command_inspector` module). This command can also be ran locally to verify the output.\n\n- Lastly, all files from the previous 2 commands will be hashed using the `git hash-object` command. If you passed the `MOON_DEBUG_PROCESS_INPUT` environment variable, you'll see a massive log entry of all files being hashed. This is what we use to generate moon's specific hash.\n\nIf all went well, you should see a log entry that looks like this:\n\n```\nmoon_task_runner::task_runner  Generated a unique hash  task_target=\"\" hash=\"\"\n```\n\nThe important piece is the hash, which is a 64-character SHA256 hash, and represents the unique hash\nof this task/target. This is what moon uses to determine a cache hit/miss, and whether or not to\nskip re-running a task.\n\nLet's copy the hash and move on to the next step.\n\n## Inspect the hash manifest\n\nWith the hash in hand, let's dig deeper into moon's internals, by inspecting the hash manifest at\n`.moon/cache/hashes/.json`, or running the [`moon hash`](/docs/commands/hash) command:\n\n```\nmoon hash\n```\n\nThe manifest is JSON and its contents are all the information used to generate its unique hash. This\ninformation is an array, and breaks down as follows:\n\n- The first item in the array is the task itself. The important fields to diagnose here are `deps` and `inputs`. Dependencies are other tasks (and their hash) that this task depends on.\n\n- Inputs are all the files (and their hash from `git hash-object`) this task requires to run.\n\n- The remaining items are toolchain/language specific, some examples are: Node.js - The current Node.js version and the resolved versions/hashes of all `package.json` dependencies.\n\n- Rust - The current Rust version and the resolved versions/hashes of all `Cargo.toml` dependencies.\n\n- TypeScript - Compiler options for changing compilation output.\n\nSome issues to look out for:\n\n- Do the dependencies match the task's configured [`deps`](/docs/config/project#deps) and [`implicitDeps`](/docs/config/tasks#implicitdeps)?\n\n- Do the inputs match the task's configured [`inputs`](/docs/config/project#inputs) and [`implicitInputs`](/docs/config/tasks#implicitinputs)? If not, try tweaking the config.\n\n- Are the toolchain/language specific items correct?\n\n- Are dependency versions/hashes correctly parsed from the appropriate lockfile?\n\n### Diffing a previous hash\n\nAnother avenue for diagnosing a task is to diff the hash against a hash from a previous run. Since\nwe require multiple hashes, we'll need to run the task multiple times,\n[inspect the logs](#inspect-trace-logs), and extract the hash for each. If you receive the same hash\nfor each run, you'll need to tweak configuration or change files to produce a different hash.\n\nOnce you have 2 unique hashes, we can pass them to the [`moon hash`](/docs/commands/hash) command. This\nwill produce a `git diff` styled output, allowing for simple line-by-line comparison debugging.\n\n```\nmoon hash\n```\n\n```\nLeft:  0b55b234f1018581c45b00241d7340dc648c63e639fbafdaf85a4cd7e718fddeRight: 2388552fee5a02062d0ef402bdc7232f0a447458b058c80ce9c3d0d4d7cfe171[\t{\t\t\"command\": \"build\",\t\t\"args\": [+\t\t\t\"./dist\"-\t\t\t\"./build\"\t\t],\t\t...\t}]\n```\n\nThis is extremely useful in diagnoising why a task is running differently than before, and is much\neasier than inspecting the hash manifest files manually!\n\n## Ask for help\n\nIf you've made it this far, and still can't figure out why a task is not working correctly, please\nask for help!\n\n- [Join the Discord community](https://discord.gg/qCh9MEynv2) (if lost)\n\n- [Report an issue](https://github.com/moonrepo/moon/issues/new/choose) (if an actual bug)\n\n## /docs/guides/docker\n\nSource: https://moonrepo.dev/docs/guides/docker\n\n# Docker integration\n\nUsing [Docker](https://www.docker.com/) to run your applications? Or build your artifacts? No\nworries, moon can be utilized with Docker, and supports a robust integration layer.\n\nsuccess\n\nLooking to speed up your Docker builds? Want to build in the cloud?\n[Give Depot a try](https://depot.dev?ref=moonrepo)!\n\n## Requirements\n\nThe first requirement, which is very important, is adding `.moon/cache` to the workspace root\n`.dockerignore` (moon assumes builds are running from the root). Not all files in `.moon/cache` are\nportable across machines/environments, so copying these file into Docker will definitely cause\ninteroperability issues.\n\n.dockerignore\n\n```\n.moon/cache\n```\n\nThe other requirement depends on how you want to integrate Git with Docker. Since moon executes\n`git` commands under the hood, there are some special considerations to be aware of when running\nmoon within Docker. There's 2 scenarios to choose from:\n\n- (recommended) Add the `.git` folder to `.dockerignore`, so that it's not `COPY`'d. moon will continue to work just fine, albeit with some functionality disabled, like caching.\n\n- Ensure that the `git` library is installed in the container, and copy the `.git` folder with `COPY`. moon will work with full functionality, but it will increase the overall size of the image because of caching.\n\n## Creating a `Dockerfile`\n\ninfo\n\nOur [`moon docker file`](/docs/commands/docker/file) command can automatically generate a `Dockerfile` based on this\nguide! We suggest generating the file then reading the guide below to understand what's going on.\n\nWe're very familiar with how tedious `Dockerfile`s are to write and maintain, so in an effort to\nreduce this headache, we've built a handful of tools to make this process much easier. With moon,\nwe'll take advantage of Docker's layer caching and staged builds as much as possible.\n\nWith that being said, there's many approaches you can utilize, depending on your workflow (we'll\ndocument them below):\n\n- Running `moon docker` commands before running `docker run|build` commands.\n\n- Running `moon docker` commands within the `Dockerfile`.\n\n- Using multi-staged or non-staged (standard) builds.\n\n- Something else unique to your setup!\n\nwarning\n\nThis guide and our Docker approach is merely a suggestion and is not a requirement for using moon\nwith Docker! Feel free to use this as a starting point, or not at all. Choose the approach that\nworks best for you!\n\n### What we're trying to avoid\n\nBefore we dive into writing a perfect `Dockerfile`, we'll briefly talk about the pain points we're\ntrying to avoid. In the context of Node.js and monorepo's, you may be familiar with having to `COPY`\neach individual `package.json` in the monorepo before installing `node_modules`, to effectively use\nlayer caching. This is very brittle, as each new application or package is created, every\n`Dockerfile` in the monorepo will need to be modified to account for this new `package.json`.\n\nFurthermore, we'll have to follow a similar process for only copying source files necessary for\nthe build or `CMD` to complete. This is very tedious, so most developers simply use `COPY . .` and\nforget about it. Copying the entire monorepo is costly, especially as it grows.\n\nAs an example, we'll use moon's official repository. The `Dockerfile` would look something like the\nfollowing.\n\n```\nFROM node:latestWORKDIR /app# Install moon binaryRUN npm install -g @moonrepo/cli# Copy moon filesCOPY ./.moon ./.moon# Copy all package.json's and lockfilesCOPY ./packages/cli/package.json ./packages/cli/package.jsonCOPY ./packages/core-linux-arm64-gnu/package.json ./packages/core-linux-arm64-gnu/package.jsonCOPY ./packages/core-linux-arm64-musl/package.json ./packages/core-linux-arm64-musl/package.jsonCOPY ./packages/core-linux-x64-gnu/package.json ./packages/core-linux-x64-gnu/package.jsonCOPY ./packages/core-linux-x64-musl/package.json ./packages/core-linux-x64-musl/package.jsonCOPY ./packages/core-macos-arm64/package.json ./packages/core-macos-arm64/package.jsonCOPY ./packages/core-macos-x64/package.json ./packages/core-macos-x64/package.jsonCOPY ./packages/core-windows-x64-msvc/package.json ./packages/core-windows-x64-msvc/package.jsonCOPY ./packages/runtime/package.json ./packages/runtime/package.jsonCOPY ./packages/types/package.json ./packages/types/package.jsonCOPY ./package.json ./package.jsonCOPY ./yarn.lock ./yarn.lockCOPY ./.yarn ./.yarnCOPY ./.yarnrc.yml ./yarnrc.yml# Install toolchain and dependencies# In non-moon repos: yarn installRUN moon docker setup# Copy project and required files# Or COPY . .COPY ./packages/types ./packages/typesCOPY ./packages/runtime ./packages/runtime# Build the targetRUN moon run runtime:build\n```\n\nFor such a small monorepo, this already looks too confusing!!! Let's remedy this by utilizing moon\nitself to the fullest!\n\n### Scaffolding the bare minimum\n\nThe first step in this process is to only copy the bare minimum of files necessary for installing\ndependencies (Node.js modules, etc). This is typically manifests (`package.json`), lockfiles\n(`yarn.lock`, etc), and any configuration (`.yarnrc.yml`, etc).\n\nThis can all be achieved with the [`moon docker scaffold`](/docs/commands/docker/scaffold) command, which scaffolds a\nskeleton of the repository structure, with only necessary files (the above). Let's update our\n`Dockerfile` usage.\n\n- Non-staged\n- Multi-staged\n\nThis assumes [`moon docker scaffold `](/docs/commands/docker/scaffold) is ran outside of the `Dockerfile`.\n\n```\nFROM node:latestWORKDIR /app# Install moon binaryRUN npm install -g @moonrepo/cli# Copy workspace skeletonCOPY ./.moon/docker/workspace .# Install toolchain and dependenciesRUN moon docker setup\n```\n\n```\n#### BASEFROM node:latest AS baseWORKDIR /app# Install moon binaryRUN npm install -g @moonrepo/cli#### SKELETONFROM base AS skeleton# Copy entire repository and scaffoldCOPY . .RUN moon docker scaffold\n#### BUILDFROM base AS build# Copy workspace skeletonCOPY --from=skeleton /app/.moon/docker/workspace .# Install toolchain and dependenciesRUN moon docker setup\n```\n\nAnd with this, our dependencies will be layer cached effectively! Let's now move onto copying source\nfiles.\n\n### Copying necessary source files\n\nThe next step is to copy all source files necessary for `CMD` or any `RUN` commands to execute\ncorrectly. This typically requires copying all source files for the project and all source files\nof the project's dependencies... NOT the entire repository!\n\nLuckily our [`moon docker scaffold `](/docs/commands/docker/scaffold) command has already done this for us! Let's\ncontinue updating our `Dockerfile` to account for this, by appending the following:\n\n- Non-staged\n- Multi-staged\n\n```\n# Copy source filesCOPY ./.moon/docker/sources .# Build something (optional)RUN moon run\n:\n```\n\n```\n# Copy source filesCOPY --from=skeleton /app/.moon/docker/sources .# Build something (optional)RUN moon run\n:\n```\n\ninfo\n\nIf you need to copy additional files for your commands to run successfully, you can configure the\n`docker.scaffold.include` setting in [`.moon/workspace.yaml`](/docs/config/workspace#scaffold) (entire\nworkspace) or [`moon.yml`](/docs/config/project#scaffold) (per project).\n\n### Pruning extraneous files\n\nNow that we've ran a command or built an artifact, we should prune the Docker environment to remove\nunneeded files and folders. We can do this with the [`moon docker prune`](/docs/commands/docker/prune) command, which\nmust be ran within the context of a `Dockerfile`!\n\n```\n# Prune workspaceRUN moon docker prune\n```\n\nWhen ran, this command will do the following, in order:\n\n- Remove extraneous dependencies (`node_modules`) for unfocused projects.\n\n- Install production only dependencies for the projects that were scaffolded.\n\ninfo\n\nThis process can be customized using the `docker.prune` setting in\n[`.moon/workspace.yaml`](/docs/config/workspace#prune).\n\n### Final result\n\nAnd with this moon integration, we've reduced the original `Dockerfile` of 35 lines to 18 lines, a\nreduction of almost 50%. The original file can also be seen as `O(n)`, as each new manifest requires\ncascading updates, while the moon approach is `O(1)`!\n\n- Non-staged\n- Multi-staged\n\n```\nFROM node:latestWORKDIR /app# Install moon binaryRUN npm install -g @moonrepo/cli# Copy workspace skeletonCOPY ./.moon/docker/workspace .# Install toolchain and dependenciesRUN moon docker setup# Copy source filesCOPY ./.moon/docker/sources .# Build something (optional)RUN moon run\n:# Prune workspaceRUN moon docker prune# CMD\n```\n\n```\n#### BASEFROM node:latest AS baseWORKDIR /app# Install moon binaryRUN npm install -g @moonrepo/cli#### SKELETONFROM base AS skeleton# Copy entire repository and scaffoldCOPY . .RUN moon docker scaffold\n#### BUILDFROM base AS build# Copy workspace skeletonCOPY --from=skeleton /app/.moon/docker/workspace .# Install toolchain and dependenciesRUN moon docker setup# Copy source filesCOPY --from=skeleton /app/.moon/docker/sources .# Build something (optional)RUN moon run\n:# Prune workspaceRUN moon docker prune# CMD\n```\n\n## Running `docker` commands\n\nWhen running `docker` commands, they must be ran from moon's workspace root (typically the\nrepository root) so that the project graph and all `moon docker` commands resolve correctly.\n\n```\ndocker build .\n```\n\nIf you're `Dockerfile`s are located within each applicable project, use the `-f` argument.\n\n```\ndocker run -f ./apps/client/Dockerfile .\n```\n\n## Troubleshooting\n\n### Supporting `node:alpine` images\n\nIf you're trying to use the `node:alpine` image with moon's\n[integrated toolchain](/docs/concepts/toolchain), you'll need to set the `MOON_TOOLCHAIN_FORCE_GLOBALS`\nenvironment variable in the Docker image to disable moon's toolchain. This is required as Node.js\ndoes not provide pre-built binaries for the Alpine target, so installing the Node.js toolchain will\nfail.\n\n```\nFROM node:alpineENV MOON_TOOLCHAIN_FORCE_GLOBALS=true\n```\n\n## /docs/guides/examples/angular\n\nSource: https://moonrepo.dev/docs/guides/examples/angular\n\n# Angular example\n\nIn this guide, you'll learn how to integrate [Angular](https://angular.io/) into moon.\n\nBegin by creating a new Angular project in the root of an existing moon project (this should not be\ncreated in the workspace root, unless a polyrepo).\n\n```\ncd apps && npx -p @angular/cli@latest ng new angular-app\n```\n\nView the [official Angular docs](https://angular.io/start) for a more in-depth guide to getting\nstarted!\n\n## Setup\n\nSince Angular is per-project, the associated moon tasks should be defined in each project's\n[`moon.yml`](/docs/config/project) file.\n\n/moon.yml\n\n```\nfileGroups:  app:    - 'src/**/*'    - 'angular.*'tasks:  dev:    command: 'ng serve'    preset: 'server'  build:    command: 'ng build'    inputs:      - '@group(app)'      - '@group(sources)'    outputs:      - 'dist'  # Extends the top-level lint  lint:    args:      - '--ext'      - '.ts'\n```\n\n### ESLint integration\n\nAngular does not provide a built-in linting abstraction, but instead there is an\n[ESLint package](https://github.com/angular-eslint/angular-eslint), which is great, but complicates\nthings a bit. Because of this, you have two options for moving forward:\n\n- Use a [global `lint` task](/docs/guides/examples/eslint) and bypass Angular's solution (preferred).\n\n- Use Angular's ESLint package solution only.\n\nRegardless of which option is chosen, the following changes are applicable to all options and should\nbe made. Begin be installing the dependencies that the\n[`@angular-eslint`](https://nextjs.org/docs/basic-features/eslint#eslint-config) package need in the\napplication's `package.json`.\n\n- Yarn\n- Yarn (classic)\n- npm\n- pnpm\n- Bun\n\n```\nyarn workspace\n add --dev @angular-eslint/builder @angular-eslint/eslint-plugin @angular-eslint/eslint-plugin-template @angular-eslint/schematics @angular-eslint/template-parser\n```\n\n```\nyarn workspace\n add --dev @angular-eslint/builder @angular-eslint/eslint-plugin @angular-eslint/eslint-plugin-template @angular-eslint/schematics @angular-eslint/template-parser\n```\n\n```\nnpm install --save-dev --workspace\n @angular-eslint/builder @angular-eslint/eslint-plugin @angular-eslint/eslint-plugin-template @angular-eslint/schematics @angular-eslint/template-parser\n```\n\n```\npnpm add --save-dev --filter\n @angular-eslint/builder @angular-eslint/eslint-plugin @angular-eslint/eslint-plugin-template @angular-eslint/schematics @angular-eslint/template-parser\n```\n\n```\nbun install --dev @angular-eslint/builder @angular-eslint/eslint-plugin @angular-eslint/eslint-plugin-template @angular-eslint/schematics @angular-eslint/template-parser\n```\n\nSince Angular has some specific rules, we'll need to tell the ESLint package to overrides the\ndefault ones. This can be achieved with a project-level `.eslintrc.json` file.\n\n/.eslintrc.json\n\n```\n{  \"root\": true,  \"ignorePatterns\": [\"projects/**/*\"],  \"overrides\": [    {      \"files\": [\"*.ts\"],      \"extends\": [        \"eslint:recommended\",        \"plugin:@typescript-eslint/recommended\",        \"plugin:@angular-eslint/recommended\",        // This is required if you use inline templates in Components        \"plugin:@angular-eslint/template/process-inline-templates\"      ],      \"rules\": {        /**         * Any TypeScript source code (NOT TEMPLATE) related rules you wish to use/reconfigure over and above the         * recommended set provided by the @angular-eslint project would go here.         */        \"@angular-eslint/directive-selector\": [          \"error\",          { \"type\": \"attribute\", \"prefix\": \"app\", \"style\": \"camelCase\" }        ],        \"@angular-eslint/component-selector\": [          \"error\",          { \"type\": \"element\", \"prefix\": \"app\", \"style\": \"kebab-case\" }        ]      }    },    {      \"files\": [\"*.html\"],      \"extends\": [        \"plugin:@angular-eslint/template/recommended\",        \"plugin:@angular-eslint/template/accessibility\"      ],      \"rules\": {        /**         * Any template/HTML related rules you wish to use/reconfigure over and above the         * recommended set provided by the @angular-eslint project would go here.         */      }    }  ]}\n```\n\nWith the basics now setup, choose the option that works best for you.\n\n- Global lint\n- Angular lint\n\nWe encourage using the global `lint` task for consistency across all projects within the repository.\nWith this approach, the `eslint` command itself will be ran and the `ng lint` command will be\nignored, but the `@angular-eslint` rules will still be used.\n\nIf you'd prefer to use the `ng lint` command, add it as a task to the project's\n[`moon.yml`](/docs/config/project).\n\n/moon.yml\n\n```\ntasks:  lint:    command: 'ng lint'    inputs:      - '@group(angular)'\n```\n\nFurthermore, if a global `lint` task exists, be sure to exclude it from being inherited.\n\n/moon.yml\n\n```\nworkspace:  inheritedTasks:    exclude: ['lint']\n```\n\nIn addition to configuring `moon.yml`, you also need to add a lint target in the `angular.json` file\nfor linting to work properly. The lint target specifies which builder to use for linting, as well as\nthe file patterns that should be linted.\n\n/angular.json\n\n```\n{  \"projects\": {    \"angular-app\": {      \"architect\": {        \"lint\": {          \"builder\": \"@angular-eslint/builder:lint\",          \"options\": {            \"lintFilePatterns\": [\"src/**/*.ts\", \"src/**/*.html\"]          }        }      }    }  }}\n```\n\nAdding this lint target is crucial for ensuring that the linting process is properly configured and\nintegrated with Angular's build system.\n\n### TypeScript integration\n\nAngular has [built-in support for TypeScript](https://angular.io/guide/typescript-configuration), so\nthere is no need for additional configuration to enable TypeScript support.\n\nAt this point we'll assume that a `tsconfig.json` has been created in the application, and\ntypechecking works. From here we suggest utilizing a [global `typecheck` task](/docs/guides/examples/typescript) for\nconsistency across all projects within the repository.\n\n## Configuration\n\n### Root-level\n\nWe suggest against root-level configuration, as Angular should be installed per-project, and the\n`ng` command expects the configuration to live relative to the project root.\n\n### Project-level\n\nWhen creating a new Angular project, a [`angular.json`](https://angular.io/guide/workspace-config)\nis created, and must exist in the project root. This allows each project to configure Angular for\ntheir needs.\n\n/angular.json\n\n```\n{  \"$schema\": \"./node_modules/@angular/cli/lib/config/schema.json\",  \"version\": 1,  \"projects\": {    \"angular-app\": {      \"projectType\": \"application\",      ...    }  },  ...}\n```\n\n## /docs/guides/examples/astro\n\nSource: https://moonrepo.dev/docs/guides/examples/astro\n\n# Astro example\n\nIn this guide, you'll learn how to integrate [Astro](https://docs.astro.build).\n\nBegin by creating a new Astro project in the root of an existing moon project (this should not be\ncreated in the workspace root, unless a polyrepo).\n\n```\ncd apps && npm create astro@latest\n```\n\n## Setup\n\nSince Astro is per-project, the associated moon tasks should be defined in each project's\n[`moon.yml`](/docs/config/project) file.\n\ntip\n\nWe suggest inheriting Astro tasks from the\n[official moon configuration preset](https://github.com/moonrepo/moon-configs/tree/master/javascript/astro).\n\n/moon.yml\n\n```\n# Inherit tasks from the `astro` preset# https://github.com/moonrepo/moon-configstags: ['astro']# Disable project referencestoolchain:  typescript:    syncProjectReferences: false\n```\n\n### ESLint integration\n\nWhen using a [`lint`](/docs/guides/examples/eslint) task, the\n[`eslint-plugin-astro`](https://ota-meshi.github.io/eslint-plugin-astro/user-guide/) package must be\ninstalled to lint `.astro` files.\n\n- Yarn\n- Yarn (classic)\n- npm\n- pnpm\n- Bun\n\n```\nyarn workspace  add --dev eslint-plugin-astro\n```\n\n```\nyarn workspace  add --dev eslint-plugin-astro\n```\n\n```\nnpm install --save-dev --workspace  eslint-plugin-astro\n```\n\n```\npnpm add --save-dev --filter  eslint-plugin-astro\n```\n\n```\nbun install --dev eslint-plugin-astro\n```\n\nOnce the dependency has been installed in the application's `package.json`. We can then enable this\nconfiguration by creating an `.eslintrc.js` file in the project root. Be sure this file is listed in\nyour lint task's inputs!\n\n/.eslintrc.js\n\n```\nmodule.exports = {  extends: ['plugin:astro/recommended'],  overrides: [    {      files: ['*.astro'],      parser: 'astro-eslint-parser',      // If using TypeScript      parserOptions: {        parser: '@typescript-eslint/parser',        extraFileExtensions: ['.astro'],        project: 'tsconfig.json',        tsconfigRootDir: __dirname,      },    },  ],};\n```\n\nAnd lastly, when linting through moon's command line, you'll need to include the `.astro` extension\nwithin the `lint` task. This can be done by extending the top-level task within the project (below),\nor by adding it to the top-level entirely.\n\n/moon.yml\n\n```\ntasks:  lint:    args:      - '--ext'      - '.ts,.tsx,.astro'\n```\n\n### Prettier integration\n\nWhen using a [`format`](/docs/guides/examples/prettier) task, the `prettier-plugin-astro` package must be installed to\nformat `.astro` files. View the official\n[Astro docs](https://docs.astro.build/en/editor-setup/#prettier) for more information.\n\n- Yarn\n- Yarn (classic)\n- npm\n- pnpm\n- Bun\n\n```\nyarn workspace  add --dev prettier-plugin-astro\n```\n\n```\nyarn workspace  add --dev prettier-plugin-astro\n```\n\n```\nnpm install --save-dev --workspace  prettier-plugin-astro\n```\n\n```\npnpm add --save-dev --filter  prettier-plugin-astro\n```\n\n```\nbun install --dev prettier-plugin-astro\n```\n\n### TypeScript integration\n\nSince Astro utilizes custom `.astro` files, it requires a specialized TypeScript integration, and\nluckily Astro provides an [in-depth guide](https://docs.astro.build/en/guides/typescript/). With\nthat being said, we do have a few requirements and pointers!\n\n- Use the official [Astro `tsconfig.json`](https://docs.astro.build/en/guides/typescript/#setup) as a basis.\n\n- From our internal testing, the `astro check` command (that typechecks `.astro` files) does not support project references. If the `composite` compiler option is enabled, the checker will fail to find `.astro` files. To work around this, we disable `workspace.typescript` in our moon config above.\n\n- Since typechecking requires 2 commands, one for `.astro` files, and the other for `.ts`, `.tsx` files, we've added the [`typecheck`](/docs/guides/examples/typescript) task as a dependency for the `check` task. This will run both commands through a single task!\n\n## Configuration\n\n### Root-level\n\nWe suggest against root-level configuration, as Astro should be installed per-project, and the\n`astro` command expects the configuration to live relative to the project root.\n\n### Project-level\n\nWhen creating a new Astro project, a\n[`astro.config.mjs`](https://docs.astro.build/en/reference/configuration-reference/) is created, and\nmust exist in the project root. This allows each project to configure Astro for their needs.\n\n/astro.config.mjs\n\n```\nimport { defineConfig } from 'astro/config';// https://astro.build/configexport default defineConfig({});\n```\n\n## /docs/guides/examples/eslint\n\nSource: https://moonrepo.dev/docs/guides/examples/eslint\n\n# ESLint example\n\nIn this guide, you'll learn how to integrate [ESLint](https://eslint.org/) into moon.\n\nBegin by installing `eslint` and any plugins in your root. We suggest using the same version across\nthe entire repository.\n\n- Yarn\n- Yarn (classic)\n- npm\n- pnpm\n- Bun\n\n```\nyarn add --dev eslint eslint-config-moon\n```\n\n```\nyarn add --dev eslint eslint-config-moon# If using workspacesyarn add --dev -W eslint eslint-config-moon\n```\n\n```\nnpm install --save-dev eslint eslint-config-moon\n```\n\n```\npnpm add --save-dev eslint eslint-config-moon# If using workspacespnpm add --save-dev -w eslint eslint-config-moon\n```\n\n```\nbun install --dev eslint eslint-config-moon\n```\n\n## Setup\n\nSince linting is a universal workflow, add a `lint` task to\n[`.moon/tasks/node.yml`](/docs/config/tasks) with the following parameters.\n\n.moon/tasks/node.yml\n\n```\ntasks:  lint:    command:      - 'eslint'      # Support other extensions      - '--ext'      - '.js,.jsx,.ts,.tsx'      # Always fix and run extra checks      - '--fix'      - '--report-unused-disable-directives'      # Dont fail if a project has nothing to lint      - '--no-error-on-unmatched-pattern'      # Do fail if we encounter a fatal error      - '--exit-on-fatal-error'      # Only 1 ignore file is supported, so use the root      - '--ignore-path'      - '@in(4)'      # Run in current dir      - '.'    inputs:      # Source and test files      - 'src/**/*'      - 'tests/**/*'      # Other config files      - '*.config.*'      # Project configs, any format, any depth      - '**/.eslintrc.*'      # Root configs, any format      - '/.eslintignore'      - '/.eslintrc.*'\n```\n\nProjects can extend this task and provide additional parameters if need be, for example.\n\n/moon.yml\n\n```\ntasks:  lint:    args:      # Enable caching for this project      - '--cache'\n```\n\n### TypeScript integration\n\nIf you're using the [`@typescript-eslint`](https://typescript-eslint.io) packages, and want to\nenable type-safety based lint rules, we suggest something similar to the official\n[monorepo configuration](https://typescript-eslint.io/docs/linting/monorepo).\n\nCreate a `tsconfig.eslint.json` in your repository root, extend your shared compiler options (we use\n[`tsconfig.options.json`](/docs/guides/examples/typescript)), and include all your project files.\n\ntsconfig.eslint.json\n\n```\n{  \"extends\": \"./tsconfig.options.json\",  \"compilerOptions\": {    \"emitDeclarationOnly\": false,    \"noEmit\": true  },  \"include\": [\"apps/**/*\", \"packages/**/*\"]}\n```\n\nAppend the following inputs to your `lint` task.\n\n.moon/tasks/node.yml\n\n```\ntasks:  lint:    # ...    inputs:      # TypeScript support      - 'types/**/*'      - 'tsconfig.json'      - '/tsconfig.eslint.json'      - '/tsconfig.options.json'\n```\n\nAnd lastly, add `parserOptions` to your [root-level config](#root-level).\n\n## Configuration\n\n### Root-level\n\nThe root-level ESLint config is required, as ESLint traverses upwards from each file to find\nconfigurations, and this denotes the stopping point. It's also used to define rules for the entire\nrepository.\n\n.eslintrc.js\n\n```\nmodule.exports = {  root: true, // Required!  extends: ['moon'],  rules: {    'no-console': 'error',  },  // TypeScript support  parser: '@typescript-eslint/parser',  parserOptions: {    project: 'tsconfig.eslint.json',    tsconfigRootDir: __dirname,  },};\n```\n\nThe `.eslintignore` file must also be defined at the root, as\n[only 1 ignore file](https://eslint.org/docs/user-guide/configuring/ignoring-code#the-eslintignore-file)\ncan exist in a repository. We ensure this ignore file is used by passing `--ignore-path` above.\n\n.eslintignore\n\n```\nnode_modules/*.min.js*.map*.snap\n```\n\n### Project-level\n\nA project-level ESLint config can be utilized by creating a `.eslintrc.` in the\nproject root. This is optional, but necessary when defining rules and ignore patterns unique to the\nproject.\n\n/.eslintrc.js\n\n```\nmodule.exports = {  // Patterns to ignore (alongside the root .eslintignore)  ignorePatterns: ['build', 'lib'],  // Project specific rules  rules: {    'no-console': 'off',  },};\n```\n\nThe\n[`extends`](https://eslint.org/docs/user-guide/configuring/configuration-files#extending-configuration-files)\nsetting should not extend the root-level config, as ESLint will automatically merge configs\nwhile traversing upwards!\n\n### Sharing\n\nTo share configuration across projects, you have 3 options:\n\n- Define settings in the [root-level config](#root-level). This only applies to the parent repository.\n\n- Create and publish an [`eslint-config`](https://eslint.org/docs/developer-guide/shareable-configs#using-a-shareable-config) or [`eslint-plugin`](https://eslint.org/docs/developer-guide/working-with-plugins) npm package. This can be used in any repository.\n\n- A combination of 1 and 2.\n\nFor options 2 and 3, if you're utilizing package workspaces, create a local package with the\nfollowing content.\n\npackages/eslint-config-company/index.js\n\n```\nmodule.exports = {  extends: ['airbnb'],};\n```\n\nWithin your root-level ESLint config, you can extend this package to inherit the settings.\n\n.eslintrc.js\n\n```\nmodule.exports = {  extends: 'eslint-config-company',};\n```\n\nWhen using this approach, the package must be built and symlinked into `node_modules` before the\nlinter will run correctly. Take this into account when going down this path!\n\n## FAQ\n\n### How to lint a single file or folder?\n\nUnfortunately, this isn't currently possible, as the `eslint` binary itself requires a file or\nfolder path to operate on, and in the task above we pass `.` (current directory). If this was not\npassed, then nothing would be linted.\n\nThis has the unintended side-effect of not being able to filter down lintable targets by passing\narbitrary file paths. This is something we hope to resolve in the future.\n\nTo work around this limitation, you can create another lint task.\n\n### Should we use `overrides`?\n\nProjects should define their own rules using an ESLint config in their project root. However, if you\nwant to avoid touching many ESLint configs (think migrations), then\n[overrides in the root](https://eslint.org/docs/user-guide/configuring/configuration-files#configuration-based-on-glob-patterns)\nare a viable option. Otherwise, we highly encourage project-level configs.\n\n.eslintrc.js\n\n```\nmodule.exports = {  // ...  overrides: [    // Only apply to apps \"foo\" and \"bar\", but not others    {      files: ['apps/foo/**/*', 'apps/bar/**/*'],      rules: {        'no-magic-numbers': 'off',      },    },  ],};\n```\n\n## /docs/guides/examples/jest\n\nSource: https://moonrepo.dev/docs/guides/examples/jest\n\n# Jest example\n\nIn this guide, you'll learn how to integrate [Jest](https://jestjs.io/) into moon.\n\nBegin by installing `jest` in your root. We suggest using the same version across the entire\nrepository.\n\n- Yarn\n- Yarn (classic)\n- npm\n- pnpm\n- Bun\n\n```\nyarn add --dev jest\n```\n\n```\nyarn add --dev jest# If using workspacesyarn add --dev -W jest\n```\n\n```\nnpm install --save-dev jest\n```\n\n```\npnpm add --save-dev jest# If using workspacespnpm add --save-dev -w jest\n```\n\n```\nbun install --dev jest\n```\n\n## Setup\n\nSince testing is a universal workflow, add a `test` task to\n[`.moon/tasks/node.yml`](/docs/config/tasks) with the following parameters.\n\n.moon/tasks/node.yml\n\n```\ntasks:  test:    command:      - 'jest'      # Always run code coverage      - '--coverage'      # Dont fail if a project has no tests      - '--passWithNoTests'    inputs:      # Source and test files      - 'src/**/*'      - 'tests/**/*'      # Project configs, any format      - 'jest.config.*'\n```\n\nProjects can extend this task and provide additional parameters if need be, for example.\n\n/moon.yml\n\n```\ntasks:  test:    args:      # Disable caching for this project      - '--no-cache'\n```\n\n## Configuration\n\n### Root-level\n\nA root-level Jest config is not required and should be avoided, instead, use a [preset](#sharing) to\nshare configuration.\n\n### Project-level\n\nA project-level Jest config can be utilized by creating a `jest.config.` in the\nproject root. This is optional, but necessary when defining project specific settings.\n\n/jest.config.js\n\n```\nmodule.exports = {  // Project specific settings  testEnvironment: 'node',};\n```\n\n### Sharing\n\nTo share configuration across projects, you can utilize Jest's built-in\n[`preset`](https://jestjs.io/docs/configuration#preset-string) functionality. If you're utilizing\npackage workspaces, create a local package with the following content, otherwise publish the npm\npackage for consumption.\n\npackages/company-jest-preset/jest-preset.js\n\n```\nmodule.exports = {  testEnvironment: 'jsdom',  watchman: true,};\n```\n\nWithin your project-level Jest config, you can extend the preset to inherit the settings.\n\n/jest.config.js\n\n```\nmodule.exports = {  preset: 'company-jest-preset',};\n```\n\nYou can take this a step further by passing the `--preset` option in the [task above](#setup), so\nthat all projects inherit the preset by default.\n\n## FAQ\n\n### How to test a single file or folder?\n\nYou can filter tests by passing a file name, folder name, glob, or regex pattern after `--`. Any\npassed files are relative from the project's root, regardless of where the `moon` command is being\nran.\n\n```\n$ moon run\n:test -- filename\n```\n\n### How to use `projects`?\n\nWith moon, there's no reason to use\n[`projects`](https://jestjs.io/docs/configuration#projects-arraystring--projectconfig) as the `test`\ntask is ran per project. If you'd like to test multiple projects, use\n[`moon run :test`](/docs/commands/run).\n\n## /docs/guides/examples/nest\n\nSource: https://moonrepo.dev/docs/guides/examples/nest\n\n# Nest example\n\nIn this guide, you'll learn how to integrate [NestJS](https://nestjs.com/) into moon.\n\nBegin by creating a new NestJS project in the root of an existing moon project (this should not be\ncreated in the workspace root, unless a polyrepo).\n\n```\nnpx @nestjs/cli@latest new nestjs-app --skip-git\n```\n\nView the [official NestJS docs](https://docs.nestjs.com/first-steps) for a more in-depth guide to\ngetting started!\n\n## Setup\n\nSince NestJS is per-project, the associated moon tasks should be defined in each project's\n[`moon.yml`](/docs/config/project) file.\n\n/moon.yml\n\n```\nlayer: 'application'fileGroups:  app:    - 'nest-cli.*'tasks:  dev:    command: 'nest start --watch'    preset: 'server'  build:    command: 'nest build'    inputs:      - '@group(app)'      - '@group(sources)'\n```\n\n### TypeScript integration\n\nNestJS has [built-in support for TypeScript](https://NestJS.io/guide/typescript-configuration), so\nthere is no need for additional configuration to enable TypeScript support.\n\nAt this point we'll assume that a `tsconfig.json` has been created in the application, and\ntypechecking works. From here we suggest utilizing a [global `typecheck` task](/docs/guides/examples/typescript) for\nconsistency across all projects within the repository.\n\n## Configuration\n\n### Root-level\n\nWe suggest against root-level configuration, as NestJS should be installed per-project, and the\n`nest` command expects the configuration to live relative to the project root.\n\n### Project-level\n\nWhen creating a new NestJS project, a [`nest-cli.json`](https://docs.nestjs.com/cli/monorepo) is\ncreated, and must exist in the project root. This allows each project to configure NestJS for\ntheir needs.\n\n/nest-cli.json\n\n```\n{  \"$schema\": \"https://json.schemastore.org/nest-cli\",  \"collection\": \"@nestjs/schematics\",  \"type\": \"application\",  \"root\": \"./\",  \"sourceRoot\": \"src\",  \"compilerOptions\": {    \"tsConfigPath\": \"tsconfig.build.json\"  }}\n```\n\n## /docs/guides/examples/next\n\nSource: https://moonrepo.dev/docs/guides/examples/next\n\n# Next example\n\nIn this guide, you'll learn how to integrate [Next.js](https://nextjs.org) into moon.\n\nBegin by creating a new Next.js project at a specified folder path (this should not be created in\nthe workspace root, unless a polyrepo).\n\n```\ncd apps && npx create-next-app\n --typescript\n```\n\nView the [official Next.js docs](https://nextjs.org/learn/basics/create-nextjs-app/setup) for a\nmore in-depth guide to getting started!\n\n## Setup\n\nSince Next.js is per-project, the associated moon tasks should be defined in each project's\n[`moon.yml`](/docs/config/project) file.\n\ntip\n\nWe suggest inheriting Next.js tasks from the\n[official moon configuration preset](https://github.com/moonrepo/moon-configs/tree/master/javascript/next).\n\n/moon.yml\n\n```\n# Inherit tasks from the `next` preset# https://github.com/moonrepo/moon-configstags: ['next']\n```\n\n### ESLint integration\n\nNext.js has [built-in support for ESLint](https://nextjs.org/docs/basic-features/eslint), which is\ngreat, but complicates things a bit. Because of this, you have two options for moving forward:\n\n- Use a [global `lint` task](/docs/guides/examples/eslint) and bypass Next.js's solution (preferred).\n\n- Use Next.js's solution only.\n\nRegardless of which option is chosen, the following changes are applicable to all options and should\nbe made. Begin be installing the\n[`eslint-config-next`](https://nextjs.org/docs/basic-features/eslint#eslint-config) dependency in\nthe application's `package.json`.\n\n- Yarn\n- Yarn (classic)\n- npm\n- pnpm\n- Bun\n\n```\nyarn workspace\n add --dev eslint-config-next\n```\n\n```\nyarn workspace\n add --dev eslint-config-next\n```\n\n```\nnpm install --save-dev --workspace\n eslint-config-next\n```\n\n```\npnpm add --save-dev --filter\n eslint-config-next\n```\n\n```\nbun install --dev eslint-config-next\n```\n\nSince the Next.js app is located within a subfolder, we'll need to tell the ESLint plugin where to\nlocate it. This can be achieved with a project-level `.eslintrc.js` file.\n\n/.eslintrc.js\n\n```\nmodule.exports = {  extends: 'next', // or 'next/core-web-vitals'  settings: {    next: {      rootDir: __dirname,    },  },};\n```\n\nWith the basics now setup, choose the option that works best for you.\n\n- Global lint\n- Next.js lint\n\nWe encourage using the global `lint` task for consistency across all projects within the repository.\nWith this approach, the `eslint` command itself will be ran and the `next lint` command will be\nignored, but the `eslint-config-next` rules will still be used.\n\nAdditionally, we suggest disabling the linter during the build process, but is not a requirement. As\na potential alternative, add the `lint` task as a dependency for the `build` task.\n\n/next.config.js\n\n```\nmodule.exports = {  eslint: {    ignoreDuringBuilds: true,  },};\n```\n\nIf you'd prefer to use the `next lint` command, add it as a task to the project's\n[`moon.yml`](/docs/config/project).\n\n/moon.yml\n\n```\ntasks:  lint:    command: 'next lint'    inputs:      - '@group(next)'\n```\n\nFurthermore, if a global `lint` task exists, be sure to exclude it from being inherited.\n\n/moon.yml\n\n```\nworkspace:  inheritedTasks:    exclude: ['lint']\n```\n\n### TypeScript integration\n\nNext.js also has\n[built-in support for TypeScript](https://nextjs.org/docs/basic-features/typescript), but has\nsimilar caveats to the [ESLint integration](#eslint-integration). TypeScript itself is a bit\ninvolved, so we suggest reading the official Next.js documentation before continuing.\n\nAt this point we'll assume that a `tsconfig.json` has been created in the application, and\ntypechecking works. From here we suggest utilizing a [global `typecheck` task](/docs/guides/examples/typescript) for\nconsistency across all projects within the repository.\n\nAdditionally, we suggest disabling the typechecker during the build process, but is not a\nrequirement. As a potential alternative, add the `typecheck` task as a dependency for the `build`\ntask.\n\n/next.config.js\n\n```\nmodule.exports = {  typescript: {    ignoreBuildErrors: true,  },};\n```\n\n## Configuration\n\n### Root-level\n\nWe suggest against root-level configuration, as Next.js should be installed per-project, and the\n`next` command expects the configuration to live relative to the project root.\n\n### Project-level\n\nWhen creating a new Next.js project, a\n[`next.config.`](https://nextjs.org/docs/api-reference/next.config.js/introduction) is\ncreated, and must exist in the project root. This allows each project to configure Next.js for\ntheir needs.\n\n/next.config.js\n\n```\nmodule.exports = {  compress: true,};\n```\n\n## /docs/guides/examples/nuxt\n\nSource: https://moonrepo.dev/docs/guides/examples/nuxt\n\n# Nuxt example\n\nIn this guide, you'll learn how to integrate [Nuxt v3](https://nuxt.com), a [Vue](/docs/guides/examples/vue) framework,\ninto moon.\n\nBegin by creating a new Nuxt project at a specified folder path (this should not be created in the\nworkspace root, unless a polyrepo).\n\n```\ncd apps && npx nuxi init\n\n```\n\nView the [official Nuxt docs](https://nuxt.com/docs/getting-started/installation) for a more\nin-depth guide to getting started!\n\n## Setup\n\nSince Nuxt is per-project, the associated moon tasks should be defined in each project's\n[`moon.yml`](/docs/config/project) file.\n\n/moon.yml\n\n```\nfileGroups:  nuxt:    - 'assets/**/*'    - 'components/**/*'    - 'composables/**/*'    - 'content/**/*'    - 'layouts/**/*'    - 'middleware/**/*'    - 'pages/**/*'    - 'plugins/**/*'    - 'public/**/*'    - 'server/**/*'    - 'utils/**/*'    - '.nuxtignore'    - 'app.config.*'    - 'app.vue'    - 'nuxt.config.*'tasks:  nuxt:    command: 'nuxt'    preset: 'server'  # Production build  build:    command: 'nuxt build'    inputs:      - '@group(nuxt)'    outputs:      - '.nuxt'      - '.output'  # Development server  dev:    command: 'nuxt dev'    preset: 'server'  # Preview production build locally  preview:    command: 'nuxt preview'    deps:      - '~:build'    preset: 'server'\n```\n\nBe sure to keep the `postinstall` script in your project's `package.json`.\n\n/package.json\n\n```\n{  // ...  \"scripts\": {    \"postinstall\": \"nuxt prepare\"  }}\n```\n\n### ESLint integration\n\nRefer to our [Vue documentation](/docs/guides/examples/vue#eslint-integration) for more information on linting.\n\n### TypeScript integration\n\nNuxt requires `vue-tsc` for typechecking, so refer to our\n[Vue documentation](/docs/guides/examples/vue#typescript-integration) for more information.\n\n## Configuration\n\n### Root-level\n\nWe suggest against root-level configuration, as Nuxt should be installed per-project, and the\n`nuxt` command expects the configuration to live relative to the project root.\n\n### Project-level\n\nWhen creating a new Nuxt project, a\n[`nuxt.config.ts`](https://v3.nuxtjs.org/api/configuration/nuxt-config) is created, and must exist\nin the project root. This allows each project to configure Next.js for their needs.\n\n/nuxt.config.ts\n\n```\nexport default defineNuxtConfig({});\n```\n\n## Testing\n\nNuxt supports testing through [Jest](https://jestjs.io/) or [Vitest](https://vitest.dev/). Refer to\nour [Jest documentation](/docs/guides/examples/jest) or [Vitest documentation](/docs/guides/examples/vite) for more information on testing.\n\n## /docs/guides/examples/packemon\n\nSource: https://moonrepo.dev/docs/guides/examples/packemon\n\n# Packemon example\n\nIn this guide, you'll learn how to integrate [Packemon](https://packemon.dev/) into moon. Packemon\nis a tool for properly building npm packages for distribution, it does this by providing the\nfollowing functionality:\n\n- Compiles source code to popular formats: CJS, MJS, ESM, UMD, etc.\n\n- Validates the `package.json` for incorrect fields or values.\n\n- Generates `exports` mappings for `package.json` based on the define configuration.\n\n- And many more [optimizations and features](https://packemon.dev/docs/features)!\n\nBegin by installing `packemon` in your root. We suggest using the same version across the entire\nrepository.\n\n- Yarn\n- Yarn (classic)\n- npm\n- pnpm\n- Bun\n\n```\nyarn add --dev packemon\n```\n\n```\nyarn add --dev packemon# If using workspacesyarn add --dev -W packemon\n```\n\n```\nnpm install --save-dev packemon\n```\n\n```\npnpm add --save-dev packemon# If using workspacespnpm add --save-dev -w packemon\n```\n\n```\nbun install --dev packemon\n```\n\n## Setup\n\nSince Packemon is per-project, the associated moon tasks should be defined in each project's\n[`moon.yml`](/docs/config/project) file.\n\ntip\n\nWe suggest inheriting Packemon tasks from the\n[official moon configuration preset](https://github.com/moonrepo/moon-configs/tree/master/javascript/packemon).\n\n/moon.yml\n\n```\n# Inherit tasks from the `packemon` preset# https://github.com/moonrepo/moon-configstags: ['packemon']# Set the output formatstasks:  build:    outputs:      - 'cjs'\n```\n\n### TypeScript integration\n\nPackemon has built-in support for TypeScript, but to not conflict with a\n[typecheck task](/docs/guides/examples/typescript), a separate `tsconfig.json` file is required, which is named\n`tsconfig..json`.\n\nThis config is necessary to only compile source files, and to not include unwanted files in the\ndeclaration output directory.\n\ntsconfig.esm.json\n\n```\n{  \"extends\": \"../../tsconfig.options.json\",  \"compilerOptions\": {    \"outDir\": \"esm\",    \"rootDir\": \"src\"  },  \"include\": [\"src/**/*\"],  \"references\": []}\n```\n\n### Build targets\n\nTo configure the target platform(s) and format(s), you must define a\n[`packemon` block](https://packemon.dev/docs/config) in the project's `package.json`. The chosen\nformats must also be listed as `outputs` in the task.\n\npackage.json\n\n```\n{  \"name\": \"package\",  // ...  \"packemon\": {    \"format\": \"esm\",    \"platform\": \"browser\"  }}\n```\n\n## /docs/guides/examples/prettier\n\nSource: https://moonrepo.dev/docs/guides/examples/prettier\n\n# Prettier example\n\nIn this guide, you'll learn how to integrate [Prettier](https://prettier.io/) into moon.\n\nBegin by installing `prettier` in your root. We suggest using the same version across the entire\nrepository.\n\n- Yarn\n- Yarn (classic)\n- npm\n- pnpm\n- Bun\n\n```\nyarn add --dev prettier\n```\n\n```\nyarn add --dev prettier# If using workspacesyarn add --dev -W prettier\n```\n\n```\nnpm install --save-dev prettier\n```\n\n```\npnpm add --save-dev prettier# If using workspacespnpm add --save-dev -w prettier\n```\n\n```\nbun install --dev prettier\n```\n\n## Setup\n\nSince code formatting is a universal workflow, add a `format` task to\n[`.moon/tasks/node.yml`](/docs/config/tasks) with the following parameters.\n\n.moon/tasks/node.yml\n\n```\ntasks:  format:    command:      - 'prettier'      # Use the same config for the entire repo      - '--config'      - '@in(4)'      # Use the same ignore patterns as well      - '--ignore-path'      - '@in(3)'      # Fail for unformatted code      - '--check'      # Run in current dir      - '.'    inputs:      # Source and test files      - 'src/**/*'      - 'tests/**/*'      # Config and other files      - '**/*.{md,mdx,yml,yaml,json}'      # Root configs, any format      - '/.prettierignore'      - '/.prettierrc.*'\n```\n\n## Configuration\n\n### Root-level\n\nThe root-level Prettier config is required, as it defines conventions and standards to apply to\nthe entire repository.\n\n.prettierrc.js\n\n```\nmodule.exports = {  arrowParens: 'always',  semi: true,  singleQuote: true,  tabWidth: 2,  trailingComma: 'all',  useTabs: true,};\n```\n\nThe `.prettierignore` file must also be defined at the root, as\n[only 1 ignore file](https://prettier.io/docs/en/ignore.html#ignoring-files-prettierignore) can\nexist in a repository. We ensure this ignore file is used by passing `--ignore-path` above.\n\n.prettierignore\n\n```\nnode_modules/*.min.js*.map*.snap\n```\n\n### Project-level\n\nWe suggest against project-level configurations, as the entire repository should be formatted\nusing the same standards. However, if you're migrating code and need an escape hatch,\n[overrides in the root](https://prettier.io/docs/en/configuration.html#configuration-overrides) will\nwork.\n\n## FAQ\n\n### How to use `--write`?\n\nUnfortunately, this isn't currently possible, as the `prettier` binary itself requires either the\n`--check` or `--write` options, and since we're configuring `--check` in the task above, that takes\nprecedence. This is also the preferred pattern as checks will run (and fail) in CI.\n\nTo work around this limitation, we suggest the following alternatives:\n\n- Configure your editor to run Prettier on save.\n\n- Define another task to write the formatted code, like `format-write`.\n\n## /docs/guides/examples/react\n\nSource: https://moonrepo.dev/docs/guides/examples/react\n\n# React example\n\nReact is an application or library concern, and not a build system one, since the bundling of React\nis abstracted away through another tool like webpack. Because of this, moon has no guidelines around\nutilizing React directly. You can use React however you wish!\n\nHowever, with that being said, we do suggest the following:\n\n- Add `react` and related dependencies to each project, not the root. This includes `@types/react` as well. This will ensure accurate [hashing](/docs/concepts/cache#hashing).\n\n- Yarn\n- Yarn (classic)\n- npm\n- pnpm\n- Bun\n\n```\nyarn workspace\n add react\n```\n\n```\nyarn workspace\n add react\n```\n\n```\nnpm install --workspace\n react\n```\n\n```\npnpm add --filter\n react\n```\n\n```\nbun install react\n```\n\n- Configure Babel with the `@babel/preset-react` preset.\n\n- Configure [TypeScript](/docs/guides/examples/typescript) compiler options with `\"jsx\": \"react-jsx\"`.\n\n## /docs/guides/examples/remix\n\nSource: https://moonrepo.dev/docs/guides/examples/remix\n\n# Remix example\n\nIn this guide, you'll learn how to integrate [Remix](https://remix.run) into moon.\n\nBegin by creating a new Remix project at a specified folder path (this should not be created in the\nworkspace root, unless a polyrepo).\n\n```\ncd apps && npx create-remix\n```\n\nDuring this installation, Remix will ask a handful of questions, but be sure to answer \"No\" for the\n\"Do you want me to run `npm install`?\" question. We suggest installing dependencies at the workspace\nroot via package workspaces!\n\nView the [official Remix docs](https://remix.run/docs/en/v1) for a more in-depth guide to getting\nstarted!\n\n## Setup\n\nSince Remix is per-project, the associated moon tasks should be defined in each project's\n[`moon.yml`](/docs/config/project) file.\n\ntip\n\nWe suggest inheriting Remix tasks from the\n[official moon configuration preset](https://github.com/moonrepo/moon-configs/tree/master/javascript/remix).\n\n/moon.yml\n\n```\n# Inherit tasks from the `remix` preset# https://github.com/moonrepo/moon-configstags: ['remix']\n```\n\n### ESLint integration\n\nRemix does not provide a built-in linting abstraction, and instead provides a simple ESLint\nconfiguration package,\n[`@remix-run/eslint-config`](https://www.npmjs.com/package/@remix-run/eslint-config). For the rest\nof this section, we're going to assume that a [global `lint` task](/docs/guides/examples/eslint) has been configured.\n\nBegin be installing the `@remix-run/eslint-config` dependency in the application's `package.json`.\nWe can then enable this configuration by creating an `.eslintrc.js` file in the project root. Be\nsure this file is listed in your `lint` task's inputs!\n\n/.eslintrc.js\n\n```\nmodule.exports = {  extends: ['@remix-run/eslint-config', '@remix-run/eslint-config/node'],  // If using TypeScript  parser: '@typescript-eslint/parser',  parserOptions: {    project: 'tsconfig.json',    tsconfigRootDir: __dirname,  },};\n```\n\n### TypeScript integration\n\nRemix ships with TypeScript support (when enabled during installation), but the `tsconfig.json` it\ngenerates is not setup for TypeScript project references, which we suggest using with a\n[global `typecheck` task](/docs/guides/examples/typescript).\n\nWhen using project references, we suggest the following `tsconfig.json`, which is a mix of Remix and\nmoon. Other compiler options, like `isolatedModules` and `esModuleInterop`, should be declared in a\nshared configuration found in the workspace root (`tsconfig.projectOptions.json` in the example).\n\n/tsconfig.json\n\n```\n{  \"extends\": \"../../tsconfig.projectOptions.json\",  \"compilerOptions\": {    \"baseUrl\": \".\",    \"emitDeclarationOnly\": false,    \"jsx\": \"react-jsx\",    \"resolveJsonModule\": true,    \"moduleResolution\": \"node\",    \"noEmit\": true,    \"paths\": {      \"~/*\": [\"./app/*\"]    }  },  \"include\": [\".eslintrc.js\", \"remix.env.d.ts\", \"**/*\"],  \"exclude\": [\".cache\", \"build\", \"public\"]}\n```\n\n## Configuration\n\n### Root-level\n\nWe suggest against root-level configuration, as Remix should be installed per-project, and the\n`remix` command expects the configuration to live relative to the project root.\n\n### Project-level\n\nWhen creating a new Remix project, a\n[`remix.config.js`](https://remix.run/docs/en/v1/api/conventions) is created, and must exist in\nthe project root. This allows each project to configure Remix for their needs.\n\n/remix.config.js\n\n```\nmodule.exports = {  appDirectory: 'app',};\n```\n\n## /docs/guides/examples/solid\n\nSource: https://moonrepo.dev/docs/guides/examples/solid\n\n# Solid example\n\n[Solid](https://www.solidjs.com) (also known as SolidJS) is a JavaScript framework for building\ninteractive web applications. Because of this, Solid is an application or library concern, and not a\nbuild system one, since the bundling of Solid is abstracted away through the application or a\nbundler.\n\nWith that being said, we do have some suggestions on utilizing Solid effectively in a monorepo. To\nbegin, install Solid to a project.\n\n- Yarn\n- Yarn (classic)\n- npm\n- pnpm\n- Bun\n\n```\nyarn workspace\n add solid-js\n```\n\n```\nyarn workspace\n add solid-js\n```\n\n```\nnpm install --workspace\n solid-js\n```\n\n```\npnpm add --filter\n solid-js\n```\n\n```\nbun install solid-js\n```\n\n## Setup\n\nSolid utilizes JSX for rendering markup, which requires\n[`babel-preset-solid`](https://www.npmjs.com/package/babel-preset-solid) for parsing and\ntransforming. To enable the preset for the entire monorepo, add the preset to a root\n`babel.config.js`, otherwise add it to a `.babelrc.js` in each project that requires it.\n\n```\nmodule.exports = {  presets: ['solid'],};\n```\n\n### TypeScript integration\n\nFor each project using Solid, add the following compiler options to the `tsconfig.json` found in the\nproject root.\n\n/tsconfig.json\n\n```\n{  \"compilerOptions\": {    \"jsx\": \"preserve\",    \"jsxImportSource\": \"solid-js\"  }}\n```\n\n### Vite integration\n\nIf you're using a [Vite](/docs/guides/examples/vite) powered application (Solid Start or starter templates), you should\nenable [`vite-plugin-solid`](https://www.npmjs.com/package/vite-plugin-solid) instead of configuring\nBabel. Be sure to read our [guide on Vite](/docs/guides/examples/vite) as well!\n\n/vite.config.js\n\n```\nimport { defineConfig } from 'vite';import solidPlugin from 'vite-plugin-solid';export default defineConfig({  // ...  plugins: [solidPlugin()],});\n```\n\n## /docs/guides/examples/storybook\n\nSource: https://moonrepo.dev/docs/guides/examples/storybook\n\n# Storybook example\n\nStorybook is a frontend workshop for building UI components and pages in isolation. Thousands of\nteams use it for UI development, testing, and documentation. It‚Äôs open source and free.\n\n[Storybook v7](https://storybook.js.org/docs/7.0) is typically coupled with\n[Vite](https://vitejs.dev/). To scaffold a new Storybook project with Vite, run the following\ncommand in a project root. This guide assumes you are using React, however it is possible to use\nalmost any (meta) framework with Storybook.\n\n```\ncd\n && npx storybook init\n```\n\nWe highly suggest reading our documentation on [using Vite (and Vitest) with moon](/docs/guides/examples/vite) and\n[using Jest with moon](/docs/guides/examples/jest) for a more holistic view.\n\n## Setup\n\nThis section assumes Storybook is being used with Vite, and is integrated on a per-project basis.\n\nAfter setting up Storybook, ensure [`moon.yml`](/docs/config/project) has the following tasks:\n\n/moon.yml\n\n```\nfileGroups:  storybook:    - 'src/**/*'    - 'stories/**/*'    - 'tests/**/*'    - '.storybook/**/*'tasks:  buildStorybook:    command: 'build-storybook --output-dir @out(0)'    inputs:      - '@group(storybook)'    outputs:      - 'build'  storybook:    preset: 'server'    command: 'start-storybook'    inputs:      - '@group(storybook)'\n```\n\nTo run the Storybook development server:\n\n```\nmoon run\n:storybook\n```\n\n### Vite integration\n\nStorybook 7 uses Vite out of the box, and as such, no configuration is required, but should you\nchoose to extend the Vite config, you can do so by passing in `viteFinal`:\n\n.storybook/main.ts\n\n```\nimport { mergeConfig } from 'vite';export default {  stories: ['../stories/**/*.stories.mdx', '../stories/**/*.stories.@(js|jsx|ts|tsx)'],  addons: ['@storybook/addon-links', '@storybook/addon-essentials'],  core: {    builder: '@storybook/builder-vite',  },  async viteFinal(config) {    // Merge custom configuration into the default config    return mergeConfig(config, {      // Use the same \"resolve\" configuration as your app      resolve: (await import('../vite.config.js')).default.resolve,      // Add dependencies to pre-optimization      optimizeDeps: {        include: ['storybook-dark-mode'],      },    });  },};\n```\n\nFor more information on how to integrate Vite with Storybook see the\n[relevant documentation](https://storybook.js.org/docs/7.0/react/builders/vite#configuration).\n\n### Webpack integration\n\nIf you want to use Webpack with your Storybook project, you can do so by installing the relevant\npackage and updating configuration.\n\n- Yarn\n- Yarn (classic)\n- npm\n- pnpm\n- Bun\n\n```\nyarn workspace\n add --dev @storybook/builder-webpack5\n```\n\n```\nyarn workspace\n add --dev @storybook/builder-webpack5\n```\n\n```\nnpm install --save-dev --workspace\n @storybook/builder-webpack5\n```\n\n```\npnpm add --save-dev --filter\n @storybook/builder-webpack5\n```\n\n```\nbun install --dev @storybook/builder-webpack5\n```\n\n.storybook/main.ts\n\n```\nexport default {  core: {    builder: '@storybook/builder-webpack5',  },};\n```\n\nFor more information on how to integrate Webpack with Storybook, see the\n[relevant documentation](https://storybook.js.org/docs/7.0/react/builders/webpack).\n\n### Jest integration\n\nYou can use Jest to test your stories, but isn't a requirement. Storybook ships with first-party\nplugins for improved developer experience.\n\nInstall the test runner and any relevant packages:\n\n- Yarn\n- Yarn (classic)\n- npm\n- pnpm\n- Bun\n\n```\nyarn workspace\n add --dev @storybook/addon-interactions @storybook/addon-coverage @storybook/jest@next @storybook/testing-library@next @storybook/test-runner@next\n```\n\n```\nyarn workspace\n add --dev @storybook/addon-interactions @storybook/addon-coverage @storybook/jest@next @storybook/testing-library@next @storybook/test-runner@next\n```\n\n```\nnpm install --save-dev --workspace\n @storybook/addon-interactions @storybook/addon-coverage @storybook/jest@next @storybook/testing-library@next @storybook/test-runner@next\n```\n\n```\npnpm add --save-dev --filter\n @storybook/addon-interactions @storybook/addon-coverage @storybook/jest@next @storybook/testing-library@next @storybook/test-runner@next\n```\n\n```\nbun install --dev @storybook/addon-interactions @storybook/addon-coverage @storybook/jest@next @storybook/testing-library@next @storybook/test-runner@next\n```\n\nAdd the test task to your project:\n\n/moon.yml\n\n```\ntasks:  testStorybook:    command: 'test-storybook'    inputs:      - '@group(storybook)'\n```\n\nThen enable plugins and interactions in your Storybook project:\n\n.storybook/main.ts\n\n```\nexport default {  stories: ['../src/**/*.stories.mdx', '../src/**/*.stories.@(js|jsx|ts|tsx)'],  addons: [    // Other Storybook addons    '@storybook/addon-interactions', // Addon is registered here    '@storybook/addon-coverage',  ],  features: {    interactionsDebugger: true, // Enable playback controls  },};\n```\n\nYou can now start writing your tests. For an extended guide on how to write tests within your\nstories, see\n[writing an interaction test](https://storybook.js.org/docs/react/writing-tests/interaction-testing#write-an-interaction-test)\non the Storybook docs.\n\n## Configuration\n\nStorybook requires a `.storybook` folder relative to the project root. Because of this, Storybook\nshould be scaffolded in each project individually. Configuration may be shared through package\nimports.\n\n## /docs/guides/examples/sveltekit\n\nSource: https://moonrepo.dev/docs/guides/examples/sveltekit\n\n# SvelteKit example\n\n[SvelteKit](https://kit.svelte.dev) is built on [Svelte](https://svelte.dev), a UI framework that\nuses a compiler to let you write breathtakingly concise components that do minimal work in the\nbrowser, using languages you already know ‚Äî HTML, CSS and JavaScript. It's a love letter to web\ndevelopment.\n\n```\ncd apps && npm create svelte@latest\n\n```\n\nYou will be prompted to choose between select templates, TypeScript, ESLint, Prettier, Playwright\nand Vitest among other options. moon supports and has guides for many of these tools.\n\nWe highly suggest reading our documentation on [using Vite (and Vitest) with moon](/docs/guides/examples/vite),\n[using ESLint with moon](/docs/guides/examples/eslint) and [using Prettier with moon](/docs/guides/examples/prettier) for a more holistic\nview.\n\n## Setup\n\nSince SvelteKit is per-project, the associated moon tasks should be defined in each project's\n[`moon.yml`](/docs/config/project) file.\n\ntip\n\nWe suggest inheriting SvelteKit tasks from the\n[official moon configuration preset](https://github.com/moonrepo/moon-configs/tree/master/javascript/sveltekit).\n\n/moon.yml\n\n```\n# Inherit tasks from the `sveltekit` preset# https://github.com/moonrepo/moon-configstags: ['sveltekit']\n```\n\n### ESLint integration\n\nSvelteKit provides an option to setup ESLint along with your project, with moon you can use a\n[global `lint` task](/docs/guides/examples/eslint). We encourage using the global `lint` task for consistency across all\nprojects within the repository. With this approach, the `eslint` command itself will be ran and the\n`svelte3` rules will still be used.\n\n/moon.yml\n\n```\ntasks:  # Extends the top-level lint  lint:    args:      - '--ext'      - '.ts,.svelte'\n```\n\nBe sure to enable the Svelte parser and plugin in a project local ESLint configuration file.\n\n.eslintrc.cjs\n\n```\nmodule.exports = {  plugins: ['svelte3'],  ignorePatterns: ['*.cjs'],  settings: {    'svelte3/typescript': () => require('typescript'),  },  overrides: [{ files: ['*.svelte'], processor: 'svelte3/svelte3' }],};\n```\n\n### TypeScript integration\n\nSvelteKit also has built-in support for TypeScript, but has similar caveats to the\n[ESLint integration](#eslint-integration). TypeScript itself is a bit involved, so we suggest\nreading the official [SvelteKit documentation](https://kit.svelte.dev/docs/introduction) before\ncontinuing.\n\nAt this point we'll assume that a `tsconfig.json` has been created in the application, and\ntypechecking works. From here we suggest utilizing a [global `typecheck` task](/docs/guides/examples/typescript) for\nconsistency across all projects within the repository. However, because Svelte isn't standard\nJavaScript, it requires the use of the `svelte-check` command for type-checking.\n\ninfo\n\nThe\n[moon configuration preset](https://github.com/moonrepo/moon-configs/tree/master/javascript/sveltekit)\nprovides the `check` task below.\n\n/moon.yml\n\n```\nworkspace:  inheritedTasks:    exclude: ['typecheck']tasks:  check:    command: 'svelte-check --tsconfig ./tsconfig.json'    deps:      - 'typecheck-sync'    inputs:      - '@group(svelte)'      - 'tsconfig.json'\n```\n\nIn case Svelte doesn't automatically create a `tsconfig.json`, you can use the following:\n\n/tsconfig.json\n\n```\n{  \"extends\": \"./.svelte-kit/tsconfig.json\",  \"compilerOptions\": {    \"allowJs\": true,    \"checkJs\": true,    \"esModuleInterop\": true,    \"forceConsistentCasingInFileNames\": true,    \"resolveJsonModule\": true,    \"skipLibCheck\": true,    \"sourceMap\": true,    \"strict\": true  }}\n```\n\n## Configuration\n\n### Root-level\n\nWe suggest against root-level configuration, as SvelteKit should be installed per-project, and the\n`vite` command expects the configuration to live relative to the project root.\n\n### Project-level\n\nWhen creating a new SvelteKit project, a\n[`svelte.config.js`](https://kit.svelte.dev/docs/configuration) is created, and must exist in the\nproject root. This allows each project to configure SvelteKit for their needs.\n\n/svelte.config.js\n\n```\nimport adapter from '@sveltejs/adapter-auto';import { vitePreprocess } from '@sveltejs/kit/vite';/** @type {import('@sveltejs/kit').Config} */const config = {  // Consult https://kit.svelte.dev/docs/integrations#preprocessors  // for more information about preprocessors  preprocess: vitePreprocess(),  kit: {    adapter: adapter(),  },};export default config;\n```\n\n## /docs/guides/examples/typescript\n\nSource: https://moonrepo.dev/docs/guides/examples/typescript\n\n# TypeScript example\n\nIn this guide, you'll learn how to integrate [TypeScript](https://www.typescriptlang.org/) into\nmoon. We'll be using [project references](/docs/guides/javascript/typescript-project-refs), as it ensures that\nonly affected projects are built, and not the entire repository.\n\nBegin by installing `typescript` and any pre-configured tsconfig packages in your root. We suggest\nusing the same version across the entire repository.\n\n- Yarn\n- Yarn (classic)\n- npm\n- pnpm\n- Bun\n\n```\nyarn add --dev typescript tsconfig-moon\n```\n\n```\nyarn add --dev typescript tsconfig-moon# If using workspacesyarn add --dev -W typescript tsconfig-moon\n```\n\n```\nnpm install --save-dev typescript tsconfig-moon\n```\n\n```\npnpm add --save-dev typescript tsconfig-moon# If using workspacespnpm add --save-dev -w typescript tsconfig-moon\n```\n\n```\nbun install --dev typescript tsconfig-moon\n```\n\n## Setup\n\nSince typechecking is a universal workflow, add a `typecheck` task to\n[`.moon/tasks/node.yml`](/docs/config/tasks) with the following parameters.\n\n.moon/tasks/node.yml\n\n```\ntasks:  typecheck:    command:      - 'tsc'      # Use incremental builds with project references      - '--build'      # Always use pretty output      - '--pretty'      # Use verbose logging to see affected projects      - '--verbose'    inputs:      # Source and test files      - 'src/**/*'      - 'tests/**/*'      # Type declarations      - 'types/**/*'      # Project configs      - 'tsconfig.json'      - 'tsconfig.*.json'      # Root configs (extended from only)      - '/tsconfig.options.json'    outputs:      # Matches `compilerOptions.outDir`      - 'lib'\n```\n\nProjects can extend this task and provide additional parameters if need be, for example.\n\n/moon.yml\n\n```\ntasks:  typecheck:    args:      # Force build every time      - '--force'\n```\n\n## Configuration\n\n### Root-level\n\nMultiple root-level TypeScript configs are required, as we need to define compiler options that\nare shared across the repository, and we need to house a list of all project references.\n\nTo start, let's create a `tsconfig.options.json` that will contain our compiler options. In our\nexample, we'll extend [tsconfig-moon](https://www.npmjs.com/package/tsconfig-moon) for convenience.\nSpecifically, the `tsconfig.workspaces.json` config, which enables ECMAScript modules, composite\nmode, declaration emitting, and incremental builds.\n\ntsconfig.options.json\n\n```\n{  \"extends\": \"tsconfig-moon/tsconfig.projects.json\",  \"compilerOptions\": {    // Your custom options    \"moduleResolution\": \"nodenext\",    \"target\": \"es2022\"  }}\n```\n\nWe'll also need the standard `tsconfig.json` to house our project references. This is used by\neditors and tooling for deep integrations.\n\ntsconfig.json\n\n```\n{  \"extends\": \"./tsconfig.options.json\",  \"files\": [],  // All project references in the repo  \"references\": []}\n```\n\nThe [`typescript.rootConfigFileName`](/docs/config/toolchain#rootconfigfilename) setting can be\nused to change the root-level config name and the\n[`typescript.syncProjectReferences`](/docs/config/toolchain#syncprojectreferences) setting will\nautomatically keep project references in sync!\n\n### Project-level\n\nEvery project will require a `tsconfig.json`, as TypeScript itself requires it. The following\n`tsconfig.json` will typecheck the entire project, including source and test files.\n\n/tsconfig.json\n\n```\n{  // Extend the root compiler options  \"extends\": \"../../tsconfig.options.json\",  \"compilerOptions\": {    // Declarations are written here    \"outDir\": \"lib\"  },  // Include files in the project  \"include\": [\"src/**/*\", \"tests/**/*\"],  // Depends on other projects  \"references\": []}\n```\n\nThe [`typescript.projectConfigFileName`](/docs/config/toolchain#projectconfigfilename) setting can\nbe used to change the project-level config name.\n\n### Sharing\n\nTo share configuration across projects, you have 3 options:\n\n- Define settings in a [root-level config](#root-level). This only applies to the parent repository.\n\n- Create and publish an [`tsconfig base`](https://www.typescriptlang.org/docs/handbook/tsconfig-json.html#tsconfig-bases) npm package. This can be used in any repository.\n\n- A combination of 1 and 2.\n\nFor options 2 and 3, if you're utilizing package workspaces, create a local package with the\nfollowing content.\n\npackages/tsconfig-company/tsconfig.json\n\n```\n{  \"compilerOptions\": {    // ...    \"lib\": [\"esnext\"]  }}\n```\n\nWithin another `tsconfig.json`, you can extend this package to inherit the settings.\n\ntsconfig.json\n\n```\n{  \"extends\": \"tsconfig-company/tsconfig.json\"}\n```\n\n## FAQ\n\n### How to preserve pretty output?\n\nTypeScript supports a pretty format where it includes codeframes and color highlighting for\nfailures. However, when `tsc` is piped or the terminal is not a TTY, the pretty format is lost. To\npreserve and always display the pretty format, be sure to pass the `--pretty` argument!\n\n## /docs/guides/examples/vite\n\nSource: https://moonrepo.dev/docs/guides/examples/vite\n\n# Vite & Vitest example\n\nIn this guide, you'll learn how to integrate [Vite](https://vitejs.dev/) and\n[Vitest](https://vitest.dev/) into moon.\n\nBegin by creating a new Vite project in the root of an existing moon project (this should not be\ncreated in the workspace root, unless a polyrepo).\n\n- Yarn\n- Yarn (classic)\n- npm\n- pnpm\n\n```\nyarn create vite\n```\n\n```\nyarn create vite\n```\n\n```\nnpm create vite\n```\n\n```\npnpm create vite\n```\n\nIf you plan on using Vitest, run the following command to add the `vitest` dependency to a project,\notherwise skip to the setup section.\n\n- Yarn\n- Yarn (classic)\n- npm\n- pnpm\n- Bun\n\n```\nyarn workspace\n add --dev vitest\n```\n\n```\nyarn workspace\n add --dev vitest\n```\n\n```\nnpm install --save-dev --workspace\n vitest\n```\n\n```\npnpm add --save-dev --filter\n vitest\n```\n\n```\nbun install --dev vitest\n```\n\n## Setup\n\nSince Vite is per-project, the associated moon tasks should be defined in each project's\n[`moon.yml`](/docs/config/project) file.\n\ntip\n\nWe suggest inheriting Vite tasks from the\n[official moon configuration preset](https://github.com/moonrepo/moon-configs/tree/master/javascript/vite).\n\n/moon.yml\n\n```\n# Inherit tasks from the `vite` and `vitest` presets# https://github.com/moonrepo/moon-configstags: ['vite', 'vitest']\n```\n\n## Configuration\n\n### Root-level\n\nWe suggest against root-level configuration, as Vite should be installed per-project, and the\n`vite` command expects the configuration to live relative to the project root.\n\n### Project-level\n\nWhen creating a new Vite project, a [`vite.config.`](https://vitejs.dev/config) is created,\nand must exist in the project root.\n\n/vite.config.js\n\n```\nimport { defineConfig } from 'vite';export default defineConfig({  // ...  build: {    // These must be `outputs` in the `build` task    outDir: 'dist',  },  test: {    // Vitest settings  },});\n```\n\nIf you'd prefer to configure Vitest in a\n[separate configuration file](https://vitest.dev/guide/#configuring-vitest), create a\n`vitest.config.` file.\n\n## /docs/guides/examples/vue\n\nSource: https://moonrepo.dev/docs/guides/examples/vue\n\n# Vue example\n\nVue is an application or library concern, and not a build system one, since the bundling of Vue is\nabstracted away through other tools. Because of this, moon has no guidelines around utilizing Vue\ndirectly. You can use Vue however you wish!\n\nHowever, with that being said, Vue is typically coupled with [Vite](https://vitejs.dev/). To\nscaffold a new Vue project with Vite, run the following command in a project root.\n\n```\nnpm init vue@latest\n```\n\nWe highly suggest reading our documentation on [using Vite (and Vitest) with moon](/docs/guides/examples/vite) for a\nmore holistic view.\n\n## Setup\n\nThis section assumes Vue is being used with Vite.\n\n### ESLint integration\n\nWhen linting with [ESLint](/docs/guides/examples/eslint) and the\n[`eslint-plugin-vue`](https://eslint.vuejs.org/user-guide/#installation) library, you'll need to\ninclude the `.vue` extension within the `lint` task. This can be done by extending the top-level\ntask within the project (below), or by adding it to the top-level entirely.\n\n/moon.yml\n\n```\ntasks:  lint:    args:      - '--ext'      - '.js,.ts,.vue'\n```\n\nFurthermore, when using TypeScript within ESLint, we need to make a few additional changes to the\n`.eslintrc.js` config found in the root (if the entire repo is Vue), or within the project (if only\nthe project is Vue).\n\n```\nmodule.exports = {  parser: 'vue-eslint-parser',  parserOptions: {    extraFileExtensions: ['.vue'],    parser: '@typescript-eslint/parser',    project: 'tsconfig.json', // Or another config    tsconfigRootDir: __dirname,  },};\n```\n\n### TypeScript integration\n\nVue does not use [TypeScript](/docs/guides/examples/typescript)'s `tsc` binary directly, but instead uses\n[`vue-tsc`](https://vuejs.org/guide/typescript/overview.html), which is a thin wrapper around `tsc`\nto support Vue components. Because of this, we should update the `typecheck` task in the project to\nutilize this command instead.\n\n/moon.yml\n\n```\nworkspace:  inheritedTasks:    exclude: ['typecheck']tasks:  typecheck:    command:      - 'vue-tsc'      - '--noEmit'      # Always use pretty output      - '--pretty'    inputs:      - 'env.d.ts'      # Source and test files      - 'src/**/*'      - 'tests/**/*'      # Project configs      - 'tsconfig.json'      - 'tsconfig.*.json'      # Root configs (extended from only)      - '/tsconfig.options.json'\n```\n\nBe sure `tsconfig.json` compiler options are based on\n[`@vue/tsconfig`](https://vuejs.org/guide/typescript/overview.html#configuring-tsconfig-json).\n\n## /docs/guides/extensions\n\nSource: https://moonrepo.dev/docs/guides/extensions\n\n# Extensions\n\nv1.20.0\n\nAn extension is a WASM plugin that allows you to extend moon with additional functionality, have\nwhitelisted access to the file system, and receive partial information about the current workspace.\nExtensions are extremely useful in offering new and unique functionality that doesn't need to be\nbuilt into moon's core. It also enables the community to build and share their own extensions!\n\n## Using extensions\n\nBefore an extension can be executed with the [`moon ext`](/docs/commands/ext) command, it must be\nconfigured with the [`extensions`](/docs/config/workspace#extensions) setting in\n[`.moon/workspace.yml`](/docs/config/workspace) (excluding [built-in's](#built-in-extensions)).\n\n.moon/workspace.yml\n\n```\nextensions:  example:    plugin: 'https://example.com/path/to/example.wasm'\n```\n\nOnce configured, it can be executed with [`moon ext`](/docs/commands/ext) by name. Arguments unique to\nthe extension must be passed after a `--` separator.\n\n```\n$ moon ext example -- --arg1 --arg2\n```\n\n## Built-in extensions\n\nmoon is shipped with a few built-in extensions that are configured and enabled by default. Official\nmoon extensions are built and published in our [moonrepo/moon-extensions](https://github.com/moonrepo/moon-extensions) repository.\n\n### `download`\n\nThe `download` extension can be used to download a file from a URL into the current workspace, as\ndefined by the `--url` argument. For example, say we want to download the latest [proto](/proto)\nbinary:\n\n```\n$ moon ext download --\\  --url https://github.com/moonrepo/proto/releases/latest/download/proto_cli-aarch64-apple-darwin.tar.xz\n```\n\nBy default this will download `proto_cli-aarch64-apple-darwin.tar.xz` into the current working\ndirectory. To customize the location, use the `--dest` argument. However, do note that the\ndestination must be within the current moon workspace, as only certain directories are whitelisted\nfor WASM.\n\n```\n$ moon ext download --\\  --url https://github.com/moonrepo/proto/releases/latest/download/proto_cli-aarch64-apple-darwin.tar.xz\\  --dest ./temp\n```\n\n#### Arguments\n\n- `--url` (required) - URL of a file to download.\n\n- `--dest` - Destination folder to save the file. Defaults to the current working directory.\n\n- `--name` - Override the file name. Defaults to the file name in the URL.\n\n### `migrate-nx`v1.22.0\n\nThis extension is currently experimental and will be improved over time.\n\nThe `migrate-nx` extension can be used to migrate an Nx powered repository to moon. This process\nwill convert the root `nx.json` and `workspace.json` files, and any `project.json` and\n`package.json` files found within the repository. The following changes are made:\n\n- Migrates `targetDefaults` as global tasks to [`.moon/tasks/node.yml`](/docs/config/tasks#tasks) (or `bun.yml`), `namedInputs` as file groups, `workspaceLayout` as projects, and more.\n\n- Migrates all `project.json` settings to [`moon.yml`](/docs/config/project#tasks) equivalent settings. Target to task conversion assumes the following: Target `executor` will be removed, and we'll attempt to extract the appropriate npm package command. For example, `@nx/webpack:build` -> `webpack build`.\n\n- Target `options` will be converted to task `args`.\n\n- The `{projectRoot}` and `{workspaceRoot}` interpolations will be replaced with moon tokens.\n\n```\n$ moon ext migrate-nx\n```\n\ncaution\n\nNx and moon are quite different, so many settings are either ignored when converting, or are not a\n1:1 conversion. We do our best to convert as much as possible, but some manual patching will most\nlikely be required! We suggest testing each converted task 1-by-1 to ensure it works as expected.\n\n#### Arguments\n\n- `--bun` - Migrate to Bun based commands instead of Node.js.\n\n- `--cleanup` - Remove Nx configs/files after migrating.\n\n#### Unsupported\n\nThe following features are not supported in moon, and are ignored when converting.\n\n- Most settings in `nx.json`.\n\n- Named input variants: external dependencies, dependent task output files, dependent project inputs, or runtime commands.\n\n- Target `configurations` and `defaultConfiguration`. Another task will be created instead that uses `extends`.\n\n- Project `root` and `sourceRoot`.\n\n### `migrate-turborepo`v1.21.0\n\nThe `migrate-turborepo` extension can be used to migrate a Turborepo powered repository to moon.\nThis process will convert the root `turbo.json` file, and any `turbo.json` files found within the\nrepository. The following changes are made:\n\n- Migrates `pipeline` (v1) and `tasks` (v2) global tasks to [`.moon/tasks/node.yml`](/docs/config/tasks#tasks) (or `bun.yml`) and project scoped tasks to [`moon.yml`](/docs/config/project#tasks). Task commands will execute `package.json` scripts through a package manager.\n\n- Migrates root `global*` settings to [`.moon/tasks/node.yml`](/docs/config/tasks#implicitinputs) (or `bun.yml`) as `implicitInputs`.\n\n```\n$ moon ext migrate-turborepo\n```\n\n#### Arguments\n\n- `--bun` - Migrate to Bun based commands instead of Node.js.\n\n- `--cleanup` - Remove Turborepo configs/files after migrating.\n\n### `unpack`v2.0.0\n\nThe `unpack` extension can be used to unpack an archive (zip/tar) from a file path or URL into a\ndestination folder.\n\n```\n$ moon ext unpack -- --src ./path/to/archive.zip --dest ./output --prefix path/to/strip\n```\n\n#### Arguments\n\n- `--src` (required) - Path or URL of a file to unpack.\n\n- `--dest` - Destination folder to unpack into. Defaults to the current working directory.\n\n- `--prefix` - A prefix path to strip from unpacked files.\n\n## Creating an extension\n\nRefer to our [official WASM guide](/docs/guides/wasm-plugins) for more information on how our WASM plugins\nwork, critical concepts to know, how to create a plugin, and more. Once you have a good\nunderstanding, you may continue this specific guide.\n\nnote\n\nRefer to our [moonrepo/moon-extensions](https://github.com/moonrepo/moon-extensions) repository for in-depth examples.\n\n### Registering metadata\n\nBefore we begin, we must implement the `register_extension` function, which simply provides some\nmetadata that we can bubble up to users, or to use for deeper integrations.\n\n```\nuse extism_pdk::*;use moon_pdk::*;#[plugin_fn]pub fn register_extension(Json(input): Json) -> FnResult> {   Ok(Json(ExtensionMetadataOutput {        name: \"Extension name\".into(),        description: Some(\"A description about what the extension does.\".into()),        plugin_version: env!(\"CARGO_PKG_VERSION\").into(),        ..ExtensionMetadataOutput::default()    }))}\n```\n\n#### Configuration schema\n\nIf you are using [configuration](#supporting-configuration), you can register the shape of the\nconfiguration using the [`schematic`](https://crates.io/crates/schematic) crate. This shape will be\nused to generate outputs such as JSON schemas, or TypeScript types.\n\n```\n#[plugin_fn]pub fn register_extension(_: ()) -> FnResult> {    Ok(Json(ExtensionMetadataOutput {        // ...        config_schema: Some(schematic::SchemaBuilder::generate::()),    }))}\n```\n\nSchematic is a heavy library, so we suggest adding the dependency like so:\n\n```\n[dependencies]schematic = { version = \"*\", default-features = false, features = [\"schema\"] }\n```\n\n### Implementing execution\n\nExtensions support a single plugin function, `execute_extension`, which is called by the\n[`moon ext`](/docs/commands/ext) command to execute the extension. This is where all your business\nlogic will reside.\n\n```\n#[host_fn]extern \"ExtismHost\" {    fn host_log(input: Json);}#[plugin_fn]pub fn execute_extension(Json(input): Json) -> FnResult {  host_log!(stdout, \"Executing extension!\");  Ok(())}\n```\n\n### Supporting arguments\n\nMost extensions will require arguments, as it provides a mechanism for users to pass information\ninto the WASM runtime. To parse arguments, we provide the\n[`Args`](https://docs.rs/clap/latest/clap/trait.Args.html) trait/macro from the\n[clap](https://crates.io/crates/clap) crate. Refer to their\n[official documentation on usage](https://docs.rs/clap/latest/clap/_derive/index.html) (we don't\nsupport everything).\n\n```\nuse moon_pdk::*;#[derive(Args)]pub struct ExampleExtensionArgs {  // --url, -u  #[arg(long, short = 'u', required = true)]  pub url: String,}\n```\n\nOnce your struct has been defined, you can parse the provided input arguments using the\n[`parse_args`](https://docs.rs/moon_pdk/latest/moon_pdk/args/fn.parse_args.html) function.\n\n```\n#[plugin_fn]pub fn execute_extension(Json(input): Json) -> FnResult {  let args = parse_args::(&input.args)?;  args.url; // --url  Ok(())}\n```\n\n### Supporting configuration\n\nUsers can configure [extensions](/docs/config/workspace#extensions) with additional settings in\n[`.moon/workspace.yml`](/docs/config/workspace). Do note that settings should be in camelCase for them\nto be parsed correctly!\n\n.moon/workspace.yml\n\n```\nextensions:  example:    plugin: 'file://./path/to/example.wasm'    someSetting: 'abc'    anotherSetting: 123\n```\n\nIn the plugin, we can map these settings (excluding `plugin`) into a struct. The `Default` trait\nmust be implemented to handle situations where settings were not configured, or some are missing.\n\n```\nconfig_struct!(  #[derive(Default)]  pub struct ExampleExtensionConfig {    pub some_setting: String,    pub another_setting: u32,  });\n```\n\nOnce your struct has been defined, you can access the configuration using the\n[`get_extension_config`](https://docs.rs/moon_pdk/latest/moon_pdk/extension/fn.get_extension_config.html)\nfunction.\n\n```\n#[plugin_fn]pub fn execute_extension(Json(input): Json) -> FnResult {  let config = get_extension_config::()?;  config.another_setting; // 123  Ok(())}\n```\n\n## /docs/guides/javascript/bun-handbook\n\nSource: https://moonrepo.dev/docs/guides/javascript/bun-handbook\n\n# Bun handbook\n\nUtilizing JavaScript (and TypeScript) in a monorepo can be a daunting task, especially when using\nBun (or Node.js), as there are many ways to structure your code and to configure your tools. With\nthis handbook, we'll help guide you through this process.\n\ninfo\n\nThis guide is a living document and will continue to be updated over time!\n\n## moon setup\n\nFor this part of the handbook, we'll be focusing on [moon](/moon), our task runner. To start,\nlanguages in moon act like plugins, where their functionality and support is not enabled unless\nexplicitly configured. We follow this approach to avoid unnecessary overhead.\n\n### Enabling the language\n\nTo enable JavaScript support via Bun, define the [`bun`](/docs/config/toolchain#bun) setting in\n[`.moon/toolchains.yml`](/docs/config/toolchain), even if an empty object.\n\n.moon/toolchains.yml\n\n```\n# Enable Bunbun: {}\n```\n\ninfo\n\nIn moon v1.40+, use `javascript` and `bun` instead of `bun` to enable the new WASM powered Bun\ntoolchain, which is far more accurate and efficient. The non-WASM toolchain will be deprecated in\nthe future.\n\nOr by pinning a `bun` version in [`.prototools`](/docs/proto/config) in the workspace root.\n\n.prototools\n\n```\nbun = \"1.0.0\"\n```\n\nThis will enable the Bun toolchain and provide the following automations around its ecosystem:\n\n- Node modules will automatically be installed if dependencies in `package.json` have changed, or the lockfile has changed, since the last time a task has ran. We'll also take `package.json` workspaces into account and install modules in the correct location; either the workspace root, in a project, or both.\n\n- Relationships between projects will automatically be discovered based on `dependencies`, `devDependencies`, and `peerDependencies` in `package.json`.\n\n### Utilizing the toolchain\n\nWhen a language is enabled, moon by default will assume that the language's binary is available\nwithin the current environment (typically on `PATH`). This has the downside of requiring all\ndevelopers and machines to manually install the correct version of the language, and to stay in\nsync.\n\nInstead, you can utilize [moon's toolchain](/docs/concepts/toolchain), which will download and\ninstall the language in the background, and ensure every task is executed using the exact version\nacross all machines.\n\nEnabling the toolchain is as simple as defining the [`bun.version`](/docs/config/toolchain#version)\nsetting.\n\n.moon/toolchains.yml\n\n```\n# Enable Bun toolchain with an explicit versionbun:  version: '1.0.0'\n```\n\nVersions can also be defined with [`.prototools`](/docs/proto/config).\n\n### Configuring the toolchain\n\nSince the JavaScript ecosystem supports multiple runtimes, moon is unable to automatically detect\nthe correct runtime for all scenarios. Does the existence of a `package.json` mean Node.js or Bun?\nWe don't know, and default to Node.js because of its popularity.\n\nTo work around this, you can set `toolchain` to \"bun\" at the task-level or project-level.\n\nmoon.yml\n\n```\n# For all tasks in the projecttoolchain:  default: 'bun'tasks:  build:    command: 'webpack'    # For this specific task    toolchain: 'bun'\n```\n\nThe task-level `toolchain.default` only needs to be set if executing a `node_modules` binary! The\n`bun` binary automatically sets the toolchain to Bun.\n\n### Using `package.json` scripts\n\nIf you're looking to prototype moon, or reduce the migration effort to moon tasks, you can configure\nmoon to inherit `package.json` scripts, and internally convert them to moon tasks. This can be\nachieved with the [`bun.inferTasksFromScripts`](/docs/config/toolchain#infertasksfromscripts)\nsetting.\n\n.moon/toolchains.yml\n\n```\nbun:  inferTasksFromScripts: true\n```\n\nOr you can run scripts through `bun run` calls.\n\nmoon.yml\n\n```\ntasks:  build:    command: 'bun run build'\n```\n\n## Handbook\n\ninfo\n\nRefer to the [Node.js handbook](/docs/guides/javascript/node-handbook) for more information on repository structure,\ndependency management, and more. Since both runtimes are extremely similar, the information in that\nhandbook also applies to Bun!\n\n## /docs/guides/javascript/deno-handbook\n\nSource: https://moonrepo.dev/docs/guides/javascript/deno-handbook\n\n# Deno handbook\n\nUtilizing Deno in a TypeScript based monorepo can be a non-trivial task. With this handbook, we'll\nhelp guide you through this process.\n\ninfo\n\nThis guide is a living document and will continue to be updated over time!\n\n## moon setup\n\nFor this part of the handbook, we'll be focusing on [moon](/moon), our task runner. To start,\nlanguages in moon act like plugins, where their functionality and support is not enabled unless\nexplicitly configured. We follow this approach to avoid unnecessary overhead.\n\n### Enabling the language\n\nTo enable TypeScript support via Deno, define the [`deno`](/docs/config/toolchain#deno) setting in\n[`.moon/toolchains.yml`](/docs/config/toolchain), even if an empty object.\n\n.moon/toolchains.yml\n\n```\n# Enable Denodeno: {}# Enable Deno and override default settingsdeno:  lockfile: true\n```\n\nOr by pinning a `deno` version in [`.prototools`](/docs/proto/config) in the workspace root.\n\n.prototools\n\n```\ndeno = \"1.31.0\"\n```\n\nThis will enable the Deno toolchain and provide the following automations around its ecosystem:\n\n- Automatic handling and caching of lockfiles (when the setting is enabled).\n\n- Relationships between projects will automatically be discovered based on `imports`, `importMap`, and `deps.ts` (currently experimental).\n\n- And more to come!\n\n### Work in progress\n\ncaution\n\nDeno support is currently experimental while we finalize the implementation.\n\nThe following features are not supported:\n\n- `deno.jsonc` files (use `deno.json` instead).\n\n- `files.exclude` are currently considered an input. These will be filtered in a future release.\n\n## Coming soon!\n\nThe handbook is currently being written while we finalize our Deno integration support!\n\n## /docs/guides/javascript/node-handbook\n\nSource: https://moonrepo.dev/docs/guides/javascript/node-handbook\n\n# Node.js handbook\n\nUtilizing JavaScript (and TypeScript) in a monorepo can be a daunting task, especially when using\nNode.js, as there are many ways to structure your code and to configure your tools. With this\nhandbook, we'll help guide you through this process.\n\ninfo\n\nThis guide is a living document and will continue to be updated over time!\n\n## moon setup\n\nFor this part of the handbook, we'll be focusing on [moon](/moon), our task runner. To start,\nlanguages in moon act like plugins, where their functionality and support is not enabled unless\nexplicitly configured. We follow this approach to avoid unnecessary overhead.\n\n### Enabling the language\n\nTo enable JavaScript support via Node.js, define the [`node`](/docs/config/toolchain#node) setting\nin [`.moon/toolchains.yml`](/docs/config/toolchain), even if an empty object.\n\n.moon/toolchains.yml\n\n```\n# Enable Node.jsnode: {}# Enable Node.js and override default settingsnode:  packageManager: 'pnpm'\n```\n\ninfo\n\nIn moon v1.40+, use `javascript` and `node` instead of `node` to enable the new WASM powered Node.js\ntoolchain, which is far more accurate and efficient. The non-WASM toolchain will be deprecated in\nthe future.\n\nOr by pinning a `node` version in [`.prototools`](/docs/proto/config) in the workspace root.\n\n.prototools\n\n```\nnode = \"18.0.0\"pnpm = \"7.29.0\"\n```\n\nThis will enable the Node.js toolchain and provide the following automations around its ecosystem:\n\n- Node modules will automatically be installed if dependencies in `package.json` have changed, or the lockfile has changed, since the last time a task has ran. We'll also take `package.json` workspaces into account and install modules in the correct location; either the workspace root, in a project, or both.\n\n- Relationships between projects will automatically be discovered based on `dependencies`, `devDependencies`, and `peerDependencies` in `package.json`. The versions of these packages will also be automatically synced when changed.\n\n- Tasks can be [automatically inferred](/docs/config/toolchain#infertasksfromscripts) from `package.json` scripts.\n\n- And much more!\n\n### Utilizing the toolchain\n\nWhen a language is enabled, moon by default will assume that the language's binary is available\nwithin the current environment (typically on `PATH`). This has the downside of requiring all\ndevelopers and machines to manually install the correct version of the language, and to stay in\nsync.\n\nInstead, you can utilize [moon's toolchain](/docs/concepts/toolchain), which will download and\ninstall the language in the background, and ensure every task is executed using the exact version\nacross all machines.\n\nEnabling the toolchain is as simple as defining the [`node.version`](/docs/config/toolchain#version)\nsetting.\n\n.moon/toolchains.yml\n\n```\n# Enable Node.js toolchain with an explicit versionnode:  version: '18.0.0'\n```\n\nVersions can also be defined with [`.prototools`](/docs/proto/config).\n\n### Using `package.json` scripts\n\nIf you're looking to prototype moon, or reduce the migration effort to moon tasks, you can configure\nmoon to inherit `package.json` scripts, and internally convert them to moon tasks. This can be\nachieved with the [`node.inferTasksFromScripts`](/docs/config/toolchain#infertasksfromscripts)\nsetting.\n\n.moon/toolchains.yml\n\n```\nnode:  inferTasksFromScripts: true\n```\n\nOr you can run scripts through `npm run` (or `pnpm`, `yarn`) calls.\n\nmoon.yml\n\n```\ntasks:  build:    command: 'npm run build'\n```\n\n## Repository structure\n\nJavaScript monorepo's work best when projects are split into applications and packages, with each\nproject containing its own `package.json` and dependencies. A root `package.json` must also exist\nthat pieces all projects together through workspaces.\n\nFor small repositories, the following structure typically works well:\n\n```\n/‚îú‚îÄ‚îÄ .moon/‚îú‚îÄ‚îÄ package.json‚îú‚îÄ‚îÄ apps/‚îÇ   ‚îú‚îÄ‚îÄ client/|   |   ‚îú‚îÄ‚îÄ ...‚îÇ   |   ‚îî‚îÄ‚îÄ package.json‚îÇ   ‚îî‚îÄ‚îÄ server/|       ‚îú‚îÄ‚îÄ ...‚îÇ       ‚îî‚îÄ‚îÄ package.json‚îî‚îÄ‚îÄ packages/    ‚îú‚îÄ‚îÄ components/    |   ‚îú‚îÄ‚îÄ ...    ‚îÇ   ‚îî‚îÄ‚îÄ package.json    ‚îú‚îÄ‚îÄ theme/    |   ‚îú‚îÄ‚îÄ ...    ‚îÇ   ‚îî‚îÄ‚îÄ package.json    ‚îî‚îÄ‚îÄ utils/        ‚îú‚îÄ‚îÄ ...        ‚îî‚îÄ‚îÄ package.json\n```\n\nFor large repositories, grouping projects by team or department helps with ownership and\norganization. With this structure, applications and libraries can be nested at any depth.\n\n```\n/‚îú‚îÄ‚îÄ .moon/‚îú‚îÄ‚îÄ package.json‚îú‚îÄ‚îÄ infra/‚îÇ   ‚îî‚îÄ‚îÄ ...‚îú‚îÄ‚îÄ internal/‚îÇ   ‚îî‚îÄ‚îÄ ...‚îú‚îÄ‚îÄ payments/‚îÇ   ‚îî‚îÄ‚îÄ ...‚îî‚îÄ‚îÄ shared/    ‚îî‚îÄ‚îÄ ...\n```\n\n### Applications\n\nApplications are runnable or executable, like an HTTP server, and are pieced together with packages\nand its own encapsulated code. They represent the whole, while packages are the pieces. Applications\ncan import and depend on packages, but they must not import and depend on other applications.\n\nIn moon, you can denote a project as an application using the [`layer`](/docs/config/project#layer)\nsetting in [`moon.yml`](/docs/config/project).\n\nmoon.yml\n\n```\nlayer: 'application'\n```\n\n### Packages\n\nPackages (also known as a libraries) are self-contained reusable pieces of code, and are the\nsuggested pattern for [code sharing](#code-sharing). Packages can import and depend on other\npackages, but they must not import and depend on applications!\n\nIn moon, you can denote a project as a library using the [`layer`](/docs/config/project#layer)\nsetting in [`moon.yml`](/docs/config/project).\n\nmoon.yml\n\n```\nlayer: 'library'\n```\n\n### Configuration\n\nEvery tool that you'll utilize in a repository will have its own configuration file. This will be a\nlot of config files, but regardless of what tool it is, where the config file should go will fall\ninto 1 of these categories:\n\n- Settings are inherited by all projects. These are known as universal tools, and enforce code consistency and quality across the entire repository. Their config file must exist in the repository root, but may support overrides in each project. Examples: Babel, [ESLint](/docs/guides/examples/eslint), [Prettier](/docs/guides/examples/prettier), [TypeScript](/docs/guides/examples/typescript)\n\n- Settings are unique per project. These are developers tools that must be configured separately for each project, as they'll have different concerns. Their config file must exist in each project, but a shared configuration may exist as a base (for example, Jest presets). Examples: [Jest](/docs/guides/examples/jest), [TypeScript](/docs/guides/examples/typescript) (with project references)\n\n- Settings are one-offs. These are typically for applications or tools that require their own config, but aren't prevalent throughout the entire repository. Examples: [Astro](/docs/guides/examples/astro), [Next](/docs/guides/examples/next), [Nuxt](/docs/guides/examples/nuxt), [Remix](/docs/guides/examples/remix), Tailwind\n\n## Dependency management\n\nDependencies, also known as node modules, are required by all projects, and are installed through a\npackage manager like npm, pnpm, or yarn. It doesn't matter which package manager you choose, but we\nhighly suggest choosing one that has proper workspaces support. If you're unfamiliar with\nworkspaces, they will:\n\n- Resolve all `package.json`'s in a repository using glob patterns.\n\n- Install dependencies from all `package.json`'s at once, in the required locations.\n\n- Create symlinks of local packages in `node_modules` (to emulate an installed package).\n\n- Deduplicate and hoist `node_modules` when applicable.\n\nAll of this functionality enables robust monorepo support, and can be enabled with the following:\n\n- npm\n- pnpm\n- Yarn\n- Yarn (classic)\n\npackage.json\n\n```\n{  // ...  \"workspaces\": [\"apps/*\", \"packages/*\"]}\n```\n\n.yarnrc.yml\n\n```\n# ...nodeLinker: 'node-modules'\n```\n\n- [Documentation](https://yarnpkg.com/features/workspaces)\n\npackage.json\n\n```\n{  // ...  \"workspaces\": [\"apps/*\", \"packages/*\"]}\n```\n\n- [Documentation](https://classic.yarnpkg.com/en/docs/workspaces)\n\npackage.json\n\n```\n{  // ...  \"workspaces\": [\"apps/*\", \"packages/*\"]}\n```\n\n- [Documentation](https://docs.npmjs.com/cli/v8/using-npm/workspaces)\n\npnpm-workspace.yaml\n\n```\npackages:  - 'apps/*'  - 'packages/*'\n```\n\n- [Documentation](https://pnpm.io/workspaces)\n\ncaution\n\nPackage workspaces are not a requirement for monorepos, but they do solve an array of problems\naround module resolution, avoiding duplicate packages in bundles, and general interoperability.\nProceed with caution for non-workspaces setups!\n\n### Workspace commands\n\nThe following common commands can be used for adding, removing, or managing dependencies in a\nworkspace. View the package manager's official documentation for a thorough list of commands.\n\n- npm\n- pnpm\n- Yarn\n- Yarn (classic)\n\nInstall dependencies:\n\n```\nnpm install\n```\n\nAdd a package:\n\n```\n# At the rootnpm install # In a projectnpm install  --workspace\n\n```\n\nRemove a package:\n\n```\n# At the rootnpm install # In a projectnpm install  --workspace\n\n```\n\nUpdate packages:\n\n```\nnpx npm-check-updates --interactive\n```\n\nInstall dependencies:\n\n```\npnpm install\n```\n\nAdd a package:\n\n```\n# At the rootpnpm add # In a projectpnpm add  --filter\n\n```\n\nRemove a package:\n\n```\n# At the rootpnpm remove # In a projectpnpm remove  --filter\n\n```\n\nUpdate packages:\n\n```\npnpm update -i -r --latest\n```\n\nInstall dependencies:\n\n```\nyarn install\n```\n\nAdd a package:\n\n```\n# At the rootyarn add # In a projectyarn workspace\n add\n```\n\nRemove a package:\n\n```\n# At the rootyarn remove # In a projectyarn workspace\n remove\n```\n\nUpdate packages:\n\n```\nyarn upgrade-interactive\n```\n\nInstall dependencies:\n\n```\nyarn install\n```\n\nAdd a package:\n\n```\n# At the rootyarn add  -w# In a projectyarn workspace\n add\n```\n\nRemove a package:\n\n```\n# At the rootyarn remove  -w# In a projectyarn workspace\n remove\n```\n\nUpdate packages:\n\n```\nyarn upgrade-interactive --latest\n```\n\n### Developer tools at the root\n\nWhile not a strict guideline to follow, we've found that installing universal developer tool related\ndependencies (Babel, ESLint, Jest, TypeScript, etc) in the root `package.json` as `devDependencies`\nto be a good pattern for consistency, quality, and the health of the repository. It provides the\nfollowing benefits:\n\n- It ensures all projects are utilizing the same version (and sometimes configuration) of a tool.\n\n- It allows the tool to easily be upgraded. Upgrade once, applied everywhere.\n\n- It avoids conflicting or outdated versions of the same package.\n\nWith that being said, this does not include development dependencies that are unique to a project!\n\n### Product libraries in a project\n\nProduct, application, and or framework specific packages should be installed as production\n`dependencies` in a project's `package.json`. We've found this pattern to work well for the\nfollowing reasons:\n\n- Application dependencies are pinned per project, avoiding accidental regressions.\n\n- Applications can upgrade their dependencies and avoid breaking neighbor applications.\n\n## Code sharing\n\nOne of the primary reasons to use a monorepo is to easily share code between projects. When code is\nco-located within the same repository, it avoids the overhead of the \"build -> version -> publish to\nregistry -> upgrade in consumer\" workflow (when the code is located in an external repository).\n\nCo-locating code also provides the benefit of fast iteration, fast adoption, and easier migration\n(when making breaking changes for example).\n\nWith [package workspaces](#dependency-management), code sharing is a breeze. As mentioned above,\nevery project that contains a `package.json` that is part of the workspace, will be symlinked into\n`node_modules`. Because of this, these packages can easily be imported using their `package.json`\nname.\n\n```\n// Imports from /packages/utils/package.jsonimport utils from '@company/utils';\n```\n\n### Depending on packages\n\nBecause packages are symlinked into `node_modules`, we can depend on them as if they were normal npm\npackages, but with 1 key difference. Since these packages aren't published, they do not have a\nversion to reference, and instead, we can use the special `workspace:^` version (yarn and pnpm only,\nuse `*` for npm).\n\n```\n{  \"name\": \"@company/consumer\",  \"dependencies\": {    \"@company/provider\": \"workspace:^\"  }}\n```\n\nThe `workspace:` version basically means \"use the package found in the current workspace\". The `:^`\ndetermines the version range to substitute with when publishing. For example, the `workspace:^`\nabove would be replaced with version of `@company/provider` as `^` when the\n`@company/consumer` package is published.\n\nThere's also `workspace:~` and `workspace:*` which substitutes to `~` and ``\nrespectively. We suggest using `:^` so that version ranges can be deduped.\n\n### Types of packages\n\nWhen sharing packages in a monorepo, there's typically 3 different kinds of packages:\n\n#### Local only\n\nA local only package is just that, it's only available locally to the repository and is not\npublished to a registry, and is not available to external repositories. For teams and companies\nthat utilize a single repository, this will be the most common type of package.\n\nA benefit of local packages is that they do not require a build step, as source files can be\nimported directly ([when configured correctly](#bundler-integration)). This avoids a lot of\n`package.json` overhead, especially in regards to `exports`, `imports`, and other import patterns.\n\n#### Internally published\n\nAn internal package is published to a private registry, and is not available to the public.\nPublished packages are far more strict than local packages, as the `package.json` structure plays a\nmuch larger role for downstream consumers, as it dictates how files are imported, where they can be\nfound, what type of formats are supported (CJS, ESM), so on and so forth.\n\nPublished packages require a build step, for both source code and TypeScript types (when\napplicable). We suggest using [esbuild](https://esbuild.github.io/) or\n[Packemon](/docs/guides/examples/packemon) to handle this entire flow. With that being said, local projects\ncan still [import their source files](#bundler-integration).\n\n#### Externally published\n\nAn external package is structured similarly to an internal package, but instead of publishing to a\nprivate registry, it's published to the npm public registry.\n\nExternal packages are primarily for open source projects, and require the repository to also be\npublic.\n\n### Bundler integration\n\nCo-locating packages is great, but how do you import and use them effectively? The easiest solution\nis to configure resolver aliases within your bundler (Webpack, Vite, etc). By doing so, you enable\nthe following functionality:\n\n- Avoids having to build (and rebuild) the package everytime its code changes.\n\n- Enables file system watching of the package, not just the application.\n\n- Allows for hot module reloading (HMR) to work.\n\n- Package code is transpiled and bundled alongside application code.\n\n- Vite\n- Webpack\n\nvite.config.ts\n\n```\nimport path from 'path';import { defineConfig } from 'vite';export default defineConfig({  // ...  resolve: {    alias: {      '@company/utils': path.join(__dirname, '../packages/utils/src'),    },  },});\n```\n\nwebpack.config.js\n\n```\nconst path = require('path');module.exports = {  // ...  resolve: {    alias: {      '@company/utils': path.join(__dirname, '../packages/utils/src'),    },  },};\n```\n\ninfo\n\nWhen configuring aliases, we suggest using the `package.json` name as the alias! This ensures that\non the consuming side, you're using the package as if it's a normal node module, and avoids\ndeviating from the ecosystem.\n\n### TypeScript integration\n\nWe suggest using TypeScript project references. Luckily, we have an\n[in-depth guide on how to properly and efficiently integrate them](/docs/guides/javascript/typescript-project-refs)!\n\n## /docs/guides/javascript/typescript-eslint\n\nSource: https://moonrepo.dev/docs/guides/javascript/typescript-eslint\n\n# typescript-eslint\n\n## ESLint integration\n\n### Disabling problematic rules\n\nA handful of ESLint rules are not compatible with the TypeScript plugin, or they cause serious\nperformance degradation, and should be disabled entirely. According to the\n[official typescript-eslint.io documentation](https://typescript-eslint.io/docs/linting/troubleshooting#eslint-plugin-import),\nmost of these rules come from the `eslint-plugin-import` plugin.\n\n.eslintrc.js\n\n```\nmodule.exports = {  // ...  rules: {    'import/default': 'off',    'import/named': 'off',    'import/namespace': 'off',    'import/no-cycle': 'off',    'import/no-deprecated': 'off',    'import/no-named-as-default': 'off',    'import/no-named-as-default-member': 'off',    'import/no-unused-modules': 'off',  },};\n```\n\n### Running from the command line\n\n### Running within editors\n\n#### ESLint\n\nUse the\n[dbaeumer.vscode-eslint](https://marketplace.visualstudio.com/items?itemName=dbaeumer.vscode-eslint)\nextension. Too avoid poor performance, do not use ESLint for formatting code (via the\n`eslint-plugin-prettier` plugin or something similar), and only use it for linting. The difference\nin speed is comparable to 100ms vs 2000ms.\n\n.vscode/settings.json\n\n```\n{  // Automatically run all linting fixes on save as a concurrent code action,  // and avoid formatting with ESLint. Use another formatter, like Prettier.  \"editor.codeActionsOnSave\": [\"source.fixAll.eslint\"],  \"eslint.format.enable\": false,  // If linting is *too slow* while typing, uncomment the following line to  // only run the linter on save only.  // \"editor.run\": \"onSave\",  // Your package manager of choice.  \"eslint.packageManager\": \"yarn\",  // Use the newer and more performant `ESLint` class implementation.  \"eslint.useESLintClass\": true,  // List of directories that that linter should operate on.  \"eslint.workingDirectories\": [{ \"pattern\": \"apps/*\" }, { \"pattern\": \"packages/*\" }]}\n```\n\n#### Prettier\n\nUse the\n[esbenp.prettier-vscode](https://marketplace.visualstudio.com/items?itemName=esbenp.prettier-vscode)\nextension.\n\n.vscode/settings.json\n\n```\n{  // Use Prettier as the default formatter for all file types. Types not  // supported by Prettier can be overridden using bracket syntax, or ignore files.  \"editor.defaultFormatter\": \"esbenp.prettier-vscode\",  \"editor.formatOnSave\": true}\n```\n\n## /docs/guides/javascript/typescript-project-refs\n\nSource: https://moonrepo.dev/docs/guides/javascript/typescript-project-refs\n\n# TypeScript project references\n\nThe ultimate in-depth guide for using TypeScript in a monorepo effectively!\n\nHow to use TypeScript in a monorepo? What are project references? Why use project references? What\nis the best way to use project references? These are just a handful of questions that are\nconstantly asked on Twitter, forums, Stack Overflow, and even your workplace.\n\nBased on years of experience managing large-scale frontend repositories, we firmly believe that\nTypeScript project references are the proper solution for effectively scaling TypeScript in a\nmonorepo. The official\n[TypeScript documentation on project references](https://www.typescriptlang.org/docs/handbook/project-references.html)\nanswers many of these questions, but it basically boils down to the following:\n\n- Project references enforce project boundaries, disallowing imports to arbitrary projects unless they have been referenced explicitly in configuration. This avoids circular references / cycles.\n\n- It enables TypeScript to process individual units, instead of the entire repository as a whole. Perfect for reducing CI and local development times.\n\n- It supports incremental compilation, so only out-of-date or affected projects are processed. The more TypeScript's cache is warmed, the faster it will be.\n\n- It simulates how types work in the Node.js package ecosystem.\n\nThis all sounds amazing but there's got to be some downsides right? Unfortunately, there is:\n\n- Project references require generating declarations to resolve type information correctly. This results in a lot of compilation artifacts littered throughout the repository. There [are ways](#gitignore) [around this](/docs/config/toolchain#routeoutdirtocache).\n\n- This approach is a bit involved and may require some cognitive overhead based on your current level of TypeScript tooling knowledge.\n\nsuccess\n\nIf you'd like a real-world repository to reference, our\n[moonrepo/moon](https://github.com/moonrepo/moon), [moonrepo/dev](https://github.com/moonrepo/dev),\nand [moonrepo/examples](https://github.com/moonrepo/examples) repositories utilizes this\narchitecture!\n\n## Preface\n\nBefore you dive into this questionably long guide, we'd like to preface with:\n\n- This guide is a living document and will continually be updated with best practices and frequently asked questions. Keep returning to learn more!\n\n- This guide assumes a basic level knowledge of TypeScript and how it works.\n\n- The architecture outlined in this guide assumes that TypeScript is only used for typechecking and not compiling. However, supporting compilation should be as easy as modifying a handful of compiler options.\n\n- Although this guide exists within moon's documentation, it does not require moon. We've kept all implementation details generic enough for it be used in any repository, but have also included many notes on how moon would improve this experience.\n\n## Configuration\n\nThe most complicated part of integrating TypeScript in a monorepo is a proper configuration setup.\nBased on our extensive experience, we suggest the following architecture as a base! This is not\nperfect and can most definitely be expanded upon or modified to fit your needs.\n\n### Root-level\n\nIn a polyrepo, the root `tsconfig.json` is typically the only configuration file, as it defines\ncommon compiler options, and includes files to typecheck. In a monorepo, these responsibilities are\nnow split across multiple configuration files.\n\n#### `tsconfig.json`\n\nTo start, the root `tsconfig.json` file is nothing more than a list of all projects in the\nmonorepo, with each project being an individual entry in the `references` field. Each entry must\ncontain a `path` field with a relative file system path to the project root (that contains their\nconfig).\n\nWe also do not define compiler options in this file, as project-level configuration files would\nnot be able to extend this file, as it would trigger a circular reference. Instead, we define\ncommon compiler options in a root [`tsconfig.options.json`](#tsconfigoptionsjson) file, that this\nfile also `extends` from.\n\nIn the end, this file should only contain 3 fields: `extends`, `files` (an empty list), and\n`references`. This abides the\n[official guidance around structure](https://www.typescriptlang.org/docs/handbook/project-references.html#overall-structure).\n\n```\n{  \"extends\": \"./tsconfig.options.json\",  \"files\": [],  \"references\": [    {      \"path\": \"apps/foo\"    },    {      \"path\": \"packages/bar\"    }    // ... more  ]}\n```\n\nWhen using moon, the\n[`typescript.syncProjectReferences`](/docs/config/toolchain#syncprojectreferences) setting will\nkeep this `references` list automatically in sync, and the name of the file can be customized with\n[`typescript.rootConfigFileName`](/docs/config/toolchain#rootconfigfilename).\n\n#### `tsconfig.options.json`\n\nThis file will contain common compiler options that will be inherited by all projects in the\nmonorepo. For project references to work correctly, the following settings must be enabled at the\nroot, and typically should not be disabled in each project.\n\n- `composite` - Enables project references and informs the TypeScript program where to find referenced outputs.\n\n- `declaration` - Project references rely on the compiled declarations (`.d.ts`) of external projects. If declarations do not exist, TypeScript will generate them on demand.\n\n- `declarationMap` - Generate sourcemaps for declarations, so that language server integrations in editors like \"Go to\" resolve correctly.\n\n- `incremental` - Enables incremental compilation, greatly improving performance.\n\n- `noEmitOnError` - If the typechecker fails, avoid generating invalid or partial declarations.\n\n- `skipLibCheck` - Avoids eager loading and analyzing all declarations, greatly improving performance.\n\nFurthermore, we have 2 settings that should be enabled per project, depending on the project type.\n\n- `emitDeclarationOnly` - For packages: Emit declarations, as they're required for references, but avoid compiling to JavaScript.\n\n- `noEmit` - For applications: Don't emit declarations, as others should not be depending on the project.\n\nFor convenience, we provide the\n[`tsconfig-moon`](https://github.com/moonrepo/dev/tree/master/packages/tsconfig) package, which\ndefines common compiler options and may be used here.\n\n```\n{  \"compilerOptions\": {    \"composite\": true,    \"declaration\": true,    \"declarationMap\": true,    \"emitDeclarationOnly\": true,    \"incremental\": true,    \"noEmitOnError\": true,    \"skipLibCheck\": true    // ... others  }}\n```\n\nWhen using moon, the name of the file can be customized with\n[`typescript.rootOptionsConfigFileName`](/docs/config/toolchain#rootoptionsconfigfilename).\n\n##### ECMAScript interoperability\n\nECMAScript modules (ESM) have been around for quite a while now, but the default TypeScript settings\nare not configured for them. We suggest the following compiler options if you want proper ESM\nsupport with interoperability with the ecosystem.\n\n```\n{  \"compilerOptions\": {    \"allowSyntheticDefaultImports\": true,    \"esModuleInterop\": true,    \"isolatedModules\": true,    \"module\": \"esnext\",    \"moduleResolution\": \"bundler\",    \"strict\": true,    \"target\": \"esnext\"    // ... others  }}\n```\n\n#### `.gitignore`\n\nProject references unfortunately generate a ton of artifacts that typically shouldn't be committed\nto the repository (but could be if you so choose). We suggest ignoring the following:\n\n.gitignore\n\n```\n# The `outDir` for declarationslib/# Build cache manifests*.tsbuildinfo\n```\n\n### Project-level\n\nEach project that contains TypeScript files and will utilize the typechecker must contain a\n`tsconfig.json` in the project root, typically as a sibling to `package.json`.\n\n#### `tsconfig.json`\n\nA `tsconfig.json` in the root of a project (application or package) is required, as it informs\nTypeScript that this is a project, and that it can be referenced by other projects. In its simplest\nform, this file should extend the root [`tsconfig.options.json`](#tsconfigoptionsjson) to inherit\ncommon compiler options, define its own compiler options (below), define includes/excludes, and any\nnecessary references.\n\nWhen using moon, the name of the file can be customized with\n[`typescript.projectConfigFileName`](/docs/config/toolchain#projectconfigfilename).\n\n- Applications\n- Packages\n\nFor applications, declaration emitting can be disabled, since external projects should not be\nimporting files from an application. If this use case ever arises, move those files into a package.\n\napps/foo/tsconfig.json\n\n```\n{  \"extends\": \"../../../../tsconfig.options.json\",  \"compilerOptions\": {    \"noEmit\": true  },  \"include\": [],  \"references\": []}\n```\n\nFor packages, we must define the location in which to generate declarations. These are the\ndeclarations that external projects would reference. This location is typically\n[gitignored](#gitignore)!\n\npackages/bar/tsconfig.json\n\n```\n{  \"extends\": \"../../../../tsconfig.options.json\",  \"compilerOptions\": {    \"emitDeclarationOnly\": true,    \"outDir\": \"./lib\"  },  \"include\": [],  \"references\": []}\n```\n\nWhen using moon, the `outDir` can automatically be re-routed to a shared cache using\n[`typescript.routeOutDirToCache`](/docs/config/toolchain#routeoutdirtocache), to avoid littering\nthe repository with compilation artifacts.\n\n##### Includes and excludes\n\nBased on experience, we suggest defining `include` instead of `exclude`, as managing a whitelist of\ntypecheckable files is much easier. When dealing with excludes, there are far too many\npossibilities. To start, you have `node_modules`, and for applications maybe `dist`, `build`,\n`.next`, or another application specific folder, and then for packages you may have `lib`, `cjs`,\n`esm`, etc. It becomes very... tedious.\n\nThe other benefit of using `include` is that it forces TypeScript to only load what's necessary,\ninstead of eager loading everything into memory, and for typechecking files that aren't part of\nsource, like configuration.\n\n/tsconfig.json\n\n```\n{  // ...  \"include\": [\"src/**/*\", \"tests/**/*\", \"*.js\", \"*.ts\"]}\n```\n\n##### Depending on other projects\n\nWhen a project depends on another project (by importing code from it), either using relative paths,\n[path aliases](#using-paths-aliases), or its `package.json` name, it must be declared as a\nreference. If not declared, TypeScript will error with a message about importing outside the project\nboundary.\n\n/tsconfig.json\n\n```\n{  // ...  \"references\": [    {      \"path\": \"../../foo\"    },    {      \"path\": \"../../bar\"    },    {      \"path\": \"../../../../baz\"    }  ]}\n```\n\nTo make use of editor intellisense and auto-imports of deeply nested files, you'll most likely need\nto add includes for referenced projects as well.\n\n/tsconfig.json\n\n```\n{  // ...  \"include\": [    // ...    \"src/**/*\",    \"../../foo/src/**/*\",    \"../../bar/src/**/*\",    \"../../../../baz/src/**/*\"  ]}\n```\n\nWhen using moon, the\n[`typescript.syncProjectReferences`](/docs/config/toolchain#syncprojectreferences) setting will\nkeep this `references` list automatically in sync, and\n[`typescript.includeProjectReferenceSources`](/docs/config/toolchain#syncprojectreferences) for\n`include`.\n\n#### `tsconfig.*.json`\n\nAdditional configurations may exist in a project that serve a role outside of typechecking, with one\nsuch role being npm package publishing. These configs are sometimes named `tsconfig.build.json`,\n`tsconfig.types.json`, or `tsconfig.lib.json`. Regardless of what they're called, these configs are\noptional, so unless you have a business need for them, you may skip this section.\n\n##### Package publishing\n\nAs mentioned previously, these configs may be used for npm packages, primarily for generating\nTypeScript declarations that are mapped through the `package.json`\n[`types` (or `typings`) field](https://www.typescriptlang.org/docs/handbook/declaration-files/publishing.html).\n\nGiven this `package.json`...\n\n/package.json\n\n```\n{  // ...  \"types\": \"./lib/index.d.ts\"}\n```\n\nOur `tsconfig.build.json` may look like...\n\n/tsconfig.build.json\n\n```\n{  \"extends\": \"../../../../tsconfig.options.json\",  \"compilerOptions\": {    \"outDir\": \"lib\",    \"rootDir\": \"src\"  },  \"include\": [\"src/**/*\"]}\n```\n\nSimple right? But why do we need an additional configuration? Why not use the other `tsconfig.json`?\nGreat questions! The major reason is that we only want to publish declarations for source files,\nand the declarations file structure should match 1:1 with the sources structure. The `tsconfig.json`\ndoes not guarantee this, as it may include test, config, or arbitrary files, all of which may not\nexist in the sources directory (`src`), and will alter the output to an incorrect directory\nstructure. Our `tsconfig.build.json` solves this problem by only including source files, and by\nforcing the source root to `src` using the `rootDir` compiler option.\n\nHowever, there is a giant caveat with this approach! Because TypeScript utilizes Node.js's module\nresolution, it will reference the declarations defined by the `package.json` `types` or\n[`exports`](#supporting-packagejson-exports) fields, instead of the `outDir` compiler option, and\nthe other `tsconfig.json` does not guarantee these files will exist. This results in TypeScript\nfailing to find the appropriate types! To solve this, add the `tsconfig.build.json` as a project\nreference to `tsconfig.json`.\n\n/tsconfig.json\n\n```\n{  // ...  \"references\": [    {      \"path\": \"./tsconfig.build.json\"    }    // ... others  ]}\n```\n\n##### Vendor specific\n\nSome vendors, like [Vite](/docs/guides/examples/vite), [Vitest](/docs/guides/examples/vite), and\n[Astro](/docs/guides/examples/astro) may include additional `tsconfig.*.json` files unique to their ecosystem.\nWe suggest following their guidelines and implementation when applicable.\n\n## Running the typechecker\n\nNow that our configuration is place, we can run the typechecker, or attempt to at least! This can be\ndone with the `tsc --build` command, which acts as a\n[build orchestrator](https://www.typescriptlang.org/docs/handbook/project-references.html#build-mode-for-typescript).\nWe also suggest passing `--verbose` for insights into what projects are compiling, and which are\nout-of-date.\n\n### On all projects\n\nFrom the root of the repository, run `tsc --build --verbose` to typecheck all projects, as defined\nin [tsconfig.json](#tsconfigjson). TypeScript will generate a directed acyclic graph (DAG) and\ncompile projects in order so that dependencies and references are resolved correctly.\n\ninfo\n\nWhy run TypeScript in the root? Typically you would only want to run against projects, but for\nsituations where you need to verify that all projects still work, running in the root is the best\napproach. Some such situations are upgrading TypeScript itself, upgrading global `@types` packages,\nupdating shared types, reworking build processes, and more.\n\n### On an individual project\n\nTo only typecheck a single project (and its dependencies), there are 2 approaches. The first is to\nrun from the root, and pass a relative path to the project, such as\n`tsc --build --verbose packages/foo`. The second is to change the working directory to the project,\nand run from there, such as `cd packages/foo && tsc --build --verbose`.\n\nBoth approaches are viable, and either may be used based on your tooling, build system, task runner,\nso on and so forth. This is the approach moon suggests with its\n[`typecheck` task](/docs/guides/examples/typescript).\n\n### On affected projects\n\nIn CI environments, it's nice to only run the typechecker on affected projects ‚Äî projects that\nhave changed files. While this isn't entirely possible with `tsc`, it is possible with moon! Head\nover to the\n[official docs for more information](/docs/run-task#running-based-on-affected-files-only).\n\n## Using `paths` aliases\n\nPath aliases, also known as path mapping or magic imports, is the concept of defining an import\nalias that re-maps its underlying location on the file system. In TypeScript, this is achieved with\nthe\n[`paths` compiler option](https://www.typescriptlang.org/docs/handbook/module-resolution.html#path-mapping).\n\nIn a monorepo world, we suggest using path aliases on a per-project basis, instead of defining them\n\"globally\" in the root. This gives projects full control of what's available and what they want to\nimport, and also plays nice with the mandatory `baseUrl` compiler option.\n\n/tsconfig.json\n\n```\n{  // ...  \"compilerOptions\": {    // ...    \"baseUrl\": \".\",    \"paths\": {      // Within the project      \":components/*\": [\"./src/components/*\"],      // To a referenced project      \":shared/*\": [\"../../shared/code/*\"]    }  },  \"references\": [    {      \"path\": \"../../shared/code\"    }  ]}\n```\n\nThe above aliases would be imported like the following:\n\n```\n// Beforeimport { Button } from '../../../../components/Button';import utils from '../../shared/code/utils';// Afterimport { Button } from ':components/Button';import utils from ':shared/utils';\n```\n\ninfo\n\nWhen using path aliases, we suggest prefixing or suffixing the alias with `:` so that it's apparent\nthat it's an alias (this also matches the new `node:` import syntax). Using no special character or\n`@` is problematic as it risks a chance of collision with a public npm package and may accidentally\nopen your repository to a\n[supply chain attack](https://snyk.io/blog/npm-security-preventing-supply-chain-attacks/). Other\ncharacters like `~` and `$` have an existing meaning in the ecosystem, so it's best to avoid them\naswell.\n\n### Importing source files from local packages\n\nIf you are importing from a project reference using a `package.json` name, then TypeScript will\nabide by Node.js module resolution logic, and will import using the\n[`main`/`types` or `exports` entry points](https://nodejs.org/api/packages.html#package-entry-points).\nThis means that you're importing compiled code instead of source code, and will require the\npackage to be constantly rebuilt if changes are made to it.\n\nHowever, why not simply import source files instead? With path aliases, you can do just that, by\ndefining a `paths` alias that maps the `package.json` name to its source files, like so.\n\n/tsconfig.json\n\n```\n{  // ...  \"compilerOptions\": {    // ...    \"paths\": {      // Index import      \"@scope/name\": [\"../../shared/package/src/index.ts\"],      // Deep imports      \"@scope/name/*\": [\"../../shared/package/src/*\"]    }  },  \"references\": [    {      \"path\": \"../../shared/package\"    }  ]}\n```\n\nWhen using moon, the\n[`typescript.syncProjectReferencesToPaths`](/docs/config/toolchain#syncprojectreferencestopaths)\nsetting will automatically create `paths` based on the local references.\n\n## Sharing and augmenting types\n\nDeclaring global types, augmenting node modules, and sharing reusable types is a common practice.\nThere are many ways to achieve this, so choose what works best for your repository. We use the\nfollowing pattern with great success.\n\nAt the root of the repository, create a `types` folder as a sibling to `tsconfig.json`. This folder\nmust only contain declarations (`.d.ts`) files for the following reasons:\n\n- Declarations can be `include`ed in a project without having to be a project reference.\n\n- Hard-coded declarations do not need to be compiled from TypeScript files.\n\nBased on the above, update your project's `tsconfig.json` to include all of these types, or just\nsome of these types.\n\n/tsconfig.json\n\n```\n{  // ...  \"include\": [\"src/**/*\", \"../../../../types/**/*\"]}\n```\n\nIn the future, moon will provide a setting to automate this workflow!\n\n## Supporting `package.json` exports\n\nIn Node.js v12, they introduced a new field to `package.json` called `exports` that aims to solve\nthe shortcomings of the `main` field. The `exports` field is very complicated, and instead of\nrepeating all of its implementation details, we suggest reading\n[the official Node.js docs on this topic](https://nodejs.org/api/packages.html#package-entry-points).\n\nWith that being said, TypeScript completely ignored the `exports` field until\n[v4.7](https://devblogs.microsoft.com/typescript/announcing-typescript-4-7/#esm-nodejs), and\nrespecting `exports` is still ignored unless the `moduleResolution` compiler option is set to\n\"nodenext\", \"node16\", or \"bundler\". If `moduleResolution` is set to \"node\", then your integration is\nresolving based on the `main` and `types` field, which are basically \"legacy\".\n\nwarning\n\nEnabling `package.json` imports/exports resolution is very complicated, and may be very tedious,\nespecially considering the state of the npm ecosystem. Proceed with caution!\n\n### State of the npm ecosystem\n\nAs mentioned above, the npm ecosystem (as of November 2022) is in a very fragile state in regards to\nimports/exports. Based on our experience attempting to utilize them in a monorepo, we ran into an\narray of problems, some of which are:\n\n- Published packages are simply utilizing imports/exports incorrectly. The semantics around CJS/ESM are very strict, and they may be configured wrong. This is exacerbated by the new `type` field.\n\n- The `exports` field overrides the `main` and `types` fields. If `exports` exists without type conditions, but the `types` field exists, the `types` entry point is completely ignored, resulting in TypeScript failures.\n\nWith that being said, there are [ways around this](#resolving-issues) and moving forward is\npossible, if you dare!\n\n### Enabling imports/exports resolution\n\nTo start, set the `moduleResolution` compiler option to \"nodenext\" (for packages) or \"bundler\" (for\napps) in the [`tsconfig.options.json`](#tsconfigoptionsjson) file.\n\n```\n{  \"compilerOptions\": {    // ...    \"moduleResolution\": \"nodenext\"  }}\n```\n\nNext, [run the typechecker from the root](#on-all-projects) against all projects. This will help\nuncover all potential issues with the dependencies you're using or the current configuration\narchitecture. If no errors are found, well congratulations, otherwise jump to the next section for\nmore information on [resolving them](#resolving-issues).\n\nIf you're trying to use `exports` in your own packages, ensure that the `types` condition is set,\nand it's the first condition in the mapping! We also suggest including `main` and the top-level\n`types` for tooling that do not support `exports` yet.\n\npackage.json\n\n```\n{  // ...  \"main\": \"./lib/index.js\",  \"types\": \"./lib/index.d.ts\",  \"exports\": {    \"./package.json\": \"./package.json\",    \".\": {      \"types\": \"./lib/index.d.ts\",      \"node\": \"./lib/index.js\"    }  }}\n```\n\ninfo\n\nManaging `exports` is non-trivial. If you'd prefer them to be automatically generated based on a set\nof inputs, we suggest using [Packemon](https://packemon.dev/)!\n\n### Resolving issues\n\nThere's only one way to resolve issues around incorrectly published `exports`, and that is package\npatching, either with [Yarn's patching feature](https://yarnpkg.com/features/protocols/#patch),\n[pnpm's patching feature](https://pnpm.io/cli/patch), or the\n[`patch-package` package](https://www.npmjs.com/package/patch-package). With patching, you can:\n\n- Inject the `types` condition/field if it's missing.\n\n- Re-structure the `exports` mapping if it's incorrect.\n\n- Fix incorrect entry point paths.\n\n- And even fix invalid TypeScript declarations or JavaScript code!\n\npackage.json\n\n```\n{  \"main\": \"./lib/index.js\",  \"types\": \"./lib/index.d.ts\",  \"exports\": {    \"./package.json\": \"./package.json\",-    \".\": \"./lib/index.js\"+    \".\": {+      \"types\": \"./lib/index.d.ts\",+      \"node\": \"./lib/index.js\"+    }  }}\n```\n\ninfo\n\nMore often than not, the owners of these packages may be unaware that their `exports` mapping is\nincorrect. Why not be a good member of the community and report an issue or even submit a pull\nrequest?\n\n## Editor integration\n\nUnfortunately, we only have experience with VS Code. If you prefer another editor and have guidance\nyou'd like to share with the community, feel free to submit a pull request and we'll include it\nbelow!\n\n### VS Code\n\n[VS Code](https://code.visualstudio.com/) has first-class support for TypeScript and project\nreferences, and should \"just work\" without any configuration. You can verify this by restarting the\nTypeScript server in VS Code (with the cmd + shift + p command palette) and navigating to\neach project. Pay attention to the status bar at the bottom, as you'll see this:\n\nWhen this status appears, it means that VS Code is compiling a project. It will re-appear multiple\ntimes, basically for each project, instead of once for the entire repository.\n\nFurthermore, ensure that VS Code is using the version of TypeScript from the `typescript` package in\n`node_modules`. Relying on the version that ships with VS Code may result in unexpected TypeScript\nfailures.\n\n.vscode/settings.json\n\n```\n{  \"typescript.tsdk\": \"node_modules/typescript/lib\"  // Or \"Select TypeScript version\" from the command palette}\n```\n\n## FAQ\n\n### I still have questions, where can I ask them?\n\nWe'd love to answer your questions and help anyway that we can. Feel free to...\n\n- Join the [moonrepo discord](https://discord.gg/qCh9MEynv2) and post your question in the `#typescript` channel.\n\n- Ping me, [Miles Johnson](https://twitter.com/mileswjohnson), on Twitter. I'll try my best to respond to every tweet.\n\n### Do I have to use project references?\n\nShort answer, no. If you have less than say 10 projects, references may be overkill. If your\nrepository is primarily an application, but then has a handful of shared npm packages, references\nmay also be unnecessary here. In the end, it really depends on how many projects exist in the\nmonorepo, and what your team/company is comfortable with.\n\nHowever, we do suggest using project references for very large monorepos (think 100s of projects),\nor repositories with a large number of contributors, or if you merely want to reduce CI typechecking\ntimes.\n\n### What about not using project references and only using source files?\n\nA popular alternative to project references is to simply use the source files as-is, by updating the\n`main` and `types` entry fields within each `package.json` to point to the original TypeScript\nfiles. This approach is also known as \"internal packages\".\n\npackage.json\n\n```\n{  // ...  \"main\": \"./src/index.tsx\",  \"types\": \"./src/index.tsx\"}\n```\n\nWhile this works, there are some downsides to this approach.\n\n- Loading declaration files are much faster than source files.\n\n- You'll lose all the benefits of TypeScript's incremental caching and compilation. TypeScript will consistently load, parse, and evaluate these source files every time. This is especially true for CI environments.\n\n- When using `package.json` workspaces, bundlers and other tools may consider these source files \"external\" as they're found in `node_modules`. This will require custom configuration to allow it.\n\n- It breaks consistency. Consistency with the npm ecosystem, and consistency with how packaging and TypeScript was designed to work. If all packages are internal, then great, but if you have some packages that are published, you now have 2 distinct patterns for \"using packages\" instead of 1.\n\nWith that being said, theres a 3rd alternative that may be the best of both worlds, using project\nreferences and source files,\n[by using `paths` aliases](#importing-source-files-from-local-packages).\n\nAll in all, this is a viable approach if you're comfortable with the downsides listed above. Use the\npattern that works best for your repository, team, or company!\n\n### How to integrate with ESLint?\n\nWe initially included ESLint integration in this guide, but it was very complex and in-depth on its\nown, so we've opted to push it to another guide. Unfortunately, that guide is not yet available, so\nplease come back soon! We'll announce when it's ready.\n\n### How to handle circular references?\n\nProject references do not support\n[circular references](https://github.com/microsoft/TypeScript/issues/33685) (cycles), which is\ngreat, as they are a code smell! If you find yourself arbitrarily importing code from random\nsources, or between 2 projects that depend on each other, then this highlights a problem with your\narchitecture. Projects should be encapsulated and isolated from outside sources, unless explicitly\nallowed through a dependency. Dependencies are \"upstream\", so having them depend on the current\nproject (the \"downstream\"), makes little to no sense.\n\nIf you're trying to adopt project references and are unfortunately hitting the circular reference\nproblem, don't fret, untangling is possible, although non-trivial depending on the size of your\nrepository. It basically boils down to creating an additional project to move coupled code to.\n\nFor example, if project A was importing from project B, and B from A, then the solution would be to\ncreate another project, C (typically a shared npm package), and move both pieces of code into C. A\nand B would then import from C, instead of from each other. We're not aware of any tools that would\nautomate this, or detect cycles, so you'll need to do it manually.\n\n## /docs/guides/mcp\n\nSource: https://moonrepo.dev/docs/guides/mcp\n\n# MCP integration\n\nv1.37.0\n\n[Model Context Protocol](https://modelcontextprotocol.io) (MCP) is an open standard that enables AI\nmodels to interact with external tools and services through a unified interface. The moon CLI\ncontains an MCP server that you can register with your code editor to allow LLMs to use moon\ndirectly.\n\n## Setup\n\n### Claude Code\n\nTo use [MCP servers in Claude Code](https://docs.anthropic.com/en/docs/claude-code/mcp), run the\nfollowing command in your terminal:\n\n```\nclaude mcp add moon -s project -e MOON_WORKSPACE_ROOT=/absolute/path/to/your/moon/workspace -- moon mcp\n```\n\nOr create an `.mcp.json` file in your project directory.\n\n```\n{  \"mcpServers\": {    \"moon\": {      \"command\": \"moon\",      \"args\": [\"mcp\"],      \"env\": {        \"MOON_WORKSPACE_ROOT\": \"/absolute/path/to/your/moon/workspace\"      }    }  }}\n```\n\n### Cursor\n\nTo use [MCP servers in Cursor](https://docs.cursor.com/context/model-context-protocol), create a\n`.cursor/mcp.json` file in your project directory, or `~/.cursor/mcp.json` globally, with the\nfollowing content:\n\n.cursor/mcp.json\n\n```\n{  \"mcpServers\": {    \"moon\": {      \"command\": \"moon\",      \"args\": [\"mcp\"],      \"env\": {        \"MOON_WORKSPACE_ROOT\": \"/absolute/path/to/your/moon/workspace\"      }    }  }}\n```\n\nOnce configured, the moon MCP server should appear in the \"Available Tools\" section on the MCP\nsettings page in Cursor.\n\n### VS Code\n\nTo use MCP servers in VS Code, you must have the\n[Copilot Chat](https://code.visualstudio.com/docs/copilot/chat/copilot-chat) extension installed.\nOnce installed, create a `.vscode/mcp.json` file with the following content:\n\n.vscode/mcp.json\n\n```\n{  \"servers\": {    \"moon\": {      \"type\": \"stdio\",      \"command\": \"moon\",      \"args\": [\"mcp\"],      // >= 1.102 (June 2025)      \"cwd\": \"${workspaceFolder}\",      // Older versions      \"env\": {        \"MOON_WORKSPACE_ROOT\": \"${workspaceFolder}\"      }    }  }}\n```\n\nOnce your MCP server is configured, you can use it with\n[GitHub Copilot‚Äôs agent mode](https://code.visualstudio.com/docs/copilot/chat/chat-agent-mode):\n\n- Open the Copilot Chat view in VS Code\n\n- Enable agent mode using the mode select dropdown\n\n- Toggle on moon's MCP tools using the \"Tools\" button\n\n### Zed\n\nTo use [MCP servers in Zed](https://zed.dev/docs/ai/mcp), create a `.zed/settings.json` file in your\nproject directory, or `~/.config/zed/settings.json` globally, with the following content:\n\n.zed/settings.json\n\n```\n{  \"context_servers\": {    \"moon\": {      \"command\": {        \"path\": \"moon\",        \"args\": [\"mcp\"],        \"env\": {          \"MOON_WORKSPACE_ROOT\": \"/absolute/path/to/your/moon/workspace\"        }      }    }  }}\n```\n\nOnce your MCP server is configured, you'll need to enable the tools using the following steps:\n\n- Open the Agent panel in Zed\n\n- Click the Write/Ask toggle button and go to \"Configure Profiles\"\n\n- Click \"Customize\" in the Ask section\n\n- Click \"Configure MCP Tools\"\n\n- Enable each tool under the \"moon\" section\n\n## Available tools\n\nThe following tools are available in the moon MCP server and can be executed by LLMs using agent\nmode.\n\n- `get_project` - Get a project and its tasks by `id`.\n\n- `get_projects` - Get all projects.\n\n- `get_task` - Get a task by `target`.\n\n- `get_tasks` - Get all tasks.\n\n- `get_touched_files` - Gets touched files between base and head revisions. v1.38.0\n\n- `sync_projects` - Runs the `SyncProject` action for one or many projects by `id`. v1.38.0\n\n- `sync_workspace` - Runs the `SyncWorkspace` action. v1.38.0\n\ninfo\n\nThe\n[request and response shapes](https://github.com/moonrepo/moon/blob/master/packages/types/src/mcp.ts)\nfor these tools are defined as TypeScript types in the\n[`@moonrepo/types`](https://www.npmjs.com/package/@moonrepo/types) package.\n\n## /docs/guides/node/examples\n\nSource: https://moonrepo.dev/docs/guides/node/examples\n\n- [Home](/)\n- JavaScript\n- [Examples](/docs/guides/node/examples)\n\nwarning\n\nDocumentation is currently for [moon v2](/blog/moon-v2-alpha) and latest proto. Documentation for moon v1 has been frozen and can be [found here](https://moonrepo.github.io/website-v1/).\n\n# Node.js examples\n\n[üìÑÔ∏è AngularIn this guide, you'll learn how to integrate Angular into moon.](/docs/guides/examples/angular)\n\n[üìÑÔ∏è AstroIn this guide, you'll learn how to integrate Astro.](/docs/guides/examples/astro)\n\n[üìÑÔ∏è ESLintIn this guide, you'll learn how to integrate ESLint into moon.](/docs/guides/examples/eslint)\n\n[üìÑÔ∏è JestIn this guide, you'll learn how to integrate Jest into moon.](/docs/guides/examples/jest)\n\n[üìÑÔ∏è NestIn this guide, you'll learn how to integrate NestJS into moon.](/docs/guides/examples/nest)\n\n[üìÑÔ∏è NextIn this guide, you'll learn how to integrate Next.js into moon.](/docs/guides/examples/next)\n\n[üìÑÔ∏è NuxtIn this guide, you'll learn how to integrate Nuxt v3, a Vue framework,](/docs/guides/examples/nuxt)\n\n[üìÑÔ∏è PackemonIn this guide, you'll learn how to integrate Packemon into moon. Packemon](/docs/guides/examples/packemon)\n\n[üìÑÔ∏è PrettierIn this guide, you'll learn how to integrate Prettier into moon.](/docs/guides/examples/prettier)\n\n[üìÑÔ∏è ReactReact is an application or library concern, and not a build system one, since the bundling of React](/docs/guides/examples/react)\n\n[üìÑÔ∏è RemixIn this guide, you'll learn how to integrate Remix into moon.](/docs/guides/examples/remix)\n\n[üìÑÔ∏è SolidSolid (also known as SolidJS) is a JavaScript framework for building](/docs/guides/examples/solid)\n\n[üìÑÔ∏è StorybookStorybook is a frontend workshop for building UI components and pages in isolation. Thousands of](/docs/guides/examples/storybook)\n\n[üìÑÔ∏è SvelteKitSvelteKit is built on Svelte, a UI framework that](/docs/guides/examples/sveltekit)\n\n[üìÑÔ∏è TypeScriptIn this guide, you'll learn how to integrate TypeScript into](/docs/guides/examples/typescript)\n\n[üìÑÔ∏è Vite & VitestIn this guide, you'll learn how to integrate Vite and](/docs/guides/examples/vite)\n\n[üìÑÔ∏è VueVue is an application or library concern, and not a build system one, since the bundling of Vue is](/docs/guides/examples/vue)\n\n[TypeScript project references](/docs/guides/javascript/typescript-project-refs)\n\n[Angular](/docs/guides/examples/angular)\n\n## /docs/guides/notifications\n\nSource: https://moonrepo.dev/docs/guides/notifications\n\n# Terminal notifications\n\nv1.38.0\n\nmoon is able to send operating system desktop notifications for specific events in the action\npipeline, on behalf of your terminal application. This is useful for continuous feedback loops and\nreacting to long-running commands while multi-tasking.\n\nNotifications are opt-in and must be enabled with the\n[`notify.terminalNotifications`](/docs/config/workspace#terminalnotifications) setting.\n\n.moon/workspace.yml\n\n```\nnotifier:  terminalNotifications: 'always'\n```\n\n## Setup\n\nNotifications must be enabled at the operating system level.\n\n### Linux\n\nLinux support is based on the [XDG specification](https://en.wikipedia.org/wiki/XDG) and utilizes\nD-BUS APIs, primarily the\n[`org.freedesktop.Notifications.Notify`](https://www.galago-project.org/specs/notification/0.9/x408.html#command-notify)\nmethod. Refer to your desktop distribution for more information.\n\nNotifications will be sent using the `moon` application name (the current executable).\n\n### macOS\n\n- Open \"System Settings\" or \"System Preferences\"\n\n- Select \"Notifications\" in the left sidebar\n\n- Select your terminal application from the list (e.g., \"Terminal\", \"iTerm\", etc)\n\n- Ensure \"Allow notifications\" is enabled\n\n- Customize the other settings as desired\n\nNotifications will be sent from your currently running terminal application, derived from the\n`TERM_PROGRAM` environment variable. If we fail to detect the terminal, it will default to \"Finder\".\n\n### Windows\n\nRequires Windows 10 or later.\n\n- Open \"Settings\"\n\n- Go to the \"System\" panel\n\n- Select \"Notifications & Actions\" in the left sidebar\n\n- Ensure notifications are enabled\n\nNotifications will be sent from the \"Windows Terminal\" app if it's currently in use, otherwise from\n\"Microsoft PowerShell\".\n\n## /docs/guides/offline-mode\n\nSource: https://moonrepo.dev/docs/guides/offline-mode\n\n# Offline mode\n\nmoon assumes that an internet connection is always available, as we download and install tools into\nthe toolchain, resolve versions against upstream manifests, and automatically install dependencies.\nWhile this is useful, having a constant internet connection isn't always viable.\n\nTo support workflows where internet isn't available or is spotty, moon will automatically check for\nan active internet connection, and drop into offline mode if necessary.\n\n## What's disabled when offline\n\nWhen offline, moon will skip or disable the following:\n\n- Automatic dependency installation will be skipped.\n\n- Toolchain will skip resolving, downloading, and installing tools, and instead use the local cache. If no local cache available, will fallback to binaries found on `PATH`.\n\n- If not available on `PATH`, will fail to run.\n\n- Upgrade and version checks will be skipped.\n\n## Toggling modes\n\nWhile we automatically check for an internet connection, both online and offline modes can be forced\nwith the `PROTO_OFFLINE` environment variable. Setting the variable to `1` or `true` will force\noffline mode, while `0` and `false` will force online mode.\n\n## Environment variables\n\nSome additional variables to interact with offline checks.\n\n- `PROTO_OFFLINE_TIMEOUT` - Customize the timeout for offline checks (in milliseconds). Defaults to `750`.\n\n- `PROTO_OFFLINE_HOSTS` - Customize additional hosts/IPs to check for offline status. Separate multiple hosts with a `,`.\n\n- `PROTO_OFFLINE_IP_VERSION` - Customize which IP version to support, `4` or `6`. If not defined, supports both.\n\n## /docs/guides/open-source\n\nSource: https://moonrepo.dev/docs/guides/open-source\n\n# Open source usage\n\nAlthough moon was designed for large monorepos, it can also be used for open source projects,\nespecially when coupled with our [built-in continuous integration support](/docs/guides/ci).\n\nHowever, a pain point with moon is that it has an explicitly configured version for each tool in the\n[toolchain](/docs/concepts/toolchain), but open source projects typically need to run checks against\nmultiple versions! To mitigate this problem, you can set the matrix value as an environment\nvariable, in the format of `MOON__VERSION`.\n\n.github/workflows/ci.yml\n\n```\nname: 'Pipeline'on:  push:    branches:      - 'master'  pull_request:jobs:  ci:    name: 'CI'    runs-on: ${{ matrix.os }}    strategy:      matrix:        os: ['ubuntu-latest', 'windows-latest']        node-version: [16, 18, 20]    steps:      # Checkout repository      - uses: 'actions/checkout@v4'        with:          fetch-depth: 0      # Install Node.js      - uses: 'actions/setup-node@v6'      # Install dependencies      - run: 'yarn install --immutable'      # Run moon and affected tasks      - run: 'yarn moon ci'        env:          MOON_NODE_VERSION: ${{ matrix.node-version }}\n```\n\ninfo\n\nThis example is only for GitHub actions, but the same mechanism can be applied to other CI\nenvironments.\n\n## Reporting run results\n\nWe also suggest using our\n[`moonrepo/run-report-action`](https://github.com/marketplace/actions/moon-ci-run-reports) GitHub\naction. This action will report the results of a [`moon ci`](/docs/commands/ci) run to a pull request\nas a comment and workflow summary.\n\n.github/workflows/ci.yml\n\n```\n# ...jobs:  ci:    name: 'CI'    runs-on: 'ubuntu-latest'    steps:      # ...      - run: 'yarn moon ci'      - uses: 'moonrepo/run-report-action@v1'        if: success() || failure()        with:          access-token: ${{ secrets.GITHUB_TOKEN }}\n```\n\nThe report looks something like the following:\n\n## /docs/guides/pkl-config\n\nSource: https://moonrepo.dev/docs/guides/pkl-config\n\n# Pkl configuration\n\nv1.32.0\n\nWhile YAML is our official configuration format, we want to support dynamic formats, and as such,\nhave added support for Pkl. What is Pkl? If you haven't heard of Pkl yet,\n[Pkl is a programmable configuration format by Apple](https://pkl-lang.org/). We like Pkl, as it\nmeets the following requirements:\n\n- Is easy to read and write.\n\n- Is dynamic and programmable (loops, variables, etc).\n\n- Has type-safety / built-in schema support.\n\n- Has Rust serde integration.\n\nThe primary requirement that we are hoping to achieve is supporting a configuration format that is\nprogrammable. We want something that has native support for variables, loops, conditions, and\nmore, so that you could curate and compose your configuration very easily. Hacking this\nfunctionality into YAML is a terrible user experience in our opinion!\n\n## Installing Pkl\n\nPkl utilizes a client-server architecture, which means that the `pkl` binary must exist in the\nenvironment for parsing and evaluating `.pkl` files. Jump over to the\n[official documentation for instructions on how to install Pkl](https://pkl-lang.org/main/current/pkl-cli/index.html#installation).\n\nIf you are using [proto](/proto), you can install Pkl with the following commands.\n\n```\nproto plugin add pkl https://raw.githubusercontent.com/milesj/proto-plugins/refs/heads/master/pkl.tomlproto install pkl --pin\n```\n\n## Using Pkl\n\nTo start using Pkl in moon, simply:\n\n- Install [Pkl](#installing-pkl) and the [VS Code extension](https://pkl-lang.org/vscode/current/index.html)\n\n- Create configs with the `.pkl` extension instead of `.yml`\n\ninfo\n\nWe highly suggest reading the Pkl\n[language reference](https://pkl-lang.org/main/current/language-reference/index.html), the\n[standard library](https://pkl-lang.org/main/current/standard-library.html), or looking at our\n[example configurations](#example-configs) when using Pkl.\n\n### Caveats and restrictions\n\nSince this is an entirely new configuration format that is quite dynamic compared to YAML, there are\nsome key differences to be aware of!\n\n- Only files are supported. Cannot use or extend from URLs.\n\n- Each `.pkl` file is evaluated in isolation (loops are processed, variables assigned, etc). This means that task inheritance and file merging cannot extend or infer this native functionality.\n\n- `default` is a [special feature](https://pkl-lang.org/main/current/language-reference/index.html#default-element) in Pkl and cannot be used as a setting name. This only applies to [`template.pkl`](/docs/config/template#default), but can be worked around by using `defaultValue` instead.\n\ntemplate.pkl\n\n```\nvariables {  [\"age\"] {    type = \"number\"    prompt = \"Age?\"    defaultValue = 0}\n```\n\n- `local` is also a reserved word in Pkl. It can be worked around by escaping it with backticks, or you can simply use the [`preset` setting](/docs/config/project#preset) instead.\n\n```\ntasks {  [\"example\"] {    `local` = true    # Or    preset = \"server\"  }}\n```\n\n## Example configs\n\n### `.moon/workspace.pkl`\n\n```\nprojects {  globs = List(\"apps/*\", \"packages/*\")  sources {    [\"root\"] = \".\"  }}vcs {  defaultBranch = \"master\"}\n```\n\n### `.moon/toolchain.pkl`\n\n```\nnode {  version = \"20.15.0\"  packageManager = \"yarn\"  yarn {    version = \"4.3.1\"  }  addEnginesConstraint = false  inferTasksFromScripts = false}\n```\n\n### `moon.pkl`\n\n```\ntype = \"application\"language = \"typescript\"dependsOn = List(\"client\", \"ui\")tasks {  [\"build\"] {    command = \"docusaurus build\"    deps = List(\"^:build\")    outputs = List(\"build\")    options {      interactive = true      retryCount = 3    }  }  [\"typecheck\"] {    command = \"tsc --build\"    inputs = new Listing {      \"@globs(sources)\"      \"@globs(tests)\"      \"tsconfig.json\"      \"/tsconfig.options.json\"    }  }}\n```\n\n## Example functionality\n\n### Loops and conditionals\n\n```\ntasks {  for (_os in List(\"linux\", \"macos\", \"windows\")) {    [\"build-\\(_os)\"] {      command = \"cargo\"      args = List(        \"--target\",        if (_os == \"linux\") \"x86_64-unknown-linux-gnu\"          else if (_os == \"macos\") \"x86_64-apple-darwin\"          else \"i686-pc-windows-msvc\",        \"--verbose\"      )      options {        os = _os      }    }  }}\n```\n\n### Local variables\n\n```\nlocal _sharedInputs = List(\"src/**/*\")tasks {  [\"test\"] {    // ...    inputs = List(\"tests/**/*\") + _sharedInputs  }  [\"lint\"] {    // ...    inputs = List(\"**/*.graphql\") + _sharedInputs  }}\n```\n\n## /docs/guides/profile\n\nSource: https://moonrepo.dev/docs/guides/profile\n\n# Task profiling\n\nTroubleshooting slow or unperformant tasks? Profile and diagnose them with ease!\n\ncaution\n\nProfiling is only supported by `node` based tasks, and is not supported by tasks that are created\nthrough `package.json` inference, or for packages that ship non-JavaScript code (like Rust or Go).\n\n## CPU snapshots\n\nCPU profiling helps you get a better understanding of which parts of your code require the most CPU\ntime, and how your code is executed and optimized by Node.js. The profiler will measure code\nexecution and activities performed by the engine itself, such as compilation, calls of system\nlibraries, optimization, and garbage collection.\n\n### Record a profile\n\nTo record a CPU profile, pass `--profile cpu` to the [`moon run`](/docs/commands/run) command. When\nsuccessful, the profile will be written to\n`.moon/cache/states/\n//snapshot.cpuprofile`.\n\n```\n$ moon run --profile cpu app:lint\n```\n\n### Analyze in Chrome\n\nCPU profiles can be reviewed and analyzed with\n[Chrome developer tools](https://developer.chrome.com/docs/devtools/) using the following steps.\n\n- Open Chrome and navigate to `chrome://inspect`.\n\n- Under \"Devices\", navigate to \"Open dedicated DevTools for Node\".\n\n- The following window will popup. Ensure the \"Profiler\" tab is selected.\n\n- Click \"Load\" and select the `snapshot.cpuprofile` that was [previously recorded](#record-a-profile). If successful, the snapshot will appear in the left column.\n\nOn macOS, press `command` + `shift` + `.` to display hidden files and folders, to locate the\n`.moon` folder.\n\n- Select the snapshot in the left column. From here, the snapshot can be analyzed and represented with [Bottom up](#bottom-up), [Top down](#top-down), or [Flame chart](#flame-chart) views.\n\n## Heap snapshots\n\nHeap profiling lets you detect memory leaks, dynamic memory problems, and locate the fragments of\ncode that caused them.\n\n### Record a profile\n\nTo record a heap profile, pass `--profile heap` to the [`moon run`](/docs/commands/run) command. When\nsuccessful, the profile will be written to\n`.moon/cache/states/\n//snapshot.heapprofile`.\n\n```\n$ moon run --profile heap app:lint\n```\n\n### Analyze in Chrome\n\nHeap profiles can be reviewed and analyzed with\n[Chrome developer tools](https://developer.chrome.com/docs/devtools/) using the following steps.\n\n- Open Chrome and navigate to `chrome://inspect`.\n\n- Under \"Devices\", navigate to \"Open dedicated DevTools for Node\".\n\n- The following window will popup. Ensure the \"Memory\" tab is selected.\n\n- Click \"Load\" and select the `snapshot.heapprofile` that was [previously recorded](#record-a-profile-1). If successful, the snapshot will appear in the left column.\n\nOn macOS, press `command` + `shift` + `.` to display hidden files and folders, to locate the\n`.moon` folder.\n\n- Select the snapshot in the left column. From here, the snapshot can be analyzed and represented with [Bottom up](#bottom-up), [Top down](#top-down), or [Flame chart](#flame-chart) views.\n\n## Views\n\nChrome DevTools provide 3 views for analyzing activities within a snapshot. Each view gives you a\ndifferent perspective on these activities.\n\n### Bottom up\n\nThe Bottom up view is helpful if you encounter a heavy function and want to find out where it was\ncalled from.\n\n- The \"Self Time\" column represents the aggregated time spent directly in that activity, across all of its occurrences.\n\n- The \"Total Time\" column represents aggregated time spent in that activity or any of its children.\n\n- The \"Function\" column is the function that was executed, including source location, and any children.\n\n### Top down\n\nThe Top down view works in a similar fashion to [Bottom up](#bottom-up), but displays functions\nstarting from the top-level entry points. These are also known as root activities.\n\n### Flame chart\n\nDevTools represents main thread activity with a flame chart. The x-axis represents the recording\nover time. The y-axis represents the call stack. The events on top cause the events below it.\n\n## /docs/guides/remote-cache\n\nSource: https://moonrepo.dev/docs/guides/remote-cache\n\n# Remote caching\n\nIs your CI pipeline running slower than usual? Are you tired of running the same build over and over\nalthough nothing has changed? Do you wish to reuse the same local cache across other machines and\nenvironments? These are just a few scenarios that remote caching aims to solve.\n\nRemote caching is a system that shares artifacts to improve performance, reduce unnecessary\ncomputation time, and alleviate resources. It achieves this by uploading hashed artifacts to a cloud\nstorage provider, like AWS S3 or Google Cloud, and downloading them on demand when a build matches a\nderived hash.\n\nTo make use of remote caching, we provide 2 solutions.\n\n## Self-hosted v1.30.0\n\nThis solution allows you to host any remote caching service that is compatible with the\n[Bazel Remote Execution v2 API](https://github.com/bazelbuild/remote-apis/tree/main/build/bazel/remote/execution/v2),\nsuch as [`bazel-remote`](https://github.com/buchgr/bazel-remote). When using this solution, the\nfollowing RE API features must be enabled:\n\n- Action result caching\n\n- Content addressable storage caching\n\n- SHA256 digest hashing\n\n- gRPC requests\n\nwarning\n\nThis feature and its implementation is currently unstable, and its documentation is incomplete.\nPlease report any issues on GitHub or through Discord!\n\n### Host your service\n\nWhen you have chosen (or built) a compatible service, host it and make it available through gRPC (we\ndo not support HTTP at this time). For example, if you plan to use `bazel-remote`, you can do\nsomething like the following:\n\n```\nbazel-remote --dir /path/to/moon-cache --max_size 10 --storage_mode uncompressed --grpc_address 0.0.0.0:9092\n```\n\nIf you've configured the [`remote.cache.compression`](/docs/config/workspace#compression) setting to\n\"zstd\", you'll need to run the binary with that storage mode as well.\n\n```\nbazel-remote --dir /path/to/moon-cache --max_size 10 --storage_mode zstd --grpc_address 0.0.0.0:9092\n```\n\ninfo\n\nView the official [`bazel-remote`](https://github.com/buchgr/bazel-remote#usage) documentation for\nall the available options, like storing artifacts in S3, configuring authentication (TLS/mTLS),\nproxies, and more.\n\n### Configure remote caching\n\nOnce your service is running, you can enable remote caching by configuring the\n[`remote`](/docs/config/workspace#remote) settings in [`.moon/workspace.yml`](/docs/config/workspace). At\nminimum, the only setting that is required is `host`.\n\n.moon/workspace.yml\n\n```\nremote:  host: 'grpc://your-host.com:9092'\n```\n\n#### TLS and mTLS\n\nWe have rudimentary support for TLS and mTLS, but it's very unstable, and has not been thoroughly\ntested. There's also [many](https://github.com/hyperium/tonic/issues/1652)\n[many](https://github.com/hyperium/tonic/issues/1989)\n[issues](https://github.com/hyperium/tonic/issues/1033) around authentication in Tonic.\n\n.moon/workspace.yml\n\n```\n# TLSremote:  host: 'grpcs://your-host.com:9092'  tls:    cert: 'certs/ca.pem'    domain: 'your-host.com'# mTLSremote:  host: 'grpcs://your-host.com:9092'  mtls:    caCert: 'certs/ca.pem'    clientCert: 'certs/client.pem'    clientKey: 'certs/client.key'    domain: 'your-host.com'\n```\n\n## Cloud-hosted: Depotv1.32.0\n\nIf you'd prefer not to host your own solution, you could use\n[Depot Cache](https://depot.dev/products/cache), a cloud-based caching solution. To make use of\nDepot, follow these steps:\n\n- Create an account on [depot.dev](https://depot.dev)\n\n- Create an organization\n\n- Go to organization settings -> API tokens\n\n- Create a new API token\n\n- Add the token as a `DEPOT_TOKEN` environment variable to your moon pipelines\n\nOnce these steps have been completed, you can enable remote caching in moon with the following\nconfiguration. If your Depot account has more than 1 organization, you'll need to set the\n`X-Depot-Org` header.\n\n.moon/workspace.yml\n\n```\nremote:  host: 'grpcs://cache.depot.dev'  auth:    token: 'DEPOT_TOKEN'    headers:      'X-Depot-Org': ''\n```\n\n## FAQ\n\n#### What is an artifact?\n\nIn the context of moon and remote caching, an artifact is the\n[outputs of a task](/docs/config/project#outputs), as well as the stdout and stderr of the task that\ngenerated the outputs. Artifacts are uniquely identified by the\n[moon generated hash](/docs/concepts/cache#hashing).\n\n#### Do I have to use remote caching?\n\nNo, remote caching is optional. It's intended purpose is to store long lived build artifacts to\nspeed up CI pipelines, and optionally local development. For the most part,\n[`moon ci`](/docs/commands/ci) does a great job of only running what's affected in pull requests, and\nis a great starting point.\n\n#### Does remote caching store source code?\n\nNo, remote caching does not store source code. It stores the\n[outputs of a task](/docs/config/project#outputs), which is typically built and compiled code. To\nverify this, you can inspect the tar archives in `.moon/cache/outputs`.\n\n#### Does moon collect any personally identifiable information?\n\nNo, moon does not collect any PII as part of the remote caching process.\n\n#### Are artifacts encrypted?\n\nWe do not encrypt on moon's side, as encryption is provided by your cloud storage provider.\n\n## /docs/guides/root-project\n\nSource: https://moonrepo.dev/docs/guides/root-project\n\n# Root-level project\n\nComing from other repositories or task runner, you may be familiar with tasks available at the\nrepository root, in which one-off, organization, maintenance, or process oriented tasks can be ran.\nmoon supports this through a concept known as a root-level project.\n\nBegin by adding the root to [`projects`](/docs/config/workspace#projects) with a source value of `.`\n(current directory relative from the workspace).\n\n.moon/workspace.yml\n\n```\n# As a mapprojects:  root: '.'# As a list of globsprojects:  - '.'\n```\n\nWhen using globs, the root project's name will be inferred from the repository folder name. Be\nwary of this as it can change based on what a developer has checked out as.\n\nOnce added, create a [`moon.yml`](/docs/config/project) in the root of the repository. From here you\ncan define tasks that can be ran using this new root-level project name, for example,\n`moon run root:`.\n\nmoon.yml\n\n```\ntasks:  versionCheck:    command: 'yarn version check'    inputs: []    options:      cache: false\n```\n\nAnd that's it, but there are a few caveats to be aware of...\n\n## Caveats\n\n### Greedy inputs\n\nwarning\n\nIn moon v1.24, root-level tasks default to no inputs. In previous versions, inputs defaulted to\n`**/*`. This section is only applicable for older moon versions!\n\nTask [`inputs`](/docs/config/project#inputs) default to `**/*`, which would result in root-level tasks\nscanning all files in the repository. This will be a very expensive operation! We suggest\nrestricting inputs to a very succinct whitelist, or disabling inputs entirely.\n\nmoon.yml\n\n```\ntasks:  oneOff:    # ...    inputs: []\n```\n\n### Inherited tasks\n\nBecause a root project is still a project in the workspace, it will inherit all tasks defined in\n[`.moon/tasks/all.yml`](/docs/config/tasks), which may be unexpected. To mitigate this, you can exclude\nsome or all of these tasks in the root config with\n[`workspace.inheritedTasks`](/docs/config/project#inheritedtasks).\n\nmoon.yml\n\n```\nworkspace:  inheritedTasks:    include: []\n```\n\n## /docs/guides/rust/handbook\n\nSource: https://moonrepo.dev/docs/guides/rust/handbook\n\n# Rust handbook\n\nUtilizing Rust in a monorepo is a trivial task, thanks to Cargo, and also moon. With this handbook,\nwe'll help guide you through this process.\n\ninfo\n\nmoon is not a build system and does not replace Cargo. Instead, moon runs `cargo` commands, and\nefficiently orchestrates those tasks within the workspace.\n\n## moon setup\n\nFor this part of the handbook, we'll be focusing on [moon](/moon), our task runner. To start,\nlanguages in moon act like plugins, where their functionality and support is not enabled unless\nexplicitly configured. We follow this approach to avoid unnecessary overhead.\n\n### Enabling the language\n\nTo enable Rust, define the [`rust`](/docs/config/toolchain#rust) setting in\n[`.moon/toolchains.yml`](/docs/config/toolchain), even if an empty object.\n\n.moon/toolchains.yml\n\n```\n# Enable Rustrust: {}# Enable Rust and override default settingsrust:  syncToolchainConfig: true\n```\n\nOr by pinning a `rust` version in [`.prototools`](/docs/proto/config) in the workspace root.\n\n.prototools\n\n```\nrust = \"1.69.0\"\n```\n\nThis will enable the Rust toolchain and provide the following automations around its ecosystem:\n\n- Manifests and lockfiles are parsed for accurate dependency versions for hashing purposes.\n\n- Cargo binaries (in `~/.cargo/bin`) are properly located and executed.\n\n- Automatically sync `rust-toolchain.toml` configuration files.\n\n- For non-workspaces, will inherit `package.name` from `Cargo.toml` as a project alias.\n\n- And more to come!\n\n### Utilizing the toolchain\n\nWhen a language is enabled, moon by default will assume that the language's binary is available\nwithin the current environment (typically on `PATH`). This has the downside of requiring all\ndevelopers and machines to manually install the correct version of the language, and to stay in\nsync.\n\nInstead, you can utilize [moon's toolchain](/docs/concepts/toolchain), which will download and\ninstall the language in the background, and ensure every task is executed using the exact version\nacross all machines.\n\nEnabling the toolchain is as simple as defining the\n[`rust.version`](/docs/config/toolchain#version-2) setting.\n\n.moon/toolchains.yml\n\n```\n# Enable Rust toolchain with an explicit versionrust:  version: '1.69.0'\n```\n\nVersions can also be defined with [`.prototools`](/docs/proto/config).\n\ncaution\n\nmoon requires `rustup` to exist in the environment, and will use this to install the necessary Rust\ntoolchains. This requires Rust to be manually installed on the machine, as moon does not\nauto-install the language, just the toolchains.\n\n## Repository structure\n\nRust/Cargo repositories come in two flavors: a single crate with one `Cargo.toml`, or multiple\ncrates with many `Cargo.toml`s using\n[Cargo workspaces](https://doc.rust-lang.org/book/ch14-03-cargo-workspaces.html). The latter is\nhighly preferred as it enables Cargo incremental caching.\n\nRegardless of which flavor your repository uses, in moon, both flavors are a single\n[moon project](/docs/concepts/project). This means that all Rust crates are grouped together into a\nsingle moon project, and the [`moon.yml`](/docs/config/project) file is located at the root relative\nto `Cargo.lock` and the `target` folder.\n\nAn example of this layout is demonstrated below:\n\n- Workspaces\n- Non-workspaces\n\n```\n/‚îú‚îÄ‚îÄ .moon/‚îú‚îÄ‚îÄ crates/‚îÇ   ‚îú‚îÄ‚îÄ client/|   ‚îÇ   ‚îú‚îÄ‚îÄ ...‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Cargo.toml‚îÇ   ‚îú‚îÄ‚îÄ server/|   ‚îÇ   ‚îú‚îÄ‚îÄ ...‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Cargo.toml‚îÇ   ‚îî‚îÄ‚îÄ utils/|       ‚îú‚îÄ‚îÄ ...‚îÇ       ‚îî‚îÄ‚îÄ Cargo.toml‚îú‚îÄ‚îÄ target/‚îú‚îÄ‚îÄ Cargo.lock‚îú‚îÄ‚îÄ Cargo.toml‚îî‚îÄ‚îÄ moon.yml\n```\n\n```\n/‚îú‚îÄ‚îÄ .moon/‚îú‚îÄ‚îÄ src/‚îÇ   ‚îî‚îÄ‚îÄ lib.rs‚îú‚îÄ‚îÄ tests/‚îÇ   ‚îî‚îÄ‚îÄ ...‚îú‚îÄ‚îÄ target/‚îú‚îÄ‚îÄ Cargo.lock‚îú‚îÄ‚îÄ Cargo.toml‚îî‚îÄ‚îÄ moon.yml\n```\n\n### Example `moon.yml`\n\nThe following configuration represents a base that covers most Rust projects.\n\n- Workspaces\n- Non-workspaces\n\n/moon.yml\n\n```\nlanguage: 'rust'layer: 'application'env:  CARGO_TERM_COLOR: 'always'fileGroups:  sources:    - 'crates/*/src/**/*'    - 'crates/*/Cargo.toml'    - 'Cargo.toml'  tests:    - 'crates/*/benches/**/*'    - 'crates/*/tests/**/*'tasks:  build:    command: 'cargo build'    inputs:      - '@globs(sources)'  check:    command: 'cargo check --workspace'    inputs:      - '@globs(sources)'  format:    command: 'cargo fmt --all --check'    inputs:      - '@globs(sources)'      - '@globs(tests)'  lint:    command: 'cargo clippy --workspace'    inputs:      - '@globs(sources)'      - '@globs(tests)'  test:    command: 'cargo test --workspace'    inputs:      - '@globs(sources)'      - '@globs(tests)'\n```\n\n/moon.yml\n\n```\nlanguage: 'rust'layer: 'application'env:  CARGO_TERM_COLOR: 'always'fileGroups:  sources:    - 'src/**/*'    - 'Cargo.toml'  tests:    - 'benches/**/*'    - 'tests/**/*'tasks:  build:    command: 'cargo build'    inputs:      - '@globs(sources)'  check:    command: 'cargo check'    inputs:      - '@globs(sources)'  format:    command: 'cargo fmt --check'    inputs:      - '@globs(sources)'      - '@globs(tests)'  lint:    command: 'cargo clippy'    inputs:      - '@globs(sources)'      - '@globs(tests)'  test:    command: 'cargo test'    inputs:      - '@globs(sources)'      - '@globs(tests)'\n```\n\n## Cargo integration\n\nYou can't use Rust without Cargo -- well you could but why would you do that? With moon, we're doing\nour best to integrate with Cargo as much as possible. Here's a few of the benefits we currently\nprovide.\n\n### Global binaries\n\nCargo supports global binaries through the\n[`cargo install`](https://doc.rust-lang.org/cargo/commands/cargo-install.html) command, which\ninstalls a crate to `~/.cargo/bin`, or makes it available through the `cargo ` command. These\nare extremely beneficial for development, but they do require every developer to manually install\nthe crate (and appropriate version) to their machine.\n\nWith moon, this is no longer an issue with the [`rust.bins`](/docs/config/toolchain#bins) setting.\nThis setting requires a list of crates (with optional versions) to install, and moon will install\nthem as part of the task runner install dependencies action. Furthermore, binaries will be installed\nwith [`cargo-binstall`](https://crates.io/crates/cargo-binstall) in an effort to reduce build and\ncompilation times.\n\n.moon/toolchains.yml\n\n```\nrust:  bins:    - 'cargo-make@0.35.0'    - 'cargo-nextest'\n```\n\nAt this point, tasks can be configured to run this binary as a command. The `cargo` prefix is\noptional, as we'll inject it when necessary.\n\n/moon.yml\n\n```\ntasks:  test:    command: 'nextest run --workspace'    toolchain: 'rust'\n```\n\ntip\n\nThe `cargo-binstall` crate may require a `GITHUB_TOKEN` environment variable to make GitHub Releases\nAPI requests, especially in CI. If you're being rate limited, or fail to find a download, try\ncreating a token with necessary permissions.\n\n### Lockfile handling\n\nTo expand our integration even further, we also take `Cargo.lock` into account, and apply the\nfollowing automations when a target is being ran:\n\n- If the lockfile does not exist, we generate one with [`cargo generate-lockfile`](https://doc.rust-lang.org/cargo/commands/cargo-generate-lockfile.html).\n\n- We parse and extract the resolved checksums and versions for more accurate hashing.\n\n## FAQ\n\n### Should we cache the `target` directory as an output?\n\nNo, we don't believe so. Both moon and Cargo support incremental caching, but they're not entirely\ncompatible, and will most likely cause problems when used together.\n\nThe biggest factor is that moon's caching and hydration uses a tarball strategy, where each task\nwould unpack a tarball on cache hit, and archive a tarball on cache miss. The Cargo target directory\nis extremely large (moon's is around 50gb), and coupling this with our tarball strategy is not\nviable. This would cause massive performance degradation.\n\nHowever, at maximum, you could cache the compiled binary itself as an output, instead of the\nentire target directory. Example:\n\nmoon.yml\n\n```\ntasks:  build:    command: 'cargo build --release'    outputs: ['target/release/moon']\n```\n\n### How can we improve CI times?\n\nRust is known for slow build times and CI is no exception. With that being said, there are a few\npatterns to help alleviate this, both on the moon side and outside of it.\n\nTo start, you can cache Rust builds in CI. This is a non-moon solution to the `target` directory\nproblem above.\n\n- If you use GitHub Actions, feel free to use our [moonrepo/setup-rust](https://github.com/moonrepo/setup-rust) action, which has built-in caching.\n\n- A more integrated solution is [sccache](https://crates.io/crates/sccache), which stores build artifacts in a cloud storage provider.\n\n## /docs/guides/sharing-config\n\nSource: https://moonrepo.dev/docs/guides/sharing-config\n\n# Sharing workspace configuration\n\nFor large companies, open source maintainers, and those that love reusability, more often than not\nyou'll want to use the same configuration across all repositories for consistency. This helps reduce\nthe maintenance burden while ensuring a similar developer experience.\n\nTo help streamline this process, moon provides an `extends` setting in both\n[`.moon/workspace.yml`](/docs/config/workspace#extends),\n[`.moon/toolchains.yml`](/docs/config/toolchain#extends), and\n[`.moon/tasks/all.yml`](/docs/config/tasks#extends). This setting requires a HTTPS URL or relative\nfile system path that points to a valid YAML document for the configuration in question.\n\nA great way to share configuration is by using GitHub's \"raw file view\", as demonstrated below using\nour very own [examples repository](https://github.com/moonrepo/examples).\n\n.moon/tasks/all.yml\n\n```\nextends: 'https://raw.githubusercontent.com/moonrepo/examples/master/.moon/tasks/all.yml'\n```\n\n## Versioning\n\nInheriting an upstream configuration can be dangerous, as the settings may change at any point,\nresulting in broken builds. To mitigate this, you can used a \"versioned\" upstream configuration,\nwhich is ideally a fixed point in time. How this is implemented is up to you or your company, but we\nsuggest the following patterns:\n\n### Using versioned filenames\n\nA rudimentary solution is to append a version to the upstream filename. When the file is modified, a\nnew version should be created, while the previous version remains untouched.\n\n```\n-extends: '../shared/project.yml'+extends: '../shared/project-v1.yml'\n```\n\n### Using branches, tags, or commits\n\nWhen using a version control platform, like GitHub above, you can reference the upstream\nconfiguration through a branch, tag, commit, or sha. Since these are a reference point in time, they\nare relatively safe.\n\n```\n-extends: 'https://raw.githubusercontent.com/moonrepo/examples/master/.moon/tasks/all.yml'+extends: 'https://raw.githubusercontent.com/moonrepo/examples/c3f10160bcd16b48b8d4d21b208bb50f6b09bd96/.moon/tasks/all.yml'\n```\n\n## /docs/guides/vcs-hooks\n\nSource: https://moonrepo.dev/docs/guides/vcs-hooks\n\n# VCS hooks\n\nv1.9.0\n\nVCS hooks (most popular with [Git](https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks)) are a\nmechanism for running scripts at pre-defined phases in the VCS's lifecycle, most commonly\npre-commit, pre-push, or pre-merge. With moon, we provide a built-in solution for managing hooks,\nand syncing them across developers and machines.\n\n- [Learn more about Git hooks](https://git-scm.com/docs/githooks)\n\n## Defining hooks\n\nHooks can be configured with the [`vcs.hooks`](/docs/config/workspace#hooks) setting in\n[`.moon/workspace.yml`](/docs/config/workspace). This setting requires a map of hook names (in the\nformat required by your VCS), to a list of arbitrary commands to run within the hook script.\nCommands are used as-is and are not formatted or interpolated in any way.\n\nTo demonstrate this, let's configure a `pre-commit` hook that runs a moon `lint` task for affected\nprojects, and also verifies that the commit message abides by a specified format (using\n[pre-commit](https://pre-commit.com/) and the\n[commitlint hook](https://github.com/alessandrojcm/commitlint-pre-commit-hook), for example).\n\n.moon/workspace.yml\n\n```\nvcs:  hooks:    pre-commit:      - 'pre-commit run'      - 'moon run :lint --affected'    commit-msg:      - 'pre-commit run --hook-stage commit-msg --commit-msg-filename $ARG1'\n```\n\ninfo\n\nAll commands are executed from the repository root (not moon's workspace root) and must exist on\n`PATH`. If `moon` is installed locally, you can execute it using a repository relative path, like\n`./node_modules/@moonrepo/cli/moon`.\n\n### Accessing argumentsv1.40.3\n\nTo ease interoperability between operating systems and terminal shells, we set passed arguments as\nenvironment variables.\n\nIn your hook commands, you can access these arguments using the `$ARG` format, where `` is the\n1-indexed position of the argument. For example, to access the first argument, you would use\n`$ARG1`, the second argument would be `$ARG2`, and so on. `$ARG0` exists and points to the current\nscript.\n\n## Enabling hooks\n\nHooks are a divisive subject, as some developers love them, and others hate them. Finding a viable\nsolution for everyone can be difficult, so with moon, we opted to support 2 distinct options, but\nonly 1 can be used at a time. Choose the option that works best for your project, team, or company!\n\ncaution\n\nIf you have existing VCS hooks, back them up as moon's implementation will overwrite them! To\nmigrate your existing hooks, [configure them as commands to run](#defining-hooks).\n\n### Automatically for everyone\n\nIf you'd like hooks to be enforced for every contributor of the repository, then simply enable the\n[`vcs.syncHooks`](/docs/config/workspace#synchooks) setting in\n[`.moon/workspace.yml`](/docs/config/workspace). This will automatically generate hook scripts and link\nthem with the local VCS checkout, everytime a [target](/docs/concepts/target) is ran.\n\n.moon/workspace.yml\n\n```\nvcs:  hooks: [...]  syncHooks: true\n```\n\ncaution\n\nAutomatically activating hooks on everyone's computer is considered a sensitive action, because it\nenables the execution of arbitrary code on the computers of the team members. Be careful about the\nhook commands you define in the [`.moon/workspace.yml`](/docs/config/workspace) file.\n\n### Manually by each developer\n\nIf you'd prefer contributors to have a choice in whether or not they want to use hooks, then simply\ndo nothing, and guide them to run the [`moon sync hooks`](/docs/commands/sync/vcs-hooks) command. This\ncommand will generate hook scripts and link them with the local VCS checkout.\n\n```\n$ moon sync hooks\n```\n\n## Disabling hooks\n\nIf you choose to stop using hooks, you'll need to cleanup the previously generated hook scripts, and\nreset the VCS checkout. To start, disable the `vcs.syncHooks` setting.\n\n.moon/workspace.yml\n\n```\nvcs:  syncHooks: false\n```\n\nAnd then run the following command, which will delete files from your local filesystem. Every\ndeveloper that is using hooks will need to run this command.\n\n```\n$ moon sync hooks --clean\n```\n\n## How it works\n\nWhen hooks are [enabled](#enabling-hooks), the following processes will take place.\n\n- The configured [hooks](#defining-hooks) will be generated as individual script files in the `.moon/hooks` directory. Whether or not you commit or ignore these script files is your choice. They are written to the `.moon` directory so that they can be reviewed, audited, and easily tested, but are required.\n\n- We then sync these generated hook scripts with the current VCS. For Git, we create `.git/hooks` files that execute our generated scripts, using repository relative commands. Any existing VCS hooks will be overwritten.\n\ninfo\n\nThe `.moon/hooks` scripts are generated as Bash scripts (use a `.sh` file extension) on Unix, and\nPowerShell scripts (use a `.ps1` file extension) on Windows.\n\n### Git\n\nOn Unix based operating systems (Linux, macOS, etc), the `.moon/hooks` scripts are executed from\n`.git/hooks` Bash files. Because of this, `bash` should be available on the system (which is\ntypically the case).\n\nOn Windows, things get tricky. Since Git has a requirement that `.git/hooks` files must be\nextensionless, and older versions of PowerShell require an extension, we have to use a workaround.\nTo handle this, the `.git/hooks` files are Bash-like scripts (that should work on most machines)\nthat execute `.moon/hooks` using the `powershell.exe` (or `pwsh.exe`) executables. Because of this,\nPowerShell must be available on the system.\n\n## Examples\n\n### Pre-commit\n\nA perfect use case for the `pre-commit` hook is to check linting and formatting of the files being\ncommitted. If either of these tasks fail, the commit will abort until they are fixed. Be sure to use\nthe [`--affected`](/docs/run-task#running-based-on-affected-files-only) option so that we only run on\nchanged projects!\n\n.moon/workspace.yml\n\n```\nvcs:  hooks:    pre-commit:      - 'moon run :lint :format --affected --status=staged'\n```\n\nBy default this will run on the entire project (all files). If you want to filter it to only the\nchanged files, enable the [`affectedFiles`](/docs/config/project#affectedfiles) task option.\n\n## /docs/guides/wasm-plugins\n\nSource: https://moonrepo.dev/docs/guides/wasm-plugins\n\n# WASM plugins\n\n[moon](/moon) and [proto](/proto) plugins can be written in\n[WebAssembly (WASM)](https://webassembly.org/), a portable binary format. This means that plugins\ncan be written in any language that compiles to WASM, like Rust, C, C++, Go, TypeScript, and more.\nBecause WASM based plugins are powered by a programming language, they implicitly support complex\nbusiness logic and behavior, have access to a sandboxed file system (via WASI), can execute child\nprocesses, and much more.\n\ndanger\n\nSince our WASM plugin implementations are still experimental, expect breaking changes to occur in\nnon-major releases.\n\n## Powered by Extism\n\nOur WASM plugin system is powered by [Extism](https://extism.org/), a Rust-based cross-language\nframework for building WASM plugins under a unified guest and host API. Under the hood, Extism uses\n[wasmtime](https://wasmtime.dev/) as its WASM runtime.\n\nFor the most part, you do not need to know about Extism's host SDK, as we have implemented the\nbulk of it within moon and proto directly. However, you should be familiar with the guest PDKs, as\nthis is what you'll be using to implement Rust-based plugins. We suggest reading the following\nmaterial:\n\n- [Plugin development kits](https://extism.org/docs/concepts/pdk) (PDKs)\n\n- The [extism-pdk](https://github.com/extism/rust-pdk) Rust crate\n\n- [Host functions](https://extism.org/docs/concepts/host-functions) (how they work)\n\n## Concepts\n\nBefore we begin, let's talk about a few concepts that are critical to WASM and our plugin systems.\n\n### Plugin identifier\n\nWhen implementing plugin functions, you'll need to access information about the current plugin. To\nget the current plugin identifier (the key the plugin was configured with), use the\n[`get_plugin_id`](https://docs.rs/warpgate_pdk/latest/warpgate_pdk/fn.get_plugin_id.html) function.\n\n```\nlet id = get_plugin_id();\n```\n\n### Virtual paths\n\nWASM by default does not have access to the host file system, but through [WASI](https://wasi.dev/),\nwe can provide sandboxed access to a pre-defined list of allowed directories. We call these\n[virtual paths](https://docs.rs/warpgate_api/latest/warpgate_api/enum.VirtualPath.html), and all\npaths provided via function input or context use them.\n\nVirtual paths are implemented by mapping a real path (host machine) to a virtual path (guest\nruntime) using file path prefixes. The following prefixes are currently supported:\n\nReal path Virtual path Only for\n\n`~` `/userhome` ~\n\n`~/.proto` `/proto` ~\n\n`~/.moon` `/moon` moon\n\nmoon workspace `/workspace` moon\n\nFor example, from the context of WASM, you may have a virtual path of `/proto/tools/node/1.2.3`,\nwhich simply maps back to `~/.proto/tools/node/1.2.3` on the host machine. However, this should\nalmost always be transparent to you, the developer, and to end users.\n\nHowever, there may be a few cases where you need access to the real path from WASM, for example,\nlogging or executing commands. For this, the real path can be accessed with the\n[`real_path`](https://docs.rs/warpgate_api/latest/warpgate_api/enum.VirtualPath.html#method.real_path)\nfunction on the `VirtualPath` enum (this is a Rust only feature).\n\n```\nvirtual_path.real_path();\n```\n\n#### File system caveats\n\nWhen working with the file system from the context of WASM, there are a few caveats to be aware of.\n\n- All `fs` calls must use the virtual path. Real paths will error.\n\n- Paths not white listed (using prefixes above) will error.\n\n- Changing file permissions is not supported (on Unix and Windows). This is because WASI does not support this.\n\n- This also means operations like unpacking archives is not possible.\n\n### Host environment\n\nSince WASM executes in its own runtime, it does not have access to the current host operating\nsystem, architecture, so on and so forth. To bridge this gap, we provide the\n[`get_host_environment`](https://docs.rs/warpgate_pdk/latest/warpgate_pdk/fn.get_host_environment.html)\nfunction.\n[Learn more about this type](https://docs.rs/warpgate_pdk/latest/warpgate_pdk/struct.HostEnvironment.html).\n\n```\nlet env = get_host_environment()?;\n```\n\nThe host operating system and architecture can be accessed with `os` and `arch` fields respectively.\nBoth fields are an enum in Rust, or a string in other languages.\n\n```\nif env.os == HostOS::Windows {    // Windows only}if env.arch == HostArch::Arm64 {    // aarch64 only}\n```\n\nFurthermore, the user's home directory (`~`) can be accessed with the `home_dir` field, which is a\n[virtual path](#virtual-paths).\n\n```\nif env.home_dir.join(some_path).exists() {    // Do something}\n```\n\n### Host functions & macros\n\nWASM is pretty powerful but it can't do everything since it's sandboxed. To work around this, we\nprovide a mechanism known as host functions, which are functions that are implemented on the host\n(in Rust), and can be executed from WASM. The following host functions are currently available:\n\n- [`exec_command`](https://docs.rs/warpgate_pdk/latest/warpgate_pdk/macro.exec_command.html) - Execute a system command on the host machine, with a provided list of arguments or environment variables.\n\n- [`from_virtual_path`](https://docs.rs/warpgate_pdk/latest/warpgate_pdk/macro.real_path.html) - Converts a virtual path into a real path.\n\n- [`get_env_var`](https://docs.rs/warpgate_pdk/latest/warpgate_pdk/macro.host_env.html) - Get an environment variable value from the host environment.\n\n- [`host_log`](https://docs.rs/warpgate_pdk/latest/warpgate_pdk/macro.host_log.html) - Log an stdout, stderr, or tracing message to the host's terminal.\n\n- [`send_request`](https://docs.rs/warpgate_pdk/latest/warpgate_pdk/macro.send_request.html) - Requests a URL on the host machine using a Rust-based HTTP client (not WASM).\n\n- [`set_env_var`](https://docs.rs/warpgate_pdk/latest/warpgate_pdk/macro.host_env.html) - Set an environment variable to the host environment.\n\n- [`to_virtual_path`](https://docs.rs/warpgate_pdk/latest/warpgate_pdk/macro.virtual_path.html) - Converts a real path into a virtual path.\n\nTo use host functions, you'll need to make them available by registering them at the top of your\nRust file (only add the functions you want to use) using the\n[extism-pdk](https://crates.io/crates/extism-pdk) crate.\n\n```\nuse extism_pdk::*;#[host_fn]extern \"ExtismHost\" {    fn exec_command(input: Json) -> Json;    fn from_virtual_path(path: String) -> String;    fn get_env_var(key: String) -> String;    fn host_log(input: Json);    fn send_request(input: Json) -> Json;    fn set_env_var(key: String, value: String);    fn to_virtual_path(path: String) -> Json;}\n```\n\ninfo\n\nTo simplify development, we provide built-in functions and macros for the host functions above.\nContinue reading for more information on these macros.\n\n#### Converting paths\n\nWhen working with virtual paths, you may need to convert them to real paths, and vice versa. The\n[`into_virtual_path`](https://docs.rs/warpgate_pdk/latest/warpgate_pdk/fn.into_virtual_path.html)\nand [`into_real_path`](https://docs.rs/warpgate_pdk/latest/warpgate_pdk/fn.into_real_path.html)\nfunctions can be used for such situations, which use the `to_virtual_path` and `from_virtual_path`\nhost functions respectively.\n\n```\n// Supports strings or pathslet virt = into_virtual_path(\"/some/real/path\")?;let real = into_real_path(PathBuf::from(\"/some/virtual/path\"))?;\n```\n\n#### Environment variables\n\nThe [`get_host_env_var`](https://docs.rs/warpgate_pdk/latest/warpgate_pdk/fn.get_host_env_var.html)\nand [`set_host_env_var`](https://docs.rs/warpgate_pdk/latest/warpgate_pdk/fn.set_host_env_var.html)\nfunctions can be used to read and write environment variables on the host, using the `set_env_var`\nand `get_env_var` host functions respectively.\n\n```\n// Set a valueset_host_env_var(\"ENV_VAR\", \"value\")?;// Get a value (returns an `Option`)let value = get_host_env_var(\"ENV_VAR\")?;\n```\n\nAdditionally, the\n[`add_host_paths`](https://docs.rs/warpgate_pdk/latest/warpgate_pdk/fn.add_host_paths.html) function\ncan be used to append paths to the `PATH` environment variable.\n\n```\n// Append to pathadd_host_paths([\"/userhome/some/virtual/path\"])?;\n```\n\n#### Executing commands\n\nThe [`exec_command!`](https://docs.rs/warpgate_pdk/latest/warpgate_pdk/macro.exec_command.html)\nmacro can be used to execute a command on the host, using the `exec_command` host function. If the\ncommand does not exist on `PATH`, an error is thrown. This macros supports three modes: pipe,\ninherit, and raw (returns `Result`).\n\n```\nlet result = exec_command!(raw, \"which\", [\"node\"]);\n```\n\nIf you want a simpler API, the\n[`exec`](https://docs.rs/warpgate_pdk/latest/warpgate_pdk/fn.exec.html),\n[`exec_captured`](https://docs.rs/warpgate_pdk/latest/warpgate_pdk/fn.exec_captured.html) (pipe),\nand [`exec_streamed`](https://docs.rs/warpgate_pdk/latest/warpgate_pdk/fn.exec_streamed.html)\n(inherit) functions can be used.\n\n```\n// Pipe stdout/stderrlet output = exec_captured(\"which\", [\"node\"])?;// Inherit stdout/stderrexec_streamed(\"npm\", [\"install\"])?;// Full controlexec(ExecCommandInput {    command: \"npm\".into(),    args: vec![\"install\".into()],    ..ExecCommandInput::default()})?;\n```\n\n#### Sending requests\n\nThe [`send_request`](https://docs.rs/warpgate_pdk/latest/warpgate_pdk/macro.send_request.html) macro\ncan be used to request a URL on the host, instead of from WASM, allowing it to use the same HTTP\nclient as the host CLI. This macro returns a response object, with the raw body in bytes, and the\nstatus code.\n\n```\nlet response = send_request!(\"https://some.com/url/to/fetch\");if response.status == 200 {  let json = response.json::()?;  let text = response.text()?;} else {  // Error!}\n```\n\nTo simplify the handling of requests -> responses, we also provide the\n[`fetch_bytes`](https://docs.rs/warpgate_pdk/latest/warpgate_pdk/fn.fetch_bytes.html),\n[`fetch_json`](https://docs.rs/warpgate_pdk/latest/warpgate_pdk/fn.fetch_json.html), and\n[`fetch_text`](https://docs.rs/warpgate_pdk/latest/warpgate_pdk/fn.fetch_text.html) functions.\n\n```\nlet json: T = fetch_json(\"https://some.com/url/to/fetch.json\")?;\n```\n\nOnly GET requests are supported.\n\n#### Logging\n\nThe [`host_log!`](https://docs.rs/warpgate_pdk/latest/warpgate_pdk/macro.host_log.html) macro can be\nused to write stdout or stderr messages to the host's terminal, using the `host_log` host function.\nIt supports the same argument patterns as `format!`.\n\nIf you want full control, like providing data/fields, use the input mode and provide\n[`HostLogInput`](https://docs.rs/warpgate_pdk/latest/warpgate_pdk/struct.HostLogInput.html).\n\n```\nhost_log!(stdout, \"Some message\");host_log!(stderr, \"Some message with {}\", \"args\");// With datahost_log!(input, HostLogInput {    message: \"Some message with data\".into(),    data: HashMap::from_iter([        (\"data\".into(), serde_json::to_value(data)?),    ]),    target: HostLogTarget::Stderr,});\n```\n\nFurthermore, the [extism-pdk](https://crates.io/crates/extism-pdk) crate provides a handful of\nmacros for writing level-based messages that'll appear in the host's terminal when `--log` is\nenabled in the CLI. These also support arguments.\n\n```\ndebug!(\"This is a debug message\");info!(\"Something informational happened\");warn!(\"Proceed with caution\");error!(\"Oh no, something went wrong\");\n```\n\n## Configuring plugin locations\n\nTo use a WASM plugin, it'll need to be configured in both moon and proto. Luckily both tools use a\nsimilar approach for configuring plugins called the\n[plugin locator](https://docs.rs/warpgate/latest/warpgate/enum.PluginLocator.html). A locator string\nis composed of 2 parts separated by `://`, the former is the protocol, and the latter is the\nlocation.\n\n```\n\"\n://\"\n```\n\nThe following locator patterns are supported:\n\n### `file`\n\nThe `file://` protocol represents a file path, either absolute or relative (from the current\nconfiguration file).\n\n```\n# Relative\"file://./path/to/example.wasm\"# Absolute\"file:///root/path/to/example.wasm\"\n```\n\n### `github`\n\nThe `github://` protocol can be used to target and download an asset from a specific GitHub release.\nThe location must be an organization + repository slug (owner/repo), and the release must have a\n`.wasm` asset available to download.\n\n```\n\"github://moonrepo/example-repo\"\n```\n\nIf you are targeting releases in a monorepo, you can append the project name after the repository.\nThe project name will be used as a prefix for tags, and will match `@v?` or\n`-v?` based tags.\n\n```\n\"github://moonrepo/example-repo/project-name\"\n```\n\nBy default, the latest release will be used and cached for 7 days. If you'd prefer to target a\nspecific release (preferred), append the release tag to the end of the location.\n\n```\n\"github://moonrepo/example-repo@v1.2.3\"\n```\n\nThis strategy is powered by the [GitHub API](https://api.github.com/) and is subject to rate\nlimiting. If running in a CI environment, we suggesting setting a `GITHUB_TOKEN` environment\nvariable to authorize API requests with. If using GitHub Actions, it's as simple as:\n\n```\n# In some job or step...env:  GITHUB_TOKEN: '${{ secrets.GITHUB_TOKEN }}'\n```\n\n### `https`\n\nThe `https://` protocol is your standard URL, and must point to an absolute file path. Files will be\ndownloaded to `~/.moon/plugins` or `~/.proto/plugins`. Non-secure URLs are not supported!\n\n```\n\"https://domain.com/path/to/plugins/example.wasm\"\n```\n\n## Creating a plugin\n\ninfo\n\nAlthough plugins can be written in any language that compiles to WASM, we've only tested Rust. The\nrest of this article assume you're using Rust and Cargo! Refer to [Extism](https://extism.org/)'s\ndocumentation for other examples.\n\nTo start, create a new crate with Cargo:\n\n```\ncargo new plugin --libcd plugin\n```\n\nSet the lib type to `cdylib`, and provide other required settings.\n\nCargo.toml\n\n```\n[package]name = \"example_plugin\"version = \"0.0.1\"edition = \"2024\"publish = false[lib]crate-type = ['cdylib'][profile.release]codegen-units = 1debug = falselto = trueopt-level = \"s\"panic = \"abort\"\n```\n\nOur Rust plugins are powered by [Extism](https://extism.org/), so lets add their PDK and ours as a\ndependency.\n\n```\ncargo add extism-pdk# For protocargo add proto_pdk# For mooncargo add moon_pdk\n```\n\nIn all Rust files, we can import all the PDKs with the following:\n\nsrc/lib.rs\n\n```\nuse extism_pdk::*;\n```\n\nWe can then build the WASM binary. The file will be available at\n`target/wasm32-wasip1/debug/.wasm`.\n\n```\ncargo build --target wasm32-wasip1\n```\n\n## Building and publishing\n\nAt this point, you should have a fully working WASM plugin, but to make it available to the\ncommunity, you'll still need to build and make the `.wasm` file available. The easiest solution is\nto publish a GitHub release and include the `.wasm` file as an asset.\n\n### Building, optimizing, and stripping\n\nWASM files are pretty fat, even when compiling in release mode. To reduce the size of these files,\nwe can use `wasm-opt` and `wasm-strip`, both of which are provided by the\n[WebAssembly](https://github.com/WebAssembly) group. The following script is what we use to build\nour own plugins.\n\ninfo\n\nThis functionality is natively supported in our\n[moonrepo/build-wasm-plugin](https://github.com/moonrepo/build-wasm-plugin) GitHub Action!\n\nbuild-wasm\n\n```\n#!/usr/bin/env bashtarget=\"${CARGO_TARGET_DIR:-target}\"input=\"$target/wasm32-wasip1/release/$1.wasm\"output=\"$target/wasm32-wasip1/$1.wasm\"echo \"Building\"cargo build --target wasm32-wasip1 --releaseecho \"Optimizing\"# https://github.com/WebAssembly/binaryen~/binaryen/bin/wasm-opt -Os \"$input\" --output \"$output\"echo \"Stripping\"# https://github.com/WebAssembly/wabt~/wabt/bin/wasm-strip \"$output\"\n```\n\n### Manually create releases\n\nWhen your plugin is ready to be published, you can create a release on GitHub using the following\nsteps.\n\n- Tag the release and push to GitHub.\n\n```\ngit tag v0.0.1git push --tags\n```\n\n- Build a release version of the plugin using the `build-wasm` script above. The file will be available at `target/wasm32-wasip1/.wasm`.\n\n```\nbuild-wasm\n```\n\n- In GitHub, navigate to the tags page, find the new tag, create a new release, and attach the built file as an asset.\n\n### Automate releases\n\nIf you're using GitHub Actions, you can automate the release process with our official\n[moonrepo/build-wasm-plugin](https://github.com/moonrepo/build-wasm-plugin) action.\n\n- Create a new workflow file at `.github/workflows/release.yml`. Refer to the link above for a working example.\n\n- Tag the release and push to GitHub.\n\n```\n# In a polyrepogit tag v0.0.1# In a monorepogit tag example_plugin-v0.0.1# Push the tagsgit push --tags\n```\n\n- The action will automatically build the plugin, create a release, and attach the built file as an asset.\n\n## /docs/guides/webhooks\n\nSource: https://moonrepo.dev/docs/guides/webhooks\n\n# Webhooks (experimental)\n\nLooking to gather metrics for your pipelines? Gain insight into run durations and failures? Maybe\nyou want to send Slack or Discord notifications? With our webhooks, all of these are possible!\n\nWhen the [`notifier.webhookUrl`](/docs/config/workspace#webhookurl) setting is configured with an HTTPS\nURL, and moon is running in a CI environment, moon will POST a payload to this endpoint for every\nevent in our pipeline.\n\n## Payload structure\n\nEvery webhook event is posted with the following request body, known as a payload.\n\n- `type` (`string`) - The type of [event](#events).\n\n- `environment` (`object | null`) - Information about the current CI/CD pipeline environment.\n\n- `event` (`object`) - The event specific payload. View each event for an example of their structure.\n\n- `createdAt` (`string`) - When the event was created, as a UTC timestamp in ISO 8601 (RFC 3339) format.\n\n- `uuid` (`string`) - A unique identifier for all webhooks in the current run batch.\n\n- `trace` (`string`) - A unique identifier for all webhooks in the overall run batch. Can be defined via `MOON_TRACE_ID` environment variable.\n\n```\n{  \"type\": \"...\",  \"environment\": \"...\",  \"event\": {    // ...  },  \"createdAt\": \"...\",  \"uuid\": \"...\",  \"trace\": \"...\"}\n```\n\nThe `uuid` field can be used to differentiate concurrently running pipelines!\n\n### Pipeline environment\n\nWhen webhooks are sent from a CI/CD pipeline, we attempt to include information about the\nenvironment under the `environment` field. If information could not be detected, this field is null,\notherwise it contains these fields.\n\n- `baseBranch` (`string | null`) - When a merge/pull request, the target (base) branch, otherwise null.\n\n- `branch` (`string`) - When a merge/pull request, the source (head) branch, otherwise the triggering branch.\n\n- `id` (`string`) - ID of the current pipeline instance.\n\n- `provider` (`string`) - Name of your CI/CD provider. GitHub Actions, GitLab, CircleCI, etc.\n\n- `requestId` (`string | null`) - The ID of the merge/pull request.\n\n- `requestUrl` (`string | null`) - Link to the merge/pull request.\n\n- `revision` (`string`) - The HEAD commit, revision, tag, ref, etc, that triggered the pipeline.\n\n- `url` (`string | null`) - Link to the current pipeline, when available.\n\n## Events\n\n### Pipeline\n\nRuns actions within moon using a robust dependency graph. Is triggered when using\n[`moon run`](/docs/commands/run).\n\n### `pipeline.started`\n\nTriggered when the pipeline has been created but before actions have started to run.\n\nThis event includes the number of actions registered within the pipeline, but does not provide\ndetailed information about the actions. Use the [`action.*`](#actionstarted) events for this.\n\n```\n{  \"type\": \"pipeline.started\",  \"createdAt\": \"...\",  \"environment\": \"...\",  \"event\": {    \"actionsCount\": 15  },  \"uuid\": \"...\"}\n```\n\n### `pipeline.finished`\n\nTriggered when the pipeline has finished running all actions, with aggregated counts based on final\nstatus.\n\nThis event is not triggered if the pipeline crashes (this does not include actions that have\nfailed, as those are legitimate runs). Use the [`pipeline.aborted`](#pipelineaborted) event if you\nwant to also catch crashes.\n\n```\n{  \"type\": \"pipeline.finished\",  \"createdAt\": \"...\",  \"environment\": \"...\",  \"event\": {    \"cachedCount\": 10,    \"baselineDuration\": {      \"secs\": 60,      \"nanos\": 3591693    },    \"duration\": {      \"secs\": 120,      \"nanos\": 3591693    },    \"estimatedSavings\": {      \"secs\": 60,      \"nanos\": 0    },    \"failedCount\": 1,    \"passedCount\": 4  },  \"uuid\": \"...\"}\n```\n\n### `pipeline.aborted`\n\nTriggered when the pipeline has crashed for unknown reasons, or had to abort as a result of a\ncritical action failing.\n\n```\n{  \"type\": \"pipeline.aborted\",  \"createdAt\": \"...\",  \"environment\": \"...\",  \"event\": {    \"error\": \"...\"  },  \"uuid\": \"...\"}\n```\n\n### Actions\n\nActions are \"jobs\" within the pipeline that are executed topologically.\n\n### `action.started`\n\nTriggered when an action within the pipeline has started to run.\n\n```\n{  \"type\": \"action.started\",  \"createdAt\": \"...\",  \"environment\": \"...\",  \"event\": {    \"action\": {      \"attempts\": null,      \"createdAt\": \"...\",      \"duration\": {        \"secs\": 0,        \"nanos\": 3591693      },      \"error\": null,      \"label\": \"InstallWorkspaceDeps(node:18.0.0)\",      \"nodeIndex\": 5,      \"status\": \"passed\"    },    \"node\": {      \"action\": \"InstallDeps\",      \"params\": [        {          \"toolchain\": \"Node\",          \"version\": \"18.0.0\"        }      ]    }  },  \"uuid\": \"...\"}\n```\n\n### `action.finished`\n\nTriggered when an action within the pipeline has finished running, either with a success or failure.\nIf the action failed, the `error` field will be set with the error message.\n\n```\n{  \"type\": \"action.finished\",  \"createdAt\": \"...\",  \"environment\": \"...\",  \"event\": {    \"action\": {      \"attempts\": null,      \"createdAt\": \"...\",      \"duration\": {        \"secs\": 0,        \"nanos\": 3591693      },      \"error\": null,      \"label\": \"InstallWorkspaceDeps(node:18.0.0)\",      \"nodeIndex\": 5,      \"status\": \"passed\"    },    \"error\": null,    \"node\": {      \"action\": \"InstallDeps\",      \"params\": {        \"toolchain\": \"Node\",        \"version\": \"18.0.0\"      }    }  },  \"uuid\": \"...\"}\n```\n\n### `dependencies.installing`\n\nTriggered when dependencies for a workspace or project have started to install. When targeting a\nproject, the `project` field will be set, otherwise `null` for the entire workspace.\n\n```\n{  \"type\": \"dependencies.installing\",  \"createdAt\": \"...\",  \"environment\": \"...\",  \"event\": {    \"project\": {      \"id\": \"server\"      // ...    },    \"runtime\": {      \"toolchain\": \"Node\",      \"version\": \"18.0.0\"    },    \"root\": \".\",    \"toolchain\": \"node\"  },  \"uuid\": \"...\"}\n```\n\n### `dependencies.installed`\n\nTriggered when dependencies for a workspace or project have finished installing. When targeting a\nproject, the `project` field will be set, otherwise `null` for the entire workspace. If the install\nfailed, the `error` field will be set with the error message.\n\nFor more information about the action, refer to the [`action.finished`](#actionfinished) event.\nInstalled deps can be scoped with the `InstallDeps(...)` labels.\n\n```\n{  \"type\": \"dependencies.installed\",  \"createdAt\": \"...\",  \"environment\": \"...\",  \"event\": {    \"error\": null,    \"project\": null,    \"runtime\": {      \"toolchain\": \"Node\",      \"version\": \"18.0.0\"    },    \"root\": \".\",    \"toolchain\": \"node\"  },  \"uuid\": \"...\"}\n```\n\n### `environment.initializing`v1.37.0\n\nTriggered when an environment is being setup for a toolchain. When targeting a project, the\n`project` field will be set, otherwise `null` for the entire workspace.\n\n```\n{  \"type\": \"environment.initializing\",  \"createdAt\": \"...\",  \"environment\": \"...\",  \"event\": {    \"project\": {      \"id\": \"server\"      // ...    },    \"root\": \".\",    \"toolchain\": \"node\"  },  \"uuid\": \"...\"}\n```\n\n### `environment.initialized`v1.37.0\n\nTriggered when an environment has been setup for a toolchain. When targeting a project, the\n`project` field will be set, otherwise `null` for the entire workspace. If setup failed, the `error`\nfield will be set with the error message.\n\nFor more information about the action, refer to the [`action.finished`](#actionfinished) event.\nInstalled deps can be scoped with the `SetupEnvironment(...)` labels.\n\n```\n{  \"type\": \"environment.initialized\",  \"createdAt\": \"...\",  \"environment\": \"...\",  \"event\": {    \"error\": null,    \"project\": null,    \"root\": \".\",    \"toolchain\": \"node\"  },  \"uuid\": \"...\"}\n```\n\n### `project.syncing`\n\nTriggered when an affected project has started syncing its workspace state. This occurs\nautomatically before a project's task is ran.\n\n```\n{  \"type\": \"project.syncing\",  \"createdAt\": \"...\",  \"environment\": \"...\",  \"event\": {    \"project\": {      \"id\": \"client\"      // ...    },    \"runtime\": {      \"toolchain\": \"Node\",      \"version\": \"18.0.0\"    }  },  \"uuid\": \"...\"}\n```\n\n### `project.synced`\n\nTriggered when an affected project has finished syncing. If the sync failed, the `error` field will\nbe set with the error message.\n\nFor more information about the action, refer to the [`action.finished`](#actionfinished) event.\nSynced projects can be scoped with the `SyncProject(...)` labels.\n\n```\n{  \"type\": \"project.synced\",  \"createdAt\": \"...\",  \"environment\": \"...\",  \"event\": {    \"error\": null,    \"project\": {      \"id\": \"client\"      // ...    },    \"runtime\": {      \"toolchain\": \"Node\",      \"version\": \"18.0.0\"    }  },  \"uuid\": \"...\"}\n```\n\n### `tool.installing`\n\nTriggered when a tool within the toolchain has started downloading and installing.\n\nThis event is always triggered, regardless of whether the tool has already been installed or not.\nFor an accurate state, use the [`action.finished`](#actionfinished) event. If the `status` is\n\"skipped\", then the tool was already installed.\n\n```\n{  \"type\": \"tool.installing\",  \"createdAt\": \"...\",  \"environment\": \"...\",  \"event\": {    \"runtime\": {      \"toolchain\": \"Node\",      \"version\": \"18.0.0\"    }  },  \"uuid\": \"...\"}\n```\n\n### `tool.installed`\n\nTriggered when a tool within the toolchain has finished installing. If the install failed, the\n`error` field will be set with the error message.\n\nFor more information about the action, refer to the [`action.finished`](#actionfinished) event.\nTools can be scoped with the `SetupToolchain(...)` labels.\n\n```\n{  \"type\": \"tool.installed\",  \"createdAt\": \"...\",  \"environment\": \"...\",  \"event\": {    \"error\": null,    \"runtime\": {      \"toolchain\": \"Node\",      \"version\": \"18.0.0\"    }  },  \"uuid\": \"...\"}\n```\n\n### `toolchain.installing`\n\nTriggered when a toolchain plugin has started downloading and installing.\n\nThis event is always triggered, regardless of whether the tool has already been installed or not.\nFor an accurate state, use the [`action.finished`](#actionfinished) event. If the `status` is\n\"skipped\", then the tool was already installed.\n\n```\n{  \"type\": \"toolchain.installing\",  \"createdAt\": \"...\",  \"environment\": \"...\",  \"event\": {    \"spec\": {      \"id\": \"node\",      \"req\": \"18.0.0\"    }  },  \"uuid\": \"...\"}\n```\n\n### `toolchain.installed`\n\nTriggered when a toolchain plugin has finished installing. If the install failed, the `error` field\nwill be set with the error message.\n\nFor more information about the action, refer to the [`action.finished`](#actionfinished) event.\nTools can be scoped with the `SetupToolchain(...)` labels.\n\n```\n{  \"type\": \"toolchain.installed\",  \"createdAt\": \"...\",  \"environment\": \"...\",  \"event\": {    \"error\": null,    \"spec\": {      \"id\": \"node\",      \"req\": \"18.0.0\"    }  },  \"uuid\": \"...\"}\n```\n\n### `task.running`\n\nTriggered when a [task](/docs/concepts/task) has started to run (via [`moon run`](/docs/commands/run) or\nsimilar command).\n\n```\n{  \"type\": \"task.running\",  \"createdAt\": \"...\",  \"environment\": \"...\",  \"event\": {    \"target\": \"app:build\"  },  \"uuid\": \"...\"}\n```\n\n### `task.ran`\n\nTriggered when a [task](/docs/concepts/task) has finished running. If the run failed, the `error` field\nwill be set with the error message.\n\nFor more information about the action, refer to the [`action.finished`](#actionfinished) event. Ran\ntasks can be scoped with the `RunTask(...)`, `RunInteractiveTask(...)`, and `RunPersistentTask(...)`\nlabels.\n\n```\n{  \"type\": \"task.ran\",  \"createdAt\": \"...\",  \"environment\": \"...\",  \"event\": {    \"error\": null,    \"target\": \"app:build\"  },  \"uuid\": \"...\"}\n```\n\n### `workspace.syncing`\n\nTriggered when the workspace is being synced.\n\n```\n{  \"type\": \"workspace.syncing\",  \"createdAt\": \"...\",  \"environment\": \"...\",  \"event\": {    \"target\": \"app:build\"  },  \"uuid\": \"...\"}\n```\n\n### `workspace.synced`\n\nTriggered when the workspace has finished syncing. If the action failed, the `error` field will be\nset with the error message.\n\n```\n{  \"type\": \"workspace.synced\",  \"createdAt\": \"...\",  \"environment\": \"...\",  \"event\": {    \"error\": null  },  \"uuid\": \"...\"}\n```\n\n## /docs/how-it-works\n\nSource: https://moonrepo.dev/docs/how-it-works\n\n- [Home](/)\n- [How it works](/docs/how-it-works)\n\nwarning\n\nDocumentation is currently for [moon v2](/blog/moon-v2-alpha) and latest proto. Documentation for moon v1 has been frozen and can be [found here](https://moonrepo.github.io/website-v1/).\n\n# How it works\n\n[üìÑÔ∏è LanguagesAlthough moon is currently focusing on the JavaScript ecosystem, our long-term vision is to be a](/docs/how-it-works/languages)\n\n[üìÑÔ∏è Project graphThe project graph is a representation of all configured](/docs/how-it-works/project-graph)\n\n[üìÑÔ∏è Task graphThe task graph is a representation of all configured](/docs/how-it-works/task-graph)\n\n[üìÑÔ∏è Action graphWhen you run a task on the command line, we generate an action graph to](/docs/how-it-works/action-graph)\n\n[Install moon](/docs/install)\n\n[Languages](/docs/how-it-works/languages)\n\n## /docs/how-it-works/action-graph\n\nSource: https://moonrepo.dev/docs/how-it-works/action-graph\n\n# Action graph\n\nWhen you run a [task](/docs/config/project#tasks-1) on the command line, we generate an action graph to\nensure [dependencies](/docs/config/project#deps) of tasks have ran before running run the primary task.\n\nThe action graph is a representation of all [tasks](/docs/concepts/task), derived from the\n[project graph](/docs/how-it-works/project-graph) and [task graph](/docs/how-it-works/task-graph), and is also represented internally\nas a directed acyclic graph (DAG).\n\n## Actions\n\nUnlike other task runners in the industry that represent each node in the graph as a task to run, we\nrepresent each node in the graph as an action to perform. This allows us to be more flexible and\nefficient with how we run tasks, and allows us to provide more functionality and automation than\nother runners.\n\nThe following actions compose our action graph:\n\n### Sync workspace\n\nThis is a common action that always runs and give's moon a chance to perform operations and health\nchecks across the entire workspace.\n\ninfo\n\nThis action can be skipped by disabling the\n[`pipeline.syncWorkspace`](/docs/config/workspace#syncworkspace) setting.\n\n### Setup toolchain\n\nThe most important action in the graph is the setup toolchain action, which downloads and installs a\ntier 3 language into the toolchain. For other tiers, this is basically a no-operation.\n\n- When the tool has already been installed, this action will be skipped.\n\n- Actions will be scoped by language and version, also known as a runtime. For example, `SetupToolchain(node:18.1.0)` or `SetupToolchain(deno:1.31.0)`.\n\n- Tools that require a global binary (found on `PATH`) will display the version as \"global\". For example, `SetupToolchain(node:global)`.\n\ninfo\n\nThis action can be skipped by setting the `MOON_SKIP_SETUP_TOOLCHAIN=true` environment variable. The\nskip can be scoped per tool by setting the value to the tool name (`node`), and also by version\n(`node:20.0.0`). Supports a comma-separated list.\n\n### Setup environmentv1.35.0\n\nThis action runs after the toolchain has been setup, but before dependencies are installed, so that\nthe development environment can be setup and configured. This includes operations such as modifying\na manifest (`package.json`, etc), updating configuration files, initializing venv's (Python), so on\nand so forth.\n\n### Setup protov1.39.0\n\nThis action runs before all toolchain related actions and ensures that [proto](/proto) has been\ninstalled and is available for use. This is required for toolchains that will be downloaded and\ninstalled.\n\n### Install dependencies\n\nBefore we run a task, we ensure that all language dependencies (`node_modules` for example) have\nbeen installed, by automatically installing them if we detect changes since the last run. We achieve\nthis by comparing lockfile modified timestamps, parsing manifest files, and hashing resolved\ndependency versions.\n\n- When dependencies do not need to be installed, this action will be skipped.\n\n- Depending on the language and configuration, we may install dependencies in a project (`InstallProjectDeps`), or in the workspace root for all projects (`InstallWorkspaceDeps`).\n\n- Actions will be scoped by language and version, also known as a runtime. For example, `InstallWorkspaceDeps(node:18.1.0)` or `InstallProjectDeps(node:18.1.0, example)`.\n\ninfo\n\nThis action can be skipped by disabling the\n[`pipeline.installDependencies`](/docs/config/workspace#installdependencies) setting.\n\n### Sync project\n\nTo ensure a consistently healthy project and repository, we run a process known as syncing\neverytime a task is ran. This action will run sync operations for all toolchains associated with\nthe project.\n\ninfo\n\nThis action can be skipped by disabling the\n[`pipeline.syncProject`](/docs/config/workspace#syncproject) setting.\n\n### Run task\n\nThe primary action in the graph is the run [task](/docs/concepts/task) action, which runs a project's\ntask as a child process, derived from a [target](/docs/concepts/target). Tasks can depend on other\ntasks, and they'll be effectively orchestrated and executed by running in topological order using a\nthread pool.\n\n### Run interactive task\n\nLike the base run task, but runs the [task interactively](/docs/concepts/task#interactive) with stdin\ncapabilities. All interactive tasks are run in isolation in the graph.\n\n### Run persistent task\n\nLike the base run task, but runs the [task in a persistent process](/docs/concepts/task#persistent)\nthat never exits. All persistent tasks are run in parallel as the last batch in the graph.\n\n## What is the graph used for?\n\nWithout the action graph, tasks would not efficiently run, or possibly at all! The graph helps to\nrun tasks in parallel, in the correct order, and to ensure a reliable outcome.\n\n## /docs/how-it-works/languages\n\nSource: https://moonrepo.dev/docs/how-it-works/languages\n\n# Languages\n\nAlthough moon is currently focusing on the JavaScript ecosystem, our long-term vision is to be a\nmulti-language task runner and monorepo management tool. To that end, we've designed our languages\nto work like plugins, where their functionality is implemented in isolation, and is opt-in.\n\ninfo\n\nWe do not support third-party language plugins at this time, but are working towards it!\n\n## Enabling a language\n\nmoon [supported languages](/docs/#supported-languages) are opt-in, and are not enabled by default. We\nchose this pattern to avoid unnecessary overhead, especially for the future when we have 10 or more\nbuilt-in languages.\n\nTo enable a supported language, simply define a configuration block with the language's name in\n[`.moon/toolchains.yml`](/docs/config/toolchain). Even an empty block will enable the language.\n\n.moon/toolchains.yml\n\n```\n# Enable Node.jsnode: {}# Enable Node.js with custom settingsnode:  packageManager: 'pnpm'# Enable Denodeno: {}\n```\n\nFor unsupported languages, use the system toolchain. Continue reading to learn more!\n\n## System language and toolchain\n\nWhen working with moon, you'll most likely have tasks that run built-in system commands that do not\nbelong to any of the supported languages. For example, you may have a task that runs `git` or\n`docker` commands, or common commands like `rm`, `cp`, `mv`, etc.\n\nFor these cases, moon provides a special language/toolchain called `system`, that is always enabled.\nThis toolchain is a catch-all, an escape-hatch, a fallback, and provides the following:\n\n- Runs a system command or a binary found on `PATH`.\n\n- Wraps the execution in a shell.\n\nTo run system commands, set a task's [`toolchain`](/docs/config/project#toolchain) setting to \"system\".\n\nmoon.yml\n\n```\ntasks:  example:    command: 'git status'    toolchain: 'system'\n```\n\n## Tier structure and responsibilities\n\nAs mentioned in our introduction,\n[language support is divided up into tiers](/docs/#supported-languages), where each tier introduces\nmore internal integrations and automations, but requires more work to properly implement.\n\nInternally each tier maps to a Rust crate, as demonstrated by the graph at the top of the article.\n\n### Tier 0 = Unsupported\n\nThe zero tier represents all languages not directly supported by moon. This tier merely exists as\na mechanism for running non-supported language binaries via the\n[system toolchain](#system-language-and-toolchain).\n\nmoon.yml\n\n```\ntasks:  example:    command: 'ruby'    toolchain: 'system'\n```\n\n### Tier 1 = Language\n\nThe first tier is the language itself. This is the most basic level of support, and is the only tier\nthat is required to be implemented for a language to be considered minimally supported. This tier is\nin charge of:\n\n- Declaring metadata about the language. For example, the name of the binary, supported file extensions, available dependency/package/version managers, names of config/manifest/lock files, etc.\n\n- Helpers for parsing lockfiles and manifest files, and interacting with the language's ecosystem (for example, Node.js module resolution).\n\n- Mechanisms for detecting the language of a project based on config files and other criteria.\n\n- Maps to a project's [`language`](/docs/config/project#language) setting.\n\nmoon.yml\n\n```\nlanguage: 'javascript'\n```\n\n### Tier 2 = Platform\n\nThe second tier requires the language functionality from tier 1, and eventually the toolchain\nfunctionality from tier 3, and provides interoperability with moon's internals. This is the most\ncomplex of all tiers, and the tier is in charge of:\n\n- Determining when, where, and how to install dependencies for a project or the workspace.\n\n- Loading project aliases and inferring implicit relationships between projects.\n\n- Syncing a project and ensuring a healthy project state.\n\n- Hashing efficiently for dependency installs and target runs.\n\n- Prepending `PATH` with appropriate lookups to execute a task.\n\n- Running a target's command with proper arguments, environment variables, and flags.\n\n- Maps to a project's [`toolchain.default`](/docs/config/project#toolchain-1) or task's [`toolchain`](/docs/config/project#toolchain) setting.\n\n- Supports a configuration block by name in [`.moon/toolchains.yml`](/docs/config/toolchain).\n\nmoon.yml\n\n```\ntasks:  example:    command: 'webpack'    toolchain: 'node'\n```\n\n.moon/toolchains.yml\n\n```\nnode: {}\n```\n\n### Tier 3 = Toolchain\n\nThe third tier is toolchain support via [proto](/proto). This is the final tier, as the toolchain is\nunusable unless the platform has been entirely integrated, and as such, the platform depends on this\ntier. This tier handles:\n\n- Downloading and installing a language into the toolchain.\n\n- Installing and deduping project dependencies.\n\n- Detecting appropriate versions of tools to use.\n\n- Determining which binary to use and execute targets with.\n\n- Supports a `version` field in the named configuration block in [`.moon/toolchains.yml`](/docs/config/toolchain).\n\n.moon/toolchains.yml\n\n```\nnode:  version: '18.0.0'\n```\n\n## /docs/how-it-works/project-graph\n\nSource: https://moonrepo.dev/docs/how-it-works/project-graph\n\n# Project graph\n\nThe project graph is a representation of all configured\n[projects in the workspace](/docs/config/workspace#projects) and their relationships between each\nother, and is represented internally as a directed acyclic graph (DAG). Below is a visual\nrepresentation of a project graph, composed of multiple applications and libraries, where both\nproject types depend on libraries.\n\ninfo\n\nThe [`moon project-graph`](/docs/commands/project-graph) command can be used to view the structure of\nyour workspace.\n\n## Relationships\n\nA relationship is between a dependent (downstream project) and a dependency/requirement (upstream\nproject). Relationships are derived from source code and configuration files within the repository,\nand fall into 1 of 2 categories:\n\n### Explicit\n\nThese are dependencies that are explicitly defined in a project's [`moon.yml`](/docs/config/project)\nconfig file, using the [`dependsOn`](/docs/config/project#dependson) setting.\n\nmoon.yml\n\n```\ndependsOn:  - 'components'  - id: 'utils'    scope: 'peer'\n```\n\n### Implicit\n\nThese are dependencies that are implicitly discovered by moon when scanning the repository. How an\nimplicit dependency is discovered is based on a\n[language's platform integration](/docs/how-it-works/languages#tier-2--platform), and how that language's ecosystem\nfunctions.\n\npackage.json\n\n```\n{  // ...  \"dependencies\": {    \"@company/components\": \"workspace:*\"  },  \"peerDependencies\": {    \"@company/utils\": \"workspace:*\"  }}\n```\n\ncaution\n\nIf a language is not officially supported by moon, then implicit dependencies will not be\nresolved. For unsupported languages, you must explicitly configure dependencies.\n\n### Scopes\n\nEvery relationship is categorized into a scope that describes the type of relationship between the\nparent and child. Scopes are currently used for [project syncing](/docs/commands/sync) and deep Docker\nintegration.\n\n- Production - Dependency is required in production, will not be pruned in production environments, and will sync as a production dependency.\n\n- Development - Dependency is required in development and production, will be pruned from production environments, and will sync as a development-only dependency.\n\n- Build - Dependency is required for building only, and will sync as a build dependency.\n\n- Peer - Dependency is a peer requirement, with language specific semantics. Will sync as a peer dependency when applicable.\n\n## What is the graph used for?\n\nGreat question, the project graph is used throughout the codebase to accomplish a variety of\nfunctions, but mainly:\n\n- Is fed into the [task graph](/docs/how-it-works/task-graph) to determine relationships of tasks between other tasks, and across projects.\n\n- Powers our [Docker](/docs/guides/docker) layer caching and scaffolding implementations.\n\n- Utilized for [project syncing](/docs/commands/sync) to ensure a healthy repository state.\n\n- Determines affected projects in [continuous integration](/docs/guides/ci) workflows.\n\n## /docs/how-it-works/task-graph\n\nSource: https://moonrepo.dev/docs/how-it-works/task-graph\n\n# Task graph\n\nThe task graph is a representation of all configured\n[tasks in the workspace](/docs/config/workspace#projects) and their relationships between each other,\nand is represented internally as a directed acyclic graph (DAG). This graph is derived from\ninformation in the [project graph](/docs/how-it-works/project-graph). Below is a visual representation of a task\ngraph.\n\ninfo\n\nThe [`moon task-graph`](/docs/commands/task-graph) command can be used to view the structure of your\nworkspace.\n\n## Relationships\n\nA relationship is between a dependent (downstream task) and a dependency/requirement (upstream\ntask). Relationships are derived explicitly with the task [`deps`](/docs/config/project#deps) setting,\nand fall into 1 of 2 categories:\n\n### Required\n\nThese are dependencies that are required to run and complete with a success, before the owning task\ncan run. If a required dependency fails, then the owning task will abort.\n\n### Optional\n\nThe opposite of [required](#required), these are dependencies that can either a) not exist during\ntask inheritance, or b) run and fail without aborting the owning task.\n\n## What is the graph used for?\n\nGreat question, the task graph is extremely important for running tasks (duh), and it also:\n\n- Is fed into the [action graph](/docs/how-it-works/action-graph) that can be executed in topological order.\n\n- Determines affected tasks in [continuous integration](/docs/guides/ci) workflows.\n\n## /docs/install\n\nSource: https://moonrepo.dev/docs/install\n\n# Install moon\n\n2 min\n\nThe following guide can be used to install moon and integrate it into an existing repository (with\nor without incremental adoption), or to a fresh repository.\n\n## Installing\n\nThe entirety of moon is packaged and shipped as a single binary. It works on all major operating\nsystems, and does not require any external dependencies. For convenience, we provide the following\nscripts to download and install moon.\n\n### proto\n\nmoon can be installed and managed in [proto's toolchain](/proto). This will install moon to\n`~/.proto/tools/moon` and make the binary available at `~/.proto/bin`.\n\n```\nproto install moon\n```\n\nFurthermore, the version of moon can be pinned on a per-project basis using the\n[`.prototools` config file](/docs/proto/config).\n\n.prototools\n\n```\nmoon = \"1.31.0\"\n```\n\ninfo\n\nWe suggest using proto to manage moon (and other tools), as it allows for multiple versions to be\ninstalled and used. The other installation options only allow for a single version (typically the\nlast installed).\n\n### Linux, macOS, WSL\n\nIn a terminal that supports Bash, run:\n\n```\nbash\ninfo\n\nIf you are using Git Bash on Windows, you can run the [Unix commands](#linux-macos-wsl) above.\n\n### npm\n\nmoon is also packaged and shipped as a single binary through the\n[`@moonrepo/cli`](https://www.npmjs.com/package/@moonrepo/cli) npm package. Begin by installing this\npackage at the root of the repository.\n\n- Yarn\n- Yarn (classic)\n- npm\n- pnpm\n- Bun\n\n```\nyarn add --dev @moonrepo/cli\n```\n\n```\nyarn add --dev @moonrepo/cli# If using workspacesyarn add --dev -W @moonrepo/cli\n```\n\n```\nnpm install --save-dev @moonrepo/cli\n```\n\n```\npnpm add --save-dev @moonrepo/cli# If using workspacespnpm add --save-dev -w @moonrepo/cli\n```\n\n```\nbun install --dev @moonrepo/cli\n```\n\nIf you are installing with Bun, you'll need to add `@moonrepo/cli` as a\n[trusted dependency](https://bun.sh/docs/install/lifecycle#trusteddependencies).\n\ninfo\n\nWhen a global `moon` binary is executed, and the `@moonrepo/cli` binary exists within the\nrepository, the npm package version will be executed instead. We do this because the npm package\ndenotes the exact version the repository is pinned it.\n\n### Other\n\nmoon can also be downloaded and installed manually, by downloading an asset from\n[https://github.com/moonrepo/moon/releases](https://github.com/moonrepo/moon/releases). Be sure to\nrename the file after downloading, and apply the executable bit (`chmod +x`) on macOS and Linux.\n\n## Upgrading\n\nIf using proto, moon can be upgraded using the following command:\n\n```\nproto install moon --pin\n```\n\nOtherwise, moon can be upgraded with the [`moon upgrade`](/docs/commands/upgrade) command. However, this\nwill only upgrade moon if it was installed in `~/.moon/bin`.\n\n```\nmoon upgrade\n```\n\nOtherwise, you can re-run the installers above and it will download, install, and overwrite with the\nlatest version.\n\n## Canary releases\n\nmoon supports canary releases, which are built and published for every commit to our development\nbranches. These releases will include features and functionality that have not yet landed on master.\nWhen using a canary release, you'll need to download and execute the binaries manually:\n\n- Using our npm package [`@moonrepo/cli`](https://www.npmjs.com/package/@moonrepo/cli?activeTab=versions) under the `canary` tag. Releases are versioned by date.\n\n- From a [GitHub prerelease](https://github.com/moonrepo/moon/releases/tag/canary) using the `canary` tag. This tag always represents the latest development release.\n\n## Nightly releases\n\nmoon supports nightly releases, which are built and published once a day from the latest commit on\nmaster. When using a nightly release, you'll need to download and execute the binaries manually.\n\n- Using our npm package [`@moonrepo/cli`](https://www.npmjs.com/package/@moonrepo/cli?activeTab=versions) under the `nightly` tag. Releases are versioned by date.\n\n- From a [GitHub prerelease](https://github.com/moonrepo/moon/releases/tag/nightly) using the `nightly` tag. This tag always represents the latest stable release.\n\n## Next steps\n\n[Setup workspace](/docs/setup-workspace)\n\n## /docs/migrate-to-moon\n\nSource: https://moonrepo.dev/docs/migrate-to-moon\n\n# Migrate to moon\n\nNow that we've talked about the workspace, projects, tasks, and more, we must talk about something\nimportant... Should you embrace moon tasks? Or keep using language/ecosystem specific scripts? Or\nboth (incremental adoption)?\n\n## Migrate to moon tasks\n\nWe suggest using moon tasks (of course), as they provide far more granular control and configurable\noptions than scripts, and a `moon.yml` is a better\n[source of truth](/docs/faq#what-should-be-considered-the-source-of-truth). Scripts aren't powerful\nenough to scale for large codebases.\n\nAn example of what this may look like can be found below. This may look like a lot, but it pays\ndividends in the long run.\n\n/moon.yml\n\n```\nlanguage: 'javascript'fileGroups:  sources:    - 'src/**/*'  tests:    - 'tests/**/*'tasks:  build:    command: 'webpack build --output-path @out(0)'    inputs:      - '@globs(sources)'      - 'webpack.config.js'    outputs:      - 'build'  dev:    command: 'webpack server'    inputs:      - '@globs(sources)'      - 'webpack.config.js'    preset: 'server'  format:    command: 'prettier --check .'    inputs:      - '@globs(sources)'      - '@globs(tests)'      - '/prettier.config.js'  lint:    command: 'eslint .'    inputs:      - '@globs(sources)'      - '@globs(tests)'      - '.eslintignore'      - '.eslintrc.js'      - '/.eslintrc.js'  test:    command: 'jest .'    inputs:      - '@globs(sources)'      - '@globs(tests)'      - 'jest.config.js'  typecheck:    command: 'tsc --build'    inputs:      - '@globs(sources)'      - '@globs(tests)'      - 'tsconfig.json'      - '/tsconfig.json'\n```\n\n## Continue using scripts\n\nAs a frontend developer you're already familiar with the Node.js ecosystem, specifically around\ndefining and using `package.json` scripts, and you may not want to deviate from this. Don't worry,\nsimply enable the [`node.inferTasksFromScripts`](/docs/config/toolchain#infertasksfromscripts) setting\nto automatically create moon tasks from a project's scripts! These can then be ran with\n[`moon run`](/docs/commands/run).\n\nThis implementation is a simple abstraction that runs `npm run ` (or pnpm/yarn) in the\nproject directory as a child process. While this works, relying on `package.json` scripts incurs the\nfollowing risks and disadvantages:\n\n- [Inputs](/docs/config/project#inputs) default to `**/*`: A change to every project relative file will mark the task as affected, even those not necessary for the task. Granular input control is lost.\n\n- A change to workspace relative files will not mark the task as affected. For example, a change to `/prettier.config.js` would not be detected for a `npm run format` script.\n\n- [Outputs](/docs/config/project#outputs) default to an empty list unless: moon will attempt to extract outputs from arguments, by looking for variations of `--out`, `--outFile`, `--dist-dir`, etc.\n\n- If no output could be determined, builds will not be cached and hydrated.\n\n- Tasks will always [run in CI](/docs/config/project#runinci) unless: moon will attempt to determine invalid CI tasks by looking for popular command usage, for example: `webpack serve`, `next dev`, `--watch` usage, and more. This is not an exhaustive check.\n\n- The script name contains variations of `dev`, `start`, or `serve`.\n\n## Next steps\n\nBy this point, you should have a better understanding behind moon's fundamentals! Why not adopt\nincrementally next? Jump into [guides](/docs/guides/ci) for advanced use cases or [concepts](/docs/concepts)\nfor a deeper understanding.\n\n[Community help & support](https://discord.gg/qCh9MEynv2)[Releases & updates](https://twitter.com/tothemoonrepo)\n\n## /docs/migrate/2.0\n\nSource: https://moonrepo.dev/docs/migrate/2.0\n\n# Migrate to moon v2.0\n\nTo ease the migration process from moon v1 to v2, we've compiled a list of all breaking changes and\nimportant changes that you should be aware of. Please read through these carefully before upgrading\nyour workspace.\n\nTo automate some of the migration process, we've created the `moon migrate v2` command that will\nmigrate all applicable settings in configuration files.\n\n```\n$ moon migrate v2\n```\n\n## CLI\n\n- Removed `x86_64-apple-darwin` (Apple Intel) as a supported operating system. Only `aarch64-apple-darwin` (Apple Silicon) is now supported.\n\n### Commands\n\n- We've done a large polish pass for all commands, based on the [CLI guidelines](https://clig.dev).\n\n- Updated the `moonx` binary to use `moon exec` instead of `moon run` under the hood.\n\n- Renamed all options and flags to kebab-case instead of camelCase. Example: `--logLevel` -> `--log-level`\n\n- Renamed options for all commands: `--platform` -> `--toolchain`\n\n- Removed commands: `moon node`\n\n- `moon migrate from-package-json` (use the `migrate-turborepo` extension instead)\n\n- `moon query hash` (use `moon hash` instead)\n\n- `moon query hash-diff` (use `moon hash` instead)\n\n#### `moon action-graph`\n\n- Changed the output of `--json` to a new JSON structure (now matches the project and task graphs).\n\n#### `moon check`\n\n- Now runs `moon exec` under the hood, with some arguments/options pre-filled.\n\n- If the project ID is not specifed, it will no longer find the closest project. Instead you must pass `--closest`.\n\n- Renamed options: `--update-cache, -u` -> `--force, -f`\n\n#### `moon ci`\n\n- Now runs `moon exec` under the hood, with some arguments/options pre-filled.\n\n- Renamed options: `--update-cache, -u` -> `--force, -f`\n\n#### `moon generate`\n\n- Changed the destination from a positional argument, to the `--to` option. Example: `moon generate ./dist` -> `moon generate --to ./dist`\n\n#### `moon init`\n\n- Removed \"scaffolding a toolchain\" functionality from the command. Use the `moon toolchain add` command instead.\n\n- Removed options: `--to` (use a positional argument instead)\n\n#### `moon mcp`\n\n- Updated protocol version to 2025-11-25.\n\n- Updated the `get_projects` tool to no longer have an `includeTasks` option.\n\n- Updated the `get_projects` tool to return a list of project fragments, instead of the whole project object. This was required as the response was too large for MCP.\n\n- Updated the `get_tasks` tool to return a list of task fragments, instead of the whole task object. This was required as the response was too large for MCP.\n\n#### `moon query projects`\n\n- Removed options: `--dependents`\n\n#### `moon run`\n\n- Now runs `moon exec` under the hood, with some arguments/options pre-filled.\n\n- Updated options: `--dependents` now requires a value, either `deep` or `direct`\n\n- Renamed options: `--update-cache, -u` -> `--force, -f`\n\n- Removed options: `--no-bail` (use `moon exec` instead)\n\n- `--profile`\n\n- `--remote` (use `--affected remote` instead)\n\n#### `moon templates`\n\n- Changed the output to render a table instead of a list.\n\n#### `moon run`\n\n- Running a target without a scope no longer locates the closest project and instead uses the new default project feature. To run a target in the closets project, use `~:` scope instead. Example: `moon run build` -> `moon run ~:build`\n\n## Workspace\n\n### Configuration: `.moon/workspace.*`\n\n- Renamed setting values: `codeowners.orderBy` value `project-name` -> `project-id`\n\n- Renamed settings: `codeowners.syncOnRun` -> `codeowners.sync`\n\n- `constraints.enforceProjectTypeRelationships` -> `constraints.enforceLayerRelationships`\n\n- `docker.prune.installToolchainDeps` -> `docker.prune.installToolchainDependencies`\n\n- `docker.scaffold.include` -> `docker.scaffold.configsPhaseGlobs`\n\n- `runner` -> `pipeline`\n\n- `unstable_remote` -> `remote`\n\n- `vcs.manager` -> `vcs.client`\n\n- `vcs.syncHooks` -> `vcs.sync`\n\n- Removed settings: `docker.scaffold.copyToolchainFiles`\n\n- `experiments.*`\n\n- `hasher.batchSize`\n\n- `pipeline.archivableTargets`\n\n## Toolchains\n\n### Configuration: `.moon/toolchain.*`\n\n- This file was renamed to `.moon/toolchains.*` (plural) to reflect that multiple toolchains are configured. This also aligns with the new `.moon/extensions.*` file.\n\n- All toolchains have been stabilized, so the `unstable_` prefix must be removed from identifiers.\n\n#### JavaScript\n\nThe `bun`, `deno`, and `node` toolchains now require the `javascript` toolchain to be defined as\nwell. All shared settings have been moved to the `javascript` toolchain.\n\nIn addition, all `node` package managers are no longer nested under the `node` toolchain, but are\nnow top-level settings. These are only required when the `javascript.packageManager` setting is\ndefined.\n\n- Moved settings: `bun.dependencyVersionFormat` -> `javascript.dependencyVersionFormat`\n\n- `bun.inferTasksFromScripts` -> `javascript.inferTasksFromScripts`\n\n- `bun.rootPackageOnly` -> `javascript.rootPackageDependenciesOnly`\n\n- `bun.syncProjectWorkspaceDependencies` -> `javascript.syncProjectWorkspaceDependencies`\n\n- `node.dependencyVersionFormat` -> `javascript.dependencyVersionFormat`\n\n- `node.dedupeOnLockfileChange` -> `javascript.dedupeOnLockfileChange`\n\n- `node.inferTasksFromScripts` -> `javascript.inferTasksFromScripts`\n\n- `node.packageManager` -> `javascript.packageManager`\n\n- `node.rootPackageOnly` -> `javascript.rootPackageDependenciesOnly`\n\n- `node.syncPackageManagerField` -> `javascript.syncPackageManagerField`\n\n- `node.syncProjectWorkspaceDependencies` -> `javascript.syncProjectWorkspaceDependencies`\n\n- `node.bun` -> `bun`\n\n- `node.npm` -> `npm`\n\n- `node.pnpm` -> `pnpm`\n\n- `node.yarn` -> `yarn`\n\n- Renamed settings: `node.binExecArgs` -> `node.executeArgs`\n\n- Removed settings: `bun.packagesRoot`\n\n- `deno.depsFile`\n\n- `deno.lockfile`\n\n- `node.addEnginesConstraint`\n\n- `node.packagesRoot`\n\n.moon/toolchains.yml\n\n```\n# Beforenode:  version: '22.14.0'  packageManager: 'yarn'  inferTasksFromScripts: false  syncPackageManagerField: true  syncProjectWorkspaceDependencies: true  yarn:    version: '4.8.0'# Afterjavascript:  packageManager: 'yarn'  inferTasksFromScripts: false  syncPackageManagerField: true  syncProjectWorkspaceDependencies: truenode:  version: '22.14.0'yarn:  version: '4.8.0'\n```\n\n## Extensions\n\n### Configuration: `.moon/extensions.*`\n\n- The `extensions` setting from `.moon/workspace.*` has been moved (and flattened) to its own file, `.moon/extensions.*`.\n\n- The built-in extensions `download`, `migrate-nx`, and `migrate-turborepo` must now be enabled in the configuration file before they can be used. Simply set an empty object. This change was made to reduce the number of extensions that are loaded by default, improving performance.\n\n.moon/extensions.yml\n\n```\ndownload: {}migrate-nx: {}\n```\n\n## Project\n\n### Configuration: `moon.*`\n\n- Renamed settings: `docker.scaffold.include` -> `docker.scaffold.sourcesPhaseGlobs`\n\n- `project.name` -> `project.title`\n\n- `type` -> `layer`\n\n- `toolchain` -> `toolchains`\n\n- `platform` -> `toolchains.default`\n\n- Removed settings: [`project.metadata`](#custom-metadata)\n\n- [`toolchain.*.disabled`](#toolchain-disabling)\n\n### Language detection\n\nThe primary `language` is now detected from toolchains, instead of being a hardcoded implementation.\nThe result may now differ, as the first toolchain in the list will be used. Additionally, languages\nthat don't have a toolchain yet, like PHP or Ruby, will not be detected and must be explicitly\nconfigured.\n\nmoon.yml\n\n```\n# Afterlanguage: 'ruby'\n```\n\n### Custom metadata\n\nThe `project.metadata` setting has been removed, but all custom metadata fields can now be defined\nat the root of the `project` setting.\n\nmoon.yml\n\n```\n# Beforeproject:  metadata:    customField: 'value'# Afterproject:  customField: 'value'\n```\n\n### Toolchain disabling\n\nThe `toolchain.*.disabled` setting was removed. Instead set the toolchain itself to null/false.\n\nmoon.yml\n\n```\n# Beforetoolchain:  typescript:    disabled: true# Aftertoolchains:  typescript: null\n```\n\n## Tasks\n\n### Configuration: `moon.*`, `.moon/tasks`\n\n- The file `.moon/tasks.yml` has been removed. If you want to support tasks that are inherited by all projects, then move this to `.moon/tasks/all.yml` and do not configure the new `inheritedBy` setting.\n\n- Renamed tokens: `$projectName` -> `$projectTitle`\n\n- `$projectType` -> `$projectLayer`\n\n- `$taskPlatform` -> `$taskToolchain`\n\n- Renamed settings: [`tasks.*.local`](#local-mode) -> `tasks.*.preset` using `server` value\n\n- `tasks.*.platform` -> `tasks.*.toolchains`\n\n- `tasks.*.options.affectedPassInputs` -> `tasks.*.options.affectedFiles.passInputsWhenNoMatch`\n\n- Removed setting values: `tasks.*.preset` value `watcher`\n\n- Changed settings: `tasks.deps.*.args` no longer supports a string. Use a list of strings instead.\n\n- `tasks.*.options.affectedFiles` now supports an object for more granular control.\n\n- Changed option defaults: `tasks.*.options.envFile` now defaults to a list of files, instead of a single file, when `true`. Refer to the blog post for more information.\n\n- `tasks.*.options.inferInputs` now defaults to `false` instead of `true`.\n\n- `tasks.*.options.shell` now defaults to `true` instead of `false`.\n\n- `tasks.*.options.unixShell` now defaults to `bash` instead of nothing.\n\n- `tasks.*.options.windowsShell` now defaults to `pwsh` instead of nothing.\n\n### Simple commands only\n\nWe've reworked `command` (and `args`) to only support simple commands. A simple command is an\nexecutable (binary, file, etc) followed by zero or many arguments.\n\nComplex commands that involve shell features like piping (`|`), redirection (`>`, `\n\nShell features like expansion, globbing, and substitution is still supported in `command`.\n\n### Local mode\n\nThe `local` task setting has been removed as the name was confusing. Users assumed it meant \"only\nrun locally\", but it actually meant \"this is a persistent server that should only run locally\".\nInstead, use the `preset` setting with a value of `server`.\n\nmoon.yml\n\n```\n# Beforetasks:  dev:    command: 'start-dev'    local: true# Beforetasks:  dev:    command: 'start-dev'    preset: 'server'\n```\n\nIf you want a task that is simply \"local only\" without other options changes, use `options.runInCI`\ndirectly.\n\nmoon.yml\n\n```\ntasks:  dev:    command: 'start-dev'    options:      runInCI: false\n```\n\n### Shells by default\n\nTasks now run in a shell by default, and will use Bash on Unix (`options.unixShell`), and pwsh on\nWindows (`options.windowsShell`). You can disable this behavior by setting `options.shell` to\n`false`.\n\nmoon.yml\n\n```\ntasks:  dev:    command: 'start-dev'    options:      shell: false\n```\n\n### Env var substitution behavior\n\nThe syntax and behavior for substituting (expanding/interpolation) environment variables has\nchanged, to better align with the standard of `.env` files. The biggest change is that flagless\ntokens (`$VAR`) and `?` flag tokens (`$VAR?`) swapped functionality. Refer to the following table:\n\nSyntax v1 v2\n\n`$VAR` Substitute with variable syntax (`$VAR`) if variable empty üí• Substitute with empty string if variable empty\n\n`$VAR!` Don't substitute and keep variable syntax (`$VAR`) üí• Removed syntax\n\n`$VAR?` Substitute with empty string if variable empty üí• Removed syntax\n\n`${VAR}` Substitute with variable syntax (`$VAR`) if variable empty üí• Substitute with empty string if variable empty\n\n`${VAR!}` Don't substitute and keep variable syntax (`$VAR`) ~\n\n`${VAR?}` Substitute with empty string if variable empty üí• Substitute with variable syntax (`$VAR`) if variable empty\n\n`${VAR:default}` Use default value if variable empty ~\n\n`${VAR:-default}`, `${VAR-default}` ‚õîÔ∏è Not supported Use default value if variable empty\n\n`${VAR:+alternate}`, `${VAR+alternate}` ‚õîÔ∏è Not supported Use alternate value if variable non-empty\n\nLegend:\n\n- `~` indicates the syntax/functionality is the same as v1\n\n- `üí•` indicates breaking change\n\n- `‚õîÔ∏è` indicates not supported\n\n### Env var precedence\n\nThe order of precedence for environment variables has slightly changed when running tasks, as it was\nconfusing to users. The new order of precedence is as follows, from lowest to highest tier, with the\nlatter overwriting the former:\n\n- Task `.env` files via `options.envFile`\n\n- Task env variables via `env` or `deps.*.env`\n\n- System variables via profile scripts (`.bashrc`, `.zshrc`, etc)\n\n- via command line: `KEY=value moon ...`\n\nIn regards to variable substitution, each tier can reference variables within the same tier, or the\nhigher tier(s), but not from lower tier(s). This is because variables are processed in reverse\norder. Refer to the following table:\n\nTier Can reference Evaluated during\n\nDotenv Dotenv, Task, System Before task execution\n\nTask Task, System After task creation\n\nSystem System CLI startup\n\nIf you don't want to inherit a system variable, you can override it in the task with a null value.\n\n```\ntasks:  dev:    env:      EXAMPLE: null\n```\n\n### Deferred `.env` files\n\nIn v1, when `options.envFile` was enabled, the `.env` file(s) were loaded at the time of task\ncreation, during the building of project/task graphs. This meant that if the `.env` file changed\nbetween the time of graph creation and task execution, the changes would not be reflected.\n\nIn v2 and later, `.env` files are loaded just before task execution, ensuring that any changes to\nthe file are picked up.\n\ncaution\n\nBecause of this change, task `env` variables will continue to override `.env` file variables, BUT\ncan no longer reference them for substitution. This is because the `.env` files are loaded later in\nthe process.\n\n### Other changes\n\n- When `options.affectedFiles` is enabled, the list of files will be joined with the OS path separator (`:` on Unix, `;` on Windows) instead of a comma (`,`) when passed as the `MOON_AFFECTED_FILES` environment variable.\n\n## Task inheritance\n\n### Deep merged instead of shallow merged\n\nIn v1, when inheriting tasks, all global configs (those in `.moon`) were shallow merged into a\nsingle config ignoring merge task options, and then merged with the local config (`moon.*`) using\nmerge task options. This was not intuitive, as users expected all configs to be merged in sequence.\nTo demonstrate this, take the following example configs, in order of inherited:\n\n```\n# .moon/tasks.ymltasks:  build:    command: 'build --cache'    options:      mutex: 'build'# .moon/tasks/tag-a.ymltasks:  build:    args: '--force'# .moon/tasks/tag-b.ymltasks:  build:    args: '--clean'\n```\n\nUsers would expect the final `build` task to be `build --cache --force --clean` with the mutex\noption set. However, since the `tasks` setting was shallow merged, only the last config (`tag-b`)\nwould be used, resulting in the task being `noop --clean` without the mutex. The `noop` pops up\nbecause the `command` setting was not configured in the last config.\n\nTo remedy this, and to improve task composition overall, global configs are no longer shallow merged\ninto a single config before merging with the local config. Instead, all configs are merged in\nsequence, while respecting the task merge options. This is the order of operations for the new\nsystem:\n\n- Load all global configs (`.moon`) into a list, in order, based on the `inheritedBy` setting.\n\n- Load the local config (`moon.*`).\n\n- Create an inheritance chain by resolving global configs first, then the local config last, while respecting `extend` and other composition settings.\n\n- Merge all task options in order, to create the final task options.\n\n- Merge all tasks in order, using the final task options to guide the merging behavior.\n\n### File groups are merged\n\nBecause of the new deep merging behavior, file groups defined in inherited configs are now merged\ntogether, instead of being replaced by the following config in the sequence. For example, given the\nconfigs:\n\n```\n# .moon/tasks/tag-a.ymlfileGroups:  sources:    - 'src/**'# .moon/tasks/tag-b.ymlfileGroups:  sources:    - 'docs/**'\n```\n\nIn v1, the final `sources` file group would only include `docs/**`, as the second config would\nreplace the first. In v2, the final `sources` file group includes both `src/**` and `docs/**`.\n\n## VCS\n\n### New hooks system\n\nWe've rewritten our Git hooks from the ground up to be based around the `core.hooksPath` setting.\nThe following changes have been made:\n\n- We no longer write hooks to the `.git/hooks` directory.\n\n- Instead, all hooks are written to `.moon/hooks` and Git is configured to use this directory.\n\n- Bash scripts no longer end in `.sh`.\n\ncaution\n\nWe currently don't have an easy way to clean the previous implementation of hooks. You may need to\nmanually remove the old scripts from `.git/hooks` and `.moon/hooks` if they are causing issues.\n\n## Other changes\n\n### Changed (touched) files\n\nWe renamed the terminology \"touched files\" to \"changed files\" throughout the codebase and\ndocumentation. This better aligns with common VCS terminology and reduces confusion. Because of\nthis, the following changes were made:\n\n- Renamed the `moon query touched-files` CLI command to `moon query changed-files`.\n\n- Renamed the `get_touched_files` MCP tool to `get_changed_files`.\n\n- Renamed the `touchedFiles` run report field to `changedFiles`.\n\n```\n# Before$ moon query touched-files# After$ moon query changed-files\n```\n\n### Docker\n\n- The scaffolded `.moon/docker/workspace` directory was renamed to `.moon/docker/configs`.\n\n- The `moon docker file` command will now loop through all toolchains and use the first image found, otherwise it defaults to \"scratch\". If you want to be explicit, set the `docker.file.image` setting.\n\n### Query language (MQL)\n\n- Renamed fields: `projectName` -> `projectId`\n\n- `projectType` -> `projectLayer`\n\n- `taskPlatform` -> `taskToolchain`\n\n```\n# BeforeprojectType=application && taskPlatform=node# AfterprojectLayer=application && taskToolchain=node\n```\n\n### Webhooks\n\n- Removed the `tool.*` events. Use `toolchain.*` events instead.\n\n- Removed the `runtime` field from `dependencies.*` events. Use the `toolchain` field instead.\n\n## /docs/proto\n\nSource: https://moonrepo.dev/docs/proto\n\n# What is proto?\n\n3 min\n\nproto is a pluggable version manager, a unified toolchain.\n\nIf you're unfamiliar with the concept of a toolchain, a toolchain is a collection of tools that are\ndownloaded, installed, and managed by version through a single interface. In the context of proto's\ntoolchain, a tool is either a programming language, a dependency/package manager for a language, or\na custom implementation provided by a plugin. It's the next step in the version manager evolution.\n\n## Features\n\n- Lightspeed! With Rust and WASM, we can guarantee exceptional performance.\n\n- Multi-language. A single CLI for managing versions for all of your languages.\n\n- Cross-platform, for a consistent experience across machines and teams.\n\n- [Contextual version detection](/docs/proto/detection), ensuring the correct version of a tool is always used.\n\n- Checksum verification, ensuring a tool came from a trusted source.\n\n- Detects and infers from a language's ecosystem for maximum compatibility.\n\n- [Pluggable architecture](/docs/proto/plugins), allowing for custom tooling.\n\n## Why proto?\n\nproto was designed to be a modern and holistic version manager for all of your favorite programming\nlanguages. We believe a single tool that works the same across every language is better than\nmultiple ad-hoc tools. While we only support a handful of languages today, we aim to support many\nmore in the future!\n\nsuccess\n\nproto powers [moon](/moon)'s toolchain, enabling a single source of truth for both tools!\n\n## How does it work?\n\nThe toolchain is a `.proto` directory within the current user's home directory, e.g., `~/.proto`.\n\nThe first step in a tool's life-cycle is being downloaded to `~/.proto/temp`. Downloads are\ntypically an archive that can be unpacked into a target directory. Once downloaded, we verify the\ndownloaded file by running a checksum. If this check fails for any reason, the tool is unusable,\nand the process is aborted.\n\nAfter a successful verification, the last step in the tool's life-cycle can begin, installation.\nDepending on the type of download, the installation process may differ. For archives, we unpack the\ntool to `~/.proto/tools//`. In the future, we'll support building from source.\n\nFrom here, we make these tools globally available by prepending `~/.proto/shims` and `~/.proto/bin`\nto `PATH` (typically as part of your shell profile). Continue reading for more about these folders.\n\n## Supported tools\n\nThe following tools are [officially supported](/docs/proto/tools) in proto via moonrepo. Additional\ntools can be supported through [third-party plugins](/docs/proto/plugins).\n\n+ npm, pnpm, yarn\n\n+ pip, poetry, uv\n\n... with [0 more proto plugins](/docs/proto/tools#third-party), and over [800 asdf plugins](/docs/proto/tool-spec#asdf)...\n\n## Supported targets\n\nBecause proto is written in Rust, we only support targets that are explicitly compiled for, which\nare currently:\n\nOperating system Architecture Target\n\nmacOS 64-bit Intel `x86_64-apple-darwin`\n\nmacOS 64-bit ARM `aarch64-apple-darwin`\n\nLinux 64-bit Intel GNU `x86_64-unknown-linux-gnu`\n\nLinux 64-bit Intel musl `x86_64-unknown-linux-musl`\n\nLinux 64-bit ARM GNU `aarch64-unknown-linux-gnu`\n\nLinux 64-bit ARM musl `aarch64-unknown-linux-musl`\n\nWindows 64-bit Intel `x86_64-pc-windows-msvc`\n\n## /docs/proto/commands/activate\n\nSource: https://moonrepo.dev/docs/proto/commands/activate\n\n# activate\n\nv0.38.0\n\nThe `proto activate ` command will activate proto for the current shell session, by exporting\nenvironment variables and prepending `PATH` for each tool configured in the current directory.\nActivation is ran each time the current directory changes using a shell hook.\n\ninfo\n\nLearn more about\n[shell activation in the official workflow documentation](/docs/proto/workflows#shell-activation)!\n\n### Arguments\n\n- `` - The shell to activate for.\n\n### Options\n\n- `--export` - Print the activate instructions in shell-specific syntax.\n\n- `--json` - Print the activate instructions in JSON format.\n\n- `--no-bin` - Do not include `~/.proto/bin` when appending `PATH`.\n\n- `--no-shim` - Do not include `~/.proto/shims` when prepending `PATH`.\n\n- `--no-init` - Do not trigger activation when initialized in the shell, and instead wait for a cd/prompt change. v0.50.0\n\n### Caveats\n\n- Only tools that have a [version configured in `.prototools`](/docs/proto/config#pinning-versions) will be activated.\n\n- Tool versions configured in the global `~/.proto/.prototools` are not included by default. Pass `--config-mode all` during activation to include them. Do note that this will worsen performance depending on the number of tools.\n\n### Setup\n\nThe following activation steps should be added after all environment variable and `PATH`\nmodifications have happened in your shell, typically at the end of your shell profile.\n\n#### Bash\n\nAdd the following line to the end of your `~/.bashrc` or `~/.bash_profile`.\n\n```\neval \"$(proto activate bash)\"\n```\n\n#### Elvish\n\nGenerate the hook:\n\n```\nproto activate elvish > ~/.elvish/lib/proto-hook.elv\n```\n\nThen add the following line to your `~/.elvish/rc.elv` file.\n\n```\nuse proto-hook\n```\n\n#### Fish\n\nAdd the following line to the end of your `~/.config/fish/config.fish`.\n\n```\nproto activate fish | source\n```\n\n#### Murex\n\nAdd the following line to the end of your `~/.murex_profile`.\n\n```\nproto activate murex -> source\n```\n\n#### Nu\n\nGenerate the hook:\n\n```\n(proto activate nu) | save ~/.config/nushell/proto-hook.nu\n```\n\nThen add the following line to your `~/.config/nushell/config.nu` file.\n\n```\nuse proto-hook.nu\n```\n\n#### Pwsh\n\nAdd the following line to the end of your profile (`$PROFILE`).\n\n```\nproto activate pwsh | Out-String | Invoke-Expression\n```\n\n#### Zsh\n\nAdd the following line to the end of your `~/.zshrc`.\n\n```\neval \"$(proto activate zsh)\"\n```\n\n## /docs/proto/commands/alias\n\nSource: https://moonrepo.dev/docs/proto/commands/alias\n\n# alias\n\nThe `proto alias   ` (or `proto a`) command will define a custom alias that\nmaps to a specific version for the provided tool. Aliases can be used anywhere a version is\naccepted.\n\n```\n$ proto alias node work 16.16\n```\n\nBy default this will update the local [`./.prototools`](/docs/proto/config) file. Pass `--to` to customize\nthe location.\n\n### Arguments\n\n- `` - Type of tool.\n\n- `` - Name of the alias. Supports alphanumeric chars.\n\n- `` - Version to map to the alias.\n\n## Options\n\n- `--to` - [Location of `.prototools`](/docs/proto/config#locations) to update. Supports `global`, `local`, and `user`. v0.41.0\n\n## /docs/proto/commands/bin\n\nSource: https://moonrepo.dev/docs/proto/commands/bin\n\n# bin\n\nThe `proto bin  [version]` command will return an absolute path to a tool's binary within the\ntoolchain. When a tool has not been installed, or a version cannot be resolved, the command will\nexit with a failure.\n\n```\n$ proto bin node 16.10.0/Users/example/.proto/tools/node/16.10.0/bin/node\n```\n\nThis command can also return directories using the `--dir` option.\n\n```\n$ proto bin node 16.10.0 --dir exes/Users/example/.proto/tools/node/16.10.0/bin$ proto bin node 16.10.0 --dir globals/Users/example/.proto/tools/node/globals/bin\n```\n\n### Arguments\n\n- `` - Type of tool.\n\n- `[version]` - Version of tool. If not provided, will attempt to [detect the version](/docs/proto/detection).\n\n### Options\n\n- `--all` - Return multiple paths, separated by newlines, instead of the first path. v0.50.0\n\n- `--dir ` - Return a directory instead of of the main file. v0.50.0 `exes` - Returns the executable's directory.\n\n- `globals` - Returns the globals/packages directory.\n\n- `--bin` - When applicable, return the `~/.proto/bin` path.\n\n- `--shim` - When applicable, return the `~/.proto/shims` path.\n\n## /docs/proto/commands/clean\n\nSource: https://moonrepo.dev/docs/proto/commands/clean\n\n# clean\n\nThe `proto clean` command can be used to uninstall stale and unused tools, plugins, and more. By\ndefault, it will remove items that haven't been used in the last 30 days.\n\n```\n$ proto clean\n```\n\nFurthermore, the command can be used to target a specific artifact type.\n\n```\n$ proto clean plugins\n```\n\n### Arguments\n\n- `[target]` - Type of target. Accepts `cache`, `plugins`, `temp`, or `tools`. v0.44.0\n\n### Options\n\n- `--days` - Number of days before a tool is considered stale.\n\n- `--json` - Print the clean result in JSON format. v0.44.0\n\n- `--yes` - Avoid and confirm all prompts.\n\n## /docs/proto/commands/completions\n\nSource: https://moonrepo.dev/docs/proto/commands/completions\n\n# completions\n\nThe `proto completions` command will generate proto command and argument completions for your\ncurrent shell. This command will write to stdout, which can then be redirected to a file of your\nchoice.\n\n```\n$ proto completions > ./path/to/write/to\n```\n\n### Options\n\n- `--shell` - Shell to explicitly generate for.\n\n### Examples\n\n- Bash\n- Fish\n- Zsh\n\nIf using [bash-completion](https://github.com/scop/bash-completion).\n\n```\nmkdir -p ~/.bash_completion.dproto completions > ~/.bash_completion.d/proto.sh\n```\n\nOtherwise write the file to a common location, and source it in your profile.\n\n```\nmkdir -p ~/.bash_completionsproto completions > ~/.bash_completions/proto.sh# In your profilesource ~/.bash_completions/proto.sh\n```\n\nWrite the file to Fish's completions directory.\n\n```\nmkdir -p ~/.config/fish/completionsproto completions > ~/.config/fish/completions/proto.fish\n```\n\nIf using [oh-my-zsh](https://ohmyz.sh/) (the `_` prefix is required).\n\n```\nmkdir -p ~/.oh-my-zsh/completionsproto completions > ~/.oh-my-zsh/completions/_proto# Reload shell (or restart terminal)omz reload\n```\n\n## /docs/proto/commands/debug\n\nSource: https://moonrepo.dev/docs/proto/commands/debug\n\n- [Home](/)\n- Commands\n- [debug](/docs/proto/commands/debug)\n\nwarning\n\nDocumentation is currently for [moon v2](/blog/moon-v2-alpha) and latest proto. Documentation for moon v1 has been frozen and can be [found here](https://moonrepo.github.io/website-v1/).\n\n# debug\n\nOperations for debugging the current proto environment.\n\n[üìÑÔ∏è configThe proto debug config command will list all .prototools configuration files (in TOML format)](/docs/proto/commands/debug/config)\n\n[üìÑÔ∏è envThe proto debug env command will print information about your current proto environment. Primarily](/docs/proto/commands/debug/env)\n\n[completions](/docs/proto/commands/completions)\n\n[config](/docs/proto/commands/debug/config)\n\n## /docs/proto/commands/debug/config\n\nSource: https://moonrepo.dev/docs/proto/commands/debug/config\n\n# debug config\n\nv0.25.0\n\nThe `proto debug config` command will list all `.prototools` configuration files (in TOML format)\nthat have been loaded, in order of precedence, with the final merged configuration printed at the\nend.\n\n```\n$ proto debug config/Users/name/.proto/.prototools ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  node = \"20.0.0\"  npm = \"bundled\"  [tools.node.aliases]  stable = \"~20\"  [settings]  auto-clean = falseFinal configuration ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  node = \"20.0.0\"  npm = \"bundled\"  [tools.node.aliases]  stable = \"~20\"  [plugins.tools]  node = \"https://github.com/moonrepo/node-plugin/releases/download/v0.6.1/node_plugin.wasm\"  [settings]  auto-clean = false  auto-install = false  detect-strategy = \"first-available\"  [settings.http]  allow-invalid-certs = false  proxies = []\n```\n\n### Options\n\n- `--json` - Print the list in JSON format.\n\n## /docs/proto/commands/debug/env\n\nSource: https://moonrepo.dev/docs/proto/commands/debug/env\n\n# debug env\n\nv0.26.0\n\nThe `proto debug env` command will print information about your current proto environment. Primarily\nthe store location, relevant file paths, and environment variables.\n\n```\n$ proto debug envStore ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  Root: /Users/name/.proto  Bins: /Users/name/.proto/bin  Shims: /Users/name/.proto/shims  Plugins: /Users/name/.proto/plugins  Tools: /Users/name/.proto/tools  Temp: /Users/name/.proto/tempEnvironment ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  Proto version: 0.44.0  Operating system: macos  Architecture: arm64  Config sources:    - /Users/name/Projects/example/.prototools    - /Users/name/.proto/.prototools  Virtual paths:    /userhome = /Users/name    /proto = /Users/name/.proto  Environment variables:    PROTO_APP_LOG = proto=info,schematic=info,starbase=info,warpgate=info,extism::pdk=info    PROTO_HOME = /Users/name/.proto    PROTO_OFFLINE_TIMEOUT = 750    PROTO_VERSION = 0.44.0\n```\n\n### Options\n\n- `--json` - Print the list in JSON format.\n\n## /docs/proto/commands/diagnose\n\nSource: https://moonrepo.dev/docs/proto/commands/diagnose\n\n# diagnose\n\nv0.37.0\n\nThe `proto diagnose` command will diagnose your proto installation for any potential issues. Issues\nare categorized into errors and warnings, with the former being a must fix, and the latter being a\nmaybe fix (depending on your usage of proto).\n\n```\n$ proto diagnoseShell: zshShell profile: /Users/name/.zshrcErrors ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  - Issue: Bin directory /Users/name/.proto/bin was found BEFORE the shims directory /Users/name/.proto/shims on PATH    Resolution: Ensure the shims path comes before the bin path in your shell    Comment: Runtime version detection will not work correctly unless shims are used\n```\n\n### Options\n\n- `--shell` - The shell to diagnose (will detect automatically).\n\n- `--json` - Print the diagnosis in JSON format.\n\n## /docs/proto/commands/exec\n\nSource: https://moonrepo.dev/docs/proto/commands/exec\n\n# exec\n\nv0.53.0\n\nThe `proto exec  -- ` (or `proto x`) command will activate a temporary\nenvironment by loading and initializing any number of tools, and then execute an arbitrary command\nwithin that environment.\n\n```\n$ proto exec node pnpm -- pnpm run dev\n```\n\nTools will automatically detect a version to execute with based on loaded `.prototools`, but the\nversion can be provided inline by suffixing the tool with `@`.\n\n```\n$ proto exec node@24.2 pnpm@10 -- pnpm run dev\n```\n\n### Shell support\n\nBy default, the command will not be executed in a shell, and will be excuted in the context of the\nparent process. If you want to execute the command within a shell (using `-c`), you can use the\n`--shell` option.\n\n```\n$ proto exec node pnpm --shell bash --\n```\n\nIf your command contains special characters, complex expressions, or shell specific syntax, you may\nneed to pass `--raw` to avoid quoting/escaping issues.\n\n```\n$ proto exec node pnpm --shell bash --raw --\n```\n\nFurthermore, if you want to launch an interactive shell session with the activated environment, you\ncan pass the shell command itself as the exec command.\n\n```\n$ proto exec node pnpm -- bash\n```\n\n### Arguments\n\n- `` - List of tool identifiers with optional version.\n\n- `` - Command to execute within the environment. Must be passed after a `--` separator.\n\n### Options\n\n- `--tools-from-config` - Inherit tools to initialize from `.prototools` configs, instead of passing an explicit list.\n\n- `--raw` - Execute the command as-is without quoting or escaping when using `--shell`.\n\n- `--shell` - Shell to execute the command with (e.g. `bash` or `pwsh`).\n\n## /docs/proto/commands/install\n\nSource: https://moonrepo.dev/docs/proto/commands/install\n\n# install\n\nThe `proto install` (or `proto i`) command can be used to install one or many tools.\n\n### Installing all toolsv0.39.0\n\nThe `proto install` command (without arguments) will download and install all tools and plugins\nfrom all parent [`.prototools`](/docs/proto/config) configuration files, and any\n[versions detected](/docs/proto/detection) in the current working directory (if not defined in\n`.prototools`).\n\n```\n$ proto install\n```\n\nBy default, this command does not install tools for versions pinned in the global\n`~/.proto/.prototools` file. Pass `--config-mode all` to include them.\n\n### Installing one tool\n\nThe `proto install  [version]` command will download and install a single tool by unpacking\ntheir archive to `~/.proto/tools/`. If the tool has already been installed, the command will\nexit early.\n\nThe command is also smart enough to resolve partial versions, so 1, 1.2, and 1.2.3 are all\nacceptable. It even supports aliases when applicable, like `latest`, `next`, `beta`, etc. To install\na canary release, use `canary`.\n\n```\n$ proto install deno$ proto install deno 1.31$ proto install deno canary\n```\n\n#### Pinning the version\n\nBy default this command will only install the tool into `~/.proto/tools` but will not make the\nbinary available. If you would like to also pin the resolved version to a `.prototools` file, use\nthe `--pin` option.\n\n```\n# ./.prototools$ proto install bun --pin$ proto install bun --pin local# ~/.proto/.prototools$ proto install bun --pin global# ~/.prototools$ proto install bun --pin user\n```\n\n### Handling plugin hooks\n\nSome tools run [post-install hooks](/docs/proto/tools) that support arbitrary arguments that can be passed\nafter `--`.\n\n```\n$ proto install go -- --no-gobin\n```\n\n### Arguments\n\n- One tool `[tool]` - Type of tool.\n\n- `[version]` - Version of tool. Defaults to a pinned version in `.prototools` or \"latest\".\n\n- `[-- ]` - Additional arguments to pass to post-install hooks.\n\n### Options\n\n- `--force` - Force install, even if already installed.\n\n- `--update-lockfile` - Don't inherit a version from the lockfile and update the existing record. v0.51.0\n\n- One tool `--build` - Build from source if available. v0.45.0\n\n- `--no-build` - Download a pre-built if available. v0.45.0\n\n- `--pin` - Pin the resolved version and create a symlink in `~/.proto/bin`. Accepts a boolean (pins locally by default), or the string \"global\", or the string \"local\".\n\n## /docs/proto/commands/list\n\nSource: https://moonrepo.dev/docs/proto/commands/list\n\n# list\n\ndanger\n\nThis command was removed in v0.44, use [`proto versions`](/docs/proto/commands/versions) instead!\n\nThe `proto list ` (or `proto ls`) command will list installed versions by scanning the\nmanifest at `~/.proto/tools//manifest.json` for possible versions.\n\n```\n$ proto list node16.16.018.2.019.4.0\n```\n\n### Arguments\n\n- `` - Type of tool.\n\n### Options\n\n- `--aliases` - Include aliases in the list.\n\n## /docs/proto/commands/list-remote\n\nSource: https://moonrepo.dev/docs/proto/commands/list-remote\n\n# list-remote\n\ndanger\n\nThis command was removed in v0.44, use [`proto versions`](/docs/proto/commands/versions) instead!\n\nThe `proto list-remote ` (or `proto lsr`) command will list available versions by resolving\nversions from the tool's remote release manifest.\n\n```\n$ proto list-remote node...18.10.018.11.018.12.018.12.118.13.018.14.018.14.118.14.219.0.019.0.119.1.019.2.019.3.019.4.019.5.019.6.019.6.119.7.0\n```\n\n### Arguments\n\n- `` - Type of tool.\n\n### Options\n\n- `--aliases` - Include aliases in the list.\n\n## /docs/proto/commands/outdated\n\nSource: https://moonrepo.dev/docs/proto/commands/outdated\n\n# outdated\n\nv0.19.0\n\nThe `proto outdated` command will load all [`.prototools`](/docs/proto/config) files and check for newer\n(matching configured range) and latest versions of each configured tool. Will also include the\nconfiguration file in which the version has been configured.\n\n```\n$ proto outdated‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ‚îÇ Tool      Current Newest  Latest  Config                              ‚îÇ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ‚îÇ bun       1.1.42  1.1.42  1.1.42  /Users/name/.proto/.prototools      ‚îÇ‚îÇ node      23.5.0  23.5.0  23.5.0  /Users/name/.proto/.prototools      ‚îÇ‚îÇ npm       10.7.0  10.7.0  11.0.0  /Users/name/.proto/.prototools      ‚îÇ‚îÇ rust      1.83.0  1.83.0  1.83.0  /Users/name/.proto/.prototools      ‚îÇ‚îÇ yarn      3.6.3   3.8.7   4.5.1   /Users/name/.proto/.prototools      ‚îÇ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\n```\n\nBy default, this command does not check tools for versions pinned in the global\n`~/.proto/.prototools` file. Pass `--config-mode all` to include them.\n\n### Options\n\n- `--json` - Print the list in JSON format.\n\n- `--latest` - When updating versions with `--update`, use the latest version instead of newest.\n\n- `--update` - Update and write newest/latest versions to their respective configuration.\n\n- `--yes` - Avoid and confirm all prompts. v0.44.0\n\n## /docs/proto/commands/pin\n\nSource: https://moonrepo.dev/docs/proto/commands/pin\n\n# pin\n\nv0.19.0\n\nThe `proto pin  ` command will pin a version (or alias) of a tool. This version will\nbe used when attempting to [detect a version](/docs/proto/detection).\n\n```\n$ proto pin go 1.20$ proto pin python 3.14 --to=global$ proto pin node lts --resolve$ proto pin npm latest --resolve --tool-native\n```\n\nBy default this will update the local [`./.prototools`](/docs/proto/config) file. Pass `--to` to customize\nthe location, or use the `--tool-native` option to use a location unique to the tool.\n\n### Arguments\n\n- `` - Type of tool.\n\n- `` - Version of tool.\n\n### Options\n\n- `--resolve` - Resolve the version to a fully-qualified semantic version before pinning.\n\n- `--to` - [Location of `.prototools`](/docs/proto/config#locations) to update. Supports `global`, `local`, and `user`. v0.41.0\n\n- `--tool-native` - Pins the version in a tool specific location. Examples: JavaScript tooling (Node, Bun, Deno, npm, pnpm, Yarn, etc) Pins version in the `devEngines` field in the `package.json` file.\n\n- v0.55.0\n\n## /docs/proto/commands/plugin\n\nSource: https://moonrepo.dev/docs/proto/commands/plugin\n\n- [Home](/)\n- Commands\n- [plugin](/docs/proto/commands/plugin)\n\nwarning\n\nDocumentation is currently for [moon v2](/blog/moon-v2-alpha) and latest proto. Documentation for moon v1 has been frozen and can be [found here](https://moonrepo.github.io/website-v1/).\n\n# plugin\n\nOperations for managing tools and plugins.\n\n[üìÑÔ∏è addThe proto plugin add command will add the provided ID and plugin locator string to](/docs/proto/commands/plugin/add)\n\n[üìÑÔ∏è infoThe proto plugin info command will display information about a tool and its plugin.](/docs/proto/commands/plugin/info)\n\n[üìÑÔ∏è listThe proto plugin list [...id] command will list all available and configured plugins, for both](/docs/proto/commands/plugin/list)\n\n[üìÑÔ∏è removeThe proto plugin remove command will remove the provided tool ID from the [plugins] section](/docs/proto/commands/plugin/remove)\n\n[üìÑÔ∏è searchThe proto plugin search command will search for plugins provided by the community, based](/docs/proto/commands/plugin/search)\n\n[pin](/docs/proto/commands/pin)\n\n[add](/docs/proto/commands/plugin/add)\n\n## /docs/proto/commands/plugin/add\n\nSource: https://moonrepo.dev/docs/proto/commands/plugin/add\n\n# plugin add\n\nv0.23.0\n\nThe `proto plugin add\n` command will add the provided ID and plugin locator string to\nthe `[plugins]` section of a chosen `.prototools`.\n\n```\n$ proto plugin add node \"https://github.com/moonrepo/node-plugin/releases/latest/download/node_plugin.wasm\"\n```\n\nLearn more about [plugin locator strings](/docs/proto/plugins#enabling-plugins).\n\n### Arguments\n\n- `` - ID of the tool.\n\n- `` - How to locate the plugin.\n\n### Options\n\n- `--to` - [Location of `.prototools`](/docs/proto/config#locations) to update. v0.41.0\n\n- `--type` - Type of plugin to add, either `tool` (default) or `backend`. v0.52.0\n\n## /docs/proto/commands/plugin/info\n\nSource: https://moonrepo.dev/docs/proto/commands/plugin/info\n\n# plugin info\n\nv0.23.0\n\nThe `proto plugin info ` command will display information about a tool and its plugin.\n\n```\n$ proto plugin info nodePlugin ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ID: node  Name: Node.js  Type: Language  Version: 0.13.0  Source URL: https://github.com/moonrepo/plugins/releases/download/node_tool-v0.13.0/node_tool.wasmInventory ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  Detected version: 23.5.0  Fallback version: 23.5.0  Store directory: /Users/name/.proto/tools/node  Executable file: /Users/name/.proto/tools/node/23.5.0/bin/node  Executables directory: /Users/name/.proto/tools/node/23.5.0/bin  Global packages directory: /Users/name/.proto/tools/node/globals/bin  Shims:    - /Users/name/.proto/shims/node  Binaries:    - /Users/name/.proto/bin/node    - /Users/name/.proto/bin/node-20    - /Users/name/.proto/bin/node-20.15    - /Users/name/.proto/bin/node-20.8    - /Users/name/.proto/bin/node-23    - /Users/name/.proto/bin/node-23.4    - /Users/name/.proto/bin/node-23.5  Installed versions:    20.8.0 - installed 12/19/24, last used 12/19/24    20.15.0 - installed 12/25/24, last used 12/25/24    23.4.0 - installed 12/19/24, last used 12/19/24    23.5.0 - installed 12/25/24, last used 12/25/24, fallback version  Remote aliases:    argon = 4.9.1    boron = 6.17.1    carbon = 8.17.0    dubnium = 10.24.1    erbium = 12.22.12    fermium = 14.21.3    gallium = 16.20.2    hydrogen = 18.20.5    iron = 20.18.1    jod = 22.12.0    latest = 23.5.0    stable = 22.12.0Configuration ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  Local aliases:    example = 19.0.0  Environment variables: ‚Äî  Settings: ‚Äî\n```\n\n### Arguments\n\n- `` - ID of tool.\n\n### Options\n\n- `--json` - Print the info in JSON format.\n\n## /docs/proto/commands/plugin/list\n\nSource: https://moonrepo.dev/docs/proto/commands/plugin/list\n\n# plugin list\n\nv0.23.0\n\nThe `proto plugin list [...id]` command will list all available and configured plugins, for both\nthird-party and built-in tools. Will load all `./.prototools` traversing upwards, and the\n`~/.proto/.prototools` file.\n\nFurthermore, it can list tool information, along with their installed versions, relevant timestamps,\navailable aliases, and store location.\n\n```\n$ proto plugin list --versionsBun ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ID: bun  Source URL: https://github.com/moonrepo/plugins/releases/download/bun_tool-v0.14.0/bun_tool.wasm  Store directory: /Users/miles/.proto/tools/bun  Versions:    1.1.42 - installed 12/25/24, fallback versionDeno ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ID: deno  Source URL: https://github.com/moonrepo/plugins/releases/download/deno_tool-v0.13.0/deno_tool.wasm  Store directory: /Users/miles/.proto/tools/deno  Versions:    1.30.0 - installed 02/01/24, last used 11/28/24    1.40.0 - installed 02/01/24, last used 12/09/24    1.43.1 - installed 12/25/24, fallback versionGo ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ID: go  Source URL: https://github.com/moonrepo/plugins/releases/download/go_tool-v0.14.0/go_tool.wasm  Store directory: /Users/miles/.proto/tools/go  Versions:    1.18.0 - installed 12/25/24, fallback version    1.19.0 - installed 12/22/24    1.20.12 - installed 12/09/23    1.23.4 - installed 12/24/24\n```\n\nA list of tool IDs can be provided to filter the output list.\n\n```\n$ proto plugin list node npm\n```\n\n### Arguments\n\n- `[id...]` - IDs of tools.\n\n### Options\n\n- `--aliases` - Print the list with resolved aliases.\n\n- `--versions` - Print the list with installed versions.\n\n- `--json` - Print the list in JSON format.\n\n## /docs/proto/commands/plugin/remove\n\nSource: https://moonrepo.dev/docs/proto/commands/plugin/remove\n\n# plugin remove\n\nv0.23.0\n\nThe `proto plugin remove ` command will remove the provided tool ID from the `[plugins]` section\nof the chosen (`.prototools`).\n\n```\n$ proto plugin remove node\n```\n\nBuilt-in plugins cannot be removed!\n\n### Arguments\n\n- `` - ID of the tool.\n\n### Options\n\n- `--from` - [Location of `.prototools`](/docs/proto/config#locations) to update. v0.41.0\n\n- `--type` - Type of plugin to remove, either `tool` (default) or `backend`. v0.52.0\n\n## /docs/proto/commands/plugin/search\n\nSource: https://moonrepo.dev/docs/proto/commands/plugin/search\n\n# plugin search\n\nv0.36.0\n\nThe `proto plugin search ` command will search for plugins provided by the community, based\non the provided query string. Built-in plugins are not searchable.\n\n```\n$ proto plugin search moonSearch results for: moonLearn more about plugins: https://moonrepo.dev/docs/proto/plugins‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ‚îÇ Plugin      Author    Format Description             Locator                                                             ‚îÇ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ‚îÇ moon        moonrepo  TOML   moon is a multi-        https://raw.githubusercontent.com/moonrepo/moon/master/proto-       ‚îÇ‚îÇ                              language build system   plugin.toml                                                         ‚îÇ‚îÇ                              and codebase management                                                                     ‚îÇ‚îÇ                              tool.                                                                                       ‚îÇ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\n```\n\n### Arguments\n\n- `` - Query string to match against.\n\n### Options\n\n- `--json` - Print the results in JSON format.\n\n## /docs/proto/commands/regen\n\nSource: https://moonrepo.dev/docs/proto/commands/regen\n\n# regen\n\nv0.27.0\n\nThe `proto regen` command can be used to regenerate all shims in the `~/.proto/shims` directory.\nThis command will also clean the shims directory before regenerating, in an effort to remove\nunexpected or broken shims.\n\n```\n$ proto regen\n```\n\nBy default this will only regenerate shims. If you want to regenerate bins in `~/.proto/bin` as\nwell, pass the `--bin` flag. This will also clean the bins directory before regenerating.\n\n```\n$ proto regen --bin\n```\n\nOnly versions pinned in `~/.proto/.prototools` will be linked as bins.\n\n## Options\n\n- `--bin` - Also recreate `~/.proto/bin` symlinks.\n\n## /docs/proto/commands/run\n\nSource: https://moonrepo.dev/docs/proto/commands/run\n\n# run\n\nThe `proto run  [version]` (or `proto r`) command will run a tool after\n[detecting a version](/docs/proto/detection) from the environment.\n\n```\n# Run and detect version from environment$ proto run bun# Run with explicit version$ proto run bun 0.5.3# Run with version from environment variable$ PROTO_BUN_VERSION=0.5.3 proto run bun\n```\n\nArguments can be passed to the underlying tool binary by providing additional arguments after `--`.\n\n```\n$ proto run bun -- run ./script.ts# When using the binary on PATH$ bun run ./script.ts\n```\n\n### Arguments\n\n- `` - Type of tool.\n\n- `[version]` - Version of tool. If not provided, will attempt to detect the version from the environment.\n\n## /docs/proto/commands/setup\n\nSource: https://moonrepo.dev/docs/proto/commands/setup\n\n# setup\n\nThe `proto setup` command will setup proto in your current shell by modifying an applicable profile\nfile and appending proto's bin directory to `PATH`. If a shell could not be detected, you'll be\nprompted to select one.\n\n```\n$ proto setup\n```\n\nDuring setup, the following profiles will be searched or prompted for.\n\n- Bash `~/.bash_profile`\n\n- `~/.bashrc`\n\n- `~/.profile`\n\n- Elvish `~/.elvish/rc.elv`\n\n- `~/.config/elvish/rc.elv`\n\n- Fish `~/.config/fish/config.fish`\n\n- Ion `~/.config/ion/initrc`\n\n- Murex `~/.murex_preload`\n\n- `~/.murex_profile`\n\n- Nu `~/.config/nushell/env.nu`\n\n- `~/.config/nushell/config.nu`\n\n- PowerShell Windows `~\\Documents\\PowerShell\\Microsoft.PowerShell_profile.ps1`\n\n- `~\\Documents\\PowerShell\\Profile.ps1`\n\n- Unix `~/.config/powershell/Microsoft.PowerShell_profile.ps1`\n\n- `~/.config/powershell/profile.ps1`\n\n- Xonsh `~/.config/xonsh/rc.xsh`\n\n- `~/.xonshrc`\n\n- Zsh `~/.zprofile`\n\n- `~/.zshenv`\n\n- `~/.zshrc`\n\n### Windows support\n\nIn addition to updating a shell profile file (most likely PowerShell), we'll also modify the `PATH`\n(or `Path`) system environment variable, by prepending the `~/.proto/shims` and `~/.proto/bin`\npaths.\n\nIf you would like to opt-out of this behavior, pass the `--no-modify-path` flag.\n\n### Options\n\n- `--shell` - Shell to explicitly setup for.\n\n- `--no-modify-profile` / `PROTO_NO_MODIFY_PROFILE` - Don't update a shell profile file.\n\n- `--no-modify-path` / `PROTO_NO_MODIFY_PATH` - Don't update the system `PATH` environment variable (Windows only).\n\n- `--yes` - Avoid interactive prompts and use defaults.\n\n## /docs/proto/commands/status\n\nSource: https://moonrepo.dev/docs/proto/commands/status\n\n# status\n\nv0.34.0\n\nThe `proto status` command will list all tools that are currently active for a target directory,\nwhat versions of those tools are resolved to, and the configuration file in which they are defined.\n\n```\n$ proto status‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ‚îÇ Tool      Configured Resolved  Installed                           Config                             ‚îÇ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ‚îÇ bun       1.1.42     1.1.42    /Users/name/.proto/tools/          /Users/name/.proto/.prototools      ‚îÇ‚îÇ                                bun/1.1.42                                                             ‚îÇ‚îÇ deno      1.43.1     1.43.1    /Users/name/.proto/tools/          /Users/name/.proto/.prototools      ‚îÇ‚îÇ                                deno/1.43.1                                                            ‚îÇ‚îÇ node      23.5.0     23.5.0    /Users/name/.proto/tools/          /Users/name/.proto/.prototools      ‚îÇ‚îÇ                                node/23.5.0                                                            ‚îÇ‚îÇ npm       ~10.7      10.7.0    /Users/name/.proto/tools/          /Users/name/.proto/.prototools      ‚îÇ‚îÇ                                npm/10.7.0                                                             ‚îÇ‚îÇ python    3.12.0     3.12.0    /Users/name/.proto/tools/          /Users/name/.proto/.prototools      ‚îÇ‚îÇ                                python/3.12.0                                                          ‚îÇ‚îÇ yarn      3.6.3      3.6.3     /Users/name/.proto/tools/          /Users/name/.proto/.prototools      ‚îÇ‚îÇ                                yarn/3.6.3                                                             ‚îÇ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\n```\n\nBy default, this command does not check tools for versions pinned in the global\n`~/.proto/.prototools` file. Pass `--config-mode all` to include them.\n\n### Options\n\n- `--json` - Print the list in JSON format.\n\n## /docs/proto/commands/unalias\n\nSource: https://moonrepo.dev/docs/proto/commands/unalias\n\n# unalias\n\nThe `proto unalias  ` (or `proto ua`) command will remove a custom alias for the\nprovided tool.\n\n```\n$ proto unalias node work\n```\n\nBy default this will update the local [`./.prototools`](/docs/proto/config) file. Pass `--from` to customize\nthe location.\n\n### Arguments\n\n- `` - Type of tool.\n\n- `` - Name of the alias. Supports alphanumeric chars.\n\n## Options\n\n- `--from` - [Location of `.prototools`](/docs/proto/config#locations) to update. Supports `global`, `local`, and `user`. v0.41.0\n\n## /docs/proto/commands/uninstall\n\nSource: https://moonrepo.dev/docs/proto/commands/uninstall\n\n# uninstall\n\nThe `proto uninstall  [version]` (or `proto ui`) command will uninstall and remove a tool from\n`~/.proto/tools/`. If the tool has not been installed, the command will exit early.\n\n```\n# Remove a specific version$ proto uninstall deno 1.31# Remove all versions$ proto uninstall deno\n```\n\n### Arguments\n\n- `` - Type of tool.\n\n- `[version]` - Version of tool.\n\n## /docs/proto/commands/unpin\n\nSource: https://moonrepo.dev/docs/proto/commands/unpin\n\n# unpin\n\nv0.36.0\n\nThe `proto unpin ` command will unpin a version of a tool.\n\n```\n$ proto unpin go$ proto unpin node --tool-native\n```\n\nBy default this will update the local [`./.prototools`](/docs/proto/config) file. Pass `--from` to customize\nthe location.\n\n### Arguments\n\n- `` - Type of tool.\n\n### Options\n\n- `--from` - [Location of `.prototools`](/docs/proto/config#locations) to update. Supports `global`, `local`, and `user`. v0.41.0\n\n- `--tool-native` - Use a tool specific location, like the `devEngines` field in the `package.json` for JavaScript tools. v0.55.0\n\n## /docs/proto/commands/upgrade\n\nSource: https://moonrepo.dev/docs/proto/commands/upgrade\n\n# upgrade\n\nThe `proto upgrade` (or `proto up`) command can be used to upgrade your current proto binary to the\nlatest version, or check if you're currently outdated.\n\n```\n$ proto upgrade# Up/downgrade to a specific version$ proto upgrade 0.39.0\n```\n\ninfo\n\nThe previous binary will be moved to `~/.proto/tools/proto/`, while the new binary will be\ninstalled to `~/.proto/bin`.\n\n### Arguments\n\n- `` - The version of proto to explicitly upgrade or downgrade to. v0.39.3\n\n### Options\n\n- `--check` - Check if there's a new version without executing the upgrade.\n\n- `--json` - Print the upgrade information as JSON.\n\n## /docs/proto/commands/use\n\nSource: https://moonrepo.dev/docs/proto/commands/use\n\n# use\n\ndanger\n\nThis command has been deprecated and its functionality was merged into [`proto install`](/docs/proto/commands/install)\nin v0.39. Use that command instead!\n\nThe `proto use` (or `proto u`) command will download and install all tools and plugins from all\nparent [`.prototools`](/docs/proto/config) configuration files, and any [versions detected](/docs/proto/detection) in\nthe current working directory (if not defined in `.prototools`).\n\n```\n$ proto use\n```\n\nThis command does not install tools for versions pinned in the global `~/.proto/.prototools`\nfile.\n\n## /docs/proto/commands/versions\n\nSource: https://moonrepo.dev/docs/proto/commands/versions\n\n# versions\n\nv0.44.0\n\nThe `proto versions ` command will list available versions by resolving versions from the\ntool's remote release manifest. Furthermore, if a version has been installed locally, it will be\ndenoted with a timestamp.\n\n```\n$ proto versions node...22.0.022.1.022.2.022.3.022.4.022.4.122.5.0 - installed 12/25/2422.5.122.6.022.7.022.8.022.9.022.10.022.11.022.12.023.0.023.1.023.2.023.3.023.4.0 - installed 12/19/2423.5.0 - installed 12/25/24\n```\n\n### Arguments\n\n- `` - Type of tool.\n\n### Options\n\n- `--aliases` - Include aliases in the list.\n\n- `--installed` - Only display installed versions.\n\n- `--json` - Print the versions and aliases in JSON format.\n\n## /docs/proto/config\n\nSource: https://moonrepo.dev/docs/proto/config\n\n# Configuration\n\nWe support configuration at both the project-level and user-level using a\n[TOML](https://toml.io/en/) based `.prototools` file. This file can be used to pin versions of\ntools, provide tool specific configuration, enable new tools via plugins, define proto settings, and\nmore.\n\n## Locationsv0.41.0\n\nproto supports 3 locations in which a `.prototools` file can exist. These locations are used\nthroughout the command line and proto's own settings.\n\n- `local` -> `./.prototools`, `.\\.prototools` (current directory)\n\n- `global` -> `~/.proto/.prototools`, `%USERPROFILE%\\.proto\\.prototools`\n\n- `user` -> `~/.prototools`, `%USERPROFILE%\\.prototools`\n\nLocal is a bit of a misnomer as a `.prototools` file can theoretically exist in any directory, but\nwhen reading/writing to a file, `local` refers to the current working directory.\n\n### Where to configure?\n\nWith so many locations to store proto configuration, the question of where to store certain\nconfigurations become blurred, especially when [resolution](#resolution-mode) comes into play. We\nsuggest the following locations:\n\n- Default/fallback [versions](#pinning-versions) of tools -> `global`\n\n- Project specific [versions](#pinning-versions) of tools -> `local`\n\n- Project specific [settings](#settings) -> `local`\n\n- Shared/developer [settings](#settings) -> `user`\n\n- Non-project related -> `user`\n\n## Resolution modev0.40.0\n\nWhen a `proto` command or shim is ran, we must find and load all applicable `.prototools` files. We\nthen deeply merge all of these configuration files into a final configuration object, with the\ncurrent directory taking highest precedence.\n\nThe order in which to resolve configuration can be defined using the `--config-mode` (`-c`) command\nline option, or the `PROTO_CONFIG_MODE` environment variable. The following 4 modes are supported:\n\n### `global`\n\nIn this mode, proto will only load the `~/.proto/.prototools` file. This \"global\" file acts as\nconfiguration at the user-level and allows for fallback settings.\n\n```\n~/.proto/.prototools\n```\n\n### `local`\n\nIn this mode, proto will only load the `.prototools` file in the current directory.\n\n```\n./.prototools\n```\n\n### `upwards`\n\nIn this mode, proto will traverse upwards starting from the current directory, and load\n`.prototools` within each directory, until we reach the system root or the user directory (`~`),\nwhichever comes first.\n\n```\n~/Projects/app/.prototools (cwd)~/Projects/.prototools~/.prototools\n```\n\nThis is the default mode for the [`activate`](/docs/proto/commands/activate),\n[`install`](/docs/proto/commands/install), [`outdated`](/docs/proto/commands/outdated), and\n[`status`](/docs/proto/commands/status) commands.\n\n### `upwards-global` / `all`\n\nThis mode works exactly like [`upwards`](#upwards) but with the functionality of [`global`](#global)\nas well. The global `~/.proto/.prototools` file is appended as the final entry.\n\n```\n~/Projects/app/.prototools (cwd)~/Projects/.prototools~/.prototools~/.proto/.prototools\n```\n\nThis is the default mode for all other commands not listed above in `upwards`.\n\n## Environment modev0.29.0\n\nWe also support environment specific configuration, such as `.prototools.production` or\n`.prototools.development`, when the `PROTO_ENV` environment variable is set. This is useful for\ndefining environment specific aliases, or tool specific configuration.\n\nThese environment aware settings take precedence over the default `.prototools` file, for the\ndirectory it's located in, and are merged in the same way as the default configuration. For example,\nthe lookup order would be the following when `PROTO_ENV=production`:\n\n```\n~/Projects/.prototools.production~/Projects/.prototools~/.prototools.production~/.prototools~/.proto/.prototools\n```\n\nThe global `~/.proto/.prototools` file does not support environment modes.\n\n## Pinning versions\n\nproto supports pinning versions of tools on a per-directory basis through our `.prototools`\nconfiguration file. This file takes precedence during [version detection](/docs/proto/detection) and can be\ncreated/updated with [`proto pin`](/docs/proto/commands/pin).\n\nAt its most basic level, you can map tools to specific versions, for the directory the file is\nlocated in. A [version](/docs/proto/tool-spec) can either be a fully-qualified version, a partial version, a\nrange or requirement, or an alias.\n\n.prototools\n\n```\nnode = \"16.16.0\"npm = \"9\"go = \"~1.20\"rust = \"stable\"\n```\n\n### Lock `proto` versionv0.39.0\n\nYou can also pin the version of proto that you want all tools to execute with by adding a `proto`\nversion entry. This approach uses shims and dynamic version detection like other tools.\n\n.prototools\n\n```\nproto = \"0.38.0\"\n```\n\n## Available settings\n\n### `[env]`v0.29.0\n\nThis setting is a map of environment variables that will be applied to all tools when they are\nexecuted, or when [`proto activate`](/docs/proto/commands/activate) is ran in a shell profile. Variables\ndefined here will not override existing environment variables (either passed on the command line,\nor inherited from the shell).\n\n.prototools\n\n```\n[env]DEBUG = \"*\"\n```\n\nAdditionally, `false` can be provided as a value, which will remove the environment variable. This\nis useful for removing inherited shell variables.\n\n.prototools\n\n```\n[env]DEBUG = false\n```\n\nVariables also support substitution using the syntax `${VAR_NAME}`. When using substitution,\nvariables in the current process and merged `[env]` can be referenced. Recursive substitution is not\nsupported!\n\nThis functionality enables per-directory environment variables!\n\n#### `file`v0.43.0\n\nThis is a special field that points to a dotenv file, relative from the current configuration file,\nthat will be loaded into the environment variables mapping. Variables defined in a dotenv file will\nbe loaded before variables manually defined within `[env]`.\n\nThis feature utilizes the [dotenvy](https://github.com/allan2/dotenvy) crate for parsing dotfiles.\n\n.prototools\n\n```\n[env]file = \".env\"\n```\n\n### `[settings]`\n\n#### `auto-install`\n\nWhen enabled, will automatically install a missing version of a tool when\n[`proto run`](/docs/proto/commands/run) is ran, instead of erroring. Defaults to `false` or\n`PROTO_AUTO_INSTALL`.\n\n.prototools\n\n```\n[settings]auto-install = true\n```\n\nwarning\n\nThis functionality requires shims (not activation) and will only work after a tool has been\ninstalled at least once. This is because the shim executable handles the interception and the shim\nis created after a tool is installed.\n\n#### `auto-clean`\n\nWhen enabled, will automatically clean up the proto store in the background, by removing unused\ntools and outdated plugins. Defaults to `false` or `PROTO_AUTO_CLEAN`.\n\n.prototools\n\n```\n[settings]auto-clean = true\n```\n\n#### `builtin-plugins`v0.39.0\n\nCan be used to customize the [built-in plugins](/docs/proto/tools#built-in) within proto. Can disable all\nbuilt-ins by passing `false`, or enabling a select few by name. Defaults to `true`, which enables\nall.\n\n.prototools\n\n```\n[settings]# Disable allbuiltin-plugins = false# Enable somebuiltin-plugins = [\"node\", \"bun\"]\n```\n\n#### `cache-duration`v0.50.1\n\nThe duration in seconds in which to cache downloaded plugins. Defaults to 30 days.\n\n.prototools\n\n```\n[settings]cache-duration = 3600\n```\n\n#### `detect-strategy`\n\nThe strategy to use when [detecting versions](/docs/proto/detection). Defaults to `first-available` or\n`PROTO_DETECT_STRATEGY`.\n\n- `first-available` - Will use the first available version that is found. Either from `.prototools` or a tool specific file (`.nvmrc`, etc).\n\n- `prefer-prototools` - Prefer a `.prototools` version, even if found in a parent directory. If none found, falls back to tool specific file.\n\n- `only-prototools` - Only use a version defined in `.prototools`. v0.34.0\n\n.prototools\n\n```\n[settings]detect-strategy = \"prefer-prototools\"\n```\n\n#### `pin-latest`\n\nWhen defined and a tool is installed with the \"latest\" alias, will automatically pin the resolved\nversion to the configured location. Defaults to disabled or `PROTO_PIN_LATEST`.\n\n- `global` - Pins globally to `~/.proto/.prototools`.\n\n- `local` - Pins locally to `./.prototools` in current directory.\n\n- `user` - Pins to the user's `~/.prototools` in their home directory. v0.41.0\n\n.prototools\n\n```\n[settings]pin-latest = \"local\"\n```\n\n#### `telemetry`\n\nWhen enabled, we collect anonymous usage statistics for tool installs and uninstalls. This helps us\nprioritize which tools to support, what tools or their versions may be broken, the plugins currently\nin use, and more. Defaults to `true`.\n\n.prototools\n\n```\n[settings]telemetry = false\n```\n\nThe data we track is publicly available and\n[can be found here](https://github.com/moonrepo/proto/blob/master/crates/cli/src/telemetry.rs).\n\n#### `unstable-lockfile`v0.51.0\n\nWhen enabled, will create a `.protolock` file relative to this configuration file. The lockfile will\nrecord and lock all tools, their versions, and checksums from the configuration file, ensuring\nconsistency across machines, and reliability.\n\n.prototools\n\n```\n[settings]unstable-lockfile = true\n```\n\n#### `unstable-registries`v0.51.0\n\nA list of OCI registries to query for plugins by\n[reference](https://oras.land/docs/concepts/reference). Registries will be queried in the order they\nare configured. Each registry object supports the following fields:\n\n- `registry` - The registry host, e.g. `ghcr.io`.\n\n- `namespace` - The namespace (or organization) that the plugin belongs to.\n\n.prototools\n\n```\n[settings]unstable-registries = [  { registry: \"ghcr.io\", namespace: \"moonrepo\" }]\n```\n\n#### `url-rewrites`v0.50.0\n\nProvides a mechanism for rewriting most URLs used by proto, such as those used for downloading\ntools. This setting accepts a map of [Rust regular expressions](https://docs.rs/regex/latest/regex/)\nto [replacement strings](https://docs.rs/regex/latest/regex/struct.Regex.html#method.replace). When\na URL is rewritten, all entries in the map are applied in order, and all matches are replaced.\n\n.prototools\n\n```\n[settings.url-rewrites]\"github.com/(\\\\w+)/(\\\\w+)\" = \"gh-mirror.corp.com/$1/$2\"\"mo+n\" = \"lunar\"\n```\n\nThe following types of URLs are rewritten:\n\n- Tool download/checksum URLs (even from third-party plugins)\n\n- Plugin download URLs\n\n- Build script URLs\n\n- Archive URLs\n\nThe following are not rewritten:\n\n- Git repository URLs\n\n- proto version check/telemetry URLs\n\n### `[settings.build]`v0.46.0\n\nCan be used to customize the build from source flow.\n\n#### `exclude-packages`\n\nConfigures a list of packages that should be excluded during installation.\n\n.prototools\n\n```\n[settings.build]exclude-packages = [\"git\", \"python3\", \"libssl-dev\"]\n```\n\n#### `install-system-packages`\n\nWhen enabled, will install packages required for building using the system package manager. Defaults\nto `true`.\n\n.prototools\n\n```\n[settings.build]install-system-packages = false\n```\n\n#### `system-package-manager`\n\nCustomize the system package manager to use when installing system packages and their dependencies.\nBy default we attempt to detect the package manager to use from the environment.\n\nThis setting accepts a map, where the key is the name of the\n[operating system](https://doc.rust-lang.org/std/env/consts/constant.OS.html), and the value is the\n[package manager](https://docs.rs/system_env/latest/system_env/enum.SystemPackageManager.html) to\nuse. Both the key and value are in kebab-case.\n\n.prototools\n\n```\n[settings.build.system-package-manager]windows = \"choco\"\n```\n\n#### `write-log-file`\n\nWhen a build has completed, write a log file to the current directory. This is always `true` when a\nbuild fails, but `false` otherwise.\n\n.prototools\n\n```\n[settings.build]write-log-file = true\n```\n\n### `[settings.http]`\n\nCan be used to customize the HTTP client used by proto, primarily for requesting files to download,\navailable versions, and more.\n\n#### `allow-invalid-certs`\n\nWhen enabled, will allow invalid certificates instead of failing. This is an escape hatch and\nshould only be used if other settings have failed. Be sure you know what you're doing! Defaults to\n`false`.\n\n.prototools\n\n```\n[settings.http]allow-invalid-certs = true\n```\n\n#### `proxies`\n\nA list of proxy URLs to use for requests. As an alternative, the `HTTP_PROXY` and `HTTPS_PROXY`\nenvironment variables can be set. URLs that start with `http://` will be considered insecure, while\n`https://` will be secure.\n\n.prototools\n\n```\n[settings.http]proxies = [\"https://internal.proxy\", \"https://corp.net/proxy\"]\n```\n\n#### `secure-proxies`v0.40.3\n\nA list of proxy URLs that will be considered secure, regardless of the HTTP protocol.\n\n.prototools\n\n```\n[settings.http]secure-proxies = [\"http://internal.proxy\", \"http://corp.net/proxy\"]\n```\n\n#### `root-cert`\n\nThe path to a root certificate to use for requests. This is useful for overriding the native\ncertificate, or for using a self-signed certificate, especially when in a corporate/internal\nenvironment. Supports `pem` and `der` files.\n\n.prototools\n\n```\n[settings.http]root-cert = \"/path/to/root/cert.pem\"\n```\n\n### `[settings.offline]`v0.41.0\n\nCan be used to customize how we detect an internet connection for offline based logic. These\nsettings are useful if you're behind a VPN or corporate proxy.\n\n#### `custom-hosts`\n\nA list of custom hosts to ping. Will be appended to our\n[default list of hosts](#override-default-hosts) and will be ran last.\n\n.prototools\n\n```\n[settings.offline]custom-hosts = [\"proxy.corp.domain.com:80\"]\n```\n\n#### `override-default-hosts`\n\nIf our default hosts are blocked or are too slow, you can disable pinging them by setting this\noption to true. Our default hosts are Google DNS, Cloudflare DNS, and then Google and Mozilla hosts.\n\nThis should be used in parallel with [`custom-hosts`](#custom-hosts).\n\n.prototools\n\n```\n[settings.offline]override-default-hosts = true\n```\n\n#### `timeout`\n\nThe timeout in milliseconds to wait for a ping against a host to resolve. Default timeout is 750ms.\n\n.prototools\n\n```\n[settings.offline]timeout = 500\n```\n\n### `[plugins]`\n\nThis setting was renamed to [`[plugins.tools]`](#pluginstools) in v0.52 but exists for backwards\ncompatibility.\n\n## Backend specific settings\n\n### `[plugins.backends]`v0.52.0\n\nCustom [backend plugins](/docs/proto/plugins) can be configured with the `[plugins.backends]` section.\n[Learn more about this syntax](/docs/proto/plugins#enabling-plugins).\n\n.prototools\n\n```\n[plugins.backends]my-backend = \"https://raw.githubusercontent.com/my/backend/master/proto-plugin.toml\"\n```\n\nOnce configured, you can manage a tool plugin using your custom backend:\n\n```\n$ proto install my-backend:tool-id\n```\n\n### `[backends.*]`v0.53.0\n\nBackends support custom configuration that will be passed to their WASM plugin, which can be used to\ncontrol the behavior for all tools managed by the backend. Please refer to the\n[official documentation](/docs/proto/tool-spec#backends) around backends.\n\n.prototools\n\n```\n[backends.example]setting = true\n```\n\n### `[backends.*.env]`v0.53.0\n\nThis setting is a map of environment variables for a specific backend, and will be applied when that\nbackend is executed through a managed tool, or when [`proto activate`](/docs/proto/commands/activate) is ran\nin a shell profile. These variables will override those defined in `[env]`. Refer to [`[env]`](#env)\nfor usage examples.\n\n.prototools\n\n```\n[backends.example.env]KEY = \"value\"\n```\n\n#### `file`v0.53.0\n\nLike [`[env].file`](#file), this is a path to a dotenv file, relative from the current configuration\nfile, that will be loaded into the environment variables mapping for this specific backend.\n\n.prototools\n\n```\n[backends.example.env]file = \"backend/.env\"\n```\n\n## Tool specific settings\n\n### `[plugins.tools]`v0.52.0\n\nCustom [tool plugins](/docs/proto/plugins) can be configured with the `[plugins.tools]` section.\n[Learn more about this syntax](/docs/proto/plugins#enabling-plugins).\n\n.prototools\n\n```\n[plugins.tools]my-tool = \"https://raw.githubusercontent.com/my/tool/master/proto-plugin.toml\"\n```\n\nOnce configured, you can manage a tool plugin:\n\n```\n$ proto install my-tool\n```\n\n### `[tools.*]`\n\nTools support custom configuration that will be passed to their WASM plugin, which can be used to\ncontrol the business logic within the plugin. Please refer to the [official documentation](/docs/proto/tools)\nof each tool (typically on their repository) for a list of available settings.\n\nAs an example, let's configure [Node.js](https://github.com/moonrepo/node-plugin) (using the `node`\nidentifier).\n\n.prototools\n\n```\nnpm = \"bundled\" # use bundled npm instead of specific version[tools.node]bundled-npm = true[tools.npm]shared-globals-dir = true\n```\n\n### `[tools.*.aliases]`\n\nAliases are custom and unique labels that map to a specific version, and can be configured manually\nwithin `.prototools`, or by calling the [`proto alias`](/docs/proto/commands/alias) command.\n\n.prototools\n\n```\n[tools.node.aliases]work = \"18\"oss = \"20\"\n```\n\n### `[tools.*.env]`v0.29.0\n\nThis setting is a map of environment variables for a specific tool, and will be applied when that\ntool is executed, or when [`proto activate`](/docs/proto/commands/activate) is ran in a shell profile. These\nvariables will override those defined in `[env]`. Refer to [`[env]`](#env) for usage examples.\n\n.prototools\n\n```\n[tools.node.env]NODE_ENV = \"production\"\n```\n\n#### `file`v0.43.0\n\nLike [`[env].file`](#file), this is a path to a dotenv file, relative from the current configuration\nfile, that will be loaded into the environment variables mapping for this specific tool.\n\n.prototools\n\n```\n[tools.node.env]file = \"frontend/.env\"\n```\n\n## GitHub Action\n\nTo streamline GitHub CI workflows, we provide the\n[`moonrepo/setup-toolchain`](https://github.com/moonrepo/setup-toolchain) action, which can be used\nto install `proto` globally, and cache the toolchain found at `~/.proto`.\n\n.github/workflows/ci.yml\n\n```\n# ...jobs:  ci:    name: 'CI'    runs-on: 'ubuntu-latest'    steps:      - uses: 'actions/checkout@v4'      - uses: 'moonrepo/setup-toolchain@v0'        with:          auto-install: true\n```\n\n## /docs/proto/detection\n\nSource: https://moonrepo.dev/docs/proto/detection\n\n# Version detection\n\n2 min\n\nThe most powerful feature in proto is its contextual version detection, that is triggered with\n[`proto run`](/docs/proto/commands/run), [`proto bin`](/docs/proto/commands/bin), or when a shim is executed. So what\ndoes this mean exactly? Before a tool in proto's toolchain can be executed, we need to determine the\nversion of the tool to execute with. If a detected version exists locally, we proceed using that\nbinary, otherwise we fail with a missing installation error.\n\nWhen detecting a version, the following steps are checked, in the order as listed:\n\n#### 1. Version is explicitly passed as a command line argument\n\n```\n$ proto run node 24.0.0\n```\n\n#### 2. Version is provided with the `PROTO_*_VERSION` environment variable\n\n```\n$ PROTO_NODE_VERSION=24.0.0 proto run node\n```\n\n#### 3. Version is located by traversing the file system\n\nThis step will attempt to find a configuration or manifest file in the current working directory,\nand traverse upwards through parent directories (stops at the user's home directory) until a file is\nfound.\n\n##### 3.1. Version is defined locally in `.prototools`\n\nA `.prototools` file was found and a version entry exists for the current tool. This is also known\nas a \"local version\" and can be created with [`proto pin`](/docs/proto/commands/pin).\n\n.prototools\n\n```\nnode = \"24.0.0\"\n```\n\n##### 3.2. Version is defined in the tool's ecosystem\n\nDepending on the tool, a version is extracted from a found file unique to that tool's ecosystem.\nThis includes version manager configs (`.nvmrc`, etc), manifest files (`package.json`, etc), and\nmore.\n\n.nvmrc\n\n```\n24.0.0\n```\n\npackage.json\n\n```\n{  \"devEngines\": {    \"runtime\": {      \"name\": \"node\",      \"version\": \"24.0.0\"    },    \"packageManager\": {      \"name\": \"npm\",      \"version\": \"11.0.0\"    }  }}\n```\n\n#### 4. Version is defined globally\n\nAs the last check, we look for a \"global version\" that was pinned with\n[`proto pin --global`](/docs/proto/commands/pin) or [`proto install --pin`](/docs/proto/commands/install). This version\nis stored at `~/.proto/.prototools` (`%USERPROFILE%\\.proto\\.prototools` on Windows).\n\n#### 5. Version could not be detected\n\nIf all the previous steps have failed, then we could not detect an applicable version, and the\nprocess will fail.\n\n## /docs/proto/faq\n\nSource: https://moonrepo.dev/docs/proto/faq\n\n# FAQ\n\n## General\n\n### Where did the name \"proto\" come from?\n\nWe wanted to keep with the space theme, and spent quite some time digging through Wikipedia and\nultimately landed on the page for [protostar](https://en.wikipedia.org/wiki/Protostar) (this is why\nour logo's a star). We really liked the definition of protostar, as it basically means \"the\nbeginning phase of a star\". Even the the prefix proto means \"first\" or \"earliest form of\".\n\nThis was great as that's the impression we had in mind for our tool. proto is the first piece\nrequired for setting up your developer environment. The toolchain is the first layer in the\nfoundation.\n\nFrom an aesthetic standpoint, proto's typography works well with moon, as most of the letters are\ncircle shaped. Double points for proto having two o's like the other products!\n\n### Are you worried about confusion with other tools like protobufs?\n\nNah.\n\n### What is a tool?\n\nA tool in the context of proto is either a language, dependency/package manager (typically for a\nlanguage), or third-party CLI. The tool is something that can be downloaded and installed by\nversion onto a machine.\n\nFurthermore, a tool should have a primary executable file that can be executed with `proto run` or\nthrough proto's shims. Additionally, a tool can also provide secondary executable files. For\nexample, `npm` (the primary) also provides `npx` and `node-gyp` (secondaries).\n\n### What is a backend?\n\nA backend is a special type of tool that provides additional integration with 3rd-party plugins,\ngreatly expanding what can be installed and managed with proto.\n\n### What is a plugin?\n\nA plugin is a WASM (or JSON, TOML, YAML) file for a tool or backend.\n\nThe terms tool and plugin are often used interchangeably, but plugin primarily refers to the WASM\nportion of a tool, while tool refers to the entire package: metadata, business logic, branding, so\non an so forth.\n\n### Will you support more languages?\n\nYes! We'd love to support as many as possible, and if you'd like to help, join our Discord\ncommunity! Feel free to create a [plugin](/docs/proto/plugins) in the mean time.\n\n### Will you support other kinds of tools?\n\nNo, we will only support languages, dependency managers, and CLIs, which should be enough. However,\nyou can create a [plugin](/docs/proto/plugins) to support other kinds of tools.\n\n### Do you support \"build from source\"?\n\nAs of version 0.45, we do! Simple pass `--build` to `proto install`. However, building from source\nis a complicated process and is unique per tool, so not all tools support it.\n\n### How to run a canary release after installing it?\n\nOnce a tool has been installed with `canary`, the canary version can be explicitly referenced using\nour [version detection rules](/docs/proto/detection). The easiest approach is to prefix the shim with an\nenvironment variable:\n\n```\n$ PROTO_BUN_VERSION=canary bun ./index.ts\n```\n\nOr to explicitly configure the version in [`.prototools`](/docs/proto/config):\n\n```\nbun = \"canary\"\n```\n\n### What kind of features are supported for HTTP requests?\n\nproto makes a lot of HTTP requests, for information such as available versions/releases, and for\ndownloading the blobs/archives themselves. Because of this, we do our best to support all kinds of\ninternet connections, proxy and intranet usage, and more, through the following:\n\n- All GET and HEAD requests are cached to `~/.proto/cache/requests` based on the [HTTP cache semantics](https://github.com/kornelski/rusty-http-cache-semantics) and relevant RFCs.\n\n- We support the [netrc file format](https://www.gnu.org/software/inetutils/manual/html_node/The-_002enetrc-file.html) and will automatically load `~/.netrc` if it exists.\n\n- We support an offline mode that will short-circuit certain workflows if there's no internet connection. We check for a connection by pinging DNS endpoints, but this can be configured with [`[settings.offline]`](/docs/proto/config#settingsoffline).\n\n- We attempt to automatically load root and system certifications so that secure connections work correctly. This can be configured with [`[settings.http]`](/docs/proto/config#settingshttp).\n\n## Troubleshooting\n\n### Network requests keep failing, how can I bypass?\n\nWhen a tool is executed, we validate the version to ensure it's correct. We achieve this by making\nnetwork requests to a remote service to gather the list of valid versions. If you're having network\nissues, or the request is timing out, you can bypass these checks with the following:\n\n- Pass a fully-qualified version as an environment variable. The version must be installed for this to work. ``` PROTO_NODE_VERSION=20.0.0 node --version ``` If executing a Node.js package manager, you'll need to set versions for both Node.js and the manager. This is required since manager's execute `node` processes under the hood. ``` PROTO_NODE_VERSION=20.0.0 PROTO_NPM_VERSION=10.0.0 npm --version ```\n\n- Pass the `PROTO_BYPASS_VERSION_CHECK` environment variable. This will bypass the network request to load versions, but does not bypass other requests. However, this is typically enough. ``` PROTO_BYPASS_VERSION_CHECK=1 node --version ```\n\n## /docs/proto/install\n\nSource: https://moonrepo.dev/docs/proto/install\n\n# Install proto\n\n1 min\n\nThe following guide can be used to install proto into your environment.\n\n## Requirements\n\n- Git - for fetching available versions/tags\n\n- tar, unzip, gz, xz - for unpacking archives\n\n```\n# macOSbrew install git unzip gzip xz# Ubuntu / Debianapt-get install git unzip gzip xz-utils# RHEL-based / Fedoradnf install git unzip gzip xz\n```\n\n## Installing\n\nThe entirety of proto is packaged and shipped as 2 binaries. It works on most operating systems,\nand does not require any external dependencies. For convenience, we provide the following scripts to\ndownload and install proto.\n\ninfo\n\nThe install location can be customized with the `PROTO_HOME` environment variable. If not provided,\nthe default location is `~/.proto`.\n\n### Linux, macOS, WSL\n\nIn a terminal that supports Bash, run the following command. This will download and install proto,\nthen open an interactive prompt to complete the installation.\n\n```\nbash administrator Powershell or Windows Terminal, run the following command. This will download\nand install proto, then open an interactive prompt to complete the installation.\n\n```\nirm https://moonrepo.dev/install/proto.ps1 | iex\n```\n\nYou may also need to run the following command for shims to be executable:\n\n```\nSet-ExecutionPolicy RemoteSigned# Without admin privilegesSet-ExecutionPolicy -Scope CurrentUser RemoteSigned\n```\n\n### Other\n\nproto can also be downloaded and installed manually, by downloading an asset from\n[https://github.com/moonrepo/proto/releases](https://github.com/moonrepo/proto/releases). Be sure to\nrename the file after downloading, and apply the executable bit (`chmod +x`) on macOS and Linux.\n\n## Upgrading\n\nTo upgrade proto, run the [`proto upgrade`](/docs/proto/commands/upgrade) command, or re-run the install\nscripts above.\n\n## Uninstalling\n\nTo uninstall proto, delete the `~/.proto` directory, and remove any `PROTO_HOME` references from\nyour shell profile.\n\n## Canary releases\n\nproto supports canary releases, which are built and published for every commit to our development\nbranches. These releases will include features and functionality that have not yet landed on master.\nCanary releases are available as a\n[GitHub prerelease](https://github.com/moonrepo/proto/releases/tag/canary) using the `canary` tag.\n\n## Nightly releases\n\nproto supports nightly releases, which are built and published once a day from the latest commit on\nmaster. Nightly releases are available as a\n[GitHub prerelease](https://github.com/moonrepo/proto/releases/tag/nightly) using the `nightly` tag.\n\n## Next steps\n\n[Choose a workflow](/docs/proto/workflows)[Learn about `.prototools`](/docs/proto/config)\n\n## /docs/proto/non-wasm-plugin\n\nSource: https://moonrepo.dev/docs/proto/non-wasm-plugin\n\n# Non-WASM plugin\n\nThe non-WASM plugin is by design, very simple. It's a JSON, TOML, or YAML file that describes a\nschema for the tool, how it should be installed, and how it should be invoked. Since this is a\nstatic configuration file, it does not support any logic or complex behavior, and is merely for\nsimple and common use cases, like CLIs.\n\ninfo\n\nJSON and YAML support was added in proto v0.42.\n\n## Create a plugin\n\nLet's start by creating a new plugin, and defining the `name` and `type` fields. The type can either\nbe `language`, `dependency-manager`, `package-manager`, or `cli`. For this example, we'll create a\nplugin for our fake product called Protostar, a CLI tool.\n\n- JSON\n- TOML\n- YAML\n\nprotostar.json\n\n```\n{  \"name\": \"Protostar\",  \"type\": \"cli\"}\n```\n\nprotostar.toml\n\n```\nname = \"Protostar\"type = \"cli\"\n```\n\nprotostar.yaml\n\n```\nname: 'Protostar'type: 'cli'\n```\n\n### Platform variations\n\nNative tools are often platform specific, and proto supports this by allowing you to define\nvariations based on operating system using the `[platform]` section. For non-native tools, this\nsection can typically be skipped.\n\nThis section requires a mapping of Rust\n[`OS` strings](https://doc.rust-lang.org/std/env/consts/constant.OS.html) to platform settings. The\nfollowing settings are available:\n\n- `archs` - A list of architectures supported for this platform. If not provided, supports all archs.\n\n- `archive-prefix` - If the tool is distributed as an archive (zip, tar, etc), this is the name of the direct folder within the archive that contains the tool, and will be removed when unpacking the archive. If there is no prefix folder within the archive, this setting can be omitted.\n\n- `exes-dir` - A relative path to a directory that contains pre-installed executables.\n\n- `exe-path` - The path to the main executable binary within the archive (without the prefix). If the tool is distributed as a single binary, this setting can be typically omitted.\n\n- `checksum-file` - Name of the checksum file to verify the downloaded file with. If the tool does not support checksum verification, this setting can be omitted.\n\n- `download-file` (required) - Name of the file to download. [Learn more about downloading](#downloading-and-installing).\n\n- JSON\n- TOML\n- YAML\n\nprotostar.json\n\n```\n{  \"platform\": {    \"linux\": {      \"archivePrefix\": \"protostar-linux\",      \"exePath\": \"bin/protostar\",      \"checksumFile\": \"protostar-{arch}-unknown-linux-{libc}.sha256\",      \"downloadFile\": \"protostar-{arch}-unknown-linux-{libc}.tar.gz\"    },    \"macos\": {      \"archivePrefix\": \"protostar-macos\",      \"exePath\": \"bin/protostar\",      \"checksumFile\": \"protostar-{arch}-apple-darwin.sha256\",      \"downloadFile\": \"protostar-{arch}-apple-darwin.tar.xz\"    },    \"windows\": {      \"archivePrefix\": \"protostar-windows\",      \"exePath\": \"bin/protostar.exe\",      \"checksumFile\": \"protostar-{arch}-pc-windows-msvc.sha256\",      \"downloadFile\": \"protostar-{arch}-pc-windows-msvc.zip\"    }  }}\n```\n\nprotostar.toml\n\n```\n[platform][platform.linux]archive-prefix = \"protostar-linux\"exe-path = \"bin/protostar\"checksum-file = \"protostar-{arch}-unknown-linux-{libc}.sha256\"download-file = \"protostar-{arch}-unknown-linux-{libc}.tar.gz\"[platform.macos]archive-prefix = \"protostar-macos\"exe-path = \"bin/protostar\"checksum-file = \"protostar-{arch}-apple-darwin.sha256\"download-file = \"protostar-{arch}-apple-darwin.tar.xz\"[platform.windows]archive-prefix = \"protostar-windows\"exe-path = \"bin/protostar.exe\"checksum-file = \"protostar-{arch}-pc-windows-msvc.sha256\"download-file = \"protostar-{arch}-pc-windows-msvc.zip\"\n```\n\nprotostar.yaml\n\n```\nplatform:  linux:    archivePrefix: 'protostar-linux'    exePath: 'bin/protostar'    checksumFile: 'protostar-{arch}-unknown-linux-{libc}.sha256'    downloadFile: 'protostar-{arch}-unknown-linux-{libc}.tar.gz'  macos:    archivePrefix: 'protostar-macos'    exePath: 'bin/protostar'    checksumFile: 'protostar-{arch}-apple-darwin.sha256'    downloadFile: 'protostar-{arch}-apple-darwin.tar.xz'  windows:    archivePrefix: 'protostar-windows'    exePath: 'bin/protostar.exe'    checksumFile: 'protostar-{arch}-pc-windows-msvc.sha256'    downloadFile: 'protostar-{arch}-pc-windows-msvc.zip'\n```\n\nYou may have noticed tokens above, like `{arch}`. These are special tokens that are replaced with a\ndynamic value at runtime, based on the current host machine executing the code. The following tokens\nare available:\n\n- `{version}` - The currently resolved version, as a fully-qualified semantic or calendar version.\n\n- `{versionMajor}` / `{versionYear}` - Only the major version. v0.41.4\n\n- `{versionMinor}` / `{versionMonth}` - Only the minor version. v0.45.2\n\n- `{versionPatch}` / `{versionDay}` - Only the patch version. v0.45.2\n\n- `{versionPrerelease}` - The prerelease identifier, if applicable. Returns an empty string otherwise. v0.41.4\n\n- `{versionBuild}` - The build identifier, if applicable. Returns an empty string otherwise. v0.41.4\n\n- `{arch}` - The architecture of the host machine, like `x86_64`. These values map to Rust's [`ARCH` constant](https://doc.rust-lang.org/std/env/consts/constant.ARCH.html), but can be customized with [`install.arch`](#downloading-and-installing).\n\n- `{os}` - The operating system of the host machine, like `windows`. These values map to Rust's [`OS` constant](https://doc.rust-lang.org/std/env/consts/constant.OS.html).\n\n- `{libc}` - For Linux machines, this is the current libc implementation, either `gnu` or `musl`. v0.31.2\n\n### Downloading and installing\n\nA non-WASM plugin only supports downloading pre-built tools, typically as an archive, and does\nnot support building from source. The `[install]` section can be used to configure how the tool\nshould be downloaded and installed into the toolchain. The following settings are available:\n\n- `arch` - A mapping of Rust [`ARCH` strings](https://doc.rust-lang.org/std/env/consts/constant.ARCH.html) to custom values for the `{arch}` token. This is useful if the tool has different terminology.\n\n- `libc` - A mapping of custom values for the `{libc}` token.\n\n- `checksum-url` - A secure URL to download the checksum file for verification. If the tool does not support checksum verification, this setting can be omitted.\n\n- `checksum-url-canary` - A URL for canary releases.\n\n- `checksum-public-key` - Public key used for verifying checksums. Only used for `.minisig` files.\n\n- `download-url` (required) - A secure URL to download the tool/archive.\n\n- `download-url-canary` - A URL for canary releases.\n\n- `primary` - Configures the primary executable.\n\n- `secondary` - Configures secondary executables.\n\nThe URL settings support `{checksum_file}` and `{download_file}` tokens, which will be replaced with\nthe values from the `[platform]` section.\n\n- JSON\n- TOML\n- YAML\n\nprotostar.json\n\n```\n{  \"install\": {    \"checksumUrl\": \"https://github.com/moonrepo/protostar/releases/download/v{version}/{checksum_file}\",    \"downloadUrl\": \"https://github.com/moonrepo/protostar/releases/download/v{version}/{download_file}\",    \"arch\": {      \"aarch64\": \"arm64\",      \"x86_64\": \"x64\"    }  }}\n```\n\nprotostar.toml\n\n```\n[install]checksum-url = \"https://github.com/moonrepo/protostar/releases/download/v{version}/{checksum_file}\"download-url = \"https://github.com/moonrepo/protostar/releases/download/v{version}/{download_file}\"[install.arch]aarch64 = \"arm64\"x86_64 = \"x64\"\n```\n\nprotostar.yaml\n\n```\ninstall:  checksumUrl: 'https://github.com/moonrepo/protostar/releases/download/v{version}/{checksum_file}'  downloadUrl: 'https://github.com/moonrepo/protostar/releases/download/v{version}/{download_file}'  arch:    aarch64: 'arm64'    x86_64: 'x64'\n```\n\n#### Executables\n\nThe available executables (bins and shims) can be customized with the `[install.exes]` section,\nwhich is required. This setting requires a map, where the key is the executable file name, and the\nvalue is an object of the following options:\n\n- `exe-path` - The file to execute, relative from the tool directory. On Windows, the `.exe` extension will automatically be appended. If you need more control over platform variance, use `[platform.*.exe-path]` instead.\n\n- `no-bin` - Do not symlink a binary in `~/.proto/bin`.\n\n- `no-shim`- Do not generate a shim in `~/.proto/shims`.\n\n- `parent-exe-name` - Name of a parent executable required to execute the executable path. For example, `node` is required for `.js` files.\n\n- `primary` - Is the main executable in the tool. There can only be 1 primary! v0.42.0\n\n- `shim-before-args` - Custom args to prepend to user-provided args within the generated shim.\n\n- `shim-after-args` - Custom args to append to user-provided args within the generated shim.\n\n- `shim-env-vars` - Custom environment variables to set when executing the shim.\n\nThis field supports both the required primary executable, and optional secondary executables. The\nprimary executable must be marked with `primary = true`.\n\n- JSON\n- TOML\n- YAML\n\nprotostar.json\n\n```\n{  \"install\": {    \"exes\": {      \"protostar\": {        \"exePath\": \"bins/protostar\",        \"primary\": true,        \"shimBeforeArgs\": [          \"--verbose\"        ]      },      \"protostar-debug\": {        \"exePath\": \"bins/protostar-debug\",        \"noShim\": true      }    }  }}\n```\n\nprotostar.toml\n\n```\n[install][install.exes][install.exes.protostar]exe-path = \"bins/protostar\"primary = trueshim-before-args = [ \"--verbose\" ][install.exes.protostar-debug]exe-path = \"bins/protostar-debug\"no-shim = true\n```\n\nprotostar.yaml\n\n```\ninstall:  exes:    protostar:      exePath: 'bins/protostar'      primary: true      shimBeforeArgs:        - '--verbose'    protostar-debug:      exePath: 'bins/protostar-debug'      noShim: true\n```\n\n#### Global packages\n\nThe `[packages]` sections can be configured that provides information about where global packages\nare stored.\n\n- `globals-lookup-dirs` - A list of directories where global binaries are stored. This setting supports interpolating environment variables via the syntax `$ENV_VAR`.\n\n- `globals-prefix` - A string that all package names are prefixed with. For example, Cargo/Rust binaries are prefixed with `cargo-`.\n\n- JSON\n- TOML\n- YAML\n\nprotostar.json\n\n```\n{  \"packages\": {    \"globalsLookupDirs\": [      \"$PROTOSTAR_HOME/bin\",      \"$HOME/.protostar/bin\"    ]  }}\n```\n\nprotostar.toml\n\n```\n[packages]globals-lookup-dirs = [ \"$PROTOSTAR_HOME/bin\", \"$HOME/.protostar/bin\" ]\n```\n\nprotostar.yaml\n\n```\npackages:  globalsLookupDirs:    - '$PROTOSTAR_HOME/bin'    - '$HOME/.protostar/bin'\n```\n\n### Resolving versions\n\nNow that the tool can be downloaded and installed, we must configure how to resolve available\nversions. Resolving is configured through the `[resolve]` section, which supports 2 patterns to\nresolve with: Git tags or a JSON manifest.\n\n#### Git tags\n\nTo resolve a list of available versions using Git tags, the following settings are available:\n\n- `git-url` (required) - The remote URL to fetch tags from.\n\n- JSON\n- TOML\n- YAML\n\nprotostar.json\n\n```\n{  \"resolve\": {    \"gitUrl\": \"https://github.com/moonrepo/protostar\"  }}\n```\n\nprotostar.toml\n\n```\n[resolve]git-url = \"https://github.com/moonrepo/protostar\"\n```\n\nprotostar.yaml\n\n```\nresolve:  gitUrl: 'https://github.com/moonrepo/protostar'\n```\n\n#### JSON manifest\n\nTo resolve a list of available versions using a JSON manifest, the following settings are available:\n\n- `manifest-url` (required) - A URL that returns a JSON response of all versions. This response must be an array of strings, or an array of objects.\n\n- `manifest-version-key` - If the response is an array of objects, this is the key to extract the version from. If the response is an array of strings, this setting can be omitted. Defaults to `version`.\n\n- JSON\n- TOML\n- YAML\n\nprotostar.json\n\n```\n{  \"resolve\": {    \"manifestUrl\": \"https://someregistry.com/protostar/versions.json\",    \"manifestVersionKey\": \"latest_version\"  }}\n```\n\nprotostar.toml\n\n```\n[resolve]manifest-url = \"https://someregistry.com/protostar/versions.json\"manifest-version-key = \"latest_version\"\n```\n\nprotostar.yaml\n\n```\nresolve:  manifestUrl: 'https://someregistry.com/protostar/versions.json'  manifestVersionKey: 'latest_version'\n```\n\n#### Versions and aliasesv0.36.0\n\nAs an alternative, we also support a static configuration of explicit versions and aliases. This is\nuseful if you have an internal tool that is relatively stable, or does not provide a means in which\nto extract version information.\n\n- `versions` - A list of versions.\n\n- `aliases` - A mapping of alias names to versions.\n\n- JSON\n- TOML\n- YAML\n\nprotostar.json\n\n```\n{  \"resolve\": {    \"versions\": [      \"1.2.3\",      \"1.2.4\",      \"1.2.5\"    ],    \"aliases\": {      \"stable\": \"1.2.4\"    }  }}\n```\n\nprotostar.toml\n\n```\n[resolve]versions = [ \"1.2.3\", \"1.2.4\", \"1.2.5\" ][resolve.aliases]stable = \"1.2.4\"\n```\n\nprotostar.yaml\n\n```\nresolve:  versions:    - '1.2.3'    - '1.2.4'    - '1.2.5'  aliases:    stable: '1.2.4'\n```\n\n#### Version patterns\n\nWhen a version is found, either from a git tag or manifest key, we attempt to parse it into a\n[valid version](/docs/proto/tool-spec) using a Rust based regex pattern and the `version-pattern` setting.\n\nThis pattern uses named regex capture groups (`(?...)`) to build the version, and to support\nfound versions that are not fully-qualified (they may be missing patch or minor versions). The\nfollowing groups are supported:\n\n- `major` / `year` - The major version number. Defaults to `0` if missing.\n\n- `minor` / `month` - The minor version number. Defaults to `0` if missing.\n\n- `patch` / `day` - The patch version number. Defaults to `0` if missing.\n\n- `pre` - The pre-release identifier, like \"rc.0\" or \"alpha.0\". Supports an optional leading `-`. Does nothing if missing.\n\n- `build` - The build metadata, like a timestamp. Supports an optional leading `+`. Does nothing if missing.\n\n- JSON\n- TOML\n- YAML\n\nprotostar.json\n\n```\n{  \"resolve\": {    \"versionPattern\": \"^@protostar/cli@((?\\\\d+)\\\\.(?\\\\d+)\\\\.(?\n\\\\d+))\"  }}\n```\n\nprotostar.toml\n\n```\n[resolve]version-pattern = \"^@protostar/cli@((?\\\\d+)\\\\.(?\\\\d+)\\\\.(?\n\\\\d+))\"\n```\n\nprotostar.yaml\n\n```\nresolve:  versionPattern: '^@protostar/cli@((?\\d+)\\.(?\\d+)\\.(?\n\\d+))'\n```\n\nIf no named capture groups are found, the match at index `1` is used as the version.\n\n### Detecting versions\n\nAnd lastly, we can configure how to [detect a version](/docs/proto/detection) contextually at runtime, using\nthe `[detect]` setting. At this time, we only support 1 setting:\n\n- `version-files` - A list of version files to extract from. The contents of these files can only be the version string itself.\n\n- JSON\n- TOML\n- YAML\n\nprotostar.json\n\n```\n{  \"detect\": {    \"versionFiles\": [      \".protostar-version\",      \".protostarrc\"    ]  }}\n```\n\nprotostar.toml\n\n```\n[detect]version-files = [ \".protostar-version\", \".protostarrc\" ]\n```\n\nprotostar.yaml\n\n```\ndetect:  versionFiles:    - '.protostar-version'    - '.protostarrc'\n```\n\n## /docs/proto/plugins\n\nSource: https://moonrepo.dev/docs/proto/plugins\n\n# Plugins\n\nproto supports a pluggable architecture as a means for consumers to integrate and manage custom\ntools (languages, CLIs, etc) within proto's toolchain. It's not possible for proto to support\neverything in core directly, so plugins are a way for the community to extend the toolchain to\ntheir needs.\n\n## Enabling plugins\n\nPlugins can be enabled by configuring them in [`.prototools`](/docs/proto/config#plugins) files, within the\n`[plugins]` section. The map key is the plugin name in kebab-case, which is used as the\nbinary/tool name in proto, and also the name for configuration and cache purposes. The map value is\na [plugin locator string](/docs/guides/wasm-plugins#configuring-plugin-locations) that defines a\nprotocol and source location.\n\n.prototools\n\n```\n[plugins.tools] = \"\n://\"\n```\n\n## Creating plugins\n\nTo ease the plugin development process, proto supports 2 types of plugins, a\n[non-WASM configuration based plugin](/docs/proto/non-wasm-plugin) for basic use cases, and a\n[WASM based plugin](/docs/proto/wasm-plugin) for advanced use cases.\n\n## Publish a plugin\n\nproto's registry is currently powered by static JSON files located in our official\n[proto repository](https://github.com/moonrepo/proto/tree/master/registry). View that link for\ninformation on how to publish a plugin.\n\n## /docs/proto/tool-spec\n\nSource: https://moonrepo.dev/docs/proto/tool-spec\n\n# Tool specification\n\n3 min\n\nSince proto is a toolchain for multiple tools, each with differing version formats, we must align\nthem on a standard specification that can resolve and store safely. To handle this, we've\nimplemented our own solution called the tool and version specification. This specification currently\nsupports semantic and calendar based versions, each with their own guidelines and caveats.\n\ninfo\n\nIf you're implementing a plugin for a specific tool that has a different version format, you'll need\nto re-format it into one of the specifications below.\n\n## Backendsv0.47.0\n\nA backend is an internal system that allows proto to use plugins from 3rd-party package/version\nmanagers within proto, greatly expanding the amount of tools that proto can install and support.\nThis functionality is achieved through special WASM plugins under the hood.\n\nTo make use of a backend, prefix the tool identifier in `.prototools` with the backend's unique\nidentifier. For example, we can install Zig via asdf.\n\n.prototools\n\n```\n# >= v0.52\"asdf:zig\" = \"0.13.0\"# does\nnot use the `asdf` binary itself, and instead emulates the environment as best we can. Because of\nthis, some tools may not be usable through proto.\n\n.prototools\n\n```\n\"asdf:\" = \"20\"\n```\n\nBy default, the ID pinned in `.prototools` is the\n[asdf shortname](https://asdf-vm.com/plugins/create.html#plugin-shortname-index) used when cloning a\nrepository. If the ID is different than the shortname (`node` vs `nodejs`), you can configure the\n`asdf-shortname` setting.\n\n.prototools\n\n```\n\"asdf:node\" = \"20\"[tools.\"asdf.node\"]asdf-shortname = \"nodejs\"\n```\n\nThe following settings are supported:\n\n- `asdf-shortname` (string) - The name of the [asdf plugin](https://github.com/asdf-vm/asdf-plugins) if different than the configured ID.\n\n- `asdf-repository` (string) - The Git repository URL in which to locate [scripts](https://asdf-vm.com/plugins/create.html#scripts-overview). If not defined, is extracted from the shortname plugin index.\n\n- `exes` (string[]) - List of executable file names (relative from `bin`) to be linked as a shim/bin. If not defined, we'll automatically scan the `bin` directory.\n\n## Semantic versions\n\nThe most common format is [semver](https://semver.org/), also known as a semantic version. This\nformat requires major, minor, and patch numbers, with optional pre-release and build metadata.\n\n.prototools\n\n```\ntool = \"1.2.3\"\n```\n\n### Syntax\n\n- `..` - 1.2.3\n\n- `..-` - 1.2.3-alpha.0\n\n- `..-+` - 1.2.3-alpha.0+nightly456\n\n- `..+` - 1.2.3+nightly456\n\n### Guidelines\n\n- major, minor, patch - `0-9` of any length\n\n- pre, build - `a-z`, `0-9`, `-`, `.`\n\n[Learn more about this format!](https://semver.org/#backusnaur-form-grammar-for-valid-semver-versions)\n\n## Calendar versionsv0.37.0\n\nAnother popular format is [calver](https://calver.org/), also known as a calendar version, which\nuses the calendar year, month, and day as version numbers. This format also supports pre-release and\nbuild metadata, but with different syntax than semver.\n\n.prototools\n\n```\ntool = \"2025-02-26\"\n```\n\n### Syntax\n\n- `-` - 2024-02\n\n- `--` - 2024-02-26\n\n- `--.` - 2024-02-26.123\n\n- `--_` - 2024-02-26_123\n\n- `--.-` - 2024-02-26.123-alpha.0\n\n- `--_-` - 2024-02-26_123-alpha.0\n\n- `---` - 2024-02-26-alpha.0\n\n### Guidelines\n\n- year - `0-9` of 1-4 length If the year is not YYYY format, it will use the year 2000 as the base. For example, `24` becomes `2024`, and `124` becomes `2124`.\n\n- month - `0-9` of 1-2 length Supports with and without a leading zero (`02` vs `2`).\n\n- Does not support invalid months (`0` or `13`).\n\n- day - `0-9` of 1-2 length Can be omitted, even with build/pre.\n\n- Supports with and without a leading zero (`02` vs `2`).\n\n- Does not support invalid days (`0` or `32`).\n\n- build - `0-9` of any length Also known as a \"micro\" number.\n\n- The leading dot `.` format is preferred.\n\n- pre - `a-z`, `0-9`, `-`, `.`\n\n[Learn more about this format!](https://calver.org/#scheme)\n\n## Requirements and ranges\n\nBesides an explicit version, we also support partial versions known as version requirements or\nversion ranges. These are quite complex as we need to support both semver and calver in unison, as\nwell as support partial/incomplete numbers (missing patch/day, missing minor/month, etc). We do our\nbest to support as many combinations as possible.\n\n.prototools\n\n```\ntool-a = \"^1\"tool-b = \"~2.1\"tool-c = \">=2000-10\"\n```\n\n### Syntax\n\n- Requirement - `[]` - `1.2.3`, `>4.5`, `~3`, `^2000-10`, etc\n\n- AND range - `[,] ...` - `>=1, `, `>=`, ` If omitted, defaults to `~` when a partial version is provided (i.e. allow the minimum specified version component to increase)\n\n- If a full version is provided, defaults to `^` (i.e. allow any newer version that is nominally compatible)\n\n- To specify an exact version, use the `=` operator explicitly.\n\n- pattern Dot-separated semver, with optional major and patch numbers.\n\n- Dash-separated calver, with optional month and day numbers.\n\n- Pre-release and build metadata are only supported when suffixed to full versions.\n\nFor example, if you want to use `npm` 11.6.2 but 11.6.3 has an issue, use:\n`npm = \"^11.6.4 || =11.6.2\"`\n\n## /docs/proto/tools\n\nSource: https://moonrepo.dev/docs/proto/tools\n\n# Supported tools\n\n## Built-in\n\nThe following tools are supported natively in proto's toolchain.\n\n## Third-party\n\n[Add tool](https://github.com/moonrepo/proto/tree/master/registry)\n\nAdditional tools can be supported through [plugins](/docs/proto/plugins).\n\n## /docs/proto/wasm-plugin\n\nSource: https://moonrepo.dev/docs/proto/wasm-plugin\n\n# WASM plugin\n\nIf you want more control over how your tool works, a WASM plugin is the way to go.\n\nsuccess\n\nRefer to our [official WASM guide](/docs/guides/wasm-plugins) for more information on how our WASM\nplugins work, critical concepts to know, and more. Once you have a good understanding, you may\ncontinue this proto specific guide.\n\n## Concepts\n\nThe following concepts are unique to proto, but be sure to also read about the general concepts in\nour [WASM plugins guide](/docs/guides/wasm-plugins#concepts).\n\n### Tool context\n\nFor plugin functions, we provide what we call the tool context, which is information that is\nconstantly changing depending on the current step or state of proto's execution. The context cannot\nbe accessed with a stand-alone function, and is instead passed as a `context` field in the input of\nmany plugin functions.\n\n```\n#[plugin_fn]pub fn download_prebuilt(Json(input): Json) -> FnResult> {    let version = input.context.version;    // ...}\n```\n\nThe following fields are available on the\n[context object](https://docs.rs/proto_pdk/latest/proto_pdk/struct.ToolContext.html):\n\n- `proto_version` - The version of proto executing the plugin. Note that this version may be for the [`proto_core` crate](https://crates.io/crates/proto_core), and not the CLI. Patch numbers will drift, but major and minor numbers should be in sync.\n\n- `temp_dir` - A virtual path to a temporary directory unique to this tool. v0.45.0\n\n- `tool_dir` - A virtual path to the tool's directory for the current version.\n\n- `version` - The current version or alias. If not resolved, will be \"latest\".\n\ncaution\n\nThe `version` field is either a fully-qualified version (1.2.3), an alias (\"latest\", \"stable\"), or\ncanary (\"canary\"). Be sure to account for all these variations when implementing plugin functions!\n\n### Tool configuration\n\nUsers can configure tools through the [`[tools.*]`](/docs/proto/config#tools) section of their `.prototools`,\nwhich can then be accessed within the WASM plugin using the\n[`get_tool_config`](https://docs.rs/proto_pdk/latest/proto_pdk/fn.get_tool_config.html) function.\n\nThis function requires a struct to deserialize into. It should implement `Default`, enable serde\ndefaults, and map keys from `kebab-case`. If you want to error on unknown settings, also enable\n`deny_unknown_fields`.\n\n```\n#[derive(Debug, Default, serde::Deserialize)]#[serde(default, deny_unknown_fields, rename_all = \"kebab-case\")]struct NodeToolConfig {    pub bundled_npm: bool,}let config = get_tool_config::()?;config.bundled_npm;\n```\n\n### Backend configurationv0.53.0\n\nLike tool configuration, users can configure backends through the\n[`[backends.*]`](/docs/proto/config#backends) section of their `.prototools`, which can then be accessed\nwithin the WASM plugin using the\n[`get_backend_config`](https://docs.rs/proto_pdk/latest/proto_pdk/fn.get_backend_config.html)\nfunction.\n\n```\n#[derive(Debug, Default, serde::Deserialize)]#[serde(default, deny_unknown_fields, rename_all = \"kebab-case\")]struct ExampleBackendConfig {    pub setting: bool,}let config = get_backend_config::()?;\n```\n\n## Creating a plugin\n\nsuccess\n\nRefer to our [official WASM guide](/docs/guides/wasm-plugins#creating-a-plugin) for steps on how to\ncreate a Rust based plugin.\n\n## Implementing tool functions\n\nPlugins are powered by a set of functions that are called from the host, and are annotated with\n`#[plugin_fn]`. These are known as plugin functions, or guest functions.\n\n### Registering the tool\n\nThe first step in a plugin's life-cycle is to register metadata about the plugin with the\n`register_tool` function. This function is called immediately after a plugin is loaded at runtime,\nand must return a human-readable name and plugin type.\n\n```\n#[plugin_fn]pub fn register_tool(_: ()) -> FnResult> {    Ok(Json(RegisterToolOutput {        name: \"Node.js\".into(),        type_of: PluginType::Language,        minimum_proto_version: Some(Version::new(0, 42, 0)),        plugin_version: Version::parse(env!(\"CARGO_PKG_VERSION\")).ok(),        ..RegisterToolOutput::default()    }))}\n```\n\nThis function also receives the plugin ID as input, allowing for conditional logic based on the ID.\nThe ID is the [key the plugin was configured with](/docs/proto/plugins#enabling-plugins), and what is passed\nto `proto` commands (e.g. `proto install `).\n\n```\n#[plugin_fn]pub fn register_tool(Json(input): Json) -> FnResult> {  input.id  // ...}\n```\n\n### Configuration schemav0.53.0\n\nIf you are using [tool configuration](#tool-configuration), you can register the shape of the\nconfiguration using the [`schematic`](https://crates.io/crates/schematic) crate and the\n`define_tool_config` function. This shape will be used to generate outputs such as JSON schemas, or\nTypeScript types.\n\n```\n#[plugin_fn]pub fn define_tool_config(_: ()) -> FnResult> {    Ok(Json(DefineToolConfigOutput {        schema: Some(schematic::SchemaBuilder::generate::()),    }))}\n```\n\nSchematic is a heavy library, so we suggest adding the dependency like so:\n\n```\n[dependencies]schematic = { version = \"\", default-features = false, features = [\"schema\"] }\n```\n\n### Installation strategy\n\n#### Downloading pre-builts\n\nOur plugin layer only supports downloading pre-built tools, typically as an archive, and does\nnot support building from source. The `download_prebuilt` function must be defined, whichs\nconfigures how the tool should be downloaded and installed.\n\nThe following fields are available:\n\n- `archive_prefix` - If the tool is distributed as an archive (zip, tar, etc), this is the name of the direct folder within the archive that contains the tool, and will be removed when unpacking the archive. If there is no prefix folder within the archive, this setting can be omitted.\n\n- `download_url` (required) - A secure URL to download the tool/archive.\n\n- `download_name` - File name of the archive to download. If not provided, will attempt to extract it from the URL.\n\n- `checksum` - The checksum hash itself. Will be used if no other option was provided. v0.47.0\n\n- `checksum_url` - A secure URL to download the checksum file for verification. If the tool does not support checksum verification, this setting can be omitted.\n\n- `checksum_public_key` - Public key used for verifying checksums. Only used for `.minisig` files.\n\n```\n#[plugin_fn]pub fn download_prebuilt(Json(input): Json) -> FnResult> {     let env = get_host_environment()?;    check_supported_os_and_arch(        NAME,        &env,        permutations! [            HostOS::Linux => [HostArch::X64, HostArch::Arm64, HostArch::Arm, HostArch::Powerpc64, HostArch::S390x],            HostOS::MacOS => [HostArch::X64, HostArch::Arm64],            HostOS::Windows => [HostArch::X64, HostArch::X86, HostArch::Arm64],        ],    )?;    let version = input.context.version;    let arch = env.arch;    let os = env.os;    let prefix = match os {        HostOS::Linux => format!(\"node-v{version}-linux-{arch}\"),        HostOS::MacOS => format!(\"node-v{version}-darwin-{arch}\"),        HostOS::Windows => format!(\"node-v{version}-win-{arch}\"),        other => {            return Err(PluginError::UnsupportedPlatform(\"Node.js\".into(), other.into()))?;        }    };    let filename = if os == HostOS::Windows {        format!(\"{prefix}.zip\")    } else {        format!(\"{prefix}.tar.xz\")    };    Ok(Json(DownloadPrebuiltOutput {        archive_prefix: Some(prefix),        download_url: format!(\"https://nodejs.org/dist/v{version}/{filename}\"),        download_name: Some(filename),        checksum_url: Some(format!(\"https://nodejs.org/dist/v{version}/SHASUMS256.txt\")),        ..DownloadPrebuiltOutput::default()    }))}\n```\n\n##### Unpacking an archive\n\nOur plugin layer will do its best to detect file extensions, unpack the downloaded file (if an\narchive), and install the tool to the correct directory. However, we're unable to account for all\nedge cases, so for situations where the install params above are not sufficient, you may define an\n`unpack_archive` function.\n\nThis function receives an input with the following fields:\n\n- `input_file` - Virtual path to the downloaded file. Maps to `~/.proto/temp//`.\n\n- `output_dir` - Virtual directory to unpack the archive into, or copy the binary to. Maps to `~/.proto/tools//`.\n\n```\n#[plugin_fn]pub fn unpack_archive(Json(input): Json) -> FnResult {    untar(input.input_file, input.output_dir)?;    Ok(())}\n```\n\n#### Build from source\n\nComing soon!\n\n#### Native installation\n\nFor tools that can't be installed through downloading pre-builts or building from source, and\nrequire a more unique/native approach (say running a script), you may define the `native_install`\nfunction.\n\nThis function allows you to execute host commands, make HTTP requests, and more, to install the\ntool. All that's required to return whether the installation was successful or not, and an optional\nerror message.\n\n```\n#[plugin_fn]pub fn native_install(Json(input): Json) -> FnResult> {    let result = exec_captured(\"command\", [\"args\"])?;    Ok(Json(NativeInstallOutput {        installed: result.exit_code == 0,        error: if result.stderr.is_empty() {            None        } else {            Some(result.stderr)        },        ..Default::default()    }))}\n```\n\n### Locating executables\n\nEven though a tool has been installed, we must inform proto of where to find executables. This can\nbe achieved with the required `locate_executables` function. The `exes` field defines the location\nof the executables, relative from the installation directory.\n\n```\n#[plugin_fn]pub fn locate_executables(    Json(_): Json,) -> FnResult> {    let env = get_host_environment()?;    Ok(Json(LocateExecutablesOutput {        exes: HashMap::from_iter([            // Primary            (                \"node\".into(),                ExecutableConfig::new_primary(                    // Helper that chooses between distinct Unix or Windows values                    env.os.for_native(\"bin/node\", \"node.exe\"),                    // Or the same value with optional Windows extension                    // env.os.get_file_name(\"node\", \"exe\")                )            ),            // Secondary            (                \"corepack\".into(),                ExecutableConfig::new(env.os.for_native(\"bin/corepack\", \"corepack.exe\"))            ),        ]),        ..LocateExecutablesOutput::default()    }))}\n```\n\nThe main executable of the tool must be marked as primary, either with\n`ExecutableConfig::new_primary`, or setting the `ExecutableConfig.primary` field to true.\n\nFurthermore, the `locate_executables` function can define a list of lookups for the globals\ninstallation directory. proto will loop through each lookup, and return the first directory that\nexists on the current file system. proto will also expand environment variables in the format of\n`$VAR_NAME`. If a variable is not defined, or has an empty value, the lookup will be skipped. To\ndemonstrate this, we'll use [Deno](https://deno.land/manual@v1.35.0/tools/script_installer).\n\n```\n#[plugin_fn]pub fn locate_executables(    Json(_): Json,) -> FnResult> {    let env = get_host_environment()?;    Ok(Json(LocateExecutablesOutput {        globals_lookup_dirs: vec![\"$DENO_INSTALL_ROOT/bin\".into(), \"$HOME/.deno/bin\".into()],        // ...        ..LocateExecutablesOutput::default()    }))}\n```\n\n### Loading and resolving versions\n\nNow that the tool can be downloaded and installed, we must configure how to resolve available\nversions to actually be installed. To provide a list of versions and language specific aliases, the\n`load_versions` function must be defined.\n\n```\n#[plugin_fn]pub fn load_versions(Json(_): Json) -> FnResult> {    let mut output = LoadVersionsOutput::default();    let response: Vec = fetch_json(\"https://nodejs.org/dist/index.json\")?;    for (index, item) in response.iter().enumerate() {        let version = VersionSpec::parse(&item.version[1..])?; // Starts with v        if index == 0 {            output.latest = Some(version.clone());        }        output.versions.push(version);    }    Ok(Json(output))}\n```\n\nFurthermore, we support an optional function named `resolve_version`, that can be defined to\nintercept the version resolution process. This function receives an input with an initial candidate,\neither an alias or version, and can replace it with a new candidate. The candidate must be a valid\nalias or version as defined in `load_versions`.\n\n```\n#[plugin_fn]pub fn resolve_version(    Json(input): Json,) -> FnResult> {    let mut output = ResolveVersionOutput::default();    if let UnresolvedVersionSpec::Alias(alias) = input.initial {        let candidate = if alias == \"node\" {            \"latest\"        } else if alias == \"lts-*\" || alias == \"lts/*\" {            \"stable\"        } else if alias.starts_with(\"lts-\") || alias.starts_with(\"lts/\") {            &alias[4..]        } else {            return Ok(Json(output));        };        output.candidate = Some(UnresolvedVersionSpec::Alias(candidate.to_owned()));    }    Ok(Json(output))}\n```\n\n### Detecting versions\n\nAnd lastly, we can configure how to [detect a version](/docs/proto/detection) contextually at runtime, using\nthe `detect_version_files` function and optional `parse_version_file` function. The\n`detect_version_files` function can return a list of files to locate within a directory.\n\n```\n#[plugin_fn]pub fn detect_version_files(input: Json) -> FnResult> {    Ok(Json(DetectVersionOutput {        files: vec![            \".nvmrc\".into(),            \".node-version\".into(),            \"package.json\".into(),        ],        ignore: vec![\"node_modules\".into()],    }))}\n```\n\nBy default our plugin layer will assume the version file's contents contain the literal version, and\nnothing else, like \"1.2.3\". If any of the files in the `detect_version_files` list require custom\nparsing (for example, `package.json` above), you can define the `parse_version_file` function.\n\nThis function receives the file name and contents as input, and must return the parsed version (if\napplicable).\n\n```\n#[plugin_fn]pub fn parse_version_file(Json(input): Json\n) -> FnResult {    let mut version = None;    if input.file == \"package.json\" {        let json: PackageJson = serde_json::from_str(&input.content)?;        if let Some(engines) = json.engines {            if let Some(constraint) = engines.get(\"node\") {                version = Some(UnresolvedVersionSpec::parse(constraint)?);            }        }    } else {        version = Some(UnresolvedVersionSpec::parse(input.content.trim())?);    }    Ok(Json(ParseVersionFileOutput { version }))}\n```\n\n## Implementing backend functions\n\nPlugins are powered by a set of functions that are called from the host, and are annotated with\n`#[plugin_fn]`. These are known as plugin functions, or guest functions.\n\n### Registering the backendv0.52.0\n\nBackends will also need to implement [`register_tool`](#registering-the-tool) for the managed tool\nwithin the backend.\n\nThe first step in a plugin's life-cycle is to register metadata about the plugin with the\n`register_backend` function. This function requires a unique backend identifier, which is typically\nthe identifier of the current tool being managed.\n\n```\n#[plugin_fn]pub fn register_backend(    Json(input): Json,) -> FnResult> {    Ok(Json(RegisterBackendOutput {        backend_id: get_plugin_id()?,        ..Default::default()    }))}\n```\n\n#### Referencing install scripts\n\nSome tools rely on command line scripts for installation, like `asdf`. To make these scripts\navailable (at `~/.proto/backends`), you can define the `source` field in the\n`RegisterBackendOutput`, which accepts a Git repository URL, or an HTTP URL to an archive to unpack.\nAdditionally, the `exes` field must be defined with a list of scripts that will be executed within\nthe backend.\n\nAs an example, here's how the `asdf` backend is implemented:\n\n```\n#[plugin_fn]pub fn register_backend(    Json(input): Json,) -> FnResult> {    Ok(Json(RegisterBackendOutput {        backend_id: get_plugin_id()?,        exes: vec![            \"bin/download\".into(),            \"bin/exec-env\".into(),            \"bin/install\".into(),            \"bin/latest-stable\".into(),            \"bin/list-all\".into(),            \"bin/list-bin-paths\".into(),            \"bin/list-legacy-filenames\".into(),            \"bin/parse-legacy-file\".into(),            \"bin/uninstall\".into(),        ],        source: Some(SourceLocation::Git(GitSource {            url: \"https://github.com/asdf-vm/asdf-nodejs.git\".into(),            ..Default::default()        })),    }))}\n```\n\nThese scripts can then be accessed on the file system using the following virtual path.\n\n```\nPathBuf::from(\"/proto/backends///bin/install\")\n```\n\n### Configuration schemav0.53.0\n\nIf you are using [backend configuration](#backend-configuration), you can register the shape of the\nconfiguration using the [`schematic`](https://crates.io/crates/schematic) crate and the\n`define_backend_config` function. This shape will be used to generate outputs such as JSON schemas,\nor TypeScript types.\n\n```\n#[plugin_fn]pub fn define_backend_config(_: ()) -> FnResult> {    Ok(Json(DefineBackendConfigOutput {        schema: Some(schematic::SchemaBuilder::generate::()),    }))}\n```\n\nSchematic is a heavy library, so we suggest adding the dependency like so:\n\n```\n[dependencies]schematic = { version = \"\", default-features = false, features = [\"schema\"] }\n```\n\n## Testing\n\nThe best way to test the plugin is to execute it through `proto` directly. To do this, you'll need\nto configure a `.prototools` file at the root of your plugin's repository that maps the plugin to a\ndebug build:\n\n```\n[plugins.tools] = \"file://./target/wasm32-wasip1/debug/.wasm\"\n```\n\nAnd everytime you make a change to the plugin, you'll need to rebuild it with:\n\n```\ncargo build --target wasm32-wasip1\n```\n\nWith these 2 pieces in place, you can now execute `proto` commands. Be sure you're running them from\nthe directory with the `.prototools` file, and that you're passing `--log trace`. Logs are extremely\nhelpful for figuring out what's going on.\n\n```\nproto --log trace install proto --log trace list-remote ...\n```\n\n### Unit tests\n\nTesting WASM plugins is a bit tricky, but we've taken it upon ourselves to streamline this process\nas much as possible with built-in test utilities, and Rust macros for generating common test cases.\nTo begin, install all necessary development dependencies:\n\n```\ncargo add --dev proto_pdk_test_utils starbase_sandbox tokio\n```\n\nAnd as mentioned above, everytime you make a change to the plugin, you'll need to rebuild it with:\n\n```\ncargo build --target wasm32-wasip1\n```\n\n#### Testing plugin functions\n\nThe common test case is simply calling plugin functions with a provided input and asserting the\noutput is correct. This can be achieved by creating a plugin instance with `create_plugin` and\ncalling the appropriate method.\n\n```\nuse proto_pdk_test_utils::*;use starbase_sandbox::create_empty_sandbox;#[tokio::test(flavor = \"multi_thread\")]async fn registers_metadata() {    let sandbox = create_empty_proto_sandbox();    let plugin = sandbox.create_plugin(\"id\").await;    assert_eq!(        plugin.register_tool(RegisterToolInput::default()).await,        RegisterToolOutput {            name: \"Name\".into(),            ..RegisterToolOutput::default()        }    );}\n```\n\ninfo\n\nWe suggest using this pattern for static functions that return a deterministic output from a\nprovided input, and not for dynamic functions that make HTTP requests or execute host commands.\n\n#### Generating cases from macros\n\nTo reduce the burden of writing custom tests for common flows, like downloading a pre-built,\nresolving versions, and generating shims, we provide a set of Rust decl macros that will generate\nthe tests for you.\n\nTo test downloading and installing, use `generate_download_install_tests!`. This macro requires a\nplugin ID and a real version to test with.\n\n```\nuse proto_pdk_test_utils::*;generate_download_install_tests!(\"id\", \"1.2.3\");\n```\n\nTo test version resolving, use `generate_resolve_versions_tests!`. This macro requires a plugin ID,\nand a mapping of version/aliases assertions to expectations.\n\n```\ngenerate_resolve_versions_tests!(\"id\", {    \"0.4\" => \"0.4.12\",    \"0.5.1\" => \"0.5.1\",    \"stable\" => \"1.0.0\",});\n```\n\nTo test installing and uninstalling globals, use `generate_globals_test!`. This macro requires a\nplugin ID, the dependency to install, and an optional environment variable to the globals directory.\n\n```\n// Doesn't support all use cases! If this doesn't work, implement a test case manually.generate_globals_test!(\"id\", \"dependency\", \"GLOBAL_INSTALL_ROOT\");\n```\n\nAnd lastly, to test shims, use `generate_shims_test!`. This requires a plugin ID and a list of shim\nfile names. This macro generates snapshots using [Insta](https://insta.rs/).\n\n```\ngenerate_shims_test!(\"id\", [\"primary\", \"secondary\"]);\n```\n\n## Building and publishing\n\nsuccess\n\nRefer to our [official WASM guide](/docs/guides/wasm-plugins#building-and-publishing) for steps on how\nto build and publish your plugin.\n\n## Resources\n\nSome helpful resources for learning about and building plugins.\n\n- [Official proto WASM plugins](https://github.com/moonrepo/plugins)\n\n- Plugin development kit [`proto_pdk` docs](https://docs.rs/proto_pdk/)\n\n- [`proto_pdk_test_utils` docs](https://docs.rs/proto_pdk_test_utils/)\n\n## /docs/proto/workflows\n\nSource: https://moonrepo.dev/docs/proto/workflows\n\n# Workflows\n\nWith proto, we provide multiple workflows for everyday use for you to choose from. They can be used\nindividually, or together, it's up to you!\n\n## Shims\n\nproto is primarily powered by the industry standard concept of shims. For each tool installed in\nproto, a shim file will exist at `~/.proto/shims` for the primary executable, and some secondary\nexecutables. Shims are not symlinks to the tool's binary, but are thin wrappers around\n[`proto run`](/docs/proto/commands/run), enabling [runtime version detection](/docs/proto/detection) on every\ninvocation! For example, these are equivalent:\n\n```\n$ proto run node -- --version20.0.0$ node --version20.0.0$ which node~/.proto/shims/node\n```\n\n### Setup\n\nTo make use of shims, prepend the `~/.proto/shims` directory to `PATH` in your shell profile. This\nmust come before the [bin directory](#binary-linking) if using both.\n\nIf you're using or plan to use [shell activation](#shell-activation), the `PATH` configuration\nhappens automatically, but shell activation will only work if the `proto` command is accessible,\nwhich requires `~/.proto/bin` to be in your `PATH`.\n\n## Binary linking\n\nAlternatively, we also support a non-shim based approach, which creates symlinks to a versioned\ntool's primary and secondary executables. For each tool installed in proto, a symlink will exist at\n`~/.proto/bin`.\n\n```\n$ node --version23.1.0$ which node~/.proto/bin/node -> ~/.proto/tools/node/23.1.0/bin/node\n```\n\nWhen a tool is installed into proto, we symlink many binaries based on all the versions that are\ninstalled in the toolchain. The primary binary will always point to the highest installed version,\nwhile we also create binaries for the highest major, and highest major + minor combinations. For\nexample:\n\n- `~/.proto/bin/node` - Points to the highest version.\n\n- `~/.proto/bin/node-` - Points to the highest version within that major range (`~major`). Is created for each separate major version, for example: `node-20`, `node-22`.\n\n- `~/.proto/bin/node-.` - Points to the highest version within that major + minor range (`~major.minor`). Is created for each separate major + minor version, for example: `node-20.1`, `node-22.4`.\n\n- `~/.proto/bin/node-canary` - Points to a canary install, if it exists.\n\n```\n$ node-22 --version22.5.1$ which node-22~/.proto/bin/node-22 -> ~/.proto/tools/node/22.5.1/bin/node\n```\n\ninfo\n\nNot all tools support symlinking a binary, as not all files are executable. For example, most\nNode.js package managers currently do not support this, as JavaScript files are not executable\n(especially on Windows). Shims are required for these tools.\n\n### Setup\n\nTo make use of bins, prepend the `~/.proto/bin` directory to `PATH` in your shell profile. This\nmust come after the [shim directory](#shims) if using shims.\n\nIf you're using or plan to use [shell activation](#shell-activation), the `PATH` configuration\nhappens automatically, but shell activation will only work if the `proto` command is accessible,\nwhich requires `~/.proto/bin` to be in your `PATH`.\n\nwarning\n\nThis directory must always exist in `PATH`, as the official proto binaries `~/.proto/bin/proto` and\n`~/.proto/bin/proto-shim` are located here. If you move those binaries to another location, you can\nomit `~/.proto/bin` from `PATH` if you like.\n\n## Shell activationv0.38.0\n\nOur last workflow is what we call shell activation (or shell hooks), and it's where the proto\nenvironment is setup/reset every time you change directories. If you're coming from another version\nmanager, you may be familiar with this kind of workflow.\n\nSo how does this work exactly? In your shell profile, you'll evaluate a call to\n[`proto activate `](/docs/proto/commands/activate), which generates a bunch of shell specific syntax\nthat registers a hook for \"run this code when the current directory or prompt line changes\". Once\nthis hook is registered and you run `cd` (for example), proto will...\n\n- Load all `.prototools` files\n\n- Extract tools with a [configured version](/docs/proto/config#pinning-versions)\n\n- For each tool: Load associated WASM plugin\n\n- Export environment variables based on [`[env]`](/docs/proto/config#env) and [`[tools.*.env]`](/docs/proto/config#toolsenv)\n\n- Prepend `PATH` with tool-specific directories (like local and global executables) for the detected version\n\n```\n$ cd /some/path && node --version20.0.0$ cd /another/path && node --version18.0.0\n```\n\n### Setup\n\nView the [`proto activate`](/docs/proto/commands/activate#setup) documentation for information on how to setup\nyour shell profile for this workflow.\n\n## Comparison\n\nThe workflows above may come across as information overload, so we've provided the following\ncomparison table outlining the features each workflow supports.\n\nShims Bins Activate\n\nRuntime version detection üü¢ üî¥ üü† only when the hook triggers\n\nSupports multiple versions üü¢ üü¢ üü¢\n\nFixed to a single version üü† with arg or env var üü¢ üü† if not using shims\n\nIncludes all tool executables üî¥ üî¥ üü¢\n\nIncludes tool globals/packages üî¥ üî¥ üü¢\n\nExports environment variables üî¥ üî¥ üü¢\n\nPrepends `PATH` üî¥ üî¥ üü¢\n\nCan pin proto's version üî¥ üî¥ üü¢\n\n## /docs/run-task\n\nSource: https://moonrepo.dev/docs/run-task\n\n# Run a task\n\n2 min\n\nEven though we've [created a task](/docs/create-task), it's not useful unless we run it, which is done\nwith the [`moon run `](/docs/commands/run) command. This command requires a single argument, a\n[primary target](/docs/concepts/target), which is the pairing of a scope and task name. In the example\nbelow, our project is `app`, the task is `build`, and the target is `app:build`.\n\n```\n$ moon run app:build\n```\n\nWhen this command is ran, it will do the following:\n\n- Generate a directed acyclic graph, known as the action (dependency) graph.\n\n- Insert [`deps`](/docs/config/project#deps) as targets into the graph.\n\n- Insert the primary target into the graph.\n\n- Run all tasks in the graph in parallel and in topological order (the dependency chain).\n\n- For each task, calculate [hashes](/docs/concepts/cache) and either: On cache hit, exit early and return the last run.\n\n- On cache miss, run the task and generate a new cache.\n\n## Running dependents\n\nmoon will always run upstream dependencies ([`deps`](/docs/config/project#deps)) before running the\nprimary target, as their outputs may be required for the primary target to function correctly.\n\nHowever, if you're working on a project that is shared and consumed by other projects, you may want\nto verify that downstream dependents have not been indirectly broken by any changes. This can be\nachieved by passing the `--dependents` option, which will run dependent targets after the primary\ntarget.\n\n```\n$ moon run app:build --dependents\n```\n\n## Running based on affected files only\n\nBy default [`moon run`](/docs/commands/run) will always run the target, regardless if files have\nactually changed. However, this is typically fine because of our\n[smart hashing & cache layer](/docs/concepts/cache). With that being said, if you'd like to only run a\ntarget if files have changed, pass the `--affected` flag.\n\n```\n$ moon run app:build --affected\n```\n\nUnder the hood, we extract locally touched (created, modified, staged, etc) files from your\nconfigured [VCS](/docs/config/workspace#vcs), and exit early if no files intersect with the task's\n[inputs](/docs/config/project#inputs).\n\n### Using remote changes\n\nIf you'd like to determine affected files based on remote changes instead of local changes, pass the\n`--remote` flag. This will extract touched files by comparing the current `HEAD` against the\n[`vcs.defaultBranch`](/docs/config/workspace#defaultbranch).\n\n```\n$ moon run app:build --affected --remote\n```\n\n### Filtering based on change status\n\nWe can take this a step further by filtering down affected files based on a change status, using the\n`--status` option. This option accepts the following values: `added`, `deleted`, `modified`,\n`staged`, `unstaged`, `untracked`. If not provided, the option defaults to all.\n\n```\n$ moon run app:build --affected --status deleted\n```\n\nMultiple status can be provided by passing the `--status` option multiple times.\n\n```\n$ moon run app:build --affected --status deleted --status modified\n```\n\n## Passing arguments to the underlying command\n\nIf you'd like to pass arbitrary arguments to the underlying task command, in addition to the already\ndefined [`args`](/docs/config/project#args), you can pass them after `--`. These arguments are appended\nas-is.\n\n```\n$ moon run app:build -- --force\n```\n\nThe `--` delimiter and any arguments must be defined last on the command line.\n\n## Advanced run targeting\n\nBy this point you should have a basic understanding of how to run tasks, but with moon, we want to\nprovide support for advanced workflows and development scenarios. For example, running a target in\nall projects:\n\n```\n$ moon run :build\n```\n\nOr perhaps running a target based on a query:\n\n```\n$ moon run :build --query \"language=[javascript, typescript]\"\n```\n\nJump to the official [`moon run` documentation](/docs/commands/run) for more examples!\n\n## Next steps\n\n[Migrate to moon](/docs/migrate-to-moon)[Learn about tasks](/docs/concepts/task)[Learn about `moon run`](/docs/commands/run)\n\n## /docs/setup-toolchain\n\nSource: https://moonrepo.dev/docs/setup-toolchain\n\n# Setup toolchain\n\n5 min\n\nOne of moon's most powerful features is the [toolchain](/docs/concepts/toolchain), which automatically\nmanages, downloads, and installs Node.js and other languages behind the scenes using\n[proto](/proto). It also enables [advanced functionality](/docs/how-it-works/languages#tier-2--platform)\nfor task running based on the platform (language and environment combination) it runs in.\n\nThe toolchain is configured with [`.moon/toolchains.yml`](/docs/config/toolchain).\n\ntip\n\nChange the language dropdown at the top right to switch the examples!\n\n## How it works\n\nFor more information on the toolchain, our tier based support, and how languages integrate into\nmoon, refer to the official [\"how it works\" language guide](/docs/how-it-works/languages) and the\n[toolchain concept](/docs/concepts/toolchain) documentation!\n\ninfo\n\nThe toolchain is optional but helps to solve an array of issues that developers face in their\nday-to-day.\n\n## Enabling a toolchain\n\nBy default all tasks run through the\n[system toolchain](/docs/how-it-works/languages#system-language-and-toolchain) and inherit no special\nfunctionality. If you want to take advantage of this functionality, like dependency hashing, package\nshorthand execution, and lockfile management, you'll need to enable the toolchain in\n[`.moon/toolchains.yml`](/docs/config/toolchain). Otherwise, you can skip to the\n[create a task](/docs/create-task) guide.\n\nBegin by declaring the necessary configuration block, even if an empty object! This configuration\ncan also be injected using the [`moon toolchain add `](/docs/commands/toolchain/add) command\n(doesn't support all languages).\n\n.moon/toolchains.yml\n\n```\njavascript:  packageManager: 'yarn'node: {}yarn: {}\n```\n\nAlthough we've enabled the toolchain, language binaries must exist on `PATH` for task execution to\nfunction correctly. Continue reading to learn how to automate this flow using tier 3 support.\n\n## Automatically installing a tool\n\nOne of the best features of moon is its integrated toolchain and automatic download and installation\nof programming languages (when supported), for all developers and machines that moon runs on. This\nfeature solves the following pain points:\n\n- Developers running tasks using different versions of languages.\n\n- Version drift of languages between machines.\n\n- Languages being installed through different version managers or install scripts.\n\n- Language binaries not existing on `PATH`.\n\n- How shell profiles should be configured.\n\nIf you have dealt with any of these pain points before and would like to eliminate them for you and\nall your developers, you can try enabling moon's tier 3 support for supported tools. This is easily\ndone by defining the `version` field for each toolchain.\n\n.moon/toolchains.yml\n\n```\njavascript:  packageManager: 'yarn'node:  version: '20.0.0'yarn:  version: '4.0.0'\n```\n\nWhen the `version` field is configured, moon will download and install the tool when a related task\nis executed for the first time! It will also set the correct `PATH` lookups and environment\nvariables automatically. Amazing right?\n\n## Next steps\n\n[Create a task](/docs/create-task)[Configure `.moon/toolchains.yml` further](/docs/config/toolchain)[Learn about the toolchain](/docs/concepts/toolchain)\n\n## /docs/setup-workspace\n\nSource: https://moonrepo.dev/docs/setup-workspace\n\n# Setup workspace\n\n2 min\n\nOnce moon has been [installed](/docs/install), we must setup the [workspace](/docs/concepts/workspace),\nwhich is denoted by the `.moon` folder ‚Äî this is known as the workspace root. The workspace is in\ncharge of:\n\n- Integrating with a version control system.\n\n- Defining configuration that applies to its entire tree.\n\n- Housing [projects](/docs/concepts/project) to build a [project graph](/docs/how-it-works/project-graph).\n\n- Running tasks with the [action graph](/docs/how-it-works/action-graph).\n\n## Initializing the repository\n\nLet's scaffold and initialize moon in a repository with the [`moon init`](/docs/commands/init) command.\nThis should typically be ran at the root, but can be nested within a directory.\n\n```\n$ moon init\n```\n\nWhen executed, the following operations will be applied.\n\n- Creates a `.moon` folder with a [`.moon/workspace.yml`](/docs/config/workspace) configuration file.\n\n- Appends necessary ignore patterns to the relative `.gitignore`.\n\n- Infers the version control system from the environment.\n\ninfo\n\nIf you're investigating moon, or merely want to prototype, you can use `moon init --minimal` to\nquickly initialize and create minimal configuration files.\n\n## Migrate from an existing build system\n\nLooking to migrate from Nx or Turborepo to moon? Use our\n[`moon ext migrate-nx`](/docs/guides/extensions#migrate-nx) or\n[`moon ext migrate-turborepo`](/docs/guides/extensions#migrate-turborepo) commands for a (somewhat)\nseamless migration!\n\nThese extensions will convert your existing configuration files to moon's format as best as\npossible, but is not a requirement.\n\n## Configuring a version control system\n\nmoon requires a version control system (VCS) to be present for functionality like file diffing,\nhashing, and revision comparison. The VCS and its default branch can be configured through the\n[`vcs`](/docs/config/workspace#vcs) setting.\n\n.moon/workspace.yml\n\n```\nvcs:  manager: 'git'  defaultBranch: 'master'\n```\n\nmoon defaults to `git` and the settings above, so feel free to skip this.\n\n## Next steps\n\n[Create a project](/docs/create-project)[Configure `.moon/workspace.yml` further](/docs/config/workspace)[Learn about the workspace](/docs/concepts/workspace)\n\n## /docs/terminology\n\nSource: https://moonrepo.dev/docs/terminology\n\n# Terminology\n\nTerm Description\n\nAction A node within the dependency graph that gets executed by the action pipeline.\n\nAction pipeline Executes actions from our dependency graph in topological order using a thread pool.\n\nAffected Touched by an explicit set of inputs or sources.\n\nCache Files and outputs that are stored on the file system to provide incremental builds and increased performance.\n\nCI Continuous integration. An environment where tests, builds, lints, etc, are continuously ran on every pull/merge request.\n\nDependency graph A directed acyclic graph (DAG) of targets to run and their dependencies.\n\nDownstream Dependents or consumers of the item in question.\n\n[Generator](/docs/guides/codegen) Generates code from pre-defined templates.\n\nHash A unique SHA256 identifier that represents the result of a ran task.\n\nHashing The mechanism of generating a hash based on multiple sources: inputs, dependencies, configs, etc.\n\nLTS Long-term support.\n\nDependency manager Installs and manages dependencies for a specific tool (`npm`), using a manifest file (`package.json`).\n\nPlatform An internal concept representing the integration of a programming language (tool) within moon, and also the environment + language that a task runs in.\n\nPrimary target The target that was explicitly ran, and is the dependee of transitive targets.\n\n[Project](/docs/concepts/project) An collection of source and test files, configurations, a manifest and dependencies, and much more. Exists within a [workspace](/docs/concepts/workspace)\n\nRevision In the context of a VCS: a branch, revision, commit, hash, or point in history.\n\nRuntime An internal concept representing the platform + version of a tool.\n\n[Target](/docs/concepts/target) A label and reference to a task within the project, in the format of `project:task`.\n\n[Task](/docs/concepts/task) A command to run within the context of and configured in a [project](/docs/concepts/project).\n\nTemplate A collection of files that get scaffolded by a generator.\n\nTemplate file An individual file within a template.\n\nTemplate variable A value that is interpolated within a template file and its file system path.\n\n[Token](/docs/concepts/token) A value within task configuration that is substituted at runtime.\n\nTool A programming language or dependency manager within the [toolchain](/docs/concepts/toolchain).\n\n[Toolchain](/docs/concepts/toolchain) Installs and manages tools within the [workspace](/docs/concepts/workspace).\n\nTransitive target A target that is the dependency of the primary target, and must be ran before the primary.\n\nTouched A file that has been created, modified, deleted, or changed in any way.\n\nUpstream Dependencies or producers of the item in question.\n\nVCS Version control system (like Git or SVN).\n\n[Workspace](/docs/concepts/workspace) Root of the moon installation, and houses one or many [projects](/docs/concepts/project). Also refers to package manager workspaces (like Yarn).\n\n\n----\n## Notes / Comments / Lessons\n\n- Collection method: sitemap URL discovery + markdown conversion (r.jina.ai primary, direct HTML fallback parser secondary).\n- Most docs pages are content-rich and command-oriented; command reference and config schemas are the highest-density sections.\n- For ongoing updates, re-run this script to refresh snapshots and compare diffs over time.\n- Capture results: success=171, failed=0.\n----\n",
              "additions": 19948,
              "deletions": 0,
              "status": "added"
            },
            {
              "file": "docs/readmes/protobuf-schema-research.md",
              "before": "",
              "after": "# Protobuf Schema Research Notes\n\nLast reviewed: 2026-02-15\n\n## Scope\n\n- Capture practical notes for authoring new `.proto` schemas.\n- Support both `proto2` and `proto3` workflows.\n- Document `protoc` usage for Rust and TypeScript generation paths.\n\n## Primary web sources\n\n- OpenCode skills docs: https://opencode.ai/docs/skills/\n- Protoc install docs: https://protobuf.dev/installation/\n- Proto2 guide: https://protobuf.dev/programming-guides/proto2/\n- Proto3 guide: https://protobuf.dev/programming-guides/proto3/\n- Field presence note: https://protobuf.dev/programming-guides/field_presence/\n- Rust generated code guide: https://protobuf.dev/reference/rust/rust-generated/\n- Rust build reference: https://protobuf.dev/reference/rust/building-rust-protos/\n- `prost-build` docs: https://docs.rs/prost-build/latest/prost_build/\n- `tonic-prost-build` docs: https://docs.rs/tonic-prost-build/latest/tonic_prost_build/\n- `ts-proto` README: https://github.com/stephenh/ts-proto\n- `protobuf-ts` README: https://github.com/timostamm/protobuf-ts\n\n## Proto2 vs proto3 (what matters most)\n\n- **Syntax line**\n  - `proto2`: `syntax = \"proto2\";`\n  - `proto3`: `syntax = \"proto3\";`\n- **Cardinality labels**\n  - `proto2`: `optional`, `required` (strongly discouraged), `repeated`, `map`.\n  - `proto3`: `optional` (recommended), implicit singular (legacy style), `repeated`, `map`.\n- **Required fields**\n  - `proto2` only, but strongly discouraged for new schemas.\n  - Not available in `proto3`.\n- **Scalar default overrides**\n  - `proto2`: supports `[default = ...]` on singular non-message fields.\n  - `proto3`: no custom scalar defaults; language defaults apply.\n- **Field presence**\n  - `proto2`: explicit presence for singular fields.\n  - `proto3`: explicit presence only with `optional` (or oneof/message); otherwise implicit for basic scalars.\n  - Proto docs recommend using `optional` in proto3 for smoother compatibility.\n- **Enum zero value**\n  - `proto3`: first enum value must be `0`.\n  - `proto2`: first value is default; using `_UNSPECIFIED = 0` is still safest.\n- **Extensions and groups**\n  - `proto2`: supports extensions; groups exist but are deprecated.\n  - `proto3`: no general extension fields/groups in the same way.\n- **Repeated scalar packing**\n  - `proto2`: use `[packed = true]` for new repeated numeric fields.\n  - `proto3`: repeated scalar numerics are packed by default.\n- **Unknown fields**\n  - Preserved in both proto2 and proto3 (binary format).\n- **Interop note**\n  - Proto2 and proto3 messages can interoperate across imports, but proto2 enums cannot be used directly in proto3 syntax.\n\n## Safe schema evolution checklist\n\n- Never renumber existing fields.\n- Never reuse deleted field numbers.\n- Reserve removed field numbers and names using `reserved`.\n- Prefer additive changes: add new fields, do not mutate existing wire meaning.\n- Avoid `required` for new work.\n- Use `oneof` when exactly one field must be present.\n\n## Protoc usage basics\n\n- Verify installation:\n\n```bash\nprotoc --version\n```\n\n- General compile shape:\n\n```bash\nprotoc -I proto --<LANG>_out=gen/<lang> proto/path/to/file.proto\n```\n\n- Validate schema and emit descriptor set (useful for CI checks):\n\n```bash\nprotoc -I proto --include_imports --descriptor_set_out=gen/schema.pb proto/path/to/file.proto\n```\n\n## Rust generation patterns\n\nRust codegen is commonly done in `build.rs` wrappers that call `protoc` for you.\n\n- `prost-build` example (`build.rs`):\n\n```rust\nfn main() -> std::io::Result<()> {\n    prost_build::compile_protos(&[\"proto/service.proto\"], &[\"proto\"])?;\n    Ok(())\n}\n```\n\n- `tonic-prost-build` example (`build.rs`):\n\n```rust\nfn main() {\n    tonic_prost_build::configure()\n        .compile_protos(&[\"proto/service.proto\"], &[\"proto\"])\n        .unwrap();\n}\n```\n\n- `protobuf` crate ecosystem example (`build.rs`, from protobuf-example):\n\n```rust\nuse protobuf_codegen::CodeGen;\n\nfn main() {\n    CodeGen::new()\n        .inputs([\"proto_example/foo.proto\", \"proto_example/bar/bar.proto\"])\n        .include(\"proto\")\n        .dependency(protobuf_well_known_types::get_dependency(\"protobuf_well_known_types\"))\n        .generate_and_compile()\n        .unwrap();\n}\n```\n\n## TypeScript generation patterns\n\nTypeScript typically uses `protoc` plugins.\n\n- `ts-proto` quickstart:\n\n```bash\nprotoc \\\n  --plugin=./node_modules/.bin/protoc-gen-ts_proto \\\n  --ts_proto_out=gen/ts \\\n  --ts_proto_opt=esModuleInterop=true \\\n  -I proto \\\n  proto/path/to/file.proto\n```\n\n- `@protobuf-ts/plugin` quickstart:\n\n```bash\nnpx protoc --ts_out gen/ts --proto_path proto proto/path/to/file.proto\n```\n\n## Agent defaults for new schema requests\n\n- Ask which syntax to use: `proto2` or `proto3`.\n- If unspecified, recommend `proto3` with explicit `optional` for scalar presence.\n- Ask which TypeScript generator to target: `ts-proto` or `@protobuf-ts/plugin`.\n- If unspecified, recommend `ts-proto` for idiomatic TS interfaces and flexible options.\n- Always call out features that are syntax-specific (for example `required`/extensions/default overrides in proto2).\n",
              "additions": 151,
              "deletions": 0,
              "status": "added"
            },
            {
              "file": "scripts/scrape_moon_docs.sh.ts",
              "before": "",
              "after": "#!/usr/bin/env bun\n\nimport { mkdirSync } from \"node:fs\";\nimport { dirname, resolve } from \"node:path\";\nimport { findRepoRoot } from \"./helpers/run_root.sh.ts\";\n\ntype ScrapeResult = {\n  url: string;\n  ok: boolean;\n  markdown?: string;\n  error?: string;\n};\n\nconst SITEMAP_URL = \"https://moonrepo.dev/sitemap.xml\";\nconst DOCS_ROOT = \"https://moonrepo.dev/docs\";\nconst DEFAULT_OUTPUT_RELATIVE =\n  \"docs/external/moonrepo/moonrepo_docs.ext.md\";\nconst CONCURRENCY = 4;\n\nfunction decodeEntities(value: string): string {\n  return value\n    .replaceAll(\"&amp;\", \"&\")\n    .replaceAll(\"&quot;\", '\"')\n    .replaceAll(\"&apos;\", \"'\")\n    .replaceAll(\"&#x27;\", \"'\")\n    .replaceAll(\"&#39;\", \"'\")\n    .replaceAll(\"&nbsp;\", \" \")\n    .replaceAll(\"&lt;\", \"<\")\n    .replaceAll(\"&gt;\", \">\");\n}\n\nfunction stripJinaEnvelope(markdown: string): string {\n  return markdown\n    .replace(/^Title:.*?\\nURL Source:.*?\\nMarkdown Content:\\n/s, \"\")\n    .trim();\n}\n\nfunction stripTags(value: string): string {\n  return value.replace(/<[^>]+>/g, \"\");\n}\n\nfunction plainTextFromHtml(value: string): string {\n  return decodeEntities(stripTags(value).replace(/\\s+/g, \" \")).trim();\n}\n\nfunction extractMainHtml(html: string): string {\n  const markdownBlockMatch = html.match(\n    /<div class=\"theme-doc-markdown markdown\">([\\s\\S]*?)<footer class=\"theme-doc-footer/s,\n  );\n\n  if (markdownBlockMatch?.[1]) {\n    return markdownBlockMatch[1];\n  }\n\n  const articleMatch = html.match(/<article>([\\s\\S]*?)<\\/article>/s);\n  if (articleMatch?.[1]) {\n    return articleMatch[1];\n  }\n\n  const mainMatch = html.match(/<main[^>]*>([\\s\\S]*?)<\\/main>/s);\n  return mainMatch?.[1] ?? html;\n}\n\nfunction htmlToMarkdown(html: string): string {\n  let content = extractMainHtml(html);\n\n  content = content\n    .replace(/<script[\\s\\S]*?<\\/script>/gi, \"\")\n    .replace(/<style[\\s\\S]*?<\\/style>/gi, \"\")\n    .replace(/<a[^>]*class=\"hash-link\"[^>]*>[\\s\\S]*?<\\/a>/gi, \"\")\n    .replace(/<span[^>]*aria-hidden=\"true\"[^>]*>[\\s\\S]*?<\\/span>/gi, \"\");\n\n  content = content.replace(\n    /<pre[^>]*><code[^>]*>([\\s\\S]*?)<\\/code><\\/pre>/gi,\n    (_match, code) => {\n      const normalizedCode = decodeEntities(\n        stripTags(code)\n          .replace(/<br\\s*\\/?>/gi, \"\\n\")\n          .replace(/\\n{3,}/g, \"\\n\\n\")\n          .trim(),\n      );\n\n      if (!normalizedCode) {\n        return \"\";\n      }\n\n      return `\\n\\n\\`\\`\\`\\n${normalizedCode}\\n\\`\\`\\`\\n\\n`;\n    },\n  );\n\n  content = content.replace(/<code[^>]*>([\\s\\S]*?)<\\/code>/gi, (_match, code) => {\n    const normalizedCode = decodeEntities(stripTags(code)).trim();\n    return normalizedCode ? `\\`${normalizedCode}\\`` : \"\";\n  });\n\n  content = content.replace(/<a[^>]*href=\"([^\"]+)\"[^>]*>([\\s\\S]*?)<\\/a>/gi, (_m, href, label) => {\n    const text = plainTextFromHtml(label);\n    if (!text) {\n      return \"\";\n    }\n\n    return `[${text}](${decodeEntities(href)})`;\n  });\n\n  content = content.replace(/<h([1-6])[^>]*>([\\s\\S]*?)<\\/h\\1>/gi, (_match, level, inner) => {\n    const heading = plainTextFromHtml(inner);\n    if (!heading) {\n      return \"\";\n    }\n\n    return `\\n\\n${\"#\".repeat(Number(level))} ${heading}\\n\\n`;\n  });\n\n  content = content.replace(/<li[^>]*>([\\s\\S]*?)<\\/li>/gi, (_match, inner) => {\n    const line = plainTextFromHtml(inner);\n    return line ? `- ${line}\\n` : \"\";\n  });\n\n  content = content\n    .replace(/<br\\s*\\/?>/gi, \"\\n\")\n    .replace(/<\\/(p|div|section|article|header|ul|ol|table|tr)>/gi, \"\\n\\n\")\n    .replace(/<(p|div|section|article|header|ul|ol|table|tr)[^>]*>/gi, \"\\n\")\n    .replace(/<t[hd][^>]*>([\\s\\S]*?)<\\/t[hd]>/gi, (_match, inner) => {\n      const cell = plainTextFromHtml(inner);\n      return cell ? `${cell} ` : \"\";\n    });\n\n  content = decodeEntities(content)\n    .replace(/<[^>]+>/g, \"\")\n    .replace(/[ \\t]+\\n/g, \"\\n\")\n    .replace(/\\n{3,}/g, \"\\n\\n\")\n    .trim();\n\n  return content;\n}\n\nfunction extractDocsUrls(sitemapXml: string): string[] {\n  const urls = Array.from(sitemapXml.matchAll(/<loc>(.*?)<\\/loc>/g), (match) =>\n    decodeEntities(match[1]?.trim() ?? \"\"),\n  )\n    .filter((url) => url.startsWith(DOCS_ROOT))\n    .filter((url) => !url.includes(\"/docs/tags\"))\n    .filter((url) => !url.includes(\"#\"));\n\n  return Array.from(new Set(urls)).sort((a, b) => a.localeCompare(b));\n}\n\nasync function fetchText(url: string): Promise<string> {\n  const response = await fetch(url, {\n    headers: {\n      \"user-agent\": \"dark-factory-doc-scraper/1.0\",\n    },\n  });\n\n  if (!response.ok) {\n    throw new Error(`Request failed (${response.status}) for ${url}`);\n  }\n\n  return await response.text();\n}\n\nasync function mapConcurrent<T, R>(\n  values: T[],\n  limit: number,\n  map: (value: T, index: number) => Promise<R>,\n): Promise<R[]> {\n  const results = new Array<R>(values.length);\n  let index = 0;\n\n  async function worker(): Promise<void> {\n    while (true) {\n      const currentIndex = index;\n      index += 1;\n\n      if (currentIndex >= values.length) {\n        return;\n      }\n\n      results[currentIndex] = await map(values[currentIndex], currentIndex);\n    }\n  }\n\n  const workerCount = Math.min(limit, values.length);\n  await Promise.all(Array.from({ length: workerCount }, () => worker()));\n  return results;\n}\n\nasync function scrapeDocsPage(url: string, count: number, total: number): Promise<ScrapeResult> {\n  const jinaUrl = `https://r.jina.ai/http://${url.replace(/^https?:\\/\\//, \"\")}`;\n\n  try {\n    console.log(`Docs // Scrape // ${count}/${total} ${url}`);\n    try {\n      const markdown = stripJinaEnvelope(await fetchText(jinaUrl));\n\n      if (markdown) {\n        return {\n          url,\n          ok: true,\n          markdown,\n        };\n      }\n    } catch {\n      // Fall through to direct HTML scrape.\n    }\n\n    const html = await fetchText(url);\n    const markdown = htmlToMarkdown(html);\n\n    if (!markdown) {\n      return {\n        url,\n        ok: false,\n        error: \"No markdown content returned from HTML fallback\",\n      };\n    }\n\n    return {\n      url,\n      ok: true,\n      markdown,\n    };\n  } catch (error) {\n    return {\n      url,\n      ok: false,\n      error: error instanceof Error ? error.message : \"Unknown scrape error\",\n    };\n  }\n}\n\nfunction buildHeader(urlCount: number, capturedAt: string): string {\n  return [\n    \"----\",\n    \"## External Docs Snapshot // moonrepo\",\n    \"\",\n    `- Captured: ${capturedAt}`,\n    `- Source root: ${DOCS_ROOT}`,\n    `- Scope: ${urlCount} pages under /docs (excluding /docs/tags)`,\n    \"- Keywords: moon, monorepo, task graph, hashing, cache, toolchain, proto, workspace, codegen, query, migration, CI\",\n    \"- Summary: moonrepo documentation centers on deterministic task orchestration, project/dependency graphs, and reproducible toolchains with proto-backed version pinning.\",\n    \"----\",\n    \"\",\n  ].join(\"\\n\");\n}\n\nfunction buildFooter(successCount: number, failureCount: number): string {\n  return [\n    \"\",\n    \"----\",\n    \"## Notes / Comments / Lessons\",\n    \"\",\n    \"- Collection method: sitemap URL discovery + markdown conversion (r.jina.ai primary, direct HTML fallback parser secondary).\",\n    \"- Most docs pages are content-rich and command-oriented; command reference and config schemas are the highest-density sections.\",\n    \"- For ongoing updates, re-run this script to refresh snapshots and compare diffs over time.\",\n    `- Capture results: success=${successCount}, failed=${failureCount}.`,\n    \"----\",\n    \"\",\n  ].join(\"\\n\");\n}\n\nfunction buildPageSection(result: ScrapeResult): string {\n  if (!result.ok) {\n    return [\n      `## ${result.url.replace(\"https://moonrepo.dev\", \"\")}`,\n      \"\",\n      `Source: ${result.url}`,\n      \"\",\n      `> Scrape failed: ${result.error ?? \"unknown error\"}`,\n      \"\",\n    ].join(\"\\n\");\n  }\n\n  return [\n    `## ${result.url.replace(\"https://moonrepo.dev\", \"\")}`,\n    \"\",\n    `Source: ${result.url}`,\n    \"\",\n    result.markdown?.trim() ?? \"\",\n    \"\",\n  ].join(\"\\n\");\n}\n\nconst repoRoot = findRepoRoot(import.meta.dir);\nconst outputArg = Bun.argv[2];\nconst outputPath = resolve(repoRoot, outputArg ?? DEFAULT_OUTPUT_RELATIVE);\n\nconst sitemapXml = await fetchText(SITEMAP_URL);\nconst docsUrls = extractDocsUrls(sitemapXml);\n\nif (docsUrls.length === 0) {\n  throw new Error(\"No docs URLs found in moonrepo sitemap\");\n}\n\nconst results = await mapConcurrent(docsUrls, CONCURRENCY, (url, index) =>\n  scrapeDocsPage(url, index + 1, docsUrls.length),\n);\n\nconst successCount = results.filter((result) => result.ok).length;\nconst failureCount = results.length - successCount;\nconst capturedAt = new Date().toISOString();\n\nconst content = [\n  buildHeader(docsUrls.length, capturedAt),\n  ...results.map(buildPageSection),\n  buildFooter(successCount, failureCount),\n].join(\"\\n\");\n\nmkdirSync(dirname(outputPath), { recursive: true });\nawait Bun.write(outputPath, content);\n\nconsole.log(\n  `Docs // Scrape // Wrote external docs snapshot (pages=${docsUrls.length},ok=${successCount},failed=${failureCount},path=${outputPath})`,\n);\n",
              "additions": 314,
              "deletions": 0,
              "status": "added"
            }
          ]
        },
        "agent": "build",
        "model": {
          "providerID": "openai",
          "modelID": "gpt-5.3-codex"
        },
        "variant": "high",
        "id": "msg_c6484620d0011ltzji40BSbVp5",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "text",
          "text": "Research on web and take notes in @docs/ then make a @.opencode/skills/ (https://opencode.ai/docs/skills/ on making protocol buffer files / schemas (v2 and v3 supported - ask user which and note differeneces or if something is v2/v3 opnly) + protoc usage (rust and typscript) so opencode can make new .pb schemas for the user ",
          "id": "prt_c6484620d002BSPA76xP67zsKT",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6484620d0011ltzji40BSbVp5"
        },
        {
          "type": "file",
          "mime": "application/x-directory",
          "filename": "docs/",
          "url": "file:///Users/alex/repos/vfp/dark-factory/docs/",
          "source": {
            "text": {
              "value": "@docs/",
              "start": 34,
              "end": 40
            },
            "type": "file",
            "path": "docs/"
          },
          "id": "prt_c6484620d003cchtT4UC3bvzRj",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6484620d0011ltzji40BSbVp5"
        },
        {
          "type": "file",
          "mime": "application/x-directory",
          "filename": ".opencode/skills/",
          "url": "file:///Users/alex/repos/vfp/dark-factory/.opencode/skills/",
          "source": {
            "text": {
              "value": "@.opencode/skills/",
              "start": 53,
              "end": 71
            },
            "type": "file",
            "path": ".opencode/skills/"
          },
          "id": "prt_c6484620d004TCZJ6hj1UpApJi",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6484620d0011ltzji40BSbVp5"
        },
        {
          "type": "text",
          "text": "Called the Read tool with the following input: {\"filePath\":\"/Users/alex/repos/vfp/dark-factory/docs/\"}",
          "synthetic": true,
          "id": "prt_c6484621a001PQiNhi3V00xdhv",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6484620d0011ltzji40BSbVp5"
        },
        {
          "type": "text",
          "text": "<path>/Users/alex/repos/vfp/dark-factory/docs/</path>\n<type>directory</type>\n<entries>\ndesigns/\nreadmes/\n\n(2 entries)\n</entries>",
          "synthetic": true,
          "id": "prt_c6484621a002xeWISXW2dcE1lG",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6484620d0011ltzji40BSbVp5"
        },
        {
          "type": "text",
          "text": "Called the Read tool with the following input: {\"filePath\":\"/Users/alex/repos/vfp/dark-factory/.opencode/skills/\"}",
          "synthetic": true,
          "id": "prt_c6484621a003UxfyuIO3bEfyKz",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6484620d0011ltzji40BSbVp5"
        },
        {
          "type": "text",
          "text": "<path>/Users/alex/repos/vfp/dark-factory/.opencode/skills/</path>\n<type>directory</type>\n<entries>\ngitter-commit/\nproto-install/\nscript-authoring/\n\n(3 entries)\n</entries>",
          "synthetic": true,
          "id": "prt_c6484621b001ZJREHoS4wti0y1",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6484620d0011ltzji40BSbVp5"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771212923426,
          "completed": 1771212936342
        },
        "parentID": "msg_c6484620d0011ltzji40BSbVp5",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 17704,
          "input": 17083,
          "output": 621,
          "reasoning": 490,
          "cache": {
            "read": 0,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "tool-calls",
        "id": "msg_c64846222001R1pI2Bc6jf4Qt2",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "9d6f15c7b06acb730f3f74807178e28dcff70941",
          "id": "prt_c64846a09001aPCCLnw7JXDsnf",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64846222001R1pI2Bc6jf4Qt2"
        },
        {
          "type": "reasoning",
          "text": "**Planning protobuf skill research**",
          "metadata": {
            "openai": {
              "itemId": "rs_0dbefd661aace6a6016992907de6ec8193886c0bc5f74f654b",
              "reasoningEncryptedContent": "gAAAAABpkpCIeHv7wOxvO2LX_-eqxuQQlZEBbzMrQffjtD75BzczU4PSVbx9w8A_9sNTDfXTtEJiSytmNm4CuRtuZciLb6-TUG1v2TEq9yQBe04wVhAPtK28bgZV3Qj3HoGu99sypjXSe7JrZ0Xtl4XYdGJVtdzqfBMuV09ihm4MSkLNxvw8unaDmyutWCmlS4DfFlL0PLNaH4WE1ewbf7BLOFl7NRj5g9LoBZ4SNk-C535mnQdYyXQydlyuOhyRHLwRtmSHKbvKBkVZIVB4RjUolKy5Qh_GgVJRZtEqhaAUCDJbPbnaBqWzLCfLRAqvOsQgu96EwvqDV3Q_fb5iu5NXvkZLD_PAVmUPwXgBU9uw1k8RJJYaPp9kqUZGxSHI6JJXfkRQJDjggdVQ0LiG4M9F6UPpscWKpwZd19bB9gB3sc25qqeWsE0b90AwAnyOSRfTSa2YlBJ4msUqdWTkleF3N_-vF2FGpIfwMg7F2BVqXRLtW3EZAAt74H0Tt-VjedSF2RpzR4Rs2iMK4vzClclZph-ofICmTf5Z0dxYTyMOj7uQ2xO6eNAaFycifzICCmTq10Q572Iqp3o7vlC7bVDcSVefc9qMUIWpq-7AHA1Ta0v4pxap7llR0W3-MbyyxEnedqsENflibrwBPc_EGT1WrAjV7Vt6NuEquSEQqQyyYhBmermieIFBG6_i5fQw4-5SDC4vzgJ6dEkgukgQCngawboQH2Rrvbjmbi30BXmKv0pT16KQiKJlTBy0MtMGfcJ2lyR-zuWbz86Km4bQcYfbrlDJFWHeKhtnXPW1PMQjSvAoGXAer8Xfh3zlVs5v6UbZTcVLDhRboIDA8Ju1wHl-f-1Kly0uwsDBYtEgm0u7wKqLwc9B9t3klPjEg3DADmfwj-HHpCsPFtRGJ6kS7dcLngF27SGGFU8fhHRsVR2zSyKGKp-MDe7kAP0BQ2mxO1FzqESkhYhSdY1QatuENguzTednBsT9QcCTVS1KuloAgiRv43kPSuueWyrszWPa3tqVctHlpYVfUSC2fBQYnZ7AoZEGUrfZ5aVI8q6hE2fqpsM6ZkAUA1hQoWCGUMcdEhxm8nhqwlM80nARjIU3wg06O-cCVhBJAX_wBQIp4biP6gD8zcNjxJZX3TRwbTY2FxTcCfAXmCaje7sqF1mLmeEo6c93or_gtQhflk_CkmORQ0GI2ZwRV5GU0DE8p-Eg9S-JPSWoMzOWIxXs1-Z-B-mLGa_nDa67eOMP_9fWlarHwXo3alquREsN6BHm1mOE8zHWXSk8yA3YYqiAqVCAoDOmMe0rIWHhrn-rPGr88geDq9IXoINXo8oM03ioPkTeY3lHfy08tOGI4bWySmaD1-8KG_jL29ZonuSqfwx7bbr6HhNjxd1dX0krslMY9lC3mw-wy7BFmklTaVTLiVJ51Gg2pktkDxJMO1E12wbwcISUgJqDBG7kuLMjKmZeB5WPF5g8qY0G01YoJQAi_FC5U2G0oEmH6RVt7BODsLUFOCyaXrZI850p_j-fytmhDdJNfekcsQ22pcPnWLe9nCIb8zszhHahVcdv2aLurN0cbmHGQc4nkQZthOeOpTwATE3Ho1eESGePjMG-MKYjtfi0IRjXWWu6wv29jfh7XP0vFUWfLW3o6Wec6idoyyM1wH2AEVzB73wFyRdqHmGNv9yhMhvfRHljq4oug0i39yD2lBDmqZx-EdUGd5-OIOkUJQhsFaPgazA37wzUhdU9imLCs80eAJoEoi-yJ7TYNOgJVAQLjwFHmbWxSqiEP86IZLlFKPUYlnfaaFxG6PguY16XpIRlSHNAvZbyLKJU48pfnQMcpyXQ-VDiDiU9jzOXKw_8tQWnMFhrgBx6CfofpGivXrZevl3R_zbk-nnIKc_pxgliCS6rgJMP4l4O9Z4GcZucjcvGyBbNBcB-kWgNDOQHShtJXGF4xZ3ILNQ2eGh_tuVA6NAaqlxQgpQVbgL_Au-Z_jb1CY0T_jHV0bGXalfQuir-3Tq0grouApfQym4ggcZxY0dTvyh5udHKIiAc6JlyVb0rhrpeQHf_WsnFxmKsx-l04rbgnOTK-gxWtakYryZED67xa_EJeSXJUINSlWeSa_1-NEi5KAVouBmzxUV04XZt9TyP2zDDDm7yl8d3-YkKbcK4FmArWgfkZicJAjthWQKIdyM3YamRIllsimeAumjtNEp1gUnGrXYNRIBbXWQ-iCcew0u5VCboAiASuP-nKoafXxXCkth49bZZYCoeEPhkx_rNX5QAdGeae9BRnfuByrkXtwFyL68On5GjdEDyMK0tLpMAbWhCNerC8E9df8Qss6U1P3qImpY3f7S5VgYMqNM6pSf4-UGiDCjOqMx3rUBH33lsSPYiNFSrROj6-xajVI9Qkfz7TabekwJ1T6XBg_0QP59G2FCsawwhk1JRqU3Dj16kR2Rh35OXDRKEKonRCJm0c8SmvhVlJm00yS3iqDnQfGl5pPpPjMDm5QgTZLjJOml_i58ahtRnCq7LdFXb3TjuqT7DbsSYSWwXipkjQGS0oLJKsFSISaUrmD05H3iqbSL4JW4o4eCPuP3znX9yUAiUOdU4AIyAWhc_jsBEXAsK2Wnib1Y6Le215OZ1sF0mujgIxt8iFrNraIpqB8grUxuWZJmIdXsqB56q9kSjU1NmkCFTOBt8SbZ0T8uUtPVBzppkpL5dZStDykUG2LJHbezTP1fARWmzPaN2QKjtG03vqaPIzij3eS6Iwi1d39UxxiiukBGmkIGHowazWLIcRW9XVmdo20eC91awyg_uPBdqqGmiyrq1UL2IOkUa1wN0pW1CWSAIXGvQDVGVDT8fK8hOiQkcRL44ClMaUV2IHiVfHEkL1WMKsrN7lZBFy1lga86H7Vv8q0kzzA946zRAcIKOqcGbi0iP-Ih2pJBmannbCX9YDlHQYtV7XpQ0fWKZ5Xb2o8k_wPsaS20jugtD04Sm67UGEXbz4TpYso6bC68nRygG-NEYhK34MZgCbew-joYnhmendWqUTXDq_vIa5lWjVScaf33r0vhZvRGoQTK-AbY4Wn6HaSDak3w5E6BVpqiaQPdIeY4wP3-MJUwaNwGULVRKlptWV7nFlUcrZPJh1VeSxkFjUmfztqCZNZXQguECN3cLp9neBRO4EViiQDkTK6u_dbdKPke9ygrywRbBCdjN7pWoGylN54yrw6nJvkQBxG1HZTaKXYKjZKWok0j2X8ypK7IOdXEmS8K8OvKD7b2KBAaK0yfTYcPiBA5m4Vp-f3fRRkpUb3Jp0y1kRcEDtvBdPLGOrnY78nu1i3pDri_GM65vbEvprVYRYO_l6MfjDkOCF6hCtBreJq5BYzN7NaGKuvYs2qiuY2OGVx9JmfsAN4f6f-Pp54TdlreYWvlZdiVOa_diaTr2BwWci_84WAX9eHr-6uuIwOH7vAbRUrRjlmmsJJa8FXKfpLocEPS6V18uQCW9LytiQUSuVRxZeT_H57mKFb0wcyoA13GKk7X6-4dysh6iOsu1_6NaL4D6r1r6yZ77-6LXoAaoUFza8nDH2D93s2zQBc6fYTzjN-nnZ_KT5dhX1LR1CQxgIYPxEWBjmHttZwwhj-xc6OXAxPkqV1l9q8gsrbiYTA33s6sT_BgFH3htBzqYeV92tmUMtNnxdqiAyeGfnJ6U-36etzjeNfjPOeB6rVOSgioq8d1Pv9dn4ZjTRzEIGH7T0-IpdjJaWVgQrHUMXRdn9s-q0EypGHuKGSwTuXV-EnT6S3A7TmqUH756ZP1Qt7X1x8L1NFvl4G_tbZFiO9bFOv6Rpx_BzppDOREQ9IDA2pmxnR9RN9KEwHX2WWnLDirDUEj_okQSWkrrxjaiN9dLeti-IACGN-rYx8yxEhN1RIW1wrWy6viIkMH7M6zI0noTzOGeV7L-52jYkeale7bJuzUMLqlej-3GnICM6OBYb_1mbIYld73A3j-Tiz4zdkhcaVrTH4t-"
            }
          },
          "time": {
            "start": 1771212925930,
            "end": 1771212936170
          },
          "id": "prt_c64846bea00113c2kiX7EUO9he",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64846222001R1pI2Bc6jf4Qt2"
        },
        {
          "type": "tool",
          "callID": "call_jhOJt6xwh5S6fM2DQa1CQzCB",
          "tool": "read",
          "state": {
            "status": "completed",
            "input": {
              "filePath": "/Users/alex/repos/vfp/dark-factory/.opencode/skills/script-authoring/SKILL.md"
            },
            "output": "<path>/Users/alex/repos/vfp/dark-factory/.opencode/skills/script-authoring/SKILL.md</path>\n<type>file</type>\n<content>1: ---\n2: name: script-authoring\n3: description: Create Bun shebang scripts from prompts, examples, bash snippets, or conversation context.\n4: ---\n5: \n6: ## What I do\n7: \n8: - Turn requested workflows into reusable scripts under `scripts/`.\n9: - Normalize script implementation to project conventions (`*.sh.ts` + shebang + helpers).\n10: - Capture successful ad-hoc command sequences as reusable script entrypoints.\n11: \n12: ## Accepted inputs\n13: \n14: Use this skill when script requirements come from any of these sources:\n15: \n16: - User prompt only (goal and constraints)\n17: - Provided example script\n18: - Provided bash script or shell command sequence\n19: - Agent-summarized conversation context (for example, previously successful setup steps)\n20: \n21: ## Output conventions\n22: \n23: - Primary scripts go in `scripts/` and use `*.sh.ts` naming.\n24: - Include shebang: `#!/usr/bin/env bun`.\n25: - Prefer shared helpers from `scripts/helpers/` instead of duplicating utility logic.\n26: - Default to explicit, readable command flow and fail fast on command errors.\n27: \n28: ## Implementation workflow\n29: \n30: 1. Identify script intent, inputs, and expected outputs from provided context.\n31: 2. If input comes from troubleshooting history, separate successful steps from failed or diagnostic attempts.\n32: 3. Exclude failed retries, dead-end commands, and one-off debugging probes from final reusable script logic.\n33: 4. Choose script name and location under `scripts/`.\n34: 5. Reuse or add helper utilities in `scripts/helpers/` when needed.\n35: 6. Implement Bun-based script and run it once when safe to verify behavior.\n36: 7. Update docs (`README.md` or `AGENTS.md`) when conventions or entrypoints change.\n37: \n38: ## Context capture rules\n39: \n40: - When converting conversation history into a script, include only the final successful sequence.\n41: - Keep troubleshooting commands as optional notes in output, not in executable script flow.\n42: - If multiple working paths exist, prefer the shortest deterministic path.\n43: \n44: ## Notes\n45: \n46: - Keep scripts idempotent where practical.\n47: - Avoid embedding secrets or environment-specific absolute paths.\n48: - If verification cannot be run safely, state exactly what should be executed by the user.\n49: \n\n(End of file - total 49 lines)\n</content>",
            "title": ".opencode/skills/script-authoring/SKILL.md",
            "metadata": {
              "preview": "---\nname: script-authoring\ndescription: Create Bun shebang scripts from prompts, examples, bash snippets, or conversation context.\n---\n\n## What I do\n\n- Turn requested workflows into reusable scripts under `scripts/`.\n- Normalize script implementation to project conventions (`*.sh.ts` + shebang + helpers).\n- Capture successful ad-hoc command sequences as reusable script entrypoints.\n\n## Accepted inputs\n\nUse this skill when script requirements come from any of these sources:\n\n- User prompt only (goal and constraints)\n- Provided example script\n- Provided bash script or shell command sequence\n- Agent-summarized conversation context (for example, previously successful setup steps)\n",
              "truncated": false,
              "loaded": []
            },
            "time": {
              "start": 1771212936179,
              "end": 1771212936183,
              "compacted": 1771213545701
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_0dbefd661aace6a601699290881f948193b316dda4288a424b"
            }
          },
          "id": "prt_c648493eb001BBTi2zFneJXSWc",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64846222001R1pI2Bc6jf4Qt2"
        },
        {
          "type": "tool",
          "callID": "call_2NLMqaGXwPwAXo7PAA0hzLaC",
          "tool": "read",
          "state": {
            "status": "completed",
            "input": {
              "filePath": "/Users/alex/repos/vfp/dark-factory/.opencode/skills/proto-install/SKILL.md"
            },
            "output": "<path>/Users/alex/repos/vfp/dark-factory/.opencode/skills/proto-install/SKILL.md</path>\n<type>file</type>\n<content>1: ---\n2: name: proto-install\n3: description: Use Bun shebang scripts to run `proto install` from repository root.\n4: ---\n5: \n6: ## What I do\n7: \n8: - Standardize `proto install` execution through repository scripts.\n9: - Ensure root execution by using the shared helper-based script entrypoint.\n10: \n11: ## When to use me\n12: \n13: Use this when:\n14: \n15: - A task needs the proto toolchain installed or refreshed.\n16: - An agent should run project setup consistently without ad-hoc shell commands.\n17: \n18: ## Preferred command\n19: \n20: - `bun scripts/proto_install.sh.ts`\n21: \n22: The script resolves repository root and runs `proto install` from there.\n23: \n24: ## Notes\n25: \n26: - Keep script usage aligned with `scripts/*.sh.ts` conventions.\n27: - If command execution fails, report the error and next required action instead of inventing fallback steps.\n28: \n\n(End of file - total 28 lines)\n</content>",
            "title": ".opencode/skills/proto-install/SKILL.md",
            "metadata": {
              "preview": "---\nname: proto-install\ndescription: Use Bun shebang scripts to run `proto install` from repository root.\n---\n\n## What I do\n\n- Standardize `proto install` execution through repository scripts.\n- Ensure root execution by using the shared helper-based script entrypoint.\n\n## When to use me\n\nUse this when:\n\n- A task needs the proto toolchain installed or refreshed.\n- An agent should run project setup consistently without ad-hoc shell commands.\n\n## Preferred command\n\n- `bun scripts/proto_install.sh.ts`",
              "truncated": false,
              "loaded": []
            },
            "time": {
              "start": 1771212936209,
              "end": 1771212936211,
              "compacted": 1771213545701
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_0dbefd661aace6a601699290881fa88193a47e2167b0079f28"
            }
          },
          "id": "prt_c648493f6001VgYm0d9oj3OiBk",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64846222001R1pI2Bc6jf4Qt2"
        },
        {
          "type": "tool",
          "callID": "call_0sPEbpw0Bq5Rr2RdRLxSkKdz",
          "tool": "read",
          "state": {
            "status": "completed",
            "input": {
              "filePath": "/Users/alex/repos/vfp/dark-factory/.opencode/skills/gitter-commit/SKILL.md"
            },
            "output": "<path>/Users/alex/repos/vfp/dark-factory/.opencode/skills/gitter-commit/SKILL.md</path>\n<type>file</type>\n<content>1: ---\n2: name: gitter-commit\n3: description: Use the gitter subagent to handle git status, diffs, and commits regularly.\n4: ---\n5: \n6: ## What I do\n7: \n8: - Remind parent agents to invoke `@gitter` when commits are requested or changes should be captured.\n9: - Provide a short template for the handoff context (scope, intent, and any constraints).\n10: \n11: ## When to use me\n12: \n13: Use this whenever the user asks for commits, when a task introduces meaningful changes, or when the working tree should be cleaned up into commits.\n14: \n15: ## Handoff template\n16: \n17: Send `@gitter` a short summary like:\n18: \n19: - Goal: <what the user asked for>\n20: - Scope: <files or areas touched>\n21: - Notes: <any constraints, tests run, or commit grouping preferences>\n22: \n\n(End of file - total 22 lines)\n</content>",
            "title": ".opencode/skills/gitter-commit/SKILL.md",
            "metadata": {
              "preview": "---\nname: gitter-commit\ndescription: Use the gitter subagent to handle git status, diffs, and commits regularly.\n---\n\n## What I do\n\n- Remind parent agents to invoke `@gitter` when commits are requested or changes should be captured.\n- Provide a short template for the handoff context (scope, intent, and any constraints).\n\n## When to use me\n\nUse this whenever the user asks for commits, when a task introduces meaningful changes, or when the working tree should be cleaned up into commits.\n\n## Handoff template\n\nSend `@gitter` a short summary like:\n\n- Goal: <what the user asked for>\n- Scope: <files or areas touched>",
              "truncated": false,
              "loaded": []
            },
            "time": {
              "start": 1771212936214,
              "end": 1771212936218,
              "compacted": 1771213545701
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_0dbefd661aace6a601699290881fb48193bc53f485735e3d02"
            }
          },
          "id": "prt_c64849412001AqRoH7yXL9TlNT",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64846222001R1pI2Bc6jf4Qt2"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "9d6f15c7b06acb730f3f74807178e28dcff70941",
          "cost": 0,
          "tokens": {
            "total": 17704,
            "input": 17083,
            "output": 621,
            "reasoning": 490,
            "cache": {
              "read": 0,
              "write": 0
            }
          },
          "id": "prt_c64849458001Vtm9Z5Hoe6gSGI",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64846222001R1pI2Bc6jf4Qt2"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771212936343,
          "completed": 1771212939813
        },
        "parentID": "msg_c6484620d0011ltzji40BSbVp5",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 18905,
          "input": 18851,
          "output": 54,
          "reasoning": 22,
          "cache": {
            "read": 0,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "tool-calls",
        "id": "msg_c64849497001w3UASZefqskcAt",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "9d6f15c7b06acb730f3f74807178e28dcff70941",
          "id": "prt_c64849beb001HZHDXXb11w63nk",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64849497001w3UASZefqskcAt"
        },
        {
          "type": "reasoning",
          "text": "**Checking documentation URL**",
          "metadata": {
            "openai": {
              "itemId": "rs_0bad7f72d294dbcd016992908aabcc8197b5e9d19e13f2dc14",
              "reasoningEncryptedContent": "gAAAAABpkpCL3_bRql9t3mKVzHqNJZiodSL7uv42tP5-VuKAM3kakDsN30s2fv3TmHLizxDFD0eoPhMvJk8rDAp5EOGwhGnlOPte_0PpkmkGeU6HxTuNV9jghTpSo20rGPg-_uRMvSrjzHZlf1nkgaBbR2wiFv4-6MgsST6lfqLw_6_ymwo62RytXK9b3Aavb8O4UBKi-_3sPKzAHxneh8tGPXW2MD2LucfL3luMEDkg5qJRIWC5EXwAN-o28kpMHSL3s1-bLjXHbJAjd-5bdlCoRLOCGefZHVVg_zZ478ZMuQ8GtiC3lWd8xZd9ulNKG9xxaSt-aIah9Tn05BdnDyQbTElIpqzYEsKqOJ4_iW2-c6AHI9ZmF16Hta6KiTEAqJFtFJhC5kFBb8FSJXGlMIxP4ObywBWbEHa18M8-Bx7qyBWGsEXV1sjcRdM3Vd55x_wiWE1H8ByGLcRf4o8-Dc59A4D4cQHFos58a6YUFJsACsgqOqI7hxeHhRH5AYReedNZEkwgdPXWFo1vTfRi5OUq1y8Fg7PKQ709NyF4GRSWHCBkrm7bTA-P2vOTGHxCbVCwX2ruln-2MZd_puhC9xJw9W30CHL0k-4KNhF7rpmI7L3zGz5V2_LzQWUBi9EW54ui4tvXDckQqEOT9AzT_jvBWSemM1aEzzQbQRQnMxqQ-ox5P2ISHlkN9cVr_a1heWG6kwM6bQ3Z0jCwmqdDnNfK0gXxNAw7sBXtDygBfJuJsCYwDEGbxYmh2JuHbAlGchTWdIfwlWOKsISAL6nIuo13vzU1Hkhv6wOOBBT7uE6Ym4PI8WPBabgsh9f0Iw4nlINUOafHX7fXvZN8tBfsPuicsqBHe16ybSmntUdjTD3IPEH67pBUKy7LwVgy5pZVjcZ-zVd36y0EVt7HiaiBBV94PLf2pkZU6VQspsrXzATbA_yC2V8VU89nKX0CdOkGbCnyxCm3JAqW"
            }
          },
          "time": {
            "start": 1771212938702,
            "end": 1771212939592
          },
          "id": "prt_c64849dce001okd7A0e2DpjA5s",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64849497001w3UASZefqskcAt"
        },
        {
          "type": "tool",
          "callID": "call_IXfUHQmLHQG4Pe5tYMTThqia",
          "tool": "webfetch",
          "state": {
            "status": "completed",
            "input": {
              "url": "https://opencode.ai/docs/skills/",
              "format": "markdown"
            },
            "output": "Agent Skills | OpenCode     [Skip to content](#_top)\n\n  [![](/docs/_astro/logo-dark.DOStV66V.svg) ![](/docs/_astro/logo-light.B0yzR0O5.svg) OpenCode](/docs/)\n\n[app.header.home](/)[app.header.docs](/docs/)\n\n[](https://github.com/anomalyco/opencode)[](https://opencode.ai/discord)\n\nSearch CtrlK\n\nCancel\n\n-   [Intro](/docs/)\n-   [Config](/docs/config/)\n-   [Providers](/docs/providers/)\n-   [Network](/docs/network/)\n-   [Enterprise](/docs/enterprise/)\n-   [Troubleshooting](/docs/troubleshooting/)\n-   [Windows (WSL)](/docs/windows-wsl/)\n-   Usage\n    \n    -   [TUI](/docs/tui/)\n    -   [CLI](/docs/cli/)\n    -   [Web](/docs/web/)\n    -   [IDE](/docs/ide/)\n    -   [Zen](/docs/zen/)\n    -   [Share](/docs/share/)\n    -   [GitHub](/docs/github/)\n    -   [GitLab](/docs/gitlab/)\n    \n-   Configure\n    \n    -   [Tools](/docs/tools/)\n    -   [Rules](/docs/rules/)\n    -   [Agents](/docs/agents/)\n    -   [Models](/docs/models/)\n    -   [Themes](/docs/themes/)\n    -   [Keybinds](/docs/keybinds/)\n    -   [Commands](/docs/commands/)\n    -   [Formatters](/docs/formatters/)\n    -   [Permissions](/docs/permissions/)\n    -   [LSP Servers](/docs/lsp/)\n    -   [MCP servers](/docs/mcp-servers/)\n    -   [ACP Support](/docs/acp/)\n    -   [Agent Skills](/docs/skills/)\n    -   [Custom Tools](/docs/custom-tools/)\n    \n-   Develop\n    \n    -   [SDK](/docs/sdk/)\n    -   [Server](/docs/server/)\n    -   [Plugins](/docs/plugins/)\n    -   [Ecosystem](/docs/ecosystem/)\n    \n\n[GitHub](https://github.com/anomalyco/opencode)[Discord](https://opencode.ai/discord)\n\nSelect theme DarkLightAuto   Select language EnglishÿßŸÑÿπÿ±ÿ®Ÿäÿ©BosanskiDanskDeutschEspa√±olFran√ßaisItalianoÊó•Êú¨Ë™ûÌïúÍµ≠Ïñ¥Norsk Bokm√•lPolskiPortugu√™s (Brasil)–†—É—Å—Å–∫–∏–π‡πÑ‡∏ó‡∏¢T√ºrk√ßeÁÆÄ‰Ωì‰∏≠ÊñáÁπÅÈ´î‰∏≠Êñá\n\nOn this page\n\n-   [Overview](#_top)\n-   [Place files](#place-files)\n-   [Understand discovery](#understand-discovery)\n-   [Write frontmatter](#write-frontmatter)\n-   [Validate names](#validate-names)\n-   [Follow length rules](#follow-length-rules)\n-   [Use an example](#use-an-example)\n-   [Recognize tool description](#recognize-tool-description)\n-   [Configure permissions](#configure-permissions)\n-   [Override per agent](#override-per-agent)\n-   [Disable the skill tool](#disable-the-skill-tool)\n-   [Troubleshoot loading](#troubleshoot-loading)\n\n## On this page\n\n-   [Overview](#_top)\n-   [Place files](#place-files)\n-   [Understand discovery](#understand-discovery)\n-   [Write frontmatter](#write-frontmatter)\n-   [Validate names](#validate-names)\n-   [Follow length rules](#follow-length-rules)\n-   [Use an example](#use-an-example)\n-   [Recognize tool description](#recognize-tool-description)\n-   [Configure permissions](#configure-permissions)\n-   [Override per agent](#override-per-agent)\n-   [Disable the skill tool](#disable-the-skill-tool)\n-   [Troubleshoot loading](#troubleshoot-loading)\n\n# Agent Skills\n\nDefine reusable behavior via SKILL.md definitions\n\nAgent skills let OpenCode discover reusable instructions from your repo or home directory. Skills are loaded on-demand via the native `skill` tool‚Äîagents see available skills and can load the full content when needed.\n\n---\n\n## [Place files](#place-files)\n\nCreate one folder per skill name and put a `SKILL.md` inside it. OpenCode searches these locations:\n\n-   Project config: `.opencode/skills/<name>/SKILL.md`\n-   Global config: `~/.config/opencode/skills/<name>/SKILL.md`\n-   Project Claude-compatible: `.claude/skills/<name>/SKILL.md`\n-   Global Claude-compatible: `~/.claude/skills/<name>/SKILL.md`\n-   Project agent-compatible: `.agents/skills/<name>/SKILL.md`\n-   Global agent-compatible: `~/.agents/skills/<name>/SKILL.md`\n\n---\n\n## [Understand discovery](#understand-discovery)\n\nFor project-local paths, OpenCode walks up from your current working directory until it reaches the git worktree. It loads any matching `skills/*/SKILL.md` in `.opencode/` and any matching `.claude/skills/*/SKILL.md` or `.agents/skills/*/SKILL.md` along the way.\n\nGlobal definitions are also loaded from `~/.config/opencode/skills/*/SKILL.md`, `~/.claude/skills/*/SKILL.md`, and `~/.agents/skills/*/SKILL.md`.\n\n---\n\n## [Write frontmatter](#write-frontmatter)\n\nEach `SKILL.md` must start with YAML frontmatter. Only these fields are recognized:\n\n-   `name` (required)\n-   `description` (required)\n-   `license` (optional)\n-   `compatibility` (optional)\n-   `metadata` (optional, string-to-string map)\n\nUnknown frontmatter fields are ignored.\n\n---\n\n## [Validate names](#validate-names)\n\n`name` must:\n\n-   Be 1‚Äì64 characters\n-   Be lowercase alphanumeric with single hyphen separators\n-   Not start or end with `-`\n-   Not contain consecutive `--`\n-   Match the directory name that contains `SKILL.md`\n\nEquivalent regex:\n\n```\n^[a-z0-9]+(-[a-z0-9]+)*$\n```\n\n---\n\n## [Follow length rules](#follow-length-rules)\n\n`description` must be 1-1024 characters. Keep it specific enough for the agent to choose correctly.\n\n---\n\n## [Use an example](#use-an-example)\n\nCreate `.opencode/skills/git-release/SKILL.md` like this:\n\n```\n---name: git-releasedescription: Create consistent releases and changelogslicense: MITcompatibility: opencodemetadata:  audience: maintainers  workflow: github---\n## What I do\n- Draft release notes from merged PRs- Propose a version bump- Provide a copy-pasteable `gh release create` command\n## When to use me\nUse this when you are preparing a tagged release.Ask clarifying questions if the target versioning scheme is unclear.\n```\n\n---\n\n## [Recognize tool description](#recognize-tool-description)\n\nOpenCode lists available skills in the `skill` tool description. Each entry includes the skill name and description:\n\n```\n<available_skills>  <skill>    <name>git-release</name>    <description>Create consistent releases and changelogs</description>  </skill></available_skills>\n```\n\nThe agent loads a skill by calling the tool:\n\n```\nskill({ name: \"git-release\" })\n```\n\n---\n\n## [Configure permissions](#configure-permissions)\n\nControl which skills agents can access using pattern-based permissions in `opencode.json`:\n\n```\n{  \"permission\": {    \"skill\": {      \"*\": \"allow\",      \"pr-review\": \"allow\",      \"internal-*\": \"deny\",      \"experimental-*\": \"ask\"    }  }}\n```\n\nPermission\n\nBehavior\n\n`allow`\n\nSkill loads immediately\n\n`deny`\n\nSkill hidden from agent, access rejected\n\n`ask`\n\nUser prompted for approval before loading\n\nPatterns support wildcards: `internal-*` matches `internal-docs`, `internal-tools`, etc.\n\n---\n\n## [Override per agent](#override-per-agent)\n\nGive specific agents different permissions than the global defaults.\n\n**For custom agents** (in agent frontmatter):\n\n```\n---permission:  skill:    \"documents-*\": \"allow\"---\n```\n\n**For built-in agents** (in `opencode.json`):\n\n```\n{  \"agent\": {    \"plan\": {      \"permission\": {        \"skill\": {          \"internal-*\": \"allow\"        }      }    }  }}\n```\n\n---\n\n## [Disable the skill tool](#disable-the-skill-tool)\n\nCompletely disable skills for agents that shouldn‚Äôt use them:\n\n**For custom agents**:\n\n```\n---tools:  skill: false---\n```\n\n**For built-in agents**:\n\n```\n{  \"agent\": {    \"plan\": {      \"tools\": {        \"skill\": false      }    }  }}\n```\n\nWhen disabled, the `<available_skills>` section is omitted entirely.\n\n---\n\n## [Troubleshoot loading](#troubleshoot-loading)\n\nIf a skill does not show up:\n\n1.  Verify `SKILL.md` is spelled in all caps\n2.  Check that frontmatter includes `name` and `description`\n3.  Ensure skill names are unique across all locations\n4.  Check permissions‚Äîskills with `deny` are hidden from agents\n\n[Edit page](https://github.com/anomalyco/opencode/edit/dev/packages/web/src/content/docs/skills.mdx)[Found a bug? Open an issue](https://github.com/anomalyco/opencode/issues/new)[Join our Discord community](https://opencode.ai/discord) Select language EnglishÿßŸÑÿπÿ±ÿ®Ÿäÿ©BosanskiDanskDeutschEspa√±olFran√ßaisItalianoÊó•Êú¨Ë™ûÌïúÍµ≠Ïñ¥Norsk Bokm√•lPolskiPortugu√™s (Brasil)–†—É—Å—Å–∫–∏–π‡πÑ‡∏ó‡∏¢T√ºrk√ßeÁÆÄ‰Ωì‰∏≠ÊñáÁπÅÈ´î‰∏≠Êñá \n\n¬© [Anomaly](https://anoma.ly)\n\nLast updated: Feb 15, 2026",
            "title": "https://opencode.ai/docs/skills/ (text/html)",
            "metadata": {
              "truncated": false
            },
            "time": {
              "start": 1771212939666,
              "end": 1771212939772,
              "compacted": 1771213545701
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_0bad7f72d294dbcd016992908b6f9081979b07030ea68de615"
            }
          },
          "id": "prt_c6484a149001PP5SENeAQbDMIH",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64849497001w3UASZefqskcAt"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "9d6f15c7b06acb730f3f74807178e28dcff70941",
          "cost": 0,
          "tokens": {
            "total": 18905,
            "input": 18851,
            "output": 54,
            "reasoning": 22,
            "cache": {
              "read": 0,
              "write": 0
            }
          },
          "id": "prt_c6484a1fd001PaqY59wi3Xc4e6",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64849497001w3UASZefqskcAt"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771212939814,
          "completed": 1771212945386
        },
        "parentID": "msg_c6484620d0011ltzji40BSbVp5",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 21244,
          "input": 2262,
          "output": 166,
          "reasoning": 132,
          "cache": {
            "read": 18816,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "tool-calls",
        "id": "msg_c6484a226001m9K6XRR1Fijful",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "9d6f15c7b06acb730f3f74807178e28dcff70941",
          "id": "prt_c6484aa61001z0jYxdeYQlWPSS",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6484a226001m9K6XRR1Fijful"
        },
        {
          "type": "reasoning",
          "text": "**Planning protobuf research and docs**",
          "metadata": {
            "openai": {
              "itemId": "rs_01a873a531b87cd2016992908e0df0819080c07b733b5e2136",
              "reasoningEncryptedContent": "gAAAAABpkpCQbu7W9xdcUk7WTcg7a1Gq8pH_GC2LId4B1xtqYJTEeT0_8xf8Bf5h62w5nxdkdZVRPHtOB5xE-hC4ujE8gAxNQobzJVUK4bnrbt9QSRBUVJkJdMSzVdZ_rV_jFPmVYFac7MJDN_JMiBDo1l4VRZn8pmgp963OwK9EBiW5SwOmOL0Wv7ZmHQnLpK83m67PZQ8wAuxWIkXlSsnIi5VM8Ex9cBIAeWPttr3URh7NRpsdylmxeereB74Kqy7vfItuR7TjW7Ido8-oLBj-HtEafUyyvr8_1Y3S9S7_KzEjza5uJf9LtIeRigm-OY2ygXj0r9p-VlPMP6uRpFeXIcRptcCnmTkx-aXEimv_8g4BXQ8lLR37Zxt51DdqIEVbQy1pcbYS7ljlvJhSCZ8CEDNrICbeH5KjLcMCope8F-2dQArhlinaVjwzF2XbwGRnyBZqlcy8S5hcRZ2ECPbzJlwAsA7f1HSm-nW73dLBFrOvntSyzF4FdE5276q6_7FerKR_4K3BYoNQ55JxA-k-yWkpsmkNX5M6kh2bLyECbBJ7oj_PSwl2GYAGZQmZhhWUenN57mfud7Gdx6j2aBI7yN0VU7Hk_y4l9ChfF-0achiVUslfxzmKBnDtnL33ms-5WYD11Q0DihxdVJbdkALxXQiyTnxGXQ0kDP-y2qb7It_ZbK54iMWRj9JdeL3IlstWePOmOphzogqS_dhtfUNbpB9rHecbt6ApqqhBZlpGqtR6gQ5bYKw0FJyIW_97ZufkssqpPt6IS5rdEdwa_9a2BH5Syn5GYmIWYp2D4wN0Vdvy3SLGFe0KxsN8OhXe0GWafCTGOx8S5_8OKgqqAdTPrlUwhQiVFJqA7aFbeYZFugLIM1JTpDd2uREHcaNX5ToJ7Bqa0Qa1yYBpXTxrqBJO8qLdKVDscD3KOcnYMe9fvqaH-scwCljgJFHtJ6PW-qnV_UFe-oxa4BkZGMyi0DFcSOlSuypxuh5bo4DleIyHwm8WjAP0mpnlfsQa-WlHL3QpURc-wT_7sEgt3Q0MpYMLc1XZ4Qn7K3yI6lbxsDvARJacmT3ujUgTSW2F4OHYTdSKYYfBqAqf3ig-abQr9CDexmHRxpE1D_pFiZ9neAwhKjr0Nb_U-g15aNQW1MQSlf9UDaSXbvH1ms1oZ-oBgQAU3zj-GvjRYpbwWNO5iwfHDoOrBHhRuSbH88L1CmXV9qQO6k59A_xEyT0h8ZbG8MIkLAB9XUhknGc7fhWGvxBh7eHv8nOL7uZ4yHDx8umgRLQjSxXYVAR8dzPyEBBhq6OZzFXcgXCNfS2zRHxpUvi9GXjksf0rnPQKJWLANH1wARLYlKNqI6mHAPxBhTOJBaOZJUh9HKs2TzoVdoEnuaTX0TNrR3z-FZai6vUTm1c_2eeLPPpr--uvizpEIZOV3le8KJ3dzUP17ToB5_YDjZOo3c5Tl0v_QvwAR9NQHHxLd81UhsZoa0WWvFS3pkSKFlQb9agqMubdhmbuYmR-QpcxUdy9bZEtrN6PXl-nfBc_ivo9s3KLBCky10xcd0wJYu_FiH_tcYk87YFR6i8o12iDQ58eCrgp3V6zp3QFZ1n0oJ0M9zd7tMe65JLZGRSjMt3uq_TNVJRccGE2sYRHBQvjnjFGibgHwDv6zd8c1DYutz-poXikKcrtOmduH6515zdAsw746eFidg=="
            }
          },
          "time": {
            "start": 1771212942172,
            "end": 1771212945036
          },
          "id": "prt_c6484ab5c0015IQr2A1AcBwifi",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6484a226001m9K6XRR1Fijful"
        },
        {
          "type": "tool",
          "callID": "call_nGcedZvRDTwH5aJOktEfulli",
          "tool": "glob",
          "state": {
            "status": "completed",
            "input": {
              "pattern": "docs/**/*",
              "path": "/Users/alex/repos/vfp/dark-factory"
            },
            "output": "/Users/alex/repos/vfp/dark-factory/docs/readmes/elysia-js.README.md\n/Users/alex/repos/vfp/dark-factory/docs/designs/core_gen1.design.md",
            "title": "",
            "metadata": {
              "count": 2,
              "truncated": false
            },
            "time": {
              "start": 1771212945317,
              "end": 1771212945341,
              "compacted": 1771213545700
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_01a873a531b87cd20169929090fdec81909f3cfd385560089e"
            }
          },
          "id": "prt_c6484b68f001rjjePr02030rKI",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6484a226001m9K6XRR1Fijful"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "9d6f15c7b06acb730f3f74807178e28dcff70941",
          "cost": 0,
          "tokens": {
            "total": 21244,
            "input": 2262,
            "output": 166,
            "reasoning": 132,
            "cache": {
              "read": 18816,
              "write": 0
            }
          },
          "id": "prt_c6484b7be001Egk4YnQl46O5KY",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6484a226001m9K6XRR1Fijful"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771212945388,
          "completed": 1771212950203
        },
        "parentID": "msg_c6484620d0011ltzji40BSbVp5",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 21415,
          "input": 175,
          "output": 120,
          "reasoning": 11,
          "cache": {
            "read": 21120,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "tool-calls",
        "id": "msg_c6484b7ec0013xjjdLanF4Thgg",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "9d6f15c7b06acb730f3f74807178e28dcff70941",
          "id": "prt_c6484c1f8001VFx8AIbbyJRIge",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6484b7ec0013xjjdLanF4Thgg"
        },
        {
          "type": "reasoning",
          "text": "",
          "metadata": {
            "openai": {
              "itemId": "rs_06dfd919d8dfdb98016992909447748193b741ff35f0906e2e",
              "reasoningEncryptedContent": "gAAAAABpkpCVXEVvSVNDWnxxte4qkq2tDOUssv73bjIoniUDjXispK_002ICat0hIksj7FMYJHPvazCHXJAh1Qn2i2D0-FTLiEWCVchpKqzyRySQPIeVNMmRxLAznay5NFrNHyTpsiDb7uDEMChjEDQLIpxwkQcj2w8RkhdGcN-chNmM29yUhP_bZ1ZYTnH5mShK5NJ9kbzkKd_RmP9N3maJ1hlsgUUHWZKbFHkoE3PPCFfDPG_okfOpL2VhNSjpYCj4BbnxLeNgBJFWXld2XfcD5GG4GTbD0uLRKE_CE-OTFeD5VfcsOVYcimXUkL8zBzPSlRIywTWzgH9b9kFFQc0IxLiY9y4q6J-ZSa-hxbyvNc0pFx-U6zcNS0LGw-A3mvFqKwQ5IBjNtZGB_gJmNDXtlFJuvILTNTNj34zZaHVr5kcmzyZA3jkGZZwhkSBo4Q5Ea-CF6h5Uk63OxrJlW1MljFggAHJy5JuSppP3TKG0rVjqwIFnNiSTBIwx6N2ta2tcpQpKHJizlBjvYyiqRC0LpaXvrk5h1s_M0E-opDyQhGR_9DpklA5l-VjE-h6he_L9vVffIkWaIW57NnPdIFEZJkkQGZ0iGKqh8hSflmnL4YssPkffoKS1mJm84z4-HDuI3aM1ozRhqm-QSOxPs0f5u-iLwCIpeLSouFgMnRaiMP7kGD55CcuLHG2ZlpTC7My7Ab55EyZT6WCQ_24xk5O35LRYLU2EAO2kuZKTYJyI9NHOR7y1H4JmCdz5Ytptn5N9h1LVV4ftt9XU0yHZ_DBswvxT2NICLXUJjKIN63tJE1_K0TSlyXtq6sqcJq3MBkkUtl7YPgPnKCoKrD6NN2siAPedCuYpRP9NzjI_tuUSi60-2nSxOcY="
            }
          },
          "time": {
            "start": 1771212948498,
            "end": 1771212950138
          },
          "id": "prt_c6484c412001jff9pJmwWZq55W",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6484b7ec0013xjjdLanF4Thgg"
        },
        {
          "type": "tool",
          "callID": "call_blLMUmIyro0NibPZliU8goan",
          "tool": "read",
          "state": {
            "status": "completed",
            "input": {
              "filePath": "/Users/alex/repos/vfp/dark-factory/docs/designs/core_gen1.design.md"
            },
            "output": "<path>/Users/alex/repos/vfp/dark-factory/docs/designs/core_gen1.design.md</path>\n<type>file</type>\n<content>1: \n\n(End of file - total 1 lines)\n</content>",
            "title": "docs/designs/core_gen1.design.md",
            "metadata": {
              "preview": "",
              "truncated": false,
              "loaded": []
            },
            "time": {
              "start": 1771212950141,
              "end": 1771212950147,
              "compacted": 1771213545700
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_06dfd919d8dfdb980169929095fc808193b2ca4ea5b4251afd"
            }
          },
          "id": "prt_c6484ca7b001voG1CHOPzVOto5",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6484b7ec0013xjjdLanF4Thgg"
        },
        {
          "type": "tool",
          "callID": "call_ITIatvTuLKMn0PrLur0FfTgU",
          "tool": "read",
          "state": {
            "status": "completed",
            "input": {
              "filePath": "/Users/alex/repos/vfp/dark-factory/README.md"
            },
            "output": "<path>/Users/alex/repos/vfp/dark-factory/README.md</path>\n<type>file</type>\n<content>1: # Dark Factory - Autonomous Agentic Development At Scale\n2: \n3: # Concept\n4: \n5: - A central `dark-factory` \"core\" is used to track `worlds`\n6: - A `world` is an `env` + `actor`(s)\n7: - `env` is like a project and represents where an `actor` is spawned.\n8:   - Similar to `projets` in OpenCode or other agent orchestrators\n9:   - `env` may be a directory on host (simplest and most common) or later expanded to:\n10:     - Remote directory on a SSH-connected machine\n11:     - Dockershell w/ virutal FS\n12:     - Git Worktree\n13: - `world` can link multiple `envs` - which assume to all be multiple versions of the same root project\n14:   - we call this concept `dimensions`\n15:   - Examples:\n16:     - Multiple cloned directories of the same root project\n17:     - Git worktree supportds\n18:     - Instanced Docker shells\n19: - When an agent is spawned - it is linked to a given env\n20:   - Linking can just be spawning the agent at the directory (IE: `opencode .`)\n21:   - Link in the future can be custom tools/mcps to overwrite default shell and FS tools to ones that understand multi-verses\n22: - `actor` is a spawned agent that operates on an env.\n23:   - Can be various agent backends (currently scoped in OpenCode, Codex and a custom agent) - but first iteration is JUST opencode\n24:   - Currently is 1-1 agent to env but future work will allow multiple agents per world or even env if operations allow.\n25: \n26: # Stack + Tools\n27: \n28: - Agentic Coding: `opencode`\n29: - Main languages: `rust` and `bun` / `typscript`\n30: - Scripting: shebanged Bun TypeScript scripts under `scripts/` (`*.sh.ts`)\n31: - Optional build system: `moon` / `proto`\n32: - Common Schema Defintion: `prisma`\n33:   - [ ] TODO: Investigate use of protobuff\n34: \n35: # Scripts\n36: \n37: - Project shell-style scripts are Bun TypeScript files with shebangs: `#!/usr/bin/env bun`.\n38: - Shared helpers live in `scripts/helpers/`.\n39: - `scripts/install.sh.ts` runs an ordered array of install steps from repository root.\n40: - `scripts/proto_install.sh.ts` runs `proto install` from repository root.\n41: - OpenCode skill reference: `.opencode/skills/proto-install/SKILL.md`.\n42: - OpenCode skill reference: `.opencode/skills/script-authoring/SKILL.md`.\n43: \n44: # Components\n45: \n46: ## Core\n47: \n48: - Central service that manages tracking of all worlds/envs/settigns etc.\n49:   - TBD: will either be stateless w/ DB and route all commands just to the agents\n50:     - OR: a background API service (Rest even) we can query from frontends\n51: - Currently looking lile will be Bun + Elysia JS\n52: \n53: ## Frontends\n54: \n55: - Various frontends that invoke / connect to Core\n56: - Main way of iterating with the system\n57: - Uses the Core API to communicate (REST / WS or GRPC in the future)\n58: - Some Frontends:\n59:   - Rust TUI (Ratatui.rs) - First One\n60:   - Web Client (Bun + Vite + Shadcn + React)\n61:   - Pure CLI (Rust)\n62: \n63: ## Agents\n64: \n65: - Abstracted communication with actual agents doing work\n66: - First is OpenCode\n67: \n\n(End of file - total 67 lines)\n</content>",
            "title": "README.md",
            "metadata": {
              "preview": "# Dark Factory - Autonomous Agentic Development At Scale\n\n# Concept\n\n- A central `dark-factory` \"core\" is used to track `worlds`\n- A `world` is an `env` + `actor`(s)\n- `env` is like a project and represents where an `actor` is spawned.\n  - Similar to `projets` in OpenCode or other agent orchestrators\n  - `env` may be a directory on host (simplest and most common) or later expanded to:\n    - Remote directory on a SSH-connected machine\n    - Dockershell w/ virutal FS\n    - Git Worktree\n- `world` can link multiple `envs` - which assume to all be multiple versions of the same root project\n  - we call this concept `dimensions`\n  - Examples:\n    - Multiple cloned directories of the same root project\n    - Git worktree supportds\n    - Instanced Docker shells\n- When an agent is spawned - it is linked to a given env\n  - Linking can just be spawning the agent at the directory (IE: `opencode .`)",
              "truncated": false,
              "loaded": []
            },
            "time": {
              "start": 1771212950143,
              "end": 1771212950148,
              "compacted": 1771213545700
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_06dfd919d8dfdb980169929095fc8c8193a95d006fb7f14062"
            }
          },
          "id": "prt_c6484ca7e001BqAhtffJc10f5O",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6484b7ec0013xjjdLanF4Thgg"
        },
        {
          "type": "tool",
          "callID": "call_nWnIpnLNn76HxImwBdUhHKfd",
          "tool": "read",
          "state": {
            "status": "completed",
            "input": {
              "filePath": "/Users/alex/repos/vfp/dark-factory/opencode.jsonc"
            },
            "output": "<path>/Users/alex/repos/vfp/dark-factory/opencode.jsonc</path>\n<type>file</type>\n<content>1: {\n2:   \"$schema\": \"https://opencode.ai/config.json\",\n3:   \"plugin\": [\"opencode-pty\"],\n4:   \"mcp\": {\n5:     \"websearch\": {\n6:       \"type\": \"remote\",\n7:       \"url\": \"https://mcp.exa.ai/mcp?tools=web_search_exa\",\n8:       \"enabled\": true,\n9:       \"headers\": {\n10:         \"x-api-key\": \"{env:EXA_API_KEY}\",\n11:       },\n12:       \"oauth\": false,\n13:     },\n14:     \"context7\": {\n15:       \"type\": \"remote\",\n16:       \"url\": \"https://mcp.context7.com/mcp\",\n17:       \"enabled\": true,\n18:       \"headers\": {\n19:         \"Authorization\": \"Bearer {env:CONTEXT7_API_KEY}\",\n20:       },\n21:       \"oauth\": false,\n22:     },\n23:     \"grep_app\": {\n24:       \"type\": \"remote\",\n25:       \"url\": \"https://mcp.grep.app\",\n26:       \"enabled\": true,\n27:       \"oauth\": false,\n28:     },\n29:     \"prefect\": {\n30:       \"type\": \"local\",\n31:       \"command\": [\"uvx\", \"--from\", \"prefect-mcp\", \"prefect-mcp-server\"],\n32:     },\n33:   },\n34: }\n35: \n\n(End of file - total 35 lines)\n</content>",
            "title": "opencode.jsonc",
            "metadata": {
              "preview": "{\n  \"$schema\": \"https://opencode.ai/config.json\",\n  \"plugin\": [\"opencode-pty\"],\n  \"mcp\": {\n    \"websearch\": {\n      \"type\": \"remote\",\n      \"url\": \"https://mcp.exa.ai/mcp?tools=web_search_exa\",\n      \"enabled\": true,\n      \"headers\": {\n        \"x-api-key\": \"{env:EXA_API_KEY}\",\n      },\n      \"oauth\": false,\n    },\n    \"context7\": {\n      \"type\": \"remote\",\n      \"url\": \"https://mcp.context7.com/mcp\",\n      \"enabled\": true,\n      \"headers\": {\n        \"Authorization\": \"Bearer {env:CONTEXT7_API_KEY}\",\n      },",
              "truncated": false,
              "loaded": []
            },
            "time": {
              "start": 1771212950144,
              "end": 1771212950150,
              "compacted": 1771213545700
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_06dfd919d8dfdb980169929095fc948193bc849c541fc94b86"
            }
          },
          "id": "prt_c6484ca7f001PeOWYuMCzOhe0X",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6484b7ec0013xjjdLanF4Thgg"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "9d6f15c7b06acb730f3f74807178e28dcff70941",
          "cost": 0,
          "tokens": {
            "total": 21415,
            "input": 175,
            "output": 120,
            "reasoning": 11,
            "cache": {
              "read": 21120,
              "write": 0
            }
          },
          "id": "prt_c6484ca87001Gcva31Zro4dAN8",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6484b7ec0013xjjdLanF4Thgg"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771212950205,
          "completed": 1771212963942
        },
        "parentID": "msg_c6484620d0011ltzji40BSbVp5",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 23227,
          "input": 1635,
          "output": 472,
          "reasoning": 296,
          "cache": {
            "read": 21120,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "tool-calls",
        "id": "msg_c6484cabd001kba6FKYf7Y42Al",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "9d6f15c7b06acb730f3f74807178e28dcff70941",
          "id": "prt_c6484d352001CuBDOqtGsLww4C",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6484cabd001kba6FKYf7Y42Al"
        },
        {
          "type": "reasoning",
          "text": "**Planning detailed protobuf research**",
          "metadata": {
            "openai": {
              "itemId": "rs_0ef6fe591fc123f7016992909891008193a6dba8aaf7b2cc1e",
              "reasoningEncryptedContent": "gAAAAABpkpCgyfzM6bbebxpFzhAKzhZQK3KQ_-BuFW8hS4nLVnk6hJGfCCEgFNYBueAdB1WZ4e9NwW-hz2_DTmFb3K3Rn-5fqI3fAw6LgukjgoO423jMMCFvQJ4qFiS969pSc8t-wI-TxZt_1qkbHEDqdX5EmEFoPfDQesqqpxznYCZubc_cgIPtg4o5zXLpVpAckeRCuzJy81h5OhTJl1NpU9USMlghqWWy9yX26O-T2Wr1HHVWhf-kEOHCmhaxOnRdtK5fy8IElsMoahcCYuuS0E4vkyiLUhYp7SySBut3RDiXh0RFt1QK5nvwai22AbK4XaXcYygTK2Ii0tBJJe96QocGv3rKDPCA1rbwgD1VB8pElB6sHxcKGCvAD-OdJeAiYvtJPlsQt4mGiW0DAiQ8NFQMVFvVoxutL2E2kGEnZYevInPHZ0IyZT00oSDXHYC7mwdexRchakZ0mzfhPJyekQE4mL_ZX_R9GUDJHVKuD1Tx9e36gR2CHKkrztjrvEcH7feWCJLmhL5eH_JPSI8YheBULRL25ivouGXoq2aLMN-vEIIsR6dculBjnv3mXUMioVZTd9BNzGgcdKTkWQ_06dW8vLK8EoQHSwKqG3lsxP7-rWiUMRYU9H7m_6tJAs3RQXfq59uggaKqeO_nNreu2s_xYx_ORQPr34L26TU--5CFYUMgRUL_3ReEB4oXVCIOo9gfaMCgwIKIJIpqU2DusINctwWpv9TcW7iLJ8nhEwc7uvbuQ8YVpb8nsBJfwKYWQZaUyJXL1TsskZrMyBowl9Ow4DMJDtalXzCHERXHuutVdTPp7HkliFr0GDmSfPSe4eb-g70gnBiErfrMP3yU34JdWrLiqxi4_LoSQqluWgK4O4n6sNz31htRtslKpZxGQoEiXwgTUXdUmYkqbKL-YK692UEkxC27OppCcm5TWtr9nYUG-KEic0_K1tcigaNS0rDS4FgM4MkMP2PC1MzpjFyK4ehaH_6UwRr2r8CPAnC82E3zad347JQaHD72ZTwaNRINBQlWil264ZC8BIPbKgfmZ88xSDXXsdeOi8LFTUQMEnyesiFIzbGTs43OqhsvVBhUIFbFJZbkc-K71IVrgB6P5LsZEtQ5dukidxNg4cHhGy0XAQ7s_GwbB9OAcOOvZdWeADGs7RUjGRnwEGrO_v4UTa3M1X3NoZR81ks-4mM-XYyZRBCK7HgxrX2naolONLdOB7Q1vErQBjWPyQTT3t5p50I9LfmlgURc-VFw30LdNlinYbpXxDLLVy_Tz0z40v5yyZ5_VQ4AVTSjJhRgkhF1-SZFYS3peT0Sm_1eE9JQ95BMugtnlmXwwC9ojsaxgd5fJKlZJPhnamgnvepDE32Nxf5_4wiCoKpR03aT4TYuTsh1GUOx7vX-8ynrMlXJNnWpKhTNxpUvZa5dEep7x5GuEPsjj6I3-PR3sjDGY1gMSQnSTA_ZKRnHIp8u3bKDh6QEPnwxt_YFmlUiwvvPtqvBCa9Y9U2jSD1_y_NjO3dnJs7V6ho6iXgHttli7ar6HGjEG8IJAgglPIkXI1x80JhwAAK3gng_VOjJbvcsco46r26mOT7rdi2Z4xr9IeIrD5u5AqX8-wV1Q9doHXL59fnokyOjZlwuwJkshmoZEaXHaJeKLGMpRws84X0NFEtQE3U4RvBDJrE8uN3rVzY8go18HU3I_qbJIrZEBcFihQbcZTzh1a8cxmna_mVQvrRrCKnzWH5d0Ug4CmCf10mJw5ACkHJDEN5auLEhPB4dZAQA7nrtrUXrTCB_EjIMPejDMvAK-_bRKLJo_uxr_XOGr_REwJ9iFIe2PrjbZY3wIK8WGlxiCjl7puy8npG76UwuvafOgfM5tUuAu05iMLHyD4QWnlg736LYmoZaDxcnZu1gegmn-Xs3QccbRbto3nRhfekJbkT2QCodkS1JbWKYy6ts7Bxz1a8L2cxqmahqhp9kEJUT0vn7ns36VeoFbziZ27cm_Ze9t2STg4teGkRTwK3AiYorEqlWXx49o7BGiJBqntOj1jdf8Lxthz4JlOItANH60KiJyWW-m9EvWKNrH0E2HATpJfnUgxBvcyJ_epNn5XV7jp4c6tOdfQscc2XJ8TrUXQhWXUEeey3DV4gnGY-ujPBL3BEoDSqQB_OYb13wuBNbP6ZMGhsso6GrJGuly7mqet6MgEyCpq7TDN0sBVqsqBilHorZCm7pIbngvNtI6tUW-XVc407pH-TW_n_VYHqMG4MgpBpWw-FuCW4h0KNgA_xRIs57exWWkj191dvX2rvYNyoJXXa-uzJwWyaSvbJP51wV7f-QT6KKFwKsr2CYo_qsMOhlL1b0BfX6CGlKIWUpHnwXnag_UpvE0-clrD2YuYB1k5OcerNr3pFTVhrdVRM6nJZ3SkzwBdM1mMcqr9N6JxYdIdWy4fA6MarZCfNB3Z-zG2m2YPbVDLsSGzp3CZtHZ-v0kX1yXb_MPdt-KkMaMIND1XpJXYK1JehUnXW1Pfddf6w8KONDmNWCjtMVXfAjK2X9Em4eYg5Kpn_Bp0It_eJvsTyk7LZC3UtBEIL01bFBd8Ibur5oo7ulTtnOCKjbbp4tpF2Wq28i1KkFw1tRvJtcInhhlrDLm2ez6jMKbSQrOYGIPepWsy1w8KXXctrmw5rdegeSXMiox76w_KE04tlTpqLscbYrOo99fShGK0ddMD6_QfSh39KsIYzO0vwEB1Gofp_y_06_mHnmF8G8dk5qtzdT7-l8wAnue1NyZE9N"
            }
          },
          "time": {
            "start": 1771212952658,
            "end": 1771212960107
          },
          "id": "prt_c6484d4520018eblre5iBiW400",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6484cabd001kba6FKYf7Y42Al"
        },
        {
          "type": "tool",
          "callID": "call_7UZdMhffCJxV4he8twKpCpAU",
          "tool": "websearch_web_search_exa",
          "state": {
            "status": "completed",
            "input": {
              "query": "Protocol Buffers proto2 vs proto3 differences required optional extensions groups unknown fields official docs",
              "numResults": 5,
              "livecrawl": "preferred",
              "type": "auto",
              "contextMaxCharacters": 12000
            },
            "output": "Title: Protobuf: proto2 vs proto3 - Oleksii Shmalko\nAuthor: Oleksii Shmalko\nURL: https://oleksii.shmalko.com/20200505102203/\nText: Protobuf: proto2 vs proto3\n\nDifferences between protobuf v2 and v3.\n\nproto3 does not support specifying default values for optional fields. In proto3, the default value is fixed for type (it is usually 0, false, empty string, etc.)\n\n- [Protobuf: in proto3, it is impossible to distinguish absent fields from default values] \n\nproto2 supports extensions mechanism\n\n- extensions are not supported for oneof\n\n## Backlinks\n\n- üìù [¬ß Protobuf] \n- üìù [Protobuf: avoid using required fields]\n\nTitle: Protocol Buffers Language Specification (Proto3)\nAuthor: \nURL: https://protobuf.dev/reference/protobuf/proto3-spec/\nText: Protocol Buffers Language Specification (Proto3) | Protocol Buffers Documentation\n\n# Protocol Buffers Language Specification (Proto3)\n\nLanguage specification reference for the Protocol Buffers language (Proto3).\n\nThe syntax is specified using [Extended Backus-Naur Form (EBNF)]:\n\n```\n| alternation\n() grouping\n[] option (zero or one time)\n{} repetition (any number of times)\n\n```\n\nFor more information about using proto3, see the [language guide].\n\n## Lexical Elements\n\n### Letters and Digits\n\n```\nletter = \"A\" ... \"Z\" | \"a\" ... \"z\"\ndecimalDigit = \"0\" ... \"9\"\noctalDigit = \"0\" ... \"7\"\nhexDigit = \"0\" ... \"9\" | \"A\" ... \"F\" | \"a\" ... \"f\"\n\n```\n\n### Identifiers\n\n```\nident = letter { letter | decimalDigit | \"_\" }\nfullIdent = ident { \".\" ident }\nmessageName = ident\nenumName = ident\nfieldName = ident\noneofName = ident\nmapName = ident\nserviceName = ident\nrpcName = ident\nmessageType = [ \".\" ] { ident \".\" } messageName\nenumType = [ \".\" ] { ident \".\" } enumName\n\n```\n\n### Integer Literals\n\n```\nintLit = decimalLit | octalLit | hexLit\ndecimalLit = [-] ( \"1\" ... \"9\" ) { decimalDigit }\noctalLit = [-] \"0\" { octalDigit }\nhexLit = [-] \"0\" ( \"x\" | \"X\" ) hexDigit { hexDigit }\n\n```\n\n### Floating-point Literals\n\n```\nfloatLit = [-] ( decimals \".\" [ decimals ] [ exponent ] | decimals exponent | \".\"decimals [ exponent ] ) | \"inf\" | \"nan\"\ndecimals = [-] decimalDigit { decimalDigit }\nexponent = ( \"e\" | \"E\" ) [ \"+\" | \"-\" ] decimals\n\n```\n\n### Boolean\n\n```\nboolLit = \"true\" | \"false\"\n\n```\n\n### String Literals\n\n```\nstrLit = strLitSingle { strLitSingle }\nstrLitSingle = ( \"'\" { charValue } \"'\" ) | ( '\"' { charValue } '\"' )\ncharValue = hexEscape | octEscape | charEscape | unicodeEscape | unicodeLongEscape | /[^\\0\\n\\\\]/\nhexEscape = '\\' ( \"x\" | \"X\" ) hexDigit [ hexDigit ]\noctEscape = '\\' octalDigit [ octalDigit [ octalDigit ] ]\ncharEscape = '\\' ( \"a\" | \"b\" | \"f\" | \"n\" | \"r\" | \"t\" | \"v\" | '\\' | \"'\" | '\"' )\nunicodeEscape = '\\' \"u\" hexDigit hexDigit hexDigit hexDigit\nunicodeLongEscape = '\\' \"U\" ( \"000\" hexDigit hexDigit hexDigit hexDigit hexDigit |\n \"0010\" hexDigit hexDigit hexDigit hexDigit\n\n```\n\n### EmptyStatement\n\n```\nemptyStatement = \";\"\n\n```\n\n### Constant\n\n```\nconstant = fullIdent | ( [ \"-\" | \"+\" ] intLit ) | ( [ \"-\" | \"+\" ] floatLit ) |\n strLit | boolLit | MessageValue\n\n`\n\nTitle: Language Guide (proto 2) | Protocol Buffers Documentation\nURL: https://protobuf.dev/programming-guides/proto2/\nText: Language Guide (proto 2) | Protocol Buffers Documentation\n\n# Language Guide (proto 2)\n\nCovers how to use the proto2 revision of Protocol Buffers language in your project.\n\nThis guide describes how to use the protocol buffer language to structure your protocol buffer data, including`.proto` file syntax and how to generate data access classes from your`.proto` files. It covers the proto2 revision of the protocol buffers language.\n\nFor information on editions syntax, see the [Protobuf Editions Language Guide].\n\nFor information on proto3 syntax, see the [Proto3 Language Guide].\n\nThis is a reference guide ‚Äì for a step by step example that uses many of the features described in this document, see the [tutorial] for your chosen language.\n\n## Defining A Message Type\n\nFirst let‚Äôs look at a very simple example. Let‚Äôs say you want to define a search request message format, where each search request has a query string, the particular page of results you are interested in, and a number of results per page. Here‚Äôs the`.proto` file you use to define the message type.\n\n```\nsyntax = \"proto2\";\n\nmessage SearchRequest {\n optional string query = 1;\n optional int32 page_number = 2;\n optional int32 results_per_page = 3;\n}\n\n```\n\nThe first line of the file specifies that you‚Äôre using the proto2 revision of the protobuf language spec.\n\n- If no`syntax` is specified, the protocol buffer compiler will assume you are using proto2.\n- The`syntax` must be the first non-empty, non-comment line of the file.\n\nThe`SearchRequest` message definition specifies three fields (name/value pairs), one for each piece of data that you want to include in this type of message. Each field has a name and a type.\n\n### Specifying Field Types\n\nIn the earlier example, all the fields are scalar types: two integers (`page_number` and`results_per_page`) and a string (`query`). You can also specify enumerations and composite types like other message types for your field.\n\n### Assigning Field Numbers\n\nYou must give each field in your message definition a number between`1` and`536,870,911` with the following restrictions:\n\n- You cannot use any previously reserved field numbers or any field numbers that have been allocated to extensions.\n- Field numbers`19,000` to`19,999` are reserved for the Pr\n\nTitle: Remaining differences between proto2 and proto3 - Google Groups\nPublished Date: 2021-03-26T00:00:00.000Z\nURL: https://groups.google.com/g/protobuf/c/Pezwn5UYZss\nText: Remaining differences between proto2 and proto3\n[![] Groups] \nGroups\nConversations\nAll groups and messages\nSend feedback to Google\nHelp\nTraining\n[] \n[Sign in] \n[Groups] \nGroups\n&#xE5C4;\n&#xE899;\n&#xE408;\n&#xE409;\n# Remaining differences between proto2 and proto3\n5,581 views\nSkip to first unread message\n&#xE946;\n![zel...@gmail.com&#39;s profile photo] \n### zel...@gmail.com\nunread,\nMar 26, 2021, 6:34:26‚ÄØAM3/26/21\n&#xE83A;\n&#xE15F;\n&#xE5D4;\nReply to author\nSign in to reply to author\nForward\nSign in to forward\nDelete\nYou do not have permission to delete messages in this group\nCopy link\nReport message\nShow original message\nEither email addresses are anonymous for this group or you need the view member email addresses permission to view the original message\nto Protocol Buffers\nHi folks.\nI just noticed that[proto3 got optional fields]. At my workplace, Square, we&#39;ve been stuck on proto2 forever, because we have a mountain of protos that both optional fields and proto option annotations all over the place.\nIs there an up-to-date summary of the remaining differences between proto2 and proto3? If proto3 is converging on full proto2 functionality support, there&#39;s a chance we could migrate to proto3, which would be extremely helpful: proto3 seems better supported in Ruby, for example.\nThanks,\nZellyn Hunter\n![David Gomez&#39;s profile photo] \n### David Gomez\nunread,\nMar 26, 2021, 7:08:42‚ÄØAM3/26/21\n&#xE83A;\n&#xE15F;\n&#xE5D4;\nReply to author\nSign in to reply to author\nForward\nSign in to forward\nDelete\nYou do not have permission to delete messages in this group\nCopy link\nReport message\nShow original message\nEither email addresses are anonymous for this group or you need the view member email addresses permission to view the original message\nto zel...@gmail.com, Protocol Buffers\nI work at Google and I can tell you that¬†proto2 and proto3 freely interoperate. That is, they can reference symbols across versions and generate code that works well together. It is entirely reasonable for a proto2 message to reference a proto3 enum or message, and vice versa, with the exception that proto3 messages cannot reference proto2 enums due to differences in semantics.\n&#xE5D3;\n&#xE5D3;\n> > -- > You received th\n\nTitle: Language Guide (proto 3) | Protocol Buffers Documentation\nURL: https://protobuf.dev/programming-guides/proto3/\nText: Language Guide (proto 3) | Protocol Buffers Documentation\n\n# Language Guide (proto 3)\n\nCovers how to use the proto3 revision of the Protocol Buffers language in your project.\n\nThis guide describes how to use the protocol buffer language to structure your protocol buffer data, including`.proto` file syntax and how to generate data access classes from your`.proto` files. It covers the proto3 revision of the protocol buffers language.\n\nFor information on editions syntax, see the [Protobuf Editions Language Guide].\n\nFor information on the proto2 syntax, see the [Proto2 Language Guide].\n\nThis is a reference guide ‚Äì for a step by step example that uses many of the features described in this document, see the [tutorial] for your chosen language.\n\n## Defining A Message Type\n\nFirst let‚Äôs look at a very simple example. Let‚Äôs say you want to define a search request message format, where each search request has a query string, the particular page of results you are interested in, and a number of results per page. Here‚Äôs the`.proto` file you use to define the message type.\n\n```\nsyntax = \"proto3\";\n\nmessage SearchRequest {\n string query = 1;\n int32 page_number = 2;\n int32 results_per_page = 3;\n}\n\n```\n\nThe first line of the file specifies that you‚Äôre using the proto3 revision of the protobuf language spec.\n\n- If no`edition` or`syntax` is specified, the protocol buffer compiler will assume you are using [proto2].\n- The`edition`(or`syntax` for proto2/proto3) must be the first non-empty, non-comment line of the file.\n\nThe`SearchRequest` message definition specifies three fields (name/value pairs), one for each piece of data that you want to include in this type of message. Each field has a name and a type.\n\n### Specifying Field Types\n\nIn the earlier example, all the fields are scalar types: two integers (`page_number` and`results_per_page`) and a string (`query`). You can also specify enumerations and composite types like other message types for your field.\n\n### Assigning Field Numbers\n\nYou must give each field in your message definition a number between`1` and`536,870,911` with the following restrictions:\n\n- You cannot use any previously reserved field numbers or any field numbers that have been allocated to [extensions].\n- Field numbers`19,000` to`19,\n\n",
            "title": "",
            "metadata": {
              "truncated": false
            },
            "time": {
              "start": 1771212960136,
              "end": 1771212963882,
              "compacted": 1771213545700
            },
            "attachments": []
          },
          "metadata": {
            "openai": {
              "itemId": "fc_0ef6fe591fc123f701699290a011ec8193aa412c0b4db568bb"
            }
          },
          "id": "prt_c6484f16d0011LYM058m7o8Yvl",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6484cabd001kba6FKYf7Y42Al"
        },
        {
          "type": "tool",
          "callID": "call_9uy7bxzr3nly2nhu8qpi96SN",
          "tool": "websearch_web_search_exa",
          "state": {
            "status": "completed",
            "input": {
              "query": "protoc rust prost-build tonic-build generate Rust from .proto docs",
              "numResults": 5,
              "livecrawl": "preferred",
              "type": "auto",
              "contextMaxCharacters": 12000
            },
            "output": "Title: tonic-prost-build - crates.io: Rust Package Registry\nPublished Date: 2026-01-28T00:00:00.000Z\nURL: https://crates.io/crates/tonic-prost-build\nText: tonic-prost-build - crates.io: Rust Package Registry\n[![] # crates.io\n] \n# The Rust community‚Äôs crate registry\nSubmit\nChange color scheme\n* light\n* dark\n* system\nMenu\n* [Browse All Crates] \n* Log in with GitHub\n# tonic-prost-buildv0.14.3\nProst build integration for tonic\n* [#grpc] \n* [#prost] \n* [#protobuf] \n* [#rpc] \n* [#tonic] \n## Metadata\n14 days ago\n2021\nedition\n[MIT] \n878\nSLoC\n12.8 KiB\npkg:cargo/tonic-prost-build@0.14.3[] \n## Install\nRun the following Cargo command in your project directory:\ncargo add tonic-prost-build\nOr add the following line to your Cargo.toml:\ntonic-prost-build = \"0.14.3\"\n## Repository\n[github.com/hyperium/tonic] \n## Owners\n* [![Lucio Franco (LucioFranco)] Lucio Franco] \n## Categories\n* [Build Utils] \n* [Network programming] \n* [Asynchronous] \n[Report crate] \n### Stats Overview\n6,621,303Downloads all time\n4Versions published\n#### Downloads over the last 90 days\nDisplay as\nStacked\n* Stacked\n* Unstacked\n\nTitle: tonic_prost_build - Rust\nAuthor: \nPublished Date: 2025-09-01T00:00:00.000Z\nURL: https://docs.rs/tonic-prost-build/latest/tonic_prost_build/\nText: tonic\\_prost\\_build - Rust\n[Docs.rs] \n* [tonic-prost-build-0.14.3] \n* tonic-prost-build 0.14.3\n* [Permalink] \n* [Docs.rs crate page] \n* [MIT] \n* Links\n* [Homepage] \n* [Repository] \n* [crates.io] \n* [Source] \n* Owners\n* [LucioFranco] \n* Dependencies\n* * [prettyplease ^0.2*normal*] \n* [proc-macro2 ^1.0*normal*] \n* [prost-build ^0.14*normal*] \n* [prost-types ^0.14*normal*] \n* [quote ^1.0*normal*] \n* [syn ^2.0*normal*] \n* [tempfile ^3.0*normal*] \n* [tonic-build ^0.14.0*normal*] \n* [tonic ^0.14.0*dev*] \n* Versions\n* * [**100%**of the crate is documented] \n* [Platform] \n* [aarch64-apple-darwin] \n* [aarch64-unknown-linux-gnu] \n* [i686-pc-windows-msvc] \n* [x86\\_64-pc-windows-msvc] \n* [x86\\_64-unknown-linux-gnu] \n* [Feature flags] \n* [docs.rs] \n* [About docs.rs] \n* [Badges] \n* [Builds] \n* [Metadata] \n* [Shorthand URLs] \n* [Download] \n* [Rustdoc JSON] \n* [Build queue] \n* [Privacy policy] \n* [Rust] \n* [Rust website] \n* [The Book] \n* [Standard Library API Reference] \n* [Rust by Example] \n* [The Cargo Guide] \n* [Clippy Documentation] \n[Skip to main content] ## [Crate tonic\\_prost\\_build] \n# Cratetonic\\_prost\\_buildCopy item path\n[Source] \nExpand description\nProst build integration for tonic.\nThis crate provides code generation for gRPC services using protobuf definitions\nvia the[`prost`] ecosystem.\n## [¬ß] Example\n[‚ìò] \n```\n`usetonic\\_prost\\_build::configure;fnmain() {\nconfigure()\n.compile\\_protos(&amp;[\"proto/service.proto\"],&amp;[\"proto\"])\n.unwrap();\n}`\n```\n## Modules[¬ß] \n[manual] This module provides utilities for generating`tonic`service stubs and clients\npurely in Rust without the need of`proto`files. It also enables you to set a custom`Codec`if you want to use a custom serialization format other than`protobuf`.## Structs[¬ß] \n[Builder] Builder for configuring and generating code from`.proto`files.[Config] Configuration options for Protobuf code generation.[FileDescriptorSet] The protocol compiler can output a FileDescriptorSet containing the .proto\nfiles it parses.[TonicAttributes] Attributes that will be added to`mod`and`struct`items.## Traits[¬ß] \n[TonicMethod] Method generation trait.[TonicService] Service generation trait.## Functions[¬ß] \n[compile\\_fds] Simple file descriptor set compiling. Use[`configure`] inste\n\nTitle: tonic_build - Rust - Docs.rs\nURL: https://docs.rs/tonic-build/latest/tonic_build/\nText: tonic\\_build - Rust\n[Docs.rs] \n* [tonic-build-0.14.2] \n* tonic-build 0.14.2\n* [Permalink] \n* [Docs.rs crate page] \n* [MIT] \n* Links\n* [Homepage] \n* [Repository] \n* [crates.io] \n* [Source] \n* Owners\n* [carllerche] \n* [LucioFranco] \n* [github:hyperium:tonic] \n* Dependencies\n* * [prettyplease ^0.2*normal*] \n* [proc-macro2 ^1.0*normal*] \n* [quote ^1.0*normal*] \n* [syn ^2.0*normal*] \n* Versions\n* * [**100%**of the crate is documented] \n* [Platform] \n* [i686-pc-windows-msvc] \n* [i686-unknown-linux-gnu] \n* [x86\\_64-apple-darwin] \n* [x86\\_64-pc-windows-msvc] \n* [x86\\_64-unknown-linux-gnu] \n* [Feature flags] \n* [docs.rs] \n* [About docs.rs] \n* [Badges] \n* [Builds] \n* [Metadata] \n* [Shorthand URLs] \n* [Download] \n* [Rustdoc JSON] \n* [Build queue] \n* [Privacy policy] \n* [Rust] \n* [Rust website] \n* [The Book] \n* [Standard Library API Reference] \n* [Rust by Example] \n* [The Cargo Guide] \n* [Clippy Documentation] \n## [Crate tonic\\_build] \n# Cratetonic\\_buildCopy item path\n[Source] \nExpand description\n## [¬ß] tonic-build\nProvides code generation for service stubs to use with tonic. For protobuf compilation via prost, use the`tonic-prost-build`crate.\n## [¬ß] Feature flags\n* `cleanup-markdown`: Enables cleaning up documentation from the generated code.\nUseful when documentation of the generated code fails`cargo test --doc`for example.\nThe`prost`feature must be enabled to use this feature.\n* `prost`: Enables usage of prost generator (enabled by default).\n* `transport`: Enables generation of`connect`method using`tonic::transport::Channel`(enabled by default).### [¬ß] Features\nRequired dependencies\n```\n`[dependencies]\ntonic = &quot;&lt;tonic-version&gt;&quot;\nprost = &quot;&lt;prost-version&gt;&quot;\n[build-dependencies]\ntonic-prost-build = &quot;&lt;tonic-version&gt;&quot;`\n```\n### [¬ß] Getting Started\nFor protobuf compilation, use`tonic-prost-build`in your[`build.rs`file] at the root of the binary/library.\nYou can rely on the defaults via\n[‚ìò] \n```\n`fnmain() -&gt;Result&lt;(), Box&lt;dynstd::error::Error&gt;&gt;&gt;&gt; {\ntonic\\_prost\\_build::compile\\_protos(\"proto/service.proto\")?;Ok(())\n}`\n```\nOr configure the generated code deeper via\n[‚ìò] \n```\n`fnmain() -&gt;Result&lt;(), Box&lt;dynstd::error::Error&gt;&gt;&gt;&gt; {\ntonic\\_prost\\_build::configure()\n.build\\_server(false)\n.compile\\_pr\n\nTitle: prost_build - Rust\nAuthor: \nPublished Date: 2025-08-22T00:00:00.000Z\nURL: https://docs.rs/prost-build\nText: prost\\_build - Rust\n[Docs.rs] \n* [prost-build-0.14.3] \n* prost-build 0.14.3\n* [Permalink] \n* [Docs.rs crate page] \n* [Apache-2.0] \n* Links\n* [Repository] \n* [crates.io] \n* [Source] \n* Owners\n* [danburkert] \n* [github:tokio-rs:prost-core] \n* Dependencies\n* * [heck \\>=0.4,\\<=0.5*normal*] \n* [itertools \\>=0.10,\\<=0.14*normal*] \n* [log ^0.4.4*normal*] \n* [multimap \\>=0.8,\\<=0.10*normal*] \n* [petgraph ^0.8*normal*] \n* [prettyplease ^0.2*normal**optional*] \n* [prost ^0.14.3*normal*] \n* [prost-types ^0.14.3*normal*] \n* [pulldown-cmark ^0.13*normal**optional*] \n* [pulldown-cmark-to-cmark ^22*normal**optional*] \n* [regex ^1.8.1*normal*] \n* [syn ^2*normal**optional*] \n* [tempfile ^3*normal*] \n* [env\\_logger ^0.11*dev*] \n* Versions\n* * [**97.06%**of the crate is documented] \n* [Platform] \n* [aarch64-apple-darwin] \n* [aarch64-unknown-linux-gnu] \n* [i686-pc-windows-msvc] \n* [x86\\_64-pc-windows-msvc] \n* [x86\\_64-unknown-linux-gnu] \n* [Feature flags] \n* [docs.rs] \n* [About docs.rs] \n* [Badges] \n* [Builds] \n* [Metadata] \n* [Shorthand URLs] \n* [Download] \n* [Rustdoc JSON] \n* [Build queue] \n* [Privacy policy] \n* [Rust] \n* [Rust website] \n* [The Book] \n* [Standard Library API Reference] \n* [Rust by Example] \n* [The Cargo Guide] \n* [Clippy Documentation] \n## [Crate prost\\_build] \n# Crateprost\\_buildCopy item path\n[Source] \nExpand description\n`prost-build`compiles`.proto`files into Rust.\n`prost-build`is designed to be used for build-time code generation as part of a Cargo\nbuild-script.\n### [¬ß] Example\nLet‚Äôs create a small library crate,`snazzy`, that defines a collection of\nsnazzy new items in a protobuf file.\n```\n`$ cargo new --lib snazzy &amp;&amp; cd snazzy`\n```\nFirst, add`prost-build`and`prost`as dependencies to`Cargo.toml`:\n```\n`$ cargo add --build prost-build\n$ cargo add prost`\n```\nNext, add`src/items.proto`to the project:\n```\n`syntax = &quot;proto3&quot;;\npackage snazzy.items;\n// A snazzy new shirt!\nmessage Shirt {\n// Label sizes\nenum Size {\nSMALL = 0;\nMEDIUM = 1;\nLARGE = 2;\n}\n// The base color\nstring color = 1;\n// The size as stated on the label\nSize size = 2;\n}`\n```\nTo generate Rust code from`items.proto`, we use`prost-build`in the crate‚Äôs`build.rs`build-script:\n```\n`usestd::io::Result;fnmain() -&gt;Result&lt;&lt;()&gt;&gt; {\nprost\\_build::compile\\_protos\n\nTitle: protoc_gen_tonic - Rust\nAuthor: \nPublished Date: 2025-03-28T00:00:00.000Z\nURL: https://docs.rs/protoc-gen-tonic/latest/protoc_gen_tonic/\nText: protoc\\_gen\\_tonic - Rust\n[Docs.rs] \n* [protoc-gen-tonic-0.5.0] \n* protoc-gen-tonic 0.5.0\n* [Permalink] \n* [Docs.rs crate page] \n* [Apache-2.0] \n* Links\n* [Homepage] \n* [Repository] \n* [crates.io] \n* [Source] \n* Owners\n* [neoeinstein] \n* Dependencies\n* * [heck ^0.5.0*normal*] \n* [prettyplease ^0.2.37*normal*] \n* [proc-macro2 ^1.0.103*normal*] \n* [prost ^0.14.1*normal*] \n* [prost-build ^0.14.1*normal*] \n* [prost-types ^0.14.1*normal*] \n* [protoc-gen-prost ^0.5.0*normal*] \n* [quote ^1.0.42*normal*] \n* [regex ^1.11.1*normal*] \n* [syn ^2.0.109*normal*] \n* [tonic-build ^0.14.1*normal*] \n* Versions\n* * [**100%**of the crate is documented] \n* [Platform] \n* [aarch64-apple-darwin] \n* [aarch64-unknown-linux-gnu] \n* [i686-pc-windows-msvc] \n* [x86\\_64-pc-windows-msvc] \n* [x86\\_64-unknown-linux-gnu] \n* [Feature flags] \n* [docs.rs] \n* [About docs.rs] \n* [Badges] \n* [Builds] \n* [Metadata] \n* [Shorthand URLs] \n* [Download] \n* [Rustdoc JSON] \n* [Build queue] \n* [Privacy policy] \n* [Rust] \n* [Rust website] \n* [The Book] \n* [Standard Library API Reference] \n* [Rust by Example] \n* [The Cargo Guide] \n* [Clippy Documentation] \n## [Crate protoc\\_gen\\_tonic] \n# Crateprotoc\\_gen\\_tonicCopy item path\n[Source] \nExpand description\n## [¬ß] protoc-gen-tonic\nA`protoc`plugin that generates*[Tonic] *gRPC server and client code using\nthe*[Prost!] *code generation engine.\nWhen used in projects that use only Rust code, the preferred mechanism for\ngenerating gRPC services with*Tonic*is to use[`tonic-build`] from\nwithin a`build.rs`file. However, when working in polyglot environments,\nit can be advantageous to utilize common tooling in the Protocol Buffers\necosystem. One common tool used for this purpose is*[buf] *, which simplifies\nthe code generation process and includes several useful features, including\nlinting, package management, and breaking change detection.\n### [¬ß] Usage\nEnsure that`protoc-gen-tonic`has been installed within a directory on your`$PATH`. Then invoke`protoc`from the command line as follows:\n```\n`protoc --tonic\\_out=proto/gen -I proto proto/greeter/v1/greeter.proto`\n```\n#### [¬ß] Options\nThis tool supports all the same options from`tonic-build`except for those\nthat are expected to have been completely handled in an earlier`prot\n\n",
            "title": "",
            "metadata": {
              "truncated": false
            },
            "time": {
              "start": 1771212960152,
              "end": 1771212961609,
              "compacted": 1771213545699
            },
            "attachments": []
          },
          "metadata": {
            "openai": {
              "itemId": "fc_0ef6fe591fc123f701699290a0120081938accc526b037ffa3"
            }
          },
          "id": "prt_c6484f189001ZLYkETuMmNTioY",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6484cabd001kba6FKYf7Y42Al"
        },
        {
          "type": "tool",
          "callID": "call_Z8XtHLNCjXC0bGmlodM2QRtZ",
          "tool": "websearch_web_search_exa",
          "state": {
            "status": "completed",
            "input": {
              "query": "TypeScript protoc ts-proto plugin usage example command",
              "numResults": 5,
              "livecrawl": "preferred",
              "type": "auto",
              "contextMaxCharacters": 12000
            },
            "output": "Title: ts-proto | Yarn\nURL: https://classic.yarnpkg.com/en/package/ts-proto\nText: Yarn\n[] \nImportant:This documentation covers Yarn 1 (Classic).\nFor Yarn 2+ docs and migration guide, see yarnpkg.com.\n# Package detail\n## ‚Ä¶[![]] 0\n‚Ä¶### [readme] \n![] \n[https://yarn.pm/‚Ä¶] \n![] copy\n[![] ‚Ä¶] \n# Use it\n`$yarn add ‚Ä¶`![] copy\n[Try in RunKit] ¬∑[Browse Files] \n# CDNs\nunpkg[unpkg.com/‚Ä¶/] \nbundle.run[bundle.run/‚Ä¶] \njsDelivr[cdn.jsdelivr.net/npm/‚Ä¶/] \n# Popularity\n![] Downloads last 30 days0\n![] jsDelivr last 30 days0\n![] Dependents[0] \n# Usage\n![] Dependencies0\n![] DevDependencies0\n![] Packages[see package.json] \n# Versions\n# Contributors\n* [![]]\n\nTitle: Getting Started with Protobufs and Typescript - Mechanical Rock\nURL: https://www.mechanicalrock.io/blog/getting-started-with-protobufs-and-typescript\nText: Getting Started with Protobufs and Typescript\n\n[<< Back to all Blogs] \n\n# Getting Started with Protobufs and Typescript\n\nEd Newsom8 April 2022\n\nGetting Protobufs to work with Typescript for the first time is not very straightforward and this article runs through the minimum steps needed to make it work. Hopefully after reading this and working through the code, you will be confident enough to start using Protobufs in your own projects.\n\nClick here to skip to the technical bits or [Click here for the code repository in Github and to skip all the words] \n\n## How Did We Get Here?\n\nA while ago I was asked to build a specific type of data API that supports Protobufs. My first reaction was to groan because I had tried to learn Protobufs previously and failed twice. Admittedly on both occasions I did not have an application to focus on and other shiny things distracted me. Before trying again I asked some of my infinitely more experienced colleagues here at [Mechanical Rock] if it was just me or is the documentation for learning Protobufs from zero really '@#^%'? There was some great discussion on this and they sent me on my way with more than a few useful hints.\n\nHaving got to the point where I understand enough to use them in anger, I realised that trying to learn Protobufs with Typescript first was the problem because that is where the doc's fall short. I actually had to revert to my first love, Python, before I could transfer that newly minted knowledge to TypeScript.\n\n## Other Stuff & Assumptions\n\nI am going to skip over the why Protobufs vs XML, the details of the [proto3 data structure] and the like which you can find in plenty of other articles. I'm assuming you know: node.js, Typescript, npm and Jest. I am using Mac/Linux here (sorry Windows users but you can deal with your own world of pain). I am also shamelessly basing this on the [Google Protobuf Tutorials] because I am sure you have already been there, hence using the Address Book example.\n\n## Making It Work\n\nWe're going to work through an end to end process to demonstrate the minimum of using Protobufs with TypeScript. Check out the [repository on Github] which brings this all together.\n\n1. De-serialise the message\n2. Do something with th\n\nTitle: Using Protobuf with TypeScript for data serialization - LogRocket Blog\nAuthor: Ibiyemi Adewakun\nURL: https://blog.logrocket.com/using-protobuf-typescript-data-serialization/\nText: Using Protobuf with TypeScript for data serialization - LogRocket Blog\n\n###### Advisory boards aren‚Äôt only for executives. Join the LogRocket Content Advisory Board today ‚Üí\n\n2023-07-17\n\n3046\n\n#typescript\n\nIbiyemi Adewakun\n\n174635\n\n109\n\n## See how LogRocket's Galileo AI surfaces the most severe issues for you\n\n### No signup required\n\nCheck it out\n\nA key part of a distributed system‚Äôs architecture is how data is transmitted between its different parts. Data transmission can be done using various methods, including HTTP requests, WebSockets, event emitters, and other protocols.\n\nIn this article, we will explore a crucial aspect of how data is transferred within distributed systems ‚Äî the serialization of data. We will focus on a specific protocol for serialization called Protobuf and also focus on serializing TypeScript objects using Protobuf messages.\n\nThe full code for our demo project can be found in [this GitHub repo]. You can check it out as we get started to help you follow along with this tutorial.\n\n### üöÄ Sign up for The Replay newsletter\n\n[The Replay] is a weekly newsletter for dev and engineering leaders.\n\nDelivered once a week, it's your curated guide to the most important conversations around frontend dev, emerging AI tools, and the state of modern software.\n\n## What is data serialization?\n\nData serialization is a process that involves transforming a data object into a stream of bytes, facilitating easier storage and transmission.\n\nData deserialization is the opposite operation. It involves reconstructing the data object from the stream of bytes into a native structure. This allows the application receiving or retrieving the data object to understand it for read and write operations.\n\nThere are several serialization data formats for storing serialized data, including XML, JSON, YAML, and Protobufs ‚Äî our main focus in this article.\n\n### Common use cases of data serialization\n\nData serialization plays an essential role in storing and transferring data within distributed systems. Some common use cases include:\n\n- Sending event messages to a topic in [a system like Kafka] \n- Putting items in a queue\n- Transporting data through messaging protocols like AMQP\n- Storing in\n\nTitle: Generate Typescript Types from Protobuf files - amlab\nURL: https://lab.amalitsky.com/posts/2024/generate-typescript-types-from-protobuf/\nText: Generate Typescript Types from Protobuf files | amlab\nTech\n[] \n# Generate Typescript Types from Protobuf files\nPublished onSep 2, 2024.\n[#CI] #codegen[#frontend] #protobuf[#tech] #typescript\nIn this article, I show how to use¬†the*[ts-proto] *package to generate API response and payload types from protobuf¬†files.\nI export only subset of all types generated, and do that from a¬†single*index.ts*file for\nthe ease of consumption¬†(import).\nLastly, we create an internal npm package with generated types, so that build¬†process\nand internal folder structure are concealed from the main application code which¬†uses\ngenerated types.\n## [] Problem Statement\nIn[Andromeda Security] *SPA*(single-page or, simply, web¬†application),\nwe use two types of APIs: GraphQL and¬†REST.\nGraphQL powers read-only views, such as dashboard and CRUD list, while REST is used¬†for\nconfiguration.\nThe mighty gang¬†of*GET*,*PUT*and*POST*methods powers our modal¬†windows.\nWeb-app codebase is written in TypeScript and requires domain specific types for code¬†modules\nworking with API servers, or, as we had for some time, hardcoded types, matching backend¬†ones.\nHardcoded types are not only frustrating to write and maintain, but are also subject¬†to\nregressions, whenever backend types change without introducing matching updates to the UI¬†code.\nWe can catch errors like that with thorough integration tests, but it is more expensive¬†and\nlabor-intensive than making sure our TS project compiles correctly on every CI¬†run.\nOn top of that we get type-aware code suggestions in an¬†IDE.\nFor our specific case, we want to generate types, interfaces and enums only, without¬†any\nimplementation code, such as RPC clients¬†wth`encode`/`decode`or json methods.\nWe don‚Äôt want to expose elaborate folder structure of original protobuf¬†files.\nIn fact, we are interested in a subset of types only, and would like to¬†be\nable to import them from a¬†single*index*file,\nas we usually do with any third-party JS¬†library.\n## [] Solution\n### [] ts-proto Plugin\nTo generate TypeScript types from protobuf I have chosen the¬†popular[ts-proto] package, which is¬†a[protoc] plugin.\nI also briefly¬†tried[ts-protoc-gen],\nbut it has a shorter list of options and seems to be incapable of¬†generating\nimplementation\n\nTitle: ts-proto\nAuthor: \nPublished Date: 2025-03-25T00:00:00.000Z\nURL: https://www.npmjs.com/package/ts-proto\nText: # ts-proto v2.11.2\n\n[![npm]] [![build]] \n\n- Version: 2.11.2\n- Homepage: https://github.com/stephenh/ts-proto#readme\n- Repository: git+https://github.com/stephenh/ts-proto.git\n- Bugs: https://github.com/stephenh/ts-proto/issues\n- License: ISC\n- Maintainers: shaberman \n- Weekly Downloads: 1.2M\n- Dependents: 434\n\n---\n\n[![npm]] \n[![build]] \n\n# ts-proto\n\n> `ts-proto` transforms your `.proto` files into strongly-typed, idiomatic TypeScript files!\n\n## ts-proto 2.x Release Notes\n\nThe 2.x release of ts-proto migrated the low-level Protobuf serializing that its `encode` and `decode` method use from the venerable, but aging & stagnant, `protobufjs` package to `@bufbuild/protobuf`.\n\nIf you only used the `encode` and `decode` methods, this should largely be a non-breaking change.\n\nHowever, if you used any code that used the old `protobufjs` `Writer` or `Reader` classes, you'll need to update your code to use the new `@bufbuild/protobuf` classes:\n\n```\nimport { BinaryReader, BinaryWriter } from \"@bufbuild/protobuf/wire\";\n```\n\nIf migrating to `@bufbuild/protobuf` is a blocker for you, you can pin your `ts-proto` version to `1.x`.\n\n**Disclaimer & apology:** I had intended to release ts-proto 2.x as an alpha release, but didn't get the semantic-release config correct, and so ts-proto 2.x was published as a major release without a proper alpha/beta cycle.\n\nIf you could file reports (or better PRs!) for any issues you come across while the release is still fresh, that would be greatly appreciated.\n\nAny tips or tricks for others on the migration would also be appreciated!\n\n## Table of contents\n\n- [ts-proto] \n\n- [Table of contents] \n\n- [Overview] \n- [QuickStart] \n\n- [Buf] \n - [ESM] \n\n- [Goals] \n\n- [Non-Goals] \n\n- [Example Types] \n- [Highlights] \n- [Auto-Batching / N+1 Prevention] \n- [Usage] \n\n- [Supported options] \n - [NestJS Support] \n - [Watch Mode] \n - [Basic gRPC implementation] \n\n- [Sponsors] \n- [Development] \n- [Assumptions] \n- [Todo] \n- [OneOf Handling] \n- [Default values and unset fields] \n- [Well-Known Types] \n\n- [Wrapper Types] \n - [JSON Types (Struct Types)] \n - [Timestamp] \n\n- [Number Types] \n- [Current Status of Optional Values] \n\n# Overview\n\nts-proto generates TypeScript types from protobuf schemas.\n\nI.e. given a `person.proto` schema like:\n\n```proto\n\n",
            "title": "",
            "metadata": {
              "truncated": false
            },
            "time": {
              "start": 1771212960153,
              "end": 1771212963432,
              "compacted": 1771213545699
            },
            "attachments": []
          },
          "metadata": {
            "openai": {
              "itemId": "fc_0ef6fe591fc123f701699290a0120c81939b7d7c7bbf26111e"
            }
          },
          "id": "prt_c6484f198001RNLkvl7qBCRkFG",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6484cabd001kba6FKYf7Y42Al"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "9d6f15c7b06acb730f3f74807178e28dcff70941",
          "cost": 0,
          "tokens": {
            "total": 23227,
            "input": 1635,
            "output": 472,
            "reasoning": 296,
            "cache": {
              "read": 21120,
              "write": 0
            }
          },
          "id": "prt_c6485002b001BGIdkUP53pZnIs",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6484cabd001kba6FKYf7Y42Al"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771212963951,
          "completed": 1771212970401
        },
        "parentID": "msg_c6484620d0011ltzji40BSbVp5",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 32167,
          "input": 8923,
          "output": 204,
          "reasoning": 84,
          "cache": {
            "read": 23040,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "tool-calls",
        "id": "msg_c6485006f001Al7LHcgXBsJjWQ",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "9d6f15c7b06acb730f3f74807178e28dcff70941",
          "id": "prt_c64850905001XZSoYAW4BtEnuA",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6485006f001Al7LHcgXBsJjWQ"
        },
        {
          "type": "reasoning",
          "text": "**Evaluating protobuf tooling sources**",
          "metadata": {
            "openai": {
              "itemId": "rs_08778ac324aa908201699290a663e8819591a5f6b2d202752f",
              "reasoningEncryptedContent": "gAAAAABpkpCp75pKJhr0fRaLs3a55u9YWUEpLnk0DRZeE6u8Rjtu2ihqZnTkvsOKTAcE2lbNvRuNIASkZ33qnv069mL-1FWOBlm2gy2X3_j1pFltlKj3ew-FUKI0CEMjvHGLUhsAVQ3tSRd1V97ZOgsOXqR4jiAY6bXacxLycx31vilb8i9LhKQXeTEc0aeHBTwO6PVZ2zgBzJMv2uiSYJsEhfpp4ccLJO9FYHr09e1a5d_R5nc9fE4pAsYA8GfNLgWOudxRHmuvUjr9WknwO1JNimc0hKri4bWXtrkVa8hI7d6OmXYEK1xk8_wIMwYsItJa07bbIGZs7mdYr4e9e7K_mWpW_zzFD8wqGJ_taT6CqnwU0j_nRFn0QDioJm3_PWRUyp0NdG1uie3tO1IahQwU0dH6tkVeS6xmzT60zIJFFFKQj1FnCOdAJ2gldSVip52o50Gn-8kvWDW8MQHi1ZArBpq5UC8XF6enrNTdzEdZ1qPZs2thJGVUJQtHnWxkxpeatql82e1AGRIIGsN0A-jc7jUOd-Zm_28VJ-KN3zLKuBx05QxyT1OyN7tUDVLweUeh6qGUAiGSK2EWg_AvN-Ke-AsiBarHHABpBT1CiNoYHQ_z-nVFkZ43OI3BKYBJLfU7V2xrt0uD83VoeMb28HeHXqdQkgAv1A-ksn_5xRuwQOBnUO5FWmMeArwKLSANYGDz9sPkqyBrc4zpRPe8kr2er8_5SAWMSFHbVwRtqfc1vhXjETm3czFP6LFO7fQt0oGyD0ZBm5YAOHgclVIB-3NhUCqsVmAYxofEPHTxiJBZUvrfbEU8cxlaZvgz0MVS-xTTdpRfkWW4M1JIoGGWQaWaoJKlTVXZ9HcKij5oP5arlO8QEYwPG9Y7DF2ZeNJuM67TBTuhU11HlxIu7xHfeEdi7xehIX7q-oUPNvh5FoTFJjCLrytbwIoMU1kyKPQY9m_X5S3nYcy5OHrM-hNkNDoJK4zZMlMA8-4mcm9HZr5hvFjGpX6vFCNq2nRqevnZvJf7P9ughsfp45PnWfmG_ti5sT7k3JL3CJlZlHqamPurKKJh8aq6ZTkE51Sqz7IxBjWheXWQZR0HDsTXZIgxazldlieEeJwLgtGGD5aMKoxV7-DUrsaqbROF6mVYD3AH8t6NXCfdtyl_N3gTMmsu9Dr4qIn8hIUwAC_kl8N_KBZJWloOB2lk9ArrqFjCY3hzqcf-lAcY77H8D-xfXGn_1ON82mAUaCoM1nRncjzl3PV9PWOW_JOVxMrcneISCs8DI1jCTKcERx0lvgWDERMr_NyMreFzEitGox8kGlMFQmWO1ME-Ya9r6B-TJG4ZB764sJJb3dcGdm57tO5L_FUkP9zGcAlIH7CEfA=="
            }
          },
          "time": {
            "start": 1771212966418,
            "end": 1771212969956
          },
          "id": "prt_c64850a12001qwBdUvS4utkWw1",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6485006f001Al7LHcgXBsJjWQ"
        },
        {
          "type": "tool",
          "callID": "call_ySFyyKvRksjp72huTtoyl4s7",
          "tool": "context7_resolve-library-id",
          "state": {
            "status": "completed",
            "input": {
              "libraryName": "protobuf",
              "query": "Official Protocol Buffers language guide proto2 proto3 differences"
            },
            "output": "Invalid API key. Please check your API key. API keys should start with 'ctx7sk' prefix.",
            "title": "",
            "metadata": {
              "truncated": false
            },
            "time": {
              "start": 1771212969957,
              "end": 1771212970219,
              "compacted": 1771213545699
            },
            "attachments": []
          },
          "metadata": {
            "openai": {
              "itemId": "fc_08778ac324aa908201699290a9d9a08195965ac4fba4b4a1e5"
            }
          },
          "id": "prt_c648517e5001ayZAkaajjFXums",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6485006f001Al7LHcgXBsJjWQ"
        },
        {
          "type": "tool",
          "callID": "call_jL2YpN1xUV0XaT7xTykpVtc1",
          "tool": "context7_resolve-library-id",
          "state": {
            "status": "completed",
            "input": {
              "libraryName": "prost-build",
              "query": "Generate Rust code from .proto using prost-build build.rs"
            },
            "output": "Invalid API key. Please check your API key. API keys should start with 'ctx7sk' prefix.",
            "title": "",
            "metadata": {
              "truncated": false
            },
            "time": {
              "start": 1771212969958,
              "end": 1771212970360,
              "compacted": 1771213545699
            },
            "attachments": []
          },
          "metadata": {
            "openai": {
              "itemId": "fc_08778ac324aa908201699290a9d9b48195bdba57e638aaf3f7"
            }
          },
          "id": "prt_c648517e6001BONomleLHrJltH",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6485006f001Al7LHcgXBsJjWQ"
        },
        {
          "type": "tool",
          "callID": "call_y8OVPScgGArNAjrVlLuxbwd9",
          "tool": "context7_resolve-library-id",
          "state": {
            "status": "completed",
            "input": {
              "libraryName": "ts-proto",
              "query": "ts-proto protoc plugin usage options"
            },
            "output": "Invalid API key. Please check your API key. API keys should start with 'ctx7sk' prefix.",
            "title": "",
            "metadata": {
              "truncated": false
            },
            "time": {
              "start": 1771212969959,
              "end": 1771212970358,
              "compacted": 1771213545699
            },
            "attachments": []
          },
          "metadata": {
            "openai": {
              "itemId": "fc_08778ac324aa908201699290a9d9bc819583310c9a654010dc"
            }
          },
          "id": "prt_c648517e7001LngYdAVjComjqD",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6485006f001Al7LHcgXBsJjWQ"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "9d6f15c7b06acb730f3f74807178e28dcff70941",
          "cost": 0,
          "tokens": {
            "total": 32167,
            "input": 8923,
            "output": 204,
            "reasoning": 84,
            "cache": {
              "read": 23040,
              "write": 0
            }
          },
          "id": "prt_c64851979001h0w6VaSXZD8sHn",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6485006f001Al7LHcgXBsJjWQ"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771212970403,
          "completed": 1771212983432
        },
        "parentID": "msg_c6484620d0011ltzji40BSbVp5",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 32819,
          "input": 274,
          "output": 545,
          "reasoning": 436,
          "cache": {
            "read": 32000,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "tool-calls",
        "id": "msg_c648519a3001dVkoAXMkiGYiY8",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "9d6f15c7b06acb730f3f74807178e28dcff70941",
          "id": "prt_c648521d5001pCkXk06C2u2hOr",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648519a3001dVkoAXMkiGYiY8"
        },
        {
          "type": "reasoning",
          "text": "**Planning official docs fetching**",
          "metadata": {
            "openai": {
              "itemId": "rs_01e5c65264d6e81601699290acce388194ae94b6b0a9401a2b",
              "reasoningEncryptedContent": "gAAAAABpkpC2cncQgpCsL-5eIZcqpIULo-bDsRjXEMOwqzFI9sFol7vRSqHP8k34qIpe6U6_fNCHCz79e05-WWdjIYTV-IPAfkTWEIfT0VQqqjDkDxUE6SBQCJCA0SHBBQqWa3QUIofvMHrOg-eBE2t7eTPQoIdT9vjE2QB9YRZmlAg7VceWBas9wbXQUTXDMDiBeTgCS77ag5Nf8QZah_X2SvZj0EG__FgJXX1g0W7dpeFwQIYOLacErKAfPhxYlg_hqYce8sPPXHpYqSnEQQymUwgDlOVMePT32a7yDgcrxepHyrzLkq8zQ3qATSBfRYyv_djSwHlv7levt7KzGyQzJsZGjp9yvjdgbBwPHbN3iOkTgN1ED1ETxVCJvcQCFdYtSyLW2lfSt8cZtHKz3ZrmFZHjxzmbakwIIkwAONRkgm47QmPL9WXrQtvg9DZYMxLD9ZS6RHVegKNndUchDtImYeAm2xbrxBXP0aY9O8NrHkwBcweOQAJ6dCcbXLGoi2lz_JVbCB_WpohEQW8WNHuBvgxhxIbyAjnuwIw8YJBmiXb8-L2bwFRFnyr1937aQuIoEHM1mUppjmEhjpkEmIYJ5SZKh57dhzabxu9ROs5IOkaGg5rIsZ4hkoi5Yu5OozhCyZD5JkZ4lXnZUtunZKT9atzfA5mRztFV4OwDRLDLnW0uO2sKB1aKWYsCmQ2OY_6TAUGRQgkp3TtvpoC-lrGtttknC6ybuQURi3W0PbAxKFWFvGJYHsBZZPPgh3lmBTp5Ll5e9N7u2u6ERLMFGRkUZJVjKNSTHnvEA6POMz5r1pfdN8Cq-PdL9I_Eu4o82mxtYtBm-Givo8XihNDP8o0cCf3_6OyPzud9nR1mjf6qdhvYb343ArMXXZdvAUyaFewt8xHfkW0x0OXOC_dHcHjpCSMGpMvOLU8SXqwvDQylNzEhU5QKH1IpC83MmKdcCPsLjmZg1MlUhNOGbO33n5NYVj4TJx1aohA_LkPoW5vdwzC0DZ-yGk07TypwwPwQG5UoNhoyO_B3LnN3JEYNnfYUvydE8vqtEYtcD8FSs1V2gEi6A913qr61Xi6GXDOUPGr-rJxAn8AKzS1A_1QUhx_3iFk3sYPA-9_3fTET2GosdGahqqyEqeIy5tUxMOC0thqPdOmlmLeWVkQr-iJ7oVpe2Px9GykicfWYGXM9WFLTBg9DRP0m9ZSPYB0Pwi7kAI1fft4HuLw8bEnKXzKvOxiq8N3b6_HdHOsuhPGUIADwNCkUHBq81CMZW1AfNsfKDY8LeJmhNpYtlZWS3rSRHfv3zV0ZhVP8TLAh7xIyT4_r5eOs7OxrPcxC_ssFwkwwTF8SYE0zyLPPi8s5ESzn3l671hf8yzFCmWMwjnM99N7Ku1JzcfXQqo58hOXOJtgyJKFVX_PTH9nQAt506g811cbcuKdekHIMCF_QFbaxFSNIqVoWACIASwcO8R4NosUZak_f2zbFwBFmTp72NohOsU4r3Q00LirzMWcQvV8khJvKaNDTHh2oMydZ1P_b8Se6tSp948DAD8xJOfa3U_IGkiPQXtSiuGk-73wD2wSSYhFaso_S7le_Q4hdkcain1IWPBye95tH5HmqDkxFDZOg94oxRTRNuy7H59O59fUWVLKHwrRNLLnV6A54hdwe4fvcJo7XnhnDku0zDwIE71pUOCcNz32xRkM774BwZsT0ehB22wo_zg5FX3LVxojGVm8GbiP5vagpf1ZZEvwmKd7pM5VvX2B2YUISJomgOchLd6GsdHrqZnAFEza2vou4UBcq7qqpH_DhcBPr4Xl6EHMw3IbU520a_n0irJoIHgYzzw6zGAVcbny0gDL-xZmAw_CVOu7Ed0UP-uGEhmmTwOIDLoJN-biIRkt8rJVrBeaJuUWsXlpo-ZoABbXE8gp-hurgXz2CSD2GXJ29gTIhp6TDpB5vEzGOSZ0RC_W_E4oD420TcninACLvSicuJCRJOpIA0dB0o_ZkgLDYMKgMA8vHjLlkUHAjT_uWmuiDzRl3NFRe2SQGOaf7Iaq019dCbVAVGwRFTWLCkyCQbIh9bzi_tzF_JkDIe-DdzYfXv3Aay-Pf3_ImDM8iivxB3HbzeMCNTrGuhWiqRAN13ARf-TRYIzmY2S3a0a3e3obUS0OBFYoTVMAL3dLyTrxj54xu0A8IMqSKNU8Ee3qv2svjMNmiOc6V13bXtC3nbu4c3N8vSUZH3GT2TCQzhqBOmq1AFh-e0fa3N-mV4Slbwi8Pb168O66gXnKV6UPRccPr_-2Um33uMlCXmo9_DoMw_Wt1gETDNHx09SuiT6efmbfCWzaVI4CGdQWd7Un5TtfpdvPxqF-fm3ixEcMrsE77-uRrFGvJIkHN3xiaBtEhKROmHnorVIH6TuLxs6IMnME88Z168sCYGhSbCeYPND1VhjjlJTN75hwQ5_82m7BJTjmgujR9JGO9C7MCTZE5GbWscGS0dlSHEFJzwlUqO2b4Vg59NURJ7YkxA9OnT4XILljbBtezsyPGmtK9cwp07z9v8GleFpvmW1i4PyyBJrChLY_sAeo-40S0B4-RJSA5cj_IkdtXcNsHyIOs7hhbtiFS_SjQ0_J3g3O2EqqsIJLCZdDTZQKQ3rts02qDe20VyCXBvTs76YUaAXll3Porc8RsfEGGk2wm5fbN8WdjmwzqKtl-Nly3ajkuRX45pOyCaHu2-F5DKx9ybxzmcO2KR_EpAUUCuUNq8LQ2GIScEEaEUaOXdJ4g9Y7dIpPOIiuWjaEwS9itdwP9vPQA2jQx8C-xnr6z89gbmFdAzT1WvksY7i_5jcUt4gJgXZ1FDFw5zTWfP-PfdQnllk7asNCm7jW-3SlARvlS6rV6AAiyxlXeUiCRQK-LorOkRawNnSlc14906MnKC2cJNffJ_0IbrNxBUEc1q_Myt3lkt9-phaTCF9EkLR8u8MHfwA_Tflc_l2nm1x5O8suBgBh3KWAUVecyYuiSUNFUWWpemPie54Iwr-hxpg56GeoTVlLTXAq9vSXRWjyUUl-spnP0-tJesjPUdfK2geDAhjdSojCKLvfdkpwiMiNWM6Iiuift7OIl14SrJRY3XkWjbc3DiPQ_q1EONohz0wfHMvnzYxN5RXIjiN0wfsOrFEZ4yJFbCghigil1Wxyj1QhtarQg0KAkb9HrA-HAkP-kY4EodYJfFgPd-6za855Ypu1iWPIie01cGZAYwCT-i01VlfME8l2xZs-1-8DO0CTiJMtUvbu_Y7clmCEWNM6SQ_vx3O2iVTCyuWQTGpWqxnoZY78ay0fRBBVl82siPDS7-41o_rMJZxU7DMBgQRGKyY61B6yaboCdd7KPYyA9cu3LqJzE_m-oDIfhndZhANNowkmW5zmxBb1Fxl32tUFyvsFJ_lTB9iC32E6YrLWg0_FV2SwfT85lLocNGoZmB9BsY1u-BZmA-M_ZEgmLABewSuBNvIQOgUhOPOry27eLIHFN1ljqaKtOfyMbR52TPrcqYPhJYNh_LUbXJZrh57eoy1GZMP_V5Kn4ov5HD7s0MpLXUqlJA5PORF7RFBzfkewnKbn_gFyLMCvzqbeM4JWkbvilhyPNOsSt"
            }
          },
          "time": {
            "start": 1771212972918,
            "end": 1771212982828
          },
          "id": "prt_c64852376001eLanmflAX32x3p",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648519a3001dVkoAXMkiGYiY8"
        },
        {
          "type": "tool",
          "callID": "call_qYccuIDt8SDWlhtjhs4YCJbq",
          "tool": "webfetch",
          "state": {
            "status": "completed",
            "input": {
              "url": "https://protobuf.dev/programming-guides/proto2/",
              "format": "markdown"
            },
            "output": "Language Guide (proto 2) | Protocol Buffers Documentation \n\n[Protocol Buffers Documentation](/)\n\n-   [Protocol Buffers](/)\n    -   [Overview](/overview/)\n    -   [Protoc Installation](/installation/ \"Protocol Buffer Compiler Installation\")\n    -   [News](/news/)\n    -   [Programming Guides](/programming-guides/)\n        -   [Language Guide (editions)](/programming-guides/editions/)\n        -   [Language Guide (proto 2)](/programming-guides/proto2/)\n        -   [Language Guide (proto 3)](/programming-guides/proto3/)\n        -   [Proto Limits](/programming-guides/proto-limits/)\n        -   [Style Guide](/programming-guides/style/)\n        -   [Enum Behavior](/programming-guides/enum/)\n        -   [Encoding](/programming-guides/encoding/)\n        -   [ProtoJSON Format](/programming-guides/json/)\n        -   [Techniques](/programming-guides/techniques/)\n        -   [Add-ons](/programming-guides/addons/ \"Third-Party Add-ons\")\n        -   [Extension Declarations](/programming-guides/extension_declarations/)\n        -   [Field Presence](/programming-guides/field_presence/ \"Application Note: Field Presence\")\n        -   [Proto Serialization Is Not Canonical](/programming-guides/serialization-not-canonical/)\n        -   [Deserializing Debug Proto Representations](/programming-guides/deserialize-debug/)\n    -   [Protobuf Editions](/editions/)\n        -   [Overview](/editions/overview/ \"Protobuf Editions Overview\")\n        -   [Feature Settings for Editions](/editions/features/)\n        -   [Implementing Editions Support](/editions/implementation/)\n    -   [Design Decisions](/design-decisions/ \"Protobuf Team Design Decisions\")\n        -   [No Nullable Setters/Getters Support](/design-decisions/nullable-getters-setters/)\n    -   [Proto Best Practices](/best-practices/)\n        -   [Avoid Cargo Culting](/best-practices/no-cargo-cults/)\n        -   [Proto Best Practices](/best-practices/dos-donts/)\n        -   [1-1-1 Best Practice](/best-practices/1-1-1/)\n    -   [Tutorials](/getting-started/)\n        -   [C++](/getting-started/cpptutorial/ \"Protocol Buffer Basics: C++\")\n        -   [C#](/getting-started/csharptutorial/ \"Protocol Buffer Basics: C#\")\n        -   [Dart](/getting-started/darttutorial/ \"Protocol Buffer Basics: Dart\")\n        -   [Go](/getting-started/gotutorial/ \"Protocol Buffer Basics: Go\")\n        -   [Java](/getting-started/javatutorial/ \"Protocol Buffer Basics: Java\")\n        -   [Kotlin](/getting-started/kotlintutorial/ \"Protocol Buffer Basics: Kotlin\")\n        -   [Python](/getting-started/pythontutorial/ \"Protocol Buffer Basics: Python\")\n    -   [Reference Guides](/reference/)\n        -   [C++](/reference/cpp/ \"C++ Reference\")\n            -   [Generated Code Guide](/reference/cpp/cpp-generated/ \"C++ Generated Code Guide\")\n            -   [String View APIs](/reference/cpp/string-view/)\n            -   [Arena Allocation Guide](/reference/cpp/arenas/ \"C++ Arena Allocation Guide\")\n            -   [Abseil Support](/reference/cpp/abseil/)\n            -   [C++ API](/reference/cpp/api-docs/)\n        -   [C#](/reference/csharp/ \"C# Reference\")\n            -   [Generated Code Guide](/reference/csharp/csharp-generated/ \"C# Generated Code Guide\")\n            -   [C# API](/reference/csharp/api-docs)\n        -   [Dart](/reference/dart/ \"Dart Reference\")\n            -   [Generated Code](/reference/dart/dart-generated/ \"Dart Generated Code\")\n            -   [Dart API](https://pub.dartlang.org/documentation/protobuf)\n        -   [Go](/reference/go/ \"Go Reference\")\n            -   [Generated Code Guide (Open)](/reference/go/go-generated/ \"Go Generated Code Guide (Open)\")\n            -   [Generated Code Guide (Opaque)](/reference/go/go-generated-opaque/ \"Go Generated Code Guide (Opaque)\")\n            -   [FAQ](/reference/go/faq/ \"Go FAQ\")\n            -   [Size Semantics](/reference/go/size/ \"Go Size Semantics\")\n            -   [Go API](https://pkg.go.dev/google.golang.org/protobuf/proto)\n            -   [Opaque API Migration](/reference/go/opaque-migration/ \"Go Opaque API Migration\")\n            -   [Opaque API: Manual Migration](/reference/go/opaque-migration-manual/ \"Go Opaque API: Manual Migration\")\n            -   [Opaque API FAQ](/reference/go/opaque-faq/ \"Go Opaque API FAQ\")\n        -   [Java](/reference/java/ \"Java Reference\")\n            -   [Generated Code Guide](/reference/java/java-generated/ \"Java Generated Code Guide\")\n            -   [Generated Proto Names](/reference/java/java-proto-names/ \"Java Proto Names\")\n            -   [Java API](/reference/java/api-docs/overview-summary.html)\n        -   [Kotlin](/reference/kotlin/ \"Kotlin Reference\")\n            -   [Kotlin](/reference/kotlin/api-docs/ \"Kotlin Reference\")\n            -   [Generated Code Guide](/reference/kotlin/kotlin-generated/ \"Kotlin Generated Code Guide\")\n        -   [Objective-C](/reference/objective-c/ \"Objective-C Reference\")\n            -   [Generated Code Guide](/reference/objective-c/objective-c-generated/ \"Objective-C Generated Code Guide\")\n        -   [PHP](/reference/php/ \"PHP Reference\")\n            -   [Generated Code Guide](/reference/php/php-generated/ \"PHP Generated Code Guide\")\n            -   [PHP API](/reference/php/api-docs/)\n        -   [Python](/reference/python/ \"Python Reference\")\n            -   [Generated Code Guide](/reference/python/python-generated/ \"Python Generated Code Guide\")\n            -   [Python Comparison](/reference/python/python-comparison/)\n            -   [Python API](https://googleapis.dev/python/protobuf/latest/)\n        -   [Ruby](/reference/ruby/ \"Ruby Reference\")\n            -   [Generated Code Guide](/reference/ruby/ruby-generated/ \"Ruby Generated Code Guide\")\n        -   [Rust](/reference/rust/ \"Rust Reference\")\n            -   [Generated Code Guide](/reference/rust/rust-generated/ \"Rust Generated Code Guide\")\n            -   [Redaction in Rust](/reference/rust/rust-redaction/)\n            -   [Building Rust Protos](/reference/rust/building-rust-protos/)\n            -   [Design Decisions](/reference/rust/rust-design-decisions/ \"Rust Proto Design Decisions\")\n        -   [Protocol Buffers](/reference/protobuf/ \"Protocol Buffers Reference\")\n            -   [2023 Language Specification](/reference/protobuf/edition-2023-spec/ \"Protocol Buffers Edition 2023 Language Specification\")\n            -   [Language Specification (Proto2 Syntax)](/reference/protobuf/proto2-spec/ \"Protocol Buffers Language Specification (Proto2 Syntax)\")\n            -   [2024 Language Specification](/reference/protobuf/edition-2024-spec/ \"Protocol Buffers Edition 2024 Language Specification\")\n            -   [Language Specification (Proto3)](/reference/protobuf/proto3-spec/ \"Protocol Buffers Language Specification (Proto3)\")\n            -   [Text Format Language Specification](/reference/protobuf/textformat-spec/)\n            -   [MIME Types](/reference/protobuf/mime-types/ \"Protocol Buffer MIME Types\")\n            -   [Well-Known Types](/reference/protobuf/google.protobuf/ \"Protocol Buffers Well-Known Types\")\n        -   [Other Languages](/reference/other/)\n    -   [Support](/support/)\n        -   [Version Support](/support/version-support/)\n        -   [Debugging](/support/debugging-playbook/)\n        -   [Migration Guide](/support/migration/)\n        -   [Cross-Version Runtime Guarantee](/support/cross-version-runtime-guarantee/)\n    -   [Downloads](/downloads/)\n    -   [History](/history/)\n    -   [Forum](https://groups.google.com/g/protobuf)\n    -   [](/navbar/)\n    -   [Search Results](/search/)\n\n[View page source](https://github.com/protocolbuffers/protocolbuffers.github.io/tree/main/content/programming-guides/proto2.md) [Edit this page](https://github.com/protocolbuffers/protocolbuffers.github.io/edit/main/content/programming-guides/proto2.md) [Create child page](https://github.com/protocolbuffers/protocolbuffers.github.io/new/main/content/programming-guides/proto2.md?filename=change-me.md&value=---%0Atitle%3A+%22Long+Page+Title%22%0AlinkTitle%3A+%22Short+Nav+Title%22%0Aweight%3A+100%0Adescription%3A+%3E-%0A+++++Page+description+for+heading+and+indexes.%0A---%0A%0A%23%23+Heading%0A%0AEdit+this+template+to+create+your+new+page.%0A%0A%2A+Give+it+a+good+name%2C+ending+in+%60.md%60+-+e.g.+%60getting-started.md%60%0A%2A+Edit+the+%22front+matter%22+section+at+the+top+of+the+page+%28weight+controls+how+its+ordered+amongst+other+pages+in+the+same+directory%3B+lowest+number+first%29.%0A%2A+Add+a+good+commit+message+at+the+bottom+of+the+page+%28%3C80+characters%3B+use+the+extended+description+field+for+more+detail%29.%0A%2A+Create+a+new+branch+so+you+can+preview+your+new+file+and+request+a+review+via+Pull+Request.%0A) [Create documentation issue](https://github.com/protocolbuffers/protocolbuffers.github.io/issues/new?title=Language%20Guide%20%28proto%202%29) [Create project issue](https://github.com/protocolbuffers/protobuf/issues/new)\n\n-   [Defining A Message Type](#simple)\n    -   [Specifying Field Types](#specifying-types)\n    -   [Assigning Field Numbers](#assigning)\n    -   [Specifying Field Cardinality](#field-labels)\n    -   [Adding More Message Types](#adding-types)\n    -   [Adding Comments](#adding-comments)\n    -   [Deleting Fields](#deleting)\n    -   [What‚Äôs Generated from Your `.proto`?](#generated)\n-   [Scalar Value Types](#scalar)\n-   [Default Field Values](#default)\n    -   [Overriding Default Scalar Values](#explicit-default)\n-   [Enumerations](#enum)\n    -   [Prefixing Enum Values](#prefixing-values)\n    -   [Enum Default Value](#enum-default)\n    -   [Enum Value Aliases](#enum-aliases)\n    -   [Reserved Values](#reserved)\n-   [Using Other Message Types](#other)\n    -   [Importing Definitions](#importing)\n    -   [Using proto3 Message Types](#proto3)\n-   [Nested Types](#nested)\n    -   [Groups](#groups)\n-   [Updating a Message Type](#updating)\n    -   [Binary Wire-unsafe Changes](#wire-unsafe-changes)\n    -   [Binary Wire-safe Changes](#wire-safe-changes)\n    -   [Binary Wire-compatible Changes (Conditionally Safe)](#conditionally-safe-changes)\n-   [Unknown Fields](#unknowns)\n    -   [Retaining Unknown Fields](#retaining)\n-   [Extensions](#extensions)\n    -   [Why Use Extensions?](#why-ext)\n    -   [Example Extension](#ext-example)\n    -   [Defining Extension Ranges](#defining-ranges)\n    -   [Choosing Extension Numbers](#choosing)\n    -   [Specifying Extension Types](#specifying-extension-types)\n    -   [Nested Extensions (not recommended)](#nested-exts)\n-   [Any](#any)\n-   [Oneof](#oneof)\n    -   [Using Oneof](#using-oneof)\n    -   [Oneof Features](#oneof-features)\n    -   [Backwards-compatibility issues](#backward)\n-   [Maps](#maps)\n    -   [Maps Features](#maps-features)\n    -   [Backwards Compatibility](#backwards)\n-   [Packages](#packages)\n    -   [Packages and Name Resolution](#name-resolution)\n-   [Defining Services](#services)\n-   [JSON Mapping](#json)\n-   [Options](#options)\n    -   [Enum Value Options](#enum-value-options)\n    -   [Custom Options](#customoptions)\n    -   [Option Retention](#option-retention)\n    -   [Option Targets](#option-targets)\n-   [Generating Your Classes](#generating)\n-   [File location](#location)\n    -   [Location Should be Language-agnostic](#location-language-agnostic)\n-   [Supported Platforms](#platforms)\n\n1.  [Programming Guides](/programming-guides/)\n2.  Language Guide (proto 2)\n\n# Language Guide (proto 2)\n\nCovers how to use the proto2 revision of Protocol Buffers language in your project.\n\nThis guide describes how to use the protocol buffer language to structure your protocol buffer data, including `.proto` file syntax and how to generate data access classes from your `.proto` files. It covers the **proto2** revision of the protocol buffers language.\n\nFor information on **editions** syntax, see the [Protobuf Editions Language Guide](/programming-guides/editions).\n\nFor information on **proto3** syntax, see the [Proto3 Language Guide](/programming-guides/proto3).\n\nThis is a reference guide ‚Äì for a step by step example that uses many of the features described in this document, see the [tutorial](/getting-started) for your chosen language.\n\n## Defining A Message Type\n\nFirst let‚Äôs look at a very simple example. Let‚Äôs say you want to define a search request message format, where each search request has a query string, the particular page of results you are interested in, and a number of results per page. Here‚Äôs the `.proto` file you use to define the message type.\n\n```proto\nsyntax = \"proto2\";\n\nmessage SearchRequest {\n  optional string query = 1;\n  optional int32 page_number = 2;\n  optional int32 results_per_page = 3;\n}\n```\n\n-   The first line of the file specifies that you‚Äôre using the proto2 revision of the protobuf language spec.\n    \n    -   The `syntax` must be the first non-empty, non-comment line of the file.\n    -   If no `syntax` is specified, the protocol buffer compiler will assume you are using proto2.\n-   The `SearchRequest` message definition specifies three fields (name/value pairs), one for each piece of data that you want to include in this type of message. Each field has a name and a type.\n    \n\n### Specifying Field Types\n\nIn the earlier example, all the fields are [scalar types](#scalar): two integers (`page_number` and `results_per_page`) and a string (`query`). You can also specify [enumerations](#enum) and composite types like other message types for your field.\n\n### Assigning Field Numbers\n\nYou must give each field in your message definition a number between `1` and `536,870,911` with the following restrictions:\n\n-   The given number **must be unique** among all fields for that message.\n-   Field numbers `19,000` to `19,999` are reserved for the Protocol Buffers implementation. The protocol buffer compiler will complain if you use one of these reserved field numbers in your message.\n-   You cannot use any previously [reserved](#fieldreserved) field numbers or any field numbers that have been allocated to [extensions](#extensions).\n\nThis number **cannot be changed once your message type is in use** because it identifies the field in the [message wire format](/programming-guides/encoding). ‚ÄúChanging‚Äù a field number is equivalent to deleting that field and creating a new field with the same type but a new number. See [Deleting Fields](#deleting) for how to do this properly.\n\nField numbers **should never be reused**. Never take a field number out of the [reserved](#fieldreserved) list for reuse with a new field definition. See [Consequences of Reusing Field Numbers](#consequences).\n\nYou should use the field numbers 1 through 15 for the most-frequently-set fields. Lower field number values take less space in the wire format. For example, field numbers in the range 1 through 15 take one byte to encode. Field numbers in the range 16 through 2047 take two bytes. You can find out more about this in [Protocol Buffer Encoding](/programming-guides/encoding#structure).\n\n#### Consequences of Reusing Field Numbers\n\nReusing a field number makes decoding wire-format messages ambiguous.\n\nThe protobuf wire format is lean and doesn‚Äôt provide a way to detect fields encoded using one definition and decoded using another.\n\nEncoding a field using one definition and then decoding that same field with a different definition can lead to:\n\n-   Developer time lost to debugging\n-   A parse/merge error (best case scenario)\n-   Leaked PII/SPII\n-   Data corruption\n\nCommon causes of field number reuse:\n\n-   renumbering fields (sometimes done to achieve a more aesthetically pleasing number order for fields). Renumbering effectively deletes and re-adds all the fields involved in the renumbering, resulting in incompatible wire-format changes.\n    \n-   deleting a field and not [reserving](#fieldreserved) the number to prevent future reuse.\n    \n    -   This has been a very easy mistake to make with [extension fields](#extensions) for several reasons. [Extension Declarations](/programming-guides/extension_declarations) provide a mechanism for reserving extension fields.\n\nThe field number is limited to 29 bits rather than 32 bits because three bits are used to specify the field‚Äôs wire format. For more on this, see the [Encoding topic](/programming-guides/encoding#structure).\n\n### Specifying Field Cardinality\n\nMessage fields can be one of the following:\n\n-   *Singular*:\n    \n    In proto2, there are two types of singular fields:\n    \n    -   `optional`: (recommended) An `optional` field is in one of two possible states:\n        \n        -   the field is set, and contains a value that was explicitly set or parsed from the wire. It will be serialized to the wire.\n        -   the field is unset, and will return the default value. It will not be serialized to the wire.\n        \n        You can check to see if the value was explicitly set.\n        \n    -   `required`: **Do not use.** Required fields are so problematic they were removed from proto3 and editions. Semantics for required field should be implemented at the application layer. When it *is* used, a well-formed message must have exactly one of this field.\n        \n-   `repeated`: this field type can be repeated zero or more times in a well-formed message. The order of the repeated values will be preserved.\n    \n-   `map`: this is a paired key/value field type. See [Maps](/programming-guides/encoding#maps) for more on this field type.\n    \n\n#### Use Packed Encoding for New Repeated Fields\n\nFor historical reasons, `repeated` fields of scalar numeric types (for example, `int32`, `int64`, `enum`) aren‚Äôt encoded as efficiently as they could be. New code should use the special option `[packed = true]` to get a more efficient encoding. For example:\n\n```proto\nrepeated int32 samples = 4 [packed = true];\nrepeated ProtoEnum results = 5 [packed = true];\n```\n\nYou can find out more about `packed` encoding in [Protocol Buffer Encoding](/programming-guides/encoding#packed).\n\n#### Required is Strongly Deprecated\n\n#### Important\n\n**Required Is Forever** As mentioned earlier **`required` must not be used for new fields**. Semantics for required fields should be implemented at the application layer instead. Existing `required` fields should be treated as permanent, immutable elements of the message definition. It is nearly impossible to safely change a field from `required` to `optional`. If there is any chance that a stale reader exists, it will consider messages without this field to be incomplete and may reject or drop them.\n\nA second issue with required fields appears when someone adds a value to an enum. In this case, the unrecognized enum value is treated as if it were missing, which also causes the required value check to fail.\n\n#### Well-formed Messages\n\nThe term ‚Äúwell-formed,‚Äù when applied to protobuf messages, refers to the bytes serialized/deserialized. The protoc parser validates that a given proto definition file is parseable.\n\nSingular fields can appear more than once in wire-format bytes. The parser will accept the input, but only the last instance of that field will be accessible through the generated bindings. See [Last One Wins](/programming-guides/encoding#last-one-wins) for more on this topic.\n\n### Adding More Message Types\n\nMultiple message types can be defined in a single `.proto` file. This is useful if you are defining multiple related messages ‚Äì so, for example, if you wanted to define the reply message format that corresponds to your `SearchResponse` message type, you could add it to the same `.proto`:\n\n```proto\nmessage SearchRequest {\n  optional string query = 1;\n  optional int32 page_number = 2;\n  optional int32 results_per_page = 3;\n}\n\nmessage SearchResponse {\n ...\n}\n```\n\n**Combining Messages leads to bloat** While multiple message types (such as message, enum, and service) can be defined in a single `.proto` file, it can also lead to dependency bloat when large numbers of messages with varying dependencies are defined in a single file. It‚Äôs recommended to include as few message types per `.proto` file as possible.\n\n### Adding Comments\n\nTo add comments to your `.proto` files:\n\n-   Prefer C/C++/Java line-end-style comments ‚Äò//‚Äô on the line before the .proto code element\n    \n-   C-style inline/multi-line comments `/* ... */` are also accepted.\n    \n    -   When using multi-line comments, a margin line of ‚Äò\\*‚Äô is preferred.\n\n```proto\n/**\n * SearchRequest represents a search query, with pagination options to\n * indicate which results to include in the response.\n */\nmessage SearchRequest {\n  optional string query = 1;\n\n  // Which page number do we want?\n  optional int32 page_number = 2;\n\n  // Number of results to return per page.\n  optional int32 results_per_page = 3;\n}\n```\n\n### Deleting Fields\n\nDeleting fields can cause serious problems if not done properly.\n\n**Do not delete** `required` fields. This is almost impossible to do safely. If you must delete a `required` field, you should first mark the field `optional` and `deprecated` and ensure that all systems which in any way observe the message have been deployed with the new schema. Then you can consider removing the field (but note that this is still an error-prone process).\n\nWhen you no longer need a field that is not `required`, first delete all references to the field from client code, and then delete the field definition from the message. However, you **must** [reserve the deleted field number](#fieldreserved). If you do not reserve the field number, it is possible for a developer to reuse that number in the future and cause a breakage.\n\nYou should also reserve the field name to allow JSON and TextFormat encodings of your message to continue to parse.\n\n#### Reserved Field Numbers\n\nIf you [update](#updating) a message type by entirely deleting a field, or commenting it out, future developers can reuse the field number when making their own updates to the type. This can cause severe issues, as described in [Consequences of Reusing Field Numbers](#consequences). To make sure this doesn‚Äôt happen, add your deleted field number to the `reserved` list.\n\nThe protoc compiler will generate error messages if any future developers try to use these reserved field numbers.\n\n```proto\nmessage Foo {\n  reserved 2, 15, 9 to 11;\n}\n```\n\nReserved field number ranges are inclusive (`9 to 11` is the same as `9, 10, 11`).\n\n#### Reserved Field Names\n\nReusing an old field name later is generally safe, except when using TextProto or JSON encodings where the field name is serialized. To avoid this risk, you can add the deleted field name to the `reserved` list.\n\nReserved names affect only the protoc compiler behavior and not runtime behavior, with one exception: TextProto implementations may discard unknown fields (without raising an error like with other unknown fields) with reserved names at parse time (only the C++ and Go implementations do so today). Runtime JSON parsing is not affected by reserved names.\n\n```proto\nmessage Foo {\n  reserved 2, 15, 9 to 11;\n  reserved \"foo\", \"bar\";\n}\n```\n\nNote that you can‚Äôt mix field names and field numbers in the same `reserved` statement.\n\n### What‚Äôs Generated from Your `.proto`?\n\nWhen you run the [protocol buffer compiler](#generating) on a `.proto`, the compiler generates the code in your chosen language you‚Äôll need to work with the message types you‚Äôve described in the file, including getting and setting field values, serializing your messages to an output stream, and parsing your messages from an input stream.\n\n-   For **C++**, the compiler generates a `.h` and `.cc` file from each `.proto`, with a class for each message type described in your file.\n-   For **Java**, the compiler generates a `.java` file with a class for each message type, as well as a special `Builder` class for creating message class instances.\n-   For **Kotlin**, in addition to the Java generated code, the compiler generates a `.kt` file for each message type with an improved Kotlin API. This includes a DSL that simplifies creating message instances, a nullable field accessor, and a copy function.\n-   **Python** is a little different ‚Äî the Python compiler generates a module with a static descriptor of each message type in your `.proto`, which is then used with a *metaclass* to create the necessary Python data access class at runtime.\n-   For **Go**, the compiler generates a `.pb.go` file with a type for each message type in your file.\n-   For **Ruby**, the compiler generates a `.rb` file with a Ruby module containing your message types.\n-   For **Objective-C**, the compiler generates a `pbobjc.h` and `pbobjc.m` file from each `.proto`, with a class for each message type described in your file.\n-   For **C#**, the compiler generates a `.cs` file from each `.proto`, with a class for each message type described in your file.\n-   For **PHP**, the compiler generates a `.php` message file for each message type described in your file, and a `.php` metadata file for each `.proto` file you compile. The metadata file is used to load the valid message types into the descriptor pool.\n-   For **Dart**, the compiler generates a `.pb.dart` file with a class for each message type in your file.\n\nYou can find out more about using the APIs for each language by following the tutorial for your chosen language. For even more API details, see the relevant [API reference](/reference/).\n\n## Scalar Value Types\n\nA scalar message field can have one of the following types ‚Äì the table shows the type specified in the `.proto` file, and the corresponding type in the automatically generated class:\n\nProto Type\n\nNotes\n\ndouble\n\nfloat\n\nint32\n\nUses variable-length encoding. Inefficient for encoding negative numbers ‚Äì if your field is likely to have negative values, use sint32 instead.\n\nint64\n\nUses variable-length encoding. Inefficient for encoding negative numbers ‚Äì if your field is likely to have negative values, use sint64 instead.\n\nuint32\n\nUses variable-length encoding.\n\nuint64\n\nUses variable-length encoding.\n\nsint32\n\nUses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int32s.\n\nsint64\n\nUses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int64s.\n\nfixed32\n\nAlways four bytes. More efficient than uint32 if values are often greater than 228.\n\nfixed64\n\nAlways eight bytes. More efficient than uint64 if values are often greater than 256.\n\nsfixed32\n\nAlways four bytes.\n\nsfixed64\n\nAlways eight bytes.\n\nbool\n\nstring\n\nA string must always contain UTF-8 encoded or 7-bit ASCII text, and cannot be longer than 232.\n\nbytes\n\nMay contain any arbitrary sequence of bytes no longer than 232.\n\nProto Type\n\nC++ Type\n\nJava/Kotlin Type\\[1\\]\n\nPython Type\\[3\\]\n\nGo Type\n\nRuby Type\n\nC# Type\n\nPHP Type\n\nDart Type\n\nRust Type\n\ndouble\n\ndouble\n\ndouble\n\nfloat\n\n\\*float64\n\nFloat\n\ndouble\n\nfloat\n\ndouble\n\nf64\n\nfloat\n\nfloat\n\nfloat\n\nfloat\n\n\\*float32\n\nFloat\n\nfloat\n\nfloat\n\ndouble\n\nf32\n\nint32\n\nint32\\_t\n\nint\n\nint\n\nint32\n\nFixnum or Bignum (as required)\n\nint\n\ninteger\n\n\\*int32\n\ni32\n\nint64\n\nint64\\_t\n\nlong\n\nint/long\\[4\\]\n\n\\*int64\n\nBignum\n\nlong\n\ninteger/string\\[6\\]\n\nInt64\n\ni64\n\nuint32\n\nuint32\\_t\n\nint\\[2\\]\n\nint/long\\[4\\]\n\n\\*uint32\n\nFixnum or Bignum (as required)\n\nuint\n\ninteger\n\nint\n\nu32\n\nuint64\n\nuint64\\_t\n\nlong\\[2\\]\n\nint/long\\[4\\]\n\n\\*uint64\n\nBignum\n\nulong\n\ninteger/string\\[6\\]\n\nInt64\n\nu64\n\nsint32\n\nint32\\_t\n\nint\n\nint\n\nint32\n\nFixnum or Bignum (as required)\n\nint\n\ninteger\n\n\\*int32\n\ni32\n\nsint64\n\nint64\\_t\n\nlong\n\nint/long\\[4\\]\n\n\\*int64\n\nBignum\n\nlong\n\ninteger/string\\[6\\]\n\nInt64\n\ni64\n\nfixed32\n\nuint32\\_t\n\nint\\[2\\]\n\nint/long\\[4\\]\n\n\\*uint32\n\nFixnum or Bignum (as required)\n\nuint\n\ninteger\n\nint\n\nu32\n\nfixed64\n\nuint64\\_t\n\nlong\\[2\\]\n\nint/long\\[4\\]\n\n\\*uint64\n\nBignum\n\nulong\n\ninteger/string\\[6\\]\n\nInt64\n\nu64\n\nsfixed32\n\nint32\\_t\n\nint\n\nint\n\n\\*int32\n\nFixnum or Bignum (as required)\n\nint\n\ninteger\n\nint\n\ni32\n\nsfixed64\n\nint64\\_t\n\nlong\n\nint/long\\[4\\]\n\n\\*int64\n\nBignum\n\nlong\n\ninteger/string\\[6\\]\n\nInt64\n\ni64\n\nbool\n\nbool\n\nboolean\n\nbool\n\n\\*bool\n\nTrueClass/FalseClass\n\nbool\n\nboolean\n\nbool\n\nbool\n\nstring\n\nstring\n\nString\n\nunicode (Python 2), str (Python 3)\n\n\\*string\n\nString (UTF-8)\n\nstring\n\nstring\n\nString\n\nProtoString\n\nbytes\n\nstring\n\nByteString\n\nbytes\n\n\\[\\]byte\n\nString (ASCII-8BIT)\n\nByteString\n\nstring\n\nList\n\nProtoBytes\n\n\\[1\\] Kotlin uses the corresponding types from Java, even for unsigned types, to ensure compatibility in mixed Java/Kotlin codebases.\n\n\\[2\\] In Java, unsigned 32-bit and 64-bit integers are represented using their signed counterparts, with the top bit simply being stored in the sign bit.\n\n\\[3\\] In all cases, setting values to a field will perform type checking to make sure it is valid.\n\n\\[4\\] 64-bit or unsigned 32-bit integers are always represented as long when decoded, but can be an int if an int is given when setting the field. In all cases, the value must fit in the type represented when set. See \\[2\\].\n\n\\[5\\] Proto2 typically doesn‚Äôt ever check the UTF-8 validity of string fields. Behavior varies between languages though, and invalid UTF-8 data should not be stored in string fields.\n\n\\[6\\] Integer is used on 64-bit machines and string is used on 32-bit machines.\n\nYou can find out more about how these types are encoded when you serialize your message in [Protocol Buffer Encoding](/programming-guides/encoding).\n\n## Default Field Values\n\nWhen a message is parsed, if the encoded message bytes do not contain a particular field, accessing that field in the parsed object returns the default value for that field. The default values are type-specific:\n\n-   For strings, the default value is the empty string.\n-   For bytes, the default value is empty bytes.\n-   For bools, the default value is false.\n-   For numeric types, the default value is zero.\n-   For message fields, the field is not set. Its exact value is language-dependent. See the [generated code guide](/reference/) for your language for details.\n-   For enums, the default value is the **first defined enum value**, which should be 0 (recommended for compatibility with open enums). See [Enum Default Value](#enum-default).\n\nThe default value for repeated fields is empty (generally an empty list in the appropriate language).\n\nThe default value for map fields is empty (generally an empty map in the appropriate language).\n\n### Overriding Default Scalar Values\n\nIn proto2, you can specify explicit default values for singular non-message fields. For example, let‚Äôs say you want to provide a default value of 10 for the `SearchRequest.results_per_page` field:\n\n```proto\noptional int32 results_per_page = 3 [default = 10];\n```\n\nIf the sender does not specify `results_per_page`, the receiver will observe the following state:\n\n-   The `results_per_page` field is not present. That is, the `has_results_per_page()` (hazzer method) method would return `false`.\n-   The value of `results_per_page` (returned from the ‚Äúgetter‚Äù) is `10`.\n\nIf the sender does send a value for `results_per_page` the default value of 10 is ignored and the sender‚Äôs value is returned from the ‚Äúgetter‚Äù.\n\nSee the [generated code guide](/reference/) for your chosen language for more details about how defaults work in generated code.\n\nBecause the default value for enums is the first defined enum value, take care when adding a value to the beginning of an enum value list. See the [Updating a Message Type](#updating) section for guidelines on how to safely change definitions.\n\n## Enumerations\n\nWhen you‚Äôre defining a message type, you might want one of its fields to only have one of a predefined list of values. For example, let‚Äôs say you want to add a `corpus` field for each `SearchRequest`, where the corpus can be `UNIVERSAL`, `WEB`, `IMAGES`, `LOCAL`, `NEWS`, `PRODUCTS` or `VIDEO`. You can do this very simply by adding an `enum` to your message definition with a constant for each possible value.\n\nIn the following example we‚Äôve added an `enum` called `Corpus` with all the possible values, and a field of type `Corpus`:\n\n```proto\nenum Corpus {\n  CORPUS_UNSPECIFIED = 0;\n  CORPUS_UNIVERSAL = 1;\n  CORPUS_WEB = 2;\n  CORPUS_IMAGES = 3;\n  CORPUS_LOCAL = 4;\n  CORPUS_NEWS = 5;\n  CORPUS_PRODUCTS = 6;\n  CORPUS_VIDEO = 7;\n}\n\nmessage SearchRequest {\n  optional string query = 1;\n  optional int32 page_number = 2;\n  optional int32 results_per_page = 3;\n  optional Corpus corpus = 4;\n}\n```\n\n### Prefixing Enum Values\n\nWhen prefixing enum values, the remainder of the name with the prefix stripped should still be a legal and style-conformant enum name. For example, avoid the following:\n\n```proto\nenum DeviceTier {\n  DEVICE_TIER_UNKNOWN = 0;\n  DEVICE_TIER_1 = 1;\n  DEVICE_TIER_2 = 2;\n}\n```\n\nInstead, use a value name like `DEVICE_TIER_TIER1`, where the `DEVICE_TIER_` portion is viewed as scoping the enum value rather than as part of the individual enum value name. Some Protobuf implementations automatically strip the prefix that matches the containing enum name where it is safe to do so, but could not in this example since a bare `1` is not a legal enum value name.\n\nWe plan for a future Edition to add support for scoped enums, which will eliminate the need to manually prefix each enum value and enable this to be written succinctly as `TIER1 = 1`.\n\n### Enum Default Value\n\nThe default value for the `SearchRequest.corpus` field is `CORPUS_UNSPECIFIED` because that is the first value defined in the enum.\n\nIt is strongly recommended to define the first value of every enum as `ENUM_TYPE_NAME_UNSPECIFIED = 0;` or `ENUM_TYPE_NAME_UNKNOWN = 0;`. This is because of the way proto2 handles unknown values for enum fields.\n\nIt is also recommended that this first, default value have no semantic meaning other than ‚Äúthis value was unspecified‚Äù.\n\nThe default value for an enum field like `SearchRequest.corpus` field can be explicitly overridden like this:\n\n```fallback\n  optional Corpus corpus = 4 [default = CORPUS_UNIVERSAL];\n```\n\n### Enum Value Aliases\n\nYou can define aliases by assigning the same value to different enum constants. To do this you need to set the `allow_alias` option to `true`. Otherwise, the protocol buffer compiler generates a warning message when aliases are found. Though all alias values are valid for serialization, only the first value is used when deserializing.\n\n```proto\nenum EnumAllowingAlias {\n  option allow_alias = true;\n  EAA_UNSPECIFIED = 0;\n  EAA_STARTED = 1;\n  EAA_RUNNING = 1;\n  EAA_FINISHED = 2;\n}\n\nenum EnumNotAllowingAlias {\n  ENAA_UNSPECIFIED = 0;\n  ENAA_STARTED = 1;\n  // ENAA_RUNNING = 1;  // Uncommenting this line will cause a warning message.\n  ENAA_FINISHED = 2;\n}\n```\n\nEnumerator constants must be in the range of a 32-bit integer. Since `enum` values use [varint encoding](/programming-guides/encoding) on the wire, negative values are inefficient and thus not recommended. You can define `enum`s within a message definition, as in the earlier example, or outside ‚Äì these `enum`s can be reused in any message definition in your `.proto` file. You can also use an `enum` type declared in one message as the type of a field in a different message, using the syntax `_MessageType_._EnumType_`.\n\nWhen you run the protocol buffer compiler on a `.proto` that uses an `enum`, the generated code will have a corresponding `enum` for Java, Kotlin, or C++, or a special `EnumDescriptor` class for Python that‚Äôs used to create a set of symbolic constants with integer values in the runtime-generated class.\n\n#### Important\n\nThe generated code may be subject to language-specific limitations on the number of enumerators (low thousands for one language). Review the limitations for the languages you plan to use.\n\n#### Important\n\nFor information on how enums should work contrasted with how they currently work in different languages, see [Enum Behavior](/programming-guides/enum).\n\nRemoving enum values is a breaking change for persisted protos. Instead of removing a value, mark the value with the `reserved` keyword to prevent the enum value from being code-generated, or keep the value but indicate that it will be removed later by using the `deprecated` field option:\n\n```proto\nenum PhoneType {\n  PHONE_TYPE_UNSPECIFIED = 0;\n  PHONE_TYPE_MOBILE = 1;\n  PHONE_TYPE_HOME = 2;\n  PHONE_TYPE_WORK = 3 [deprecated = true];\n  reserved 4,5;\n}\n```\n\nFor more information about how to work with message `enum`s in your applications, see the [generated code guide](/reference/) for your chosen language.\n\n### Reserved Values\n\nIf you [update](#updating) an enum type by entirely removing an enum entry, or commenting it out, future users can reuse the numeric value when making their own updates to the type. This can cause severe issues if they later load old instances of the same `.proto`, including data corruption, privacy bugs, and so on. One way to make sure this doesn‚Äôt happen is to specify that the numeric values (and/or names, which can also cause issues for JSON serialization) of your deleted entries are `reserved`. The protocol buffer compiler will complain if any future users try to use these identifiers. You can specify that your reserved numeric value range goes up to the maximum possible value using the `max` keyword.\n\n```proto\nenum Foo {\n  reserved 2, 15, 9 to 11, 40 to max;\n  reserved \"FOO\", \"BAR\";\n}\n```\n\nNote that you can‚Äôt mix field names and numeric values in the same `reserved` statement.\n\n## Using Other Message Types\n\nYou can use other message types as field types. For example, let‚Äôs say you wanted to include `Result` messages in each `SearchResponse` message ‚Äì to do this, you can define a `Result` message type in the same `.proto` and then specify a field of type `Result` in `SearchResponse`:\n\n```proto\nmessage SearchResponse {\n  repeated Result results = 1;\n}\n\nmessage Result {\n  optional string url = 1;\n  optional string title = 2;\n  repeated string snippets = 3;\n}\n```\n\n### Importing Definitions\n\nIn the earlier example, the `Result` message type is defined in the same file as `SearchResponse` ‚Äì what if the message type you want to use as a field type is already defined in another `.proto` file?\n\nYou can use definitions from other `.proto` files by *importing* them. To import another `.proto`‚Äôs definitions, you add an import statement to the top of your file:\n\n```proto\nimport \"myproject/other_protos.proto\";\n```\n\nBy default, you can use definitions only from directly imported `.proto` files. However, sometimes you may need to move a `.proto` file to a new location. Instead of moving the `.proto` file directly and updating all the call sites in a single change, you can put a placeholder `.proto` file in the old location to forward all the imports to the new location using the `import public` notion.\n\n**Note that the public import functionality is not available in Java, Kotlin, TypeScript, JavaScript, GCL, as well as C++ targets that use protobuf static reflection.**\n\n`import public` dependencies can be transitively relied upon by any code importing the proto containing the `import public` statement. For example:\n\n```proto\n// new.proto\n// All definitions are moved here\n```\n\n```proto\n// old.proto\n// This is the proto that all clients are importing.\nimport public \"new.proto\";\nimport \"other.proto\";\n```\n\n```proto\n// client.proto\nimport \"old.proto\";\n// You use definitions from old.proto and new.proto, but not other.proto\n```\n\nThe protocol compiler searches for imported files in a set of directories specified on the protocol compiler command line using the `-I`/`--proto_path` flag. If no flag was given, it looks in the directory in which the compiler was invoked. In general you should set the `--proto_path` flag to the root of your project and use fully qualified names for all imports.\n\n### Using proto3 Message Types\n\nIt‚Äôs possible to import [proto3](/programming-guides/proto3) and [edition 2023](/programming-guides/editions) message types and use them in your proto2 messages, and vice versa. However, proto2 enums cannot be used directly in proto3 syntax (it‚Äôs okay if an imported proto2 message uses them).\n\n## Nested Types\n\nYou can define and use message types inside other message types, as in the following example ‚Äì here the `Result` message is defined inside the `SearchResponse` message:\n\n```proto\nmessage SearchResponse {\n  message Result {\n    optional string url = 1;\n    optional string title = 2;\n    repeated string snippets = 3;\n  }\n  repeated Result results = 1;\n}\n```\n\nIf you want to reuse this message type outside its parent message type, you refer to it as `_Parent_._Type_`:\n\n```proto\nmessage SomeOtherMessage {\n  optional SearchResponse.Result result = 1;\n}\n```\n\nYou can nest messages as deeply as you like. In the example below, note that the two nested types named `Inner` are entirely independent, since they are defined within different messages:\n\n```proto\nmessage Outer {       // Level 0\n  message MiddleAA {  // Level 1\n    message Inner {   // Level 2\n      optional int64 ival = 1;\n      optional bool  booly = 2;\n    }\n  }\n  message MiddleBB {  // Level 1\n    message Inner {   // Level 2\n      optional int32  ival = 1;\n      optional bool   booly = 2;\n    }\n  }\n}\n```\n\n### Groups\n\n**Note that the groups feature is deprecated and should not be used when creating new message types. Use nested message types instead.**\n\nGroups are another way to nest information in your message definitions. For example, another way to specify a `SearchResponse` containing a number of `Result`s is as follows:\n\n```proto\nmessage SearchResponse {\n  repeated group Result = 1 {\n    optional string url = 1;\n    optional string title = 2;\n    repeated string snippets = 3;\n  }\n}\n```\n\nA group simply combines a nested message type and a field into a single declaration. In your code, you can treat this message just as if it had a `Result` type field called `result` (the latter name is converted to lower-case so that it does not conflict with the former). Therefore, this example is exactly equivalent to the `SearchResponse` earlier, except that the message has a different [wire format](/programming-guides/encoding).\n\n## Updating a Message Type\n\nIf an existing message type no longer meets all your needs ‚Äì for example, you‚Äôd like the message format to have an extra field ‚Äì but you‚Äôd still like to use code created with the old format, don‚Äôt worry! It‚Äôs very simple to update message types without breaking any of your existing code when you use the binary wire format.\n\n#### Note\n\nIf you use ProtoJSON or [proto text format](/reference/protobuf/textformat-spec) to store your protocol buffer messages, the changes that you can make in your proto definition are different. The ProtoJSON wire format safe changes are described [here](/programming-guides/json#json-wire-safety).\n\nCheck [Proto Best Practices](/best-practices/dos-donts) and the following rules:\n\n### Binary Wire-unsafe Changes\n\nWire-unsafe changes are schema changes that will break if you use parse data that was serialized using the old schema with a parser that is using the new schema (or vice versa). Only make wire-unsafe changes if you know that all serializers and deserializers of the data are using the new schema.\n\n-   Changing field numbers for any existing field is not safe.\n    -   Changing the field number is equivalent to deleting the field and adding a new field with the same type. If you want to renumber a field, see the instructions for [deleting a field](#deleting).\n-   Moving fields into an existing `oneof` is not safe.\n\n### Binary Wire-safe Changes\n\nWire-safe changes are ones where it is fully safe to evolve the schema in this way without risk of data loss or new parse failures.\n\nNote that any wire-safe changes may be a breaking change to application code in a given language. For example, adding a value to a preexisting enum would be a compilation break for any code with an exhaustive switch on that enum. For that reason, Google may avoid making some of these types of changes on public messages: the AIPs contain guidance for which of these changes are safe to make there.\n\n-   Adding new fields is safe.\n    -   If you add new fields, any messages serialized by code using your ‚Äúold‚Äù message format can still be parsed by your new generated code. You should keep in mind the [default values](#default) for these elements so that new code can properly interact with messages generated by old code. Similarly, messages created by your new code can be parsed by your old code: old binaries simply ignore the new field when parsing. See the [Unknown Fields](#unknowns) section for details.\n-   Removing fields is safe.\n    -   The same field number must not used again in your updated message type. You may want to rename the field instead, perhaps adding the prefix ‚ÄúOBSOLETE\\_‚Äù, or make the field number [reserved](#fieldreserved), so that future users of your `.proto` can‚Äôt accidentally reuse the number.\n-   Adding additional values to an enum is safe.\n-   Changing a single explicit presence field or extension into a member of a **new** `oneof` is safe.\n-   Changing a `oneof` which contains only one field to an explicit presence field is safe.\n-   Changing a field into an extension of same number and type is safe.\n\n### Binary Wire-compatible Changes (Conditionally Safe)\n\nUnlike Wire-safe changes, wire-compatible means that the same data can be parsed both before and after a given change. However, a parse of the data may be lossy under this shape of change. For example, changing an int32 to an int64 is a compatible change, but if a value larger than INT32\\_MAX is written, a client that reads it as an int32 will discard the high order bits of the number.\n\nYou can make compatible changes to your schema only if you manage the roll out to your system carefully. For example, you may change an int32 to an int64 but ensure you continue to only write legal int32 values until the new schema is deployed to all endpoints, and then subsequently start writing larger values after that.\n\nIf your schema is published outside of your organization, you should generally not make wire-compatible changes, as you cannot manage the deployment of the new schema to know when the different range of values may be safe to use.\n\n-   `int32`, `uint32`, `int64`, `uint64`, and `bool` are all compatible.\n    -   If a number is parsed from the wire which doesn‚Äôt fit in the corresponding type, you will get the same effect as if you had cast the number to that type in C++ (for example, if a 64-bit number is read as an int32, it will be truncated to 32 bits).\n-   `sint32` and `sint64` are compatible with each other but are *not* compatible with the other integer types.\n    -   If the value written was between INT\\_MIN and INT\\_MAX inclusive it will parse as the same value with either type. If an sint64 value was written outside of that range and parsed as an sint32, the varint is truncated to 32 bits and then zigzag decoding occurs (which will cause a different value to be observed).\n-   `string` and `bytes` are compatible as long as the bytes are valid UTF-8.\n-   Embedded messages are compatible with `bytes` if the bytes contain an encoded instance of the message.\n-   `fixed32` is compatible with `sfixed32`, and `fixed64` with `sfixed64`.\n-   For `string`, `bytes`, and message fields, singular is compatible with `repeated`.\n    -   Given serialized data of a repeated field as input, clients that expect this field to be singular will take the last input value if it‚Äôs a primitive type field or merge all input elements if it‚Äôs a message type field. Note that this is **not** generally safe for numeric types, including bools and enums. Repeated fields of numeric types are serialized in the [packed](/programming-guides/encoding#packed) format by default, which will not be parsed correctly when a singular field is expected.\n-   `enum` is compatible with `int32`, `uint32`, `int64`, and `uint64`\n    -   Be aware that client code may treat them differently when the message is deserialized: for example, unrecognized proto3 `enum` values will be preserved in the message, but how this is represented when the message is deserialized is language-dependent.\n-   Changing a field between a `map<K, V>` and the corresponding `repeated` message field is binary compatible (see [Maps](#maps), below, for the message layout and other restrictions).\n    -   However, the safety of the change is application-dependent: when deserializing and reserializing a message, clients using the `repeated` field definition will produce a semantically identical result; however, clients using the `map` field definition may reorder entries and drop entries with duplicate keys.\n\n## Unknown Fields\n\nUnknown fields are well-formed protocol buffer serialized data representing fields that the parser does not recognize. For example, when an old binary parses data sent by a new binary with new fields, those new fields become unknown fields in the old binary.\n\nProto2 messages preserve unknown fields and include them during parsing and in the serialized output.\n\n### Retaining Unknown Fields\n\nSome actions can cause unknown fields to be lost. For example, if you do one of the following, unknown fields are lost:\n\n-   Serialize a proto to JSON.\n-   Iterate over all of the fields in a message to populate a new message.\n\nTo avoid losing unknown fields, do the following:\n\n-   Use binary; avoid using text formats for data exchange.\n-   Use message-oriented APIs, such as `CopyFrom()` and `MergeFrom()`, to copy data rather than copying field-by-field\n\nTextFormat is a bit of a special case. Serializing to TextFormat prints unknown fields using their field numbers. But parsing TextFormat data back into a binary proto fails if there are entries that use field numbers.\n\n## Extensions\n\nAn extension is a field defined outside of its container message; usually in a `.proto` file separate from the container message‚Äôs `.proto` file.\n\n### Why Use Extensions?\n\nThere are two main reasons to use extensions:\n\n-   The container message‚Äôs `.proto` file will have fewer imports/dependencies. This can improve build times, break circular dependencies, and otherwise promote loose coupling. Extensions are very good for this.\n-   Allow systems to attach data to a container message with minimal dependency and coordination. Extensions are not a great solution for this because of the limited field number space and the [Consequences of Reusing Field Numbers](#consequences). If your use case requires very low coordination for a large number of extensions, consider using the [`Any` message type](/reference/protobuf/google.protobuf#any) instead.\n\n### Example Extension\n\nLet‚Äôs look at an example extension:\n\n```proto\n// file kittens/video_ext.proto\n\nimport \"kittens/video.proto\";\nimport \"media/user_content.proto\";\n\npackage kittens;\n\n// This extension allows kitten videos in a media.UserContent message.\nextend media.UserContent {\n  // Video is a message imported from kittens/video.proto\n  repeated Video kitten_videos = 126;\n}\n```\n\nNote that the file defining the extension (`kittens/video_ext.proto`) imports the container message‚Äôs file (`media/user_content.proto`).\n\nThe container message must reserve a subset of its field numbers for extensions.\n\n```proto\n// file media/user_content.proto\n\npackage media;\n\n\n...48030 bytes truncated...\n\nThe tool call succeeded but the output was truncated. Full output saved to: /Users/alex/.local/share/opencode/tool-output/tool_c64854c2c001dfOJNdXfS7psNG\nUse the Task tool to have explore agent process this file with Grep and Read (with offset/limit). Do NOT read the full file yourself - delegate to save context.",
            "title": "https://protobuf.dev/programming-guides/proto2/ (text/html; charset=utf-8)",
            "metadata": {
              "truncated": true,
              "outputPath": "/Users/alex/.local/share/opencode/tool-output/tool_c64854c2c001dfOJNdXfS7psNG"
            },
            "time": {
              "start": 1771212982849,
              "end": 1771212983340,
              "compacted": 1771213545698
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_01e5c65264d6e81601699290b6cab48194bcef2e55ed3b9618"
            }
          },
          "id": "prt_c64854a2e001PXN2Nn2Inis0B1",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648519a3001dVkoAXMkiGYiY8"
        },
        {
          "type": "tool",
          "callID": "call_Ng88q3uNo2OClJuXFtIVB0Cz",
          "tool": "webfetch",
          "state": {
            "status": "completed",
            "input": {
              "url": "https://protobuf.dev/programming-guides/proto3/",
              "format": "markdown"
            },
            "output": "Language Guide (proto 3) | Protocol Buffers Documentation \n\n[Protocol Buffers Documentation](/)\n\n-   [Protocol Buffers](/)\n    -   [Overview](/overview/)\n    -   [Protoc Installation](/installation/ \"Protocol Buffer Compiler Installation\")\n    -   [News](/news/)\n    -   [Programming Guides](/programming-guides/)\n        -   [Language Guide (editions)](/programming-guides/editions/)\n        -   [Language Guide (proto 2)](/programming-guides/proto2/)\n        -   [Language Guide (proto 3)](/programming-guides/proto3/)\n        -   [Proto Limits](/programming-guides/proto-limits/)\n        -   [Style Guide](/programming-guides/style/)\n        -   [Enum Behavior](/programming-guides/enum/)\n        -   [Encoding](/programming-guides/encoding/)\n        -   [ProtoJSON Format](/programming-guides/json/)\n        -   [Techniques](/programming-guides/techniques/)\n        -   [Add-ons](/programming-guides/addons/ \"Third-Party Add-ons\")\n        -   [Extension Declarations](/programming-guides/extension_declarations/)\n        -   [Field Presence](/programming-guides/field_presence/ \"Application Note: Field Presence\")\n        -   [Proto Serialization Is Not Canonical](/programming-guides/serialization-not-canonical/)\n        -   [Deserializing Debug Proto Representations](/programming-guides/deserialize-debug/)\n    -   [Protobuf Editions](/editions/)\n        -   [Overview](/editions/overview/ \"Protobuf Editions Overview\")\n        -   [Feature Settings for Editions](/editions/features/)\n        -   [Implementing Editions Support](/editions/implementation/)\n    -   [Design Decisions](/design-decisions/ \"Protobuf Team Design Decisions\")\n        -   [No Nullable Setters/Getters Support](/design-decisions/nullable-getters-setters/)\n    -   [Proto Best Practices](/best-practices/)\n        -   [Avoid Cargo Culting](/best-practices/no-cargo-cults/)\n        -   [Proto Best Practices](/best-practices/dos-donts/)\n        -   [1-1-1 Best Practice](/best-practices/1-1-1/)\n    -   [Tutorials](/getting-started/)\n        -   [C++](/getting-started/cpptutorial/ \"Protocol Buffer Basics: C++\")\n        -   [C#](/getting-started/csharptutorial/ \"Protocol Buffer Basics: C#\")\n        -   [Dart](/getting-started/darttutorial/ \"Protocol Buffer Basics: Dart\")\n        -   [Go](/getting-started/gotutorial/ \"Protocol Buffer Basics: Go\")\n        -   [Java](/getting-started/javatutorial/ \"Protocol Buffer Basics: Java\")\n        -   [Kotlin](/getting-started/kotlintutorial/ \"Protocol Buffer Basics: Kotlin\")\n        -   [Python](/getting-started/pythontutorial/ \"Protocol Buffer Basics: Python\")\n    -   [Reference Guides](/reference/)\n        -   [C++](/reference/cpp/ \"C++ Reference\")\n            -   [Generated Code Guide](/reference/cpp/cpp-generated/ \"C++ Generated Code Guide\")\n            -   [String View APIs](/reference/cpp/string-view/)\n            -   [Arena Allocation Guide](/reference/cpp/arenas/ \"C++ Arena Allocation Guide\")\n            -   [Abseil Support](/reference/cpp/abseil/)\n            -   [C++ API](/reference/cpp/api-docs/)\n        -   [C#](/reference/csharp/ \"C# Reference\")\n            -   [Generated Code Guide](/reference/csharp/csharp-generated/ \"C# Generated Code Guide\")\n            -   [C# API](/reference/csharp/api-docs)\n        -   [Dart](/reference/dart/ \"Dart Reference\")\n            -   [Generated Code](/reference/dart/dart-generated/ \"Dart Generated Code\")\n            -   [Dart API](https://pub.dartlang.org/documentation/protobuf)\n        -   [Go](/reference/go/ \"Go Reference\")\n            -   [Generated Code Guide (Open)](/reference/go/go-generated/ \"Go Generated Code Guide (Open)\")\n            -   [Generated Code Guide (Opaque)](/reference/go/go-generated-opaque/ \"Go Generated Code Guide (Opaque)\")\n            -   [FAQ](/reference/go/faq/ \"Go FAQ\")\n            -   [Size Semantics](/reference/go/size/ \"Go Size Semantics\")\n            -   [Go API](https://pkg.go.dev/google.golang.org/protobuf/proto)\n            -   [Opaque API Migration](/reference/go/opaque-migration/ \"Go Opaque API Migration\")\n            -   [Opaque API: Manual Migration](/reference/go/opaque-migration-manual/ \"Go Opaque API: Manual Migration\")\n            -   [Opaque API FAQ](/reference/go/opaque-faq/ \"Go Opaque API FAQ\")\n        -   [Java](/reference/java/ \"Java Reference\")\n            -   [Generated Code Guide](/reference/java/java-generated/ \"Java Generated Code Guide\")\n            -   [Generated Proto Names](/reference/java/java-proto-names/ \"Java Proto Names\")\n            -   [Java API](/reference/java/api-docs/overview-summary.html)\n        -   [Kotlin](/reference/kotlin/ \"Kotlin Reference\")\n            -   [Kotlin](/reference/kotlin/api-docs/ \"Kotlin Reference\")\n            -   [Generated Code Guide](/reference/kotlin/kotlin-generated/ \"Kotlin Generated Code Guide\")\n        -   [Objective-C](/reference/objective-c/ \"Objective-C Reference\")\n            -   [Generated Code Guide](/reference/objective-c/objective-c-generated/ \"Objective-C Generated Code Guide\")\n        -   [PHP](/reference/php/ \"PHP Reference\")\n            -   [Generated Code Guide](/reference/php/php-generated/ \"PHP Generated Code Guide\")\n            -   [PHP API](/reference/php/api-docs/)\n        -   [Python](/reference/python/ \"Python Reference\")\n            -   [Generated Code Guide](/reference/python/python-generated/ \"Python Generated Code Guide\")\n            -   [Python Comparison](/reference/python/python-comparison/)\n            -   [Python API](https://googleapis.dev/python/protobuf/latest/)\n        -   [Ruby](/reference/ruby/ \"Ruby Reference\")\n            -   [Generated Code Guide](/reference/ruby/ruby-generated/ \"Ruby Generated Code Guide\")\n        -   [Rust](/reference/rust/ \"Rust Reference\")\n            -   [Generated Code Guide](/reference/rust/rust-generated/ \"Rust Generated Code Guide\")\n            -   [Redaction in Rust](/reference/rust/rust-redaction/)\n            -   [Building Rust Protos](/reference/rust/building-rust-protos/)\n            -   [Design Decisions](/reference/rust/rust-design-decisions/ \"Rust Proto Design Decisions\")\n        -   [Protocol Buffers](/reference/protobuf/ \"Protocol Buffers Reference\")\n            -   [2023 Language Specification](/reference/protobuf/edition-2023-spec/ \"Protocol Buffers Edition 2023 Language Specification\")\n            -   [Language Specification (Proto2 Syntax)](/reference/protobuf/proto2-spec/ \"Protocol Buffers Language Specification (Proto2 Syntax)\")\n            -   [2024 Language Specification](/reference/protobuf/edition-2024-spec/ \"Protocol Buffers Edition 2024 Language Specification\")\n            -   [Language Specification (Proto3)](/reference/protobuf/proto3-spec/ \"Protocol Buffers Language Specification (Proto3)\")\n            -   [Text Format Language Specification](/reference/protobuf/textformat-spec/)\n            -   [MIME Types](/reference/protobuf/mime-types/ \"Protocol Buffer MIME Types\")\n            -   [Well-Known Types](/reference/protobuf/google.protobuf/ \"Protocol Buffers Well-Known Types\")\n        -   [Other Languages](/reference/other/)\n    -   [Support](/support/)\n        -   [Version Support](/support/version-support/)\n        -   [Debugging](/support/debugging-playbook/)\n        -   [Migration Guide](/support/migration/)\n        -   [Cross-Version Runtime Guarantee](/support/cross-version-runtime-guarantee/)\n    -   [Downloads](/downloads/)\n    -   [History](/history/)\n    -   [Forum](https://groups.google.com/g/protobuf)\n    -   [](/navbar/)\n    -   [Search Results](/search/)\n\n[View page source](https://github.com/protocolbuffers/protocolbuffers.github.io/tree/main/content/programming-guides/proto3.md) [Edit this page](https://github.com/protocolbuffers/protocolbuffers.github.io/edit/main/content/programming-guides/proto3.md) [Create child page](https://github.com/protocolbuffers/protocolbuffers.github.io/new/main/content/programming-guides/proto3.md?filename=change-me.md&value=---%0Atitle%3A+%22Long+Page+Title%22%0AlinkTitle%3A+%22Short+Nav+Title%22%0Aweight%3A+100%0Adescription%3A+%3E-%0A+++++Page+description+for+heading+and+indexes.%0A---%0A%0A%23%23+Heading%0A%0AEdit+this+template+to+create+your+new+page.%0A%0A%2A+Give+it+a+good+name%2C+ending+in+%60.md%60+-+e.g.+%60getting-started.md%60%0A%2A+Edit+the+%22front+matter%22+section+at+the+top+of+the+page+%28weight+controls+how+its+ordered+amongst+other+pages+in+the+same+directory%3B+lowest+number+first%29.%0A%2A+Add+a+good+commit+message+at+the+bottom+of+the+page+%28%3C80+characters%3B+use+the+extended+description+field+for+more+detail%29.%0A%2A+Create+a+new+branch+so+you+can+preview+your+new+file+and+request+a+review+via+Pull+Request.%0A) [Create documentation issue](https://github.com/protocolbuffers/protocolbuffers.github.io/issues/new?title=Language%20Guide%20%28proto%203%29) [Create project issue](https://github.com/protocolbuffers/protobuf/issues/new)\n\n-   [Defining A Message Type](#simple)\n    -   [Specifying Field Types](#specifying-types)\n    -   [Assigning Field Numbers](#assigning)\n    -   [Specifying Field Cardinality](#field-labels)\n    -   [Adding More Message Types](#adding-types)\n    -   [Adding Comments](#adding-comments)\n    -   [Deleting Fields](#deleting)\n    -   [What‚Äôs Generated from Your `.proto`?](#generated)\n-   [Scalar Value Types](#scalar)\n-   [Default Field Values](#default)\n-   [Enumerations](#enum)\n    -   [Prefixing Enum Values](#prefixing-values)\n    -   [Enum Default Value](#enum-default)\n    -   [Enum Value Aliases](#enum-aliases)\n    -   [Reserved Values](#reserved)\n-   [Using Other Message Types](#other)\n    -   [Importing Definitions](#importing)\n    -   [Using proto2 Message Types](#proto2)\n-   [Nested Types](#nested)\n-   [Updating A Message Type](#updating)\n    -   [Binary Wire-unsafe Changes](#wire-unsafe-changes)\n    -   [Binary Wire-safe Changes](#wire-safe-changes)\n    -   [Binary Wire-compatible Changes (Conditionally Safe)](#conditionally-safe-changes)\n-   [Unknown Fields](#unknowns)\n    -   [Retaining Unknown Fields](#retaining)\n-   [Any](#any)\n-   [Oneof](#oneof)\n    -   [Using Oneof](#using-oneof)\n    -   [Oneof Features](#oneof-features)\n    -   [Backwards-compatibility issues](#backward)\n-   [Maps](#maps)\n    -   [Maps Features](#maps-features)\n    -   [Backwards Compatibility](#backwards)\n-   [Packages](#packages)\n    -   [Packages and Name Resolution](#name-resolution)\n-   [Defining Services](#services)\n-   [JSON Mapping](#json)\n-   [Options](#options)\n    -   [Enum Value Options](#enum-value-options)\n    -   [Custom Options](#customoptions)\n    -   [Option Retention](#option-retention)\n    -   [Option Targets](#option-targets)\n-   [Generating Your Classes](#generating)\n-   [File location](#location)\n    -   [Location Should be Language-agnostic](#location-language-agnostic)\n-   [Supported Platforms](#platforms)\n\n1.  [Programming Guides](/programming-guides/)\n2.  Language Guide (proto 3)\n\n# Language Guide (proto 3)\n\nCovers how to use the proto3 revision of the Protocol Buffers language in your project.\n\nThis guide describes how to use the protocol buffer language to structure your protocol buffer data, including `.proto` file syntax and how to generate data access classes from your `.proto` files. It covers the **proto3** revision of the protocol buffers language.\n\nFor information on **editions** syntax, see the [Protobuf Editions Language Guide](/programming-guides/editions).\n\nFor information on the **proto2** syntax, see the [Proto2 Language Guide](/programming-guides/proto2).\n\nThis is a reference guide ‚Äì for a step by step example that uses many of the features described in this document, see the [tutorial](/getting-started) for your chosen language.\n\n## Defining A Message Type\n\nFirst let‚Äôs look at a very simple example. Let‚Äôs say you want to define a search request message format, where each search request has a query string, the particular page of results you are interested in, and a number of results per page. Here‚Äôs the `.proto` file you use to define the message type.\n\n```proto\nsyntax = \"proto3\";\n\nmessage SearchRequest {\n  string query = 1;\n  int32 page_number = 2;\n  int32 results_per_page = 3;\n}\n```\n\n-   The first line of the file specifies that you‚Äôre using the proto3 revision of the protobuf language spec.\n    \n    -   The `edition` (or `syntax` for proto2/proto3) must be the first non-empty, non-comment line of the file.\n    -   If no `edition` or `syntax` is specified, the protocol buffer compiler will assume you are using [proto2](/programming-guides/proto2).\n-   The `SearchRequest` message definition specifies three fields (name/value pairs), one for each piece of data that you want to include in this type of message. Each field has a name and a type.\n    \n\n### Specifying Field Types\n\nIn the earlier example, all the fields are [scalar types](#scalar): two integers (`page_number` and `results_per_page`) and a string (`query`). You can also specify [enumerations](#enum) and composite types like other message types for your field.\n\n### Assigning Field Numbers\n\nYou must give each field in your message definition a number between `1` and `536,870,911` with the following restrictions:\n\n-   The given number **must be unique** among all fields for that message.\n-   Field numbers `19,000` to `19,999` are reserved for the Protocol Buffers implementation. The protocol buffer compiler will complain if you use one of these reserved field numbers in your message.\n-   You cannot use any previously [reserved](#fieldreserved) field numbers or any field numbers that have been allocated to [extensions](/programming-guides/proto2#extensions).\n\nThis number **cannot be changed once your message type is in use** because it identifies the field in the [message wire format](/programming-guides/encoding). ‚ÄúChanging‚Äù a field number is equivalent to deleting that field and creating a new field with the same type but a new number. See [Deleting Fields](#deleting) for how to do this properly.\n\nField numbers **should never be reused**. Never take a field number out of the [reserved](#fieldreserved) list for reuse with a new field definition. See [Consequences of Reusing Field Numbers](#consequences).\n\nYou should use the field numbers 1 through 15 for the most-frequently-set fields. Lower field number values take less space in the wire format. For example, field numbers in the range 1 through 15 take one byte to encode. Field numbers in the range 16 through 2047 take two bytes. You can find out more about this in [Protocol Buffer Encoding](/programming-guides/encoding#structure).\n\n#### Consequences of Reusing Field Numbers\n\nReusing a field number makes decoding wire-format messages ambiguous.\n\nThe protobuf wire format is lean and doesn‚Äôt provide a way to detect fields encoded using one definition and decoded using another.\n\nEncoding a field using one definition and then decoding that same field with a different definition can lead to:\n\n-   Developer time lost to debugging\n-   A parse/merge error (best case scenario)\n-   Leaked PII/SPII\n-   Data corruption\n\nCommon causes of field number reuse:\n\n-   renumbering fields (sometimes done to achieve a more aesthetically pleasing number order for fields). Renumbering effectively deletes and re-adds all the fields involved in the renumbering, resulting in incompatible wire-format changes.\n-   deleting a field and not [reserving](#fieldreserved) the number to prevent future reuse.\n\nThe field number is limited to 29 bits rather than 32 bits because three bits are used to specify the field‚Äôs wire format. For more on this, see the [Encoding topic](/programming-guides/encoding#structure).\n\n### Specifying Field Cardinality\n\nMessage fields can be one of the following:\n\n-   *Singular*:\n    \n    In proto3, there are two types of singular fields:\n    \n    -   `optional`: (recommended) An `optional` field is in one of two possible states:\n        \n        -   the field is set, and contains a value that was explicitly set or parsed from the wire. It will be serialized to the wire.\n        -   the field is unset, and will return the default value. It will not be serialized to the wire.\n        \n        You can check to see if the value was explicitly set.\n        \n        `optional` is recommended over *implicit* fields for maximum compatibility with protobuf editions and proto2.\n        \n    -   *implicit*: (not recommended) An implicit field has no explicit cardinality label and behaves as follows:\n        \n        -   if the field is a message type, it behaves just like an `optional` field.\n            \n        -   if the field is not a message, it has two states:\n            \n            -   the field is set to a non-default (non-zero) value that was explicitly set or parsed from the wire. It will be serialized to the wire.\n            -   the field is set to the default (zero) value. It will not be serialized to the wire. In fact, you cannot determine whether the default (zero) value was set or parsed from the wire or not provided at all. For more on this subject, see [Field Presence](/programming-guides/field_presence).\n-   `repeated`: this field type can be repeated zero or more times in a well-formed message. The order of the repeated values will be preserved.\n    \n-   `map`: this is a paired key/value field type. See [Maps](/programming-guides/encoding#maps) for more on this field type.\n    \n\n#### Repeated Fields are Packed by Default\n\nIn proto3, `repeated` fields of scalar numeric types use `packed` encoding by default.\n\nYou can find out more about `packed` encoding in [Protocol Buffer Encoding](/programming-guides/encoding#packed).\n\n#### Message Type Fields Always Have Field Presence\n\nIn proto3, message-type fields already have field presence. Because of this, adding the `optional` modifier doesn‚Äôt change the field presence for the field.\n\nThe definitions for `Message2` and `Message3` in the following code sample generate the same code for all languages, and there is no difference in representation in binary, JSON, and TextFormat:\n\n```proto\nsyntax=\"proto3\";\n\npackage foo.bar;\n\nmessage Message1 {}\n\nmessage Message2 {\n  Message1 foo = 1;\n}\n\nmessage Message3 {\n  optional Message1 bar = 1;\n}\n```\n\n#### Well-formed Messages\n\nThe term ‚Äúwell-formed,‚Äù when applied to protobuf messages, refers to the bytes serialized/deserialized. The protoc parser validates that a given proto definition file is parseable.\n\nSingular fields can appear more than once in wire-format bytes. The parser will accept the input, but only the last instance of that field will be accessible through the generated bindings. See [Last One Wins](/programming-guides/encoding#last-one-wins) for more on this topic.\n\n### Adding More Message Types\n\nMultiple message types can be defined in a single `.proto` file. This is useful if you are defining multiple related messages ‚Äì so, for example, if you wanted to define the reply message format that corresponds to your `SearchResponse` message type, you could add it to the same `.proto`:\n\n```proto\nmessage SearchRequest {\n  string query = 1;\n  int32 page_number = 2;\n  int32 results_per_page = 3;\n}\n\nmessage SearchResponse {\n ...\n}\n```\n\n**Combining Messages leads to bloat** While multiple message types (such as message, enum, and service) can be defined in a single `.proto` file, it can also lead to dependency bloat when large numbers of messages with varying dependencies are defined in a single file. It‚Äôs recommended to include as few message types per `.proto` file as possible.\n\n### Adding Comments\n\nTo add comments to your `.proto` files:\n\n-   Prefer C/C++/Java line-end-style comments ‚Äò//‚Äô on the line before the .proto code element\n    \n-   C-style inline/multi-line comments `/* ... */` are also accepted.\n    \n    -   When using multi-line comments, a margin line of ‚Äò\\*‚Äô is preferred.\n\n```proto\n/**\n * SearchRequest represents a search query, with pagination options to\n * indicate which results to include in the response.\n */\nmessage SearchRequest {\n  string query = 1;\n\n  // Which page number do we want?\n  int32 page_number = 2;\n\n  // Number of results to return per page.\n  int32 results_per_page = 3;\n}\n```\n\n### Deleting Fields\n\nDeleting fields can cause serious problems if not done properly.\n\nWhen you no longer need a field and all references have been deleted from client code, you may delete the field definition from the message. However, you **must** [reserve the deleted field number](#fieldreserved). If you do not reserve the field number, it is possible for a developer to reuse that number in the future.\n\nYou should also reserve the field name to allow JSON and TextFormat encodings of your message to continue to parse.\n\n#### Reserved Field Numbers\n\nIf you [update](#updating) a message type by entirely deleting a field, or commenting it out, future developers can reuse the field number when making their own updates to the type. This can cause severe issues, as described in [Consequences of Reusing Field Numbers](#consequences). To make sure this doesn‚Äôt happen, add your deleted field number to the `reserved` list.\n\nThe protoc compiler will generate error messages if any future developers try to use these reserved field numbers.\n\n```proto\nmessage Foo {\n  reserved 2, 15, 9 to 11;\n}\n```\n\nReserved field number ranges are inclusive (`9 to 11` is the same as `9, 10, 11`).\n\n#### Reserved Field Names\n\nReusing an old field name later is generally safe, except when using TextProto or JSON encodings where the field name is serialized. To avoid this risk, you can add the deleted field name to the `reserved` list.\n\nReserved names affect only the protoc compiler behavior and not runtime behavior, with one exception: TextProto implementations may discard unknown fields (without raising an error like with other unknown fields) with reserved names at parse time (only the C++ and Go implementations do so today). Runtime JSON parsing is not affected by reserved names.\n\n```proto\nmessage Foo {\n  reserved 2, 15, 9 to 11;\n  reserved \"foo\", \"bar\";\n}\n```\n\nNote that you can‚Äôt mix field names and field numbers in the same `reserved` statement.\n\n### What‚Äôs Generated from Your `.proto`?\n\nWhen you run the [protocol buffer compiler](#generating) on a `.proto`, the compiler generates the code in your chosen language you‚Äôll need to work with the message types you‚Äôve described in the file, including getting and setting field values, serializing your messages to an output stream, and parsing your messages from an input stream.\n\n-   For **C++**, the compiler generates a `.h` and `.cc` file from each `.proto`, with a class for each message type described in your file.\n-   For **Java**, the compiler generates a `.java` file with a class for each message type, as well as a special `Builder` class for creating message class instances.\n-   For **Kotlin**, in addition to the Java generated code, the compiler generates a `.kt` file for each message type with an improved Kotlin API. This includes a DSL that simplifies creating message instances, a nullable field accessor, and a copy function.\n-   **Python** is a little different ‚Äî the Python compiler generates a module with a static descriptor of each message type in your `.proto`, which is then used with a *metaclass* to create the necessary Python data access class at runtime.\n-   For **Go**, the compiler generates a `.pb.go` file with a type for each message type in your file.\n-   For **Ruby**, the compiler generates a `.rb` file with a Ruby module containing your message types.\n-   For **Objective-C**, the compiler generates a `pbobjc.h` and `pbobjc.m` file from each `.proto`, with a class for each message type described in your file.\n-   For **C#**, the compiler generates a `.cs` file from each `.proto`, with a class for each message type described in your file.\n-   For **PHP**, the compiler generates a `.php` message file for each message type described in your file, and a `.php` metadata file for each `.proto` file you compile. The metadata file is used to load the valid message types into the descriptor pool.\n-   For **Dart**, the compiler generates a `.pb.dart` file with a class for each message type in your file.\n\nYou can find out more about using the APIs for each language by following the tutorial for your chosen language. For even more API details, see the relevant [API reference](/reference/).\n\n## Scalar Value Types\n\nA scalar message field can have one of the following types ‚Äì the table shows the type specified in the `.proto` file, and the corresponding type in the automatically generated class:\n\nProto Type\n\nNotes\n\ndouble\n\nUses [IEEE 754](https://en.wikipedia.org/wiki/IEEE_754) double-precision format.\n\nfloat\n\nUses [IEEE 754](https://en.wikipedia.org/wiki/IEEE_754) single-precision format.\n\nint32\n\nUses variable-length encoding. Inefficient for encoding negative numbers ‚Äì if your field is likely to have negative values, use sint32 instead.\n\nint64\n\nUses variable-length encoding. Inefficient for encoding negative numbers ‚Äì if your field is likely to have negative values, use sint64 instead.\n\nuint32\n\nUses variable-length encoding.\n\nuint64\n\nUses variable-length encoding.\n\nsint32\n\nUses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int32s.\n\nsint64\n\nUses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int64s.\n\nfixed32\n\nAlways four bytes. More efficient than uint32 if values are often greater than 228.\n\nfixed64\n\nAlways eight bytes. More efficient than uint64 if values are often greater than 256.\n\nsfixed32\n\nAlways four bytes.\n\nsfixed64\n\nAlways eight bytes.\n\nbool\n\nstring\n\nA string must always contain UTF-8 encoded or 7-bit ASCII text, and cannot be longer than 232.\n\nbytes\n\nMay contain any arbitrary sequence of bytes no longer than 232.\n\nProto Type\n\nC++ Type\n\nJava/Kotlin Type\\[1\\]\n\nPython Type\\[3\\]\n\nGo Type\n\nRuby Type\n\nC# Type\n\nPHP Type\n\nDart Type\n\nRust Type\n\ndouble\n\ndouble\n\ndouble\n\nfloat\n\nfloat64\n\nFloat\n\ndouble\n\nfloat\n\ndouble\n\nf64\n\nfloat\n\nfloat\n\nfloat\n\nfloat\n\nfloat32\n\nFloat\n\nfloat\n\nfloat\n\ndouble\n\nf32\n\nint32\n\nint32\\_t\n\nint\n\nint\n\nint32\n\nFixnum or Bignum (as required)\n\nint\n\ninteger\n\nint\n\ni32\n\nint64\n\nint64\\_t\n\nlong\n\nint/long\\[4\\]\n\nint64\n\nBignum\n\nlong\n\ninteger/string\\[6\\]\n\nInt64\n\ni64\n\nuint32\n\nuint32\\_t\n\nint\\[2\\]\n\nint/long\\[4\\]\n\nuint32\n\nFixnum or Bignum (as required)\n\nuint\n\ninteger\n\nint\n\nu32\n\nuint64\n\nuint64\\_t\n\nlong\\[2\\]\n\nint/long\\[4\\]\n\nuint64\n\nBignum\n\nulong\n\ninteger/string\\[6\\]\n\nInt64\n\nu64\n\nsint32\n\nint32\\_t\n\nint\n\nint\n\nint32\n\nFixnum or Bignum (as required)\n\nint\n\ninteger\n\nint\n\ni32\n\nsint64\n\nint64\\_t\n\nlong\n\nint/long\\[4\\]\n\nint64\n\nBignum\n\nlong\n\ninteger/string\\[6\\]\n\nInt64\n\ni64\n\nfixed32\n\nuint32\\_t\n\nint\\[2\\]\n\nint/long\\[4\\]\n\nuint32\n\nFixnum or Bignum (as required)\n\nuint\n\ninteger\n\nint\n\nu32\n\nfixed64\n\nuint64\\_t\n\nlong\\[2\\]\n\nint/long\\[4\\]\n\nuint64\n\nBignum\n\nulong\n\ninteger/string\\[6\\]\n\nInt64\n\nu64\n\nsfixed32\n\nint32\\_t\n\nint\n\nint\n\nint32\n\nFixnum or Bignum (as required)\n\nint\n\ninteger\n\nint\n\ni32\n\nsfixed64\n\nint64\\_t\n\nlong\n\nint/long\\[4\\]\n\nint64\n\nBignum\n\nlong\n\ninteger/string\\[6\\]\n\nInt64\n\ni64\n\nbool\n\nbool\n\nboolean\n\nbool\n\nbool\n\nTrueClass/FalseClass\n\nbool\n\nboolean\n\nbool\n\nbool\n\nstring\n\nstd::string\n\nString\n\nstr/unicode\\[5\\]\n\nstring\n\nString (UTF-8)\n\nstring\n\nstring\n\nString\n\nProtoString\n\nbytes\n\nstd::string\n\nByteString\n\nstr (Python 2), bytes (Python 3)\n\n\\[\\]byte\n\nString (ASCII-8BIT)\n\nByteString\n\nstring\n\nList\n\nProtoBytes\n\n\\[1\\] Kotlin uses the corresponding types from Java, even for unsigned types, to ensure compatibility in mixed Java/Kotlin codebases.\n\n\\[2\\] In Java, unsigned 32-bit and 64-bit integers are represented using their signed counterparts, with the top bit simply being stored in the sign bit.\n\n\\[3\\] In all cases, setting values to a field will perform type checking to make sure it is valid.\n\n\\[4\\] 64-bit or unsigned 32-bit integers are always represented as long when decoded, but can be an int if an int is given when setting the field. In all cases, the value must fit in the type represented when set. See \\[2\\].\n\n\\[5\\] Python strings are represented as unicode on decode but can be str if an ASCII string is given (this is subject to change).\n\n\\[6\\] Integer is used on 64-bit machines and string is used on 32-bit machines.\n\nYou can find out more about how these types are encoded when you serialize your message in [Protocol Buffer Encoding](/programming-guides/encoding).\n\n## Default Field Values\n\nWhen a message is parsed, if the encoded message bytes do not contain a particular field, accessing that field in the parsed object returns the default value for that field. The default values are type-specific:\n\n-   For strings, the default value is the empty string.\n-   For bytes, the default value is empty bytes.\n-   For bools, the default value is false.\n-   For numeric types, the default value is zero.\n-   For message fields, the field is not set. Its exact value is language-dependent. See the [generated code guide](/reference/) for details.\n-   For enums, the default value is the **first defined enum value**, which must be 0. See [Enum Default Value](#enum-default).\n\nThe default value for repeated fields is empty (generally an empty list in the appropriate language).\n\nThe default value for map fields is empty (generally an empty map in the appropriate language).\n\nNote that for implicit-presence scalar fields, once a message is parsed there‚Äôs no way of telling whether that field was explicitly set to the default value (for example whether a boolean was set to `false`) or just not set at all: you should bear this in mind when defining your message types. For example, don‚Äôt have a boolean that switches on some behavior when set to `false` if you don‚Äôt want that behavior to also happen by default. Also note that if a scalar message field **is** set to its default, the value will not be serialized on the wire. If a float or double value is set to +0 it will not be serialized, but -0 is considered distinct and will be serialized.\n\nSee the [generated code guide](/reference/) for your chosen language for more details about how defaults work in generated code.\n\n## Enumerations\n\nWhen you‚Äôre defining a message type, you might want one of its fields to only have one of a predefined list of values. For example, let‚Äôs say you want to add a `corpus` field for each `SearchRequest`, where the corpus can be `UNIVERSAL`, `WEB`, `IMAGES`, `LOCAL`, `NEWS`, `PRODUCTS` or `VIDEO`. You can do this very simply by adding an `enum` to your message definition with a constant for each possible value.\n\nIn the following example we‚Äôve added an `enum` called `Corpus` with all the possible values, and a field of type `Corpus`:\n\n```proto\nenum Corpus {\n  CORPUS_UNSPECIFIED = 0;\n  CORPUS_UNIVERSAL = 1;\n  CORPUS_WEB = 2;\n  CORPUS_IMAGES = 3;\n  CORPUS_LOCAL = 4;\n  CORPUS_NEWS = 5;\n  CORPUS_PRODUCTS = 6;\n  CORPUS_VIDEO = 7;\n}\n\nmessage SearchRequest {\n  string query = 1;\n  int32 page_number = 2;\n  int32 results_per_page = 3;\n  Corpus corpus = 4;\n}\n```\n\n### Prefixing Enum Values\n\nWhen prefixing enum values, the remainder of the name with the prefix stripped should still be a legal and style-conformant enum name. For example, avoid the following:\n\n```proto\nenum DeviceTier {\n  DEVICE_TIER_UNKNOWN = 0;\n  DEVICE_TIER_1 = 1;\n  DEVICE_TIER_2 = 2;\n}\n```\n\nInstead, use a value name like `DEVICE_TIER_TIER1`, where the `DEVICE_TIER_` portion is viewed as scoping the enum value rather than as part of the individual enum value name. Some Protobuf implementations automatically strip the prefix that matches the containing enum name where it is safe to do so, but could not in this example since a bare `1` is not a legal enum value name.\n\nWe plan for a future Edition to add support for scoped enums, which will eliminate the need to manually prefix each enum value and enable this to be written succinctly as `TIER1 = 1`.\n\n### Enum Default Value\n\nThe default value for the `SearchRequest.corpus` field is `CORPUS_UNSPECIFIED` because that is the first value defined in the enum.\n\nIn proto3, the first value defined in an enum definition **must** have the value zero and should have the name `ENUM_TYPE_NAME_UNSPECIFIED` or `ENUM_TYPE_NAME_UNKNOWN`. This is because:\n\n-   There must be a zero value, so that we can use 0 as a numeric [default value](#default).\n-   The zero value needs to be the first element, for compatibility with the [proto2](/programming-guides/proto2) semantics where the first enum value is the default unless a different value is explicitly specified.\n\nIt is also recommended that this first, default value have no semantic meaning other than ‚Äúthis value was unspecified‚Äù.\n\n### Enum Value Aliases\n\nYou can define aliases by assigning the same value to different enum constants. To do this you need to set the `allow_alias` option to `true`. Otherwise, the protocol buffer compiler generates a warning message when aliases are found. Though all alias values are valid for serialization, only the first value is used when deserializing.\n\n```proto\nenum EnumAllowingAlias {\n  option allow_alias = true;\n  EAA_UNSPECIFIED = 0;\n  EAA_STARTED = 1;\n  EAA_RUNNING = 1;\n  EAA_FINISHED = 2;\n}\n\nenum EnumNotAllowingAlias {\n  ENAA_UNSPECIFIED = 0;\n  ENAA_STARTED = 1;\n  // ENAA_RUNNING = 1;  // Uncommenting this line will cause a warning message.\n  ENAA_FINISHED = 2;\n}\n```\n\nEnumerator constants must be in the range of a 32-bit integer. Since `enum` values use [varint encoding](/programming-guides/encoding) on the wire, negative values are inefficient and thus not recommended. You can define `enum`s within a message definition, as in the earlier example, or outside ‚Äì these `enum`s can be reused in any message definition in your `.proto` file. You can also use an `enum` type declared in one message as the type of a field in a different message, using the syntax `_MessageType_._EnumType_`.\n\nWhen you run the protocol buffer compiler on a `.proto` that uses an `enum`, the generated code will have a corresponding `enum` for Java, Kotlin, or C++, or a special `EnumDescriptor` class for Python that‚Äôs used to create a set of symbolic constants with integer values in the runtime-generated class.\n\n#### Important\n\nThe generated code may be subject to language-specific limitations on the number of enumerators (low thousands for one language). Review the limitations for the languages you plan to use.\n\nDuring deserialization, unrecognized enum values will be preserved in the message, though how this is represented when the message is deserialized is language-dependent. In languages that support open enum types with values outside the range of specified symbols, such as C++ and Go, the unknown enum value is simply stored as its underlying integer representation. In languages with closed enum types such as Java, a case in the enum is used to represent an unrecognized value, and the underlying integer can be accessed with special accessors. In either case, if the message is serialized the unrecognized value will still be serialized with the message.\n\n#### Important\n\nFor information on how enums should work contrasted with how they currently work in different languages, see [Enum Behavior](/programming-guides/enum).\n\nFor more information about how to work with message `enum`s in your applications, see the [generated code guide](/reference/) for your chosen language.\n\n### Reserved Values\n\nIf you [update](#updating) an enum type by entirely removing an enum entry, or commenting it out, future users can reuse the numeric value when making their own updates to the type. This can cause severe issues if they later load old instances of the same `.proto`, including data corruption, privacy bugs, and so on. One way to make sure this doesn‚Äôt happen is to specify that the numeric values (and/or names, which can also cause issues for JSON serialization) of your deleted entries are `reserved`. The protocol buffer compiler will complain if any future users try to use these identifiers. You can specify that your reserved numeric value range goes up to the maximum possible value using the `max` keyword.\n\n```proto\nenum Foo {\n  reserved 2, 15, 9 to 11, 40 to max;\n  reserved \"FOO\", \"BAR\";\n}\n```\n\nNote that you can‚Äôt mix field names and numeric values in the same `reserved` statement.\n\n## Using Other Message Types\n\nYou can use other message types as field types. For example, let‚Äôs say you wanted to include `Result` messages in each `SearchResponse` message ‚Äì to do this, you can define a `Result` message type in the same `.proto` and then specify a field of type `Result` in `SearchResponse`:\n\n```proto\nmessage SearchResponse {\n  repeated Result results = 1;\n}\n\nmessage Result {\n  string url = 1;\n  string title = 2;\n  repeated string snippets = 3;\n}\n```\n\n### Importing Definitions\n\nIn the earlier example, the `Result` message type is defined in the same file as `SearchResponse` ‚Äì what if the message type you want to use as a field type is already defined in another `.proto` file?\n\nYou can use definitions from other `.proto` files by *importing* them. To import another `.proto`‚Äôs definitions, you add an import statement to the top of your file:\n\n```proto\nimport \"myproject/other_protos.proto\";\n```\n\nThe protobuf compiler searches for imported files in a set of directories specified using the `-I`/`--proto_path` flag. The path given in an `import` statement is resolved relative to these directories. For more information on using the compiler, see [Generating Your Classes](#generating).\n\nFor example, consider the following directory structure:\n\n```fallback\nmy_project/\n‚îú‚îÄ‚îÄ protos/\n‚îÇ   ‚îú‚îÄ‚îÄ main.proto\n‚îÇ   ‚îî‚îÄ‚îÄ common/\n‚îÇ       ‚îî‚îÄ‚îÄ timestamp.proto\n```\n\nTo use definitions from `timestamp.proto` within `main.proto`, you would run the compiler from the `my_project` directory and set `--proto_path=protos`. The `import` statement in `main.proto` would then be:\n\n```proto\n// Located in my_project/protos/main.proto\nimport \"common/timestamp.proto\";\n```\n\nIn general you should set the `--proto_path` flag to the highest-level directory that contains protos. This is often the root of the project, but in this example it‚Äôs in a separate `/protos` directory.\n\nBy default, you can use definitions only from directly imported `.proto` files. However, sometimes you may need to move a `.proto` file to a new location. Instead of moving the `.proto` file directly and updating all the call sites in a single change, you can put a placeholder `.proto` file in the old location to forward all the imports to the new location using the `import public` notion.\n\n**Note:** The public import functionality available in Java is most effective when moving an entire .proto file or when using `java_multiple_files = true`. In these cases, generated names remain stable, avoiding the need to update references in your code. While technically functional when moving a subset of a .proto file without `java_multiple_files = true`, doing so requires simultaneous updates to many references, thus might not significantly ease migration. The functionality is not available in Kotlin, TypeScript, JavaScript, GCL, or with C++ targets that use protobuf static reflection.\n\n`import public` dependencies can be transitively relied upon by any code importing the proto containing the `import public` statement. For example:\n\n```proto\n// new.proto\n// All definitions are moved here\n```\n\n```proto\n// old.proto\n// This is the proto that all clients are importing.\nimport public \"new.proto\";\nimport \"other.proto\";\n```\n\n```proto\n// client.proto\nimport \"old.proto\";\n// You use definitions from old.proto and new.proto, but not other.proto\n```\n\n### Using proto2 Message Types\n\nIt‚Äôs possible to import [proto2](/programming-guides/proto2) message types and use them in your proto3 messages, and vice versa. However, proto2 enums cannot be used directly in proto3 syntax (it‚Äôs okay if an imported proto2 message uses them).\n\n## Nested Types\n\nYou can define and use message types inside other message types, as in the following example ‚Äì here the `Result` message is defined inside the `SearchResponse` message:\n\n```proto\nmessage SearchResponse {\n  message Result {\n    string url = 1;\n    string title = 2;\n    repeated string snippets = 3;\n  }\n  repeated Result results = 1;\n}\n```\n\nIf you want to reuse this message type outside its parent message type, you refer to it as `_Parent_._Type_`:\n\n```proto\nmessage SomeOtherMessage {\n  SearchResponse.Result result = 1;\n}\n```\n\nYou can nest messages as deeply as you like. In the example below, note that the two nested types named `Inner` are entirely independent, since they are defined within different messages:\n\n```proto\nmessage Outer {       // Level 0\n  message MiddleAA {  // Level 1\n    message Inner {   // Level 2\n      int64 ival = 1;\n      bool  booly = 2;\n    }\n  }\n  message MiddleBB {  // Level 1\n    message Inner {   // Level 2\n      int32 ival = 1;\n      bool  booly = 2;\n    }\n  }\n}\n```\n\n## Updating A Message Type\n\nIf an existing message type no longer meets all your needs ‚Äì for example, you‚Äôd like the message format to have an extra field ‚Äì but you‚Äôd still like to use code created with the old format, don‚Äôt worry! It‚Äôs very simple to update message types without breaking any of your existing code when you use the binary wire format.\n\n#### Note\n\nIf you use ProtoJSON or [proto text format](/reference/protobuf/textformat-spec) to store your protocol buffer messages, the changes that you can make in your proto definition are different. The ProtoJSON wire format safe changes are described [here](/programming-guides/json#json-wire-safety).\n\nCheck [Proto Best Practices](/best-practices/dos-donts) and the following rules:\n\n### Binary Wire-unsafe Changes\n\nWire-unsafe changes are schema changes that will break if you use parse data that was serialized using the old schema with a parser that is using the new schema (or vice versa). Only make wire-unsafe changes if you know that all serializers and deserializers of the data are using the new schema.\n\n-   Changing field numbers for any existing field is not safe.\n    -   Changing the field number is equivalent to deleting the field and adding a new field with the same type. If you want to renumber a field, see the instructions for [deleting a field](#deleting).\n-   Moving fields into an existing `oneof` is not safe.\n\n### Binary Wire-safe Changes\n\nWire-safe changes are ones where it is fully safe to evolve the schema in this way without risk of data loss or new parse failures.\n\nNote that any wire-safe changes may be a breaking change to application code in a given language. For example, adding a value to a preexisting enum would be a compilation break for any code with an exhaustive switch on that enum. For that reason, Google may avoid making some of these types of changes on public messages: the AIPs contain guidance for which of these changes are safe to make there.\n\n-   Adding new fields is safe.\n    -   If you add new fields, any messages serialized by code using your ‚Äúold‚Äù message format can still be parsed by your new generated code. You should keep in mind the [default values](#default) for these elements so that new code can properly interact with messages generated by old code. Similarly, messages created by your new code can be parsed by your old code: old binaries simply ignore the new field when parsing. See the [Unknown Fields](#unknowns) section for details.\n-   Removing fields is safe.\n    -   The same field number must not used again in your updated message type. You may want to rename the field instead, perhaps adding the prefix ‚ÄúOBSOLETE\\_‚Äù, or make the field number [reserved](#fieldreserved), so that future users of your `.proto` can‚Äôt accidentally reuse the number.\n-   Adding additional values to an enum is safe.\n-   Changing a single explicit presence field or extension into a member of a **new** `oneof` is safe.\n-   Changing a `oneof` which contains only one field to an explicit presence field is safe.\n-   Changing a field into an extension of same number and type is safe.\n\n### Binary Wire-compatible Changes (Conditionally Safe)\n\nUnlike Wire-safe changes, wire-compatible means that the same data can be parsed both before and after a given change. However, a parse of the data may be lossy under this shape of change. For example, changing an int32 to an int64 is a compatible change, but if a value larger than INT32\\_MAX is written, a client that reads it as an int32 will discard the high order bits of the number.\n\nYou can make compatible changes to your schema only if you manage the roll out to your system carefully. For example, you may change an int32 to an int64 but ensure you continue to only write legal int32 values until the new schema is deployed to all endpoints, and then subsequently start writing larger values after that.\n\nIf your schema is published outside of your organization, you should generally not make wire-compatible changes, as you cannot manage the deployment of the new schema to know when the different range of values may be safe to use.\n\n-   `int32`, `uint32`, `int64`, `uint64`, and `bool` are all compatible.\n    -   If a number is parsed from the wire which doesn‚Äôt fit in the corresponding type, you will get the same effect as if you had cast the number to that type in C++ (for example, if a 64-bit number is read as an int32, it will be truncated to 32 bits).\n-   `sint32` and `sint64` are compatible with each other but are *not* compatible with the other integer types.\n    -   If the value written was between INT\\_MIN and INT\\_MAX inclusive it will parse as the same value with either type. If an sint64 value was written outside of that range and parsed as an sint32, the varint is truncated to 32 bits and then zigzag decoding occurs (which will cause a different value to be observed).\n-   `string` and `bytes` are compatible as long as the bytes are valid UTF-8.\n-   Embedded messages are compatible with `bytes` if the bytes contain an encoded instance of the message.\n-   `fixed32` is compatible with `sfixed32`, and `fixed64` with `sfixed64`.\n-   For `string`, `bytes`, and message fields, singular is compatible with `repeated`.\n    -   Given serialized data of a repeated field as input, clients that expect this field to be singular will take the last input value if it‚Äôs a primitive type field or merge all input elements if it‚Äôs a message type field. Note that this is **not** generally safe for numeric types, including bools and enums. Repeated fields of numeric types are serialized in the [packed](/programming-guides/encoding#packed) format by default, which will not be parsed correctly when a singular field is expected.\n-   `enum` is compatible with `int32`, `uint32`, `int64`, and `uint64`\n    -   Be aware that client code may treat them differently when the message is deserialized: for example, unrecognized proto3 `enum` values will be preserved in the message, but how this is represented when the message is deserialized is language-dependent.\n-   Changing a field between a `map<K, V>` and the corresponding `repeated` message field is binary compatible (see [Maps](#maps), below, for the message layout and other restrictions).\n    -   However, the safety of the change is application-dependent: when deserializing and reserializing a message, clients using the `repeated` field definition will produce a semantically identical result; however, clients using the `map` field definition may reorder entries and drop entries with duplicate keys.\n\n## Unknown Fields\n\nUnknown fields are well-formed protocol buffer serialized data representing fields that the parser does not recognize. For example, when an old binary parses data sent by a new binary with new fields, those new fields become unknown fields in the old binary.\n\nProto3 messages preserve unknown fields and include them during parsing and in the serialized output, which matches proto2 behavior.\n\n### Retaining Unknown Fields\n\nSome actions can cause unknown fields to be lost. For example, if you do one of the following, unknown fields are lost:\n\n-   Serialize a proto to JSON.\n-   Iterate over all of the fields in a message to populate a new message.\n\nTo avoid losing unknown fields, do the following:\n\n-   Use binary; avoid using text formats for data exchange.\n-   Use message-oriented APIs, such as `CopyFrom()` and `MergeFrom()`, to copy data rather than copying field-by-field\n\nTextFormat is a bit of a special case. Serializing to TextFormat prints unknown fields using their field numbers. But parsing TextFormat data back into a binary proto fails if there are entries that use field numbers.\n\n## Any\n\nThe `Any` message type lets you use messages as embedded types without having their .proto definition. An `Any` contains an arbitrary serialized message as `bytes`, along with a URL that acts as a globally unique identifier for and resolves to that message‚Äôs type. To use the `Any` type, you need to [import](#other) `google/protobuf/any.proto`.\n\n```proto\nimport \"google/protobuf/any.proto\";\n\nmessage ErrorStatus {\n  string message = 1;\n  repeated google.protobuf.Any details = 2;\n}\n```\n\nThe default type URL for a given message type is `type.googleapis.com/_packagename_._messagename_`.\n\nDifferent language implementations will support runtime library helpers to pack and unpack `Any` values in a typesafe manner ‚Äì for example, in Java, the `Any` type will have special `pack()` and `unpack()` accessors, while in C++ there are `PackFrom()` and `UnpackTo()` methods:\n\n```cpp\n// Storing an arbitrary message type in Any.\nNetworkErrorDetails details = ...;\nErrorStatus status;\nstatus.add_details()->PackFrom(details);\n\n// Reading an arbitrary message from Any.\nErrorStatus status = ...;\nfor (const google::protobuf::Any& detail : status.details()) {\n  if (detail.Is<NetworkErrorDetails>()) {\n    NetworkErrorDetails network_error;\n    detail.UnpackTo(&network_error);\n    ... processing network_error ...\n  }\n}\n```\n\n## Oneof\n\nIf you have a message with many singular fields and where at most one field will be set at the same time, you can enforce this behavior and save memory by using the oneof feature.\n\nOneof fields are like optional fields except all the fields in a oneof share memory, and at most one field can be set at the same time. Setting any member of the oneof automatically clears all the other members. You can check which value in a oneof is set (if any) using a special `case()` or `WhichOneof()` method, depending on your chosen language.\n\nNote that if *multiple values are set, the last set value as determined by the order in the proto will overwrite all previous ones*.\n\nField numbers for oneof fields must be unique within the enclosing message.\n\n### Using Oneof\n\nTo define a oneof in your `.proto` you use the `oneof` keyword followed by your oneof name, in this case `test_oneof`:\n\n```proto\nmessage SampleMessage {\n  oneof test_oneof {\n    string name = 4;\n    SubMessage sub_message = 9;\n  }\n}\n```\n\n\n...27689 bytes truncated...\n\nThe tool call succeeded but the output was truncated. Full output saved to: /Users/alex/.local/share/opencode/tool-output/tool_c64854c53001b38CBmnZ8az5EU\nUse the Task tool to have explore agent process this file with Grep and Read (with offset/limit). Do NOT read the full file yourself - delegate to save context.",
            "title": "https://protobuf.dev/programming-guides/proto3/ (text/html; charset=utf-8)",
            "metadata": {
              "truncated": true,
              "outputPath": "/Users/alex/.local/share/opencode/tool-output/tool_c64854c53001b38CBmnZ8az5EU"
            },
            "time": {
              "start": 1771212982872,
              "end": 1771212983380,
              "compacted": 1771213545697
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_01e5c65264d6e81601699290b6cacc8194aa5f19a2c9931ae4"
            }
          },
          "id": "prt_c64854a480015UOppQhci6WpbX",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648519a3001dVkoAXMkiGYiY8"
        },
        {
          "type": "tool",
          "callID": "call_7oIFzr6ewUSBRQNpDhT8mnWe",
          "tool": "webfetch",
          "state": {
            "status": "completed",
            "input": {
              "url": "https://protobuf.dev/programming-guides/field_presence/",
              "format": "markdown"
            },
            "output": "Application Note: Field Presence | Protocol Buffers Documentation \n\n[Protocol Buffers Documentation](/)\n\n-   [Protocol Buffers](/)\n    -   [Overview](/overview/)\n    -   [Protoc Installation](/installation/ \"Protocol Buffer Compiler Installation\")\n    -   [News](/news/)\n    -   [Programming Guides](/programming-guides/)\n        -   [Language Guide (editions)](/programming-guides/editions/)\n        -   [Language Guide (proto 2)](/programming-guides/proto2/)\n        -   [Language Guide (proto 3)](/programming-guides/proto3/)\n        -   [Proto Limits](/programming-guides/proto-limits/)\n        -   [Style Guide](/programming-guides/style/)\n        -   [Enum Behavior](/programming-guides/enum/)\n        -   [Encoding](/programming-guides/encoding/)\n        -   [ProtoJSON Format](/programming-guides/json/)\n        -   [Techniques](/programming-guides/techniques/)\n        -   [Add-ons](/programming-guides/addons/ \"Third-Party Add-ons\")\n        -   [Extension Declarations](/programming-guides/extension_declarations/)\n        -   [Field Presence](/programming-guides/field_presence/ \"Application Note: Field Presence\")\n        -   [Proto Serialization Is Not Canonical](/programming-guides/serialization-not-canonical/)\n        -   [Deserializing Debug Proto Representations](/programming-guides/deserialize-debug/)\n    -   [Protobuf Editions](/editions/)\n        -   [Overview](/editions/overview/ \"Protobuf Editions Overview\")\n        -   [Feature Settings for Editions](/editions/features/)\n        -   [Implementing Editions Support](/editions/implementation/)\n    -   [Design Decisions](/design-decisions/ \"Protobuf Team Design Decisions\")\n        -   [No Nullable Setters/Getters Support](/design-decisions/nullable-getters-setters/)\n    -   [Proto Best Practices](/best-practices/)\n        -   [Avoid Cargo Culting](/best-practices/no-cargo-cults/)\n        -   [Proto Best Practices](/best-practices/dos-donts/)\n        -   [1-1-1 Best Practice](/best-practices/1-1-1/)\n    -   [Tutorials](/getting-started/)\n        -   [C++](/getting-started/cpptutorial/ \"Protocol Buffer Basics: C++\")\n        -   [C#](/getting-started/csharptutorial/ \"Protocol Buffer Basics: C#\")\n        -   [Dart](/getting-started/darttutorial/ \"Protocol Buffer Basics: Dart\")\n        -   [Go](/getting-started/gotutorial/ \"Protocol Buffer Basics: Go\")\n        -   [Java](/getting-started/javatutorial/ \"Protocol Buffer Basics: Java\")\n        -   [Kotlin](/getting-started/kotlintutorial/ \"Protocol Buffer Basics: Kotlin\")\n        -   [Python](/getting-started/pythontutorial/ \"Protocol Buffer Basics: Python\")\n    -   [Reference Guides](/reference/)\n        -   [C++](/reference/cpp/ \"C++ Reference\")\n            -   [Generated Code Guide](/reference/cpp/cpp-generated/ \"C++ Generated Code Guide\")\n            -   [String View APIs](/reference/cpp/string-view/)\n            -   [Arena Allocation Guide](/reference/cpp/arenas/ \"C++ Arena Allocation Guide\")\n            -   [Abseil Support](/reference/cpp/abseil/)\n            -   [C++ API](/reference/cpp/api-docs/)\n        -   [C#](/reference/csharp/ \"C# Reference\")\n            -   [Generated Code Guide](/reference/csharp/csharp-generated/ \"C# Generated Code Guide\")\n            -   [C# API](/reference/csharp/api-docs)\n        -   [Dart](/reference/dart/ \"Dart Reference\")\n            -   [Generated Code](/reference/dart/dart-generated/ \"Dart Generated Code\")\n            -   [Dart API](https://pub.dartlang.org/documentation/protobuf)\n        -   [Go](/reference/go/ \"Go Reference\")\n            -   [Generated Code Guide (Open)](/reference/go/go-generated/ \"Go Generated Code Guide (Open)\")\n            -   [Generated Code Guide (Opaque)](/reference/go/go-generated-opaque/ \"Go Generated Code Guide (Opaque)\")\n            -   [FAQ](/reference/go/faq/ \"Go FAQ\")\n            -   [Size Semantics](/reference/go/size/ \"Go Size Semantics\")\n            -   [Go API](https://pkg.go.dev/google.golang.org/protobuf/proto)\n            -   [Opaque API Migration](/reference/go/opaque-migration/ \"Go Opaque API Migration\")\n            -   [Opaque API: Manual Migration](/reference/go/opaque-migration-manual/ \"Go Opaque API: Manual Migration\")\n            -   [Opaque API FAQ](/reference/go/opaque-faq/ \"Go Opaque API FAQ\")\n        -   [Java](/reference/java/ \"Java Reference\")\n            -   [Generated Code Guide](/reference/java/java-generated/ \"Java Generated Code Guide\")\n            -   [Generated Proto Names](/reference/java/java-proto-names/ \"Java Proto Names\")\n            -   [Java API](/reference/java/api-docs/overview-summary.html)\n        -   [Kotlin](/reference/kotlin/ \"Kotlin Reference\")\n            -   [Kotlin](/reference/kotlin/api-docs/ \"Kotlin Reference\")\n            -   [Generated Code Guide](/reference/kotlin/kotlin-generated/ \"Kotlin Generated Code Guide\")\n        -   [Objective-C](/reference/objective-c/ \"Objective-C Reference\")\n            -   [Generated Code Guide](/reference/objective-c/objective-c-generated/ \"Objective-C Generated Code Guide\")\n        -   [PHP](/reference/php/ \"PHP Reference\")\n            -   [Generated Code Guide](/reference/php/php-generated/ \"PHP Generated Code Guide\")\n            -   [PHP API](/reference/php/api-docs/)\n        -   [Python](/reference/python/ \"Python Reference\")\n            -   [Generated Code Guide](/reference/python/python-generated/ \"Python Generated Code Guide\")\n            -   [Python Comparison](/reference/python/python-comparison/)\n            -   [Python API](https://googleapis.dev/python/protobuf/latest/)\n        -   [Ruby](/reference/ruby/ \"Ruby Reference\")\n            -   [Generated Code Guide](/reference/ruby/ruby-generated/ \"Ruby Generated Code Guide\")\n        -   [Rust](/reference/rust/ \"Rust Reference\")\n            -   [Generated Code Guide](/reference/rust/rust-generated/ \"Rust Generated Code Guide\")\n            -   [Redaction in Rust](/reference/rust/rust-redaction/)\n            -   [Building Rust Protos](/reference/rust/building-rust-protos/)\n            -   [Design Decisions](/reference/rust/rust-design-decisions/ \"Rust Proto Design Decisions\")\n        -   [Protocol Buffers](/reference/protobuf/ \"Protocol Buffers Reference\")\n            -   [2023 Language Specification](/reference/protobuf/edition-2023-spec/ \"Protocol Buffers Edition 2023 Language Specification\")\n            -   [Language Specification (Proto2 Syntax)](/reference/protobuf/proto2-spec/ \"Protocol Buffers Language Specification (Proto2 Syntax)\")\n            -   [2024 Language Specification](/reference/protobuf/edition-2024-spec/ \"Protocol Buffers Edition 2024 Language Specification\")\n            -   [Language Specification (Proto3)](/reference/protobuf/proto3-spec/ \"Protocol Buffers Language Specification (Proto3)\")\n            -   [Text Format Language Specification](/reference/protobuf/textformat-spec/)\n            -   [MIME Types](/reference/protobuf/mime-types/ \"Protocol Buffer MIME Types\")\n            -   [Well-Known Types](/reference/protobuf/google.protobuf/ \"Protocol Buffers Well-Known Types\")\n        -   [Other Languages](/reference/other/)\n    -   [Support](/support/)\n        -   [Version Support](/support/version-support/)\n        -   [Debugging](/support/debugging-playbook/)\n        -   [Migration Guide](/support/migration/)\n        -   [Cross-Version Runtime Guarantee](/support/cross-version-runtime-guarantee/)\n    -   [Downloads](/downloads/)\n    -   [History](/history/)\n    -   [Forum](https://groups.google.com/g/protobuf)\n    -   [](/navbar/)\n    -   [Search Results](/search/)\n\n[View page source](https://github.com/protocolbuffers/protocolbuffers.github.io/tree/main/content/programming-guides/field_presence.md) [Edit this page](https://github.com/protocolbuffers/protocolbuffers.github.io/edit/main/content/programming-guides/field_presence.md) [Create child page](https://github.com/protocolbuffers/protocolbuffers.github.io/new/main/content/programming-guides/field_presence.md?filename=change-me.md&value=---%0Atitle%3A+%22Long+Page+Title%22%0AlinkTitle%3A+%22Short+Nav+Title%22%0Aweight%3A+100%0Adescription%3A+%3E-%0A+++++Page+description+for+heading+and+indexes.%0A---%0A%0A%23%23+Heading%0A%0AEdit+this+template+to+create+your+new+page.%0A%0A%2A+Give+it+a+good+name%2C+ending+in+%60.md%60+-+e.g.+%60getting-started.md%60%0A%2A+Edit+the+%22front+matter%22+section+at+the+top+of+the+page+%28weight+controls+how+its+ordered+amongst+other+pages+in+the+same+directory%3B+lowest+number+first%29.%0A%2A+Add+a+good+commit+message+at+the+bottom+of+the+page+%28%3C80+characters%3B+use+the+extended+description+field+for+more+detail%29.%0A%2A+Create+a+new+branch+so+you+can+preview+your+new+file+and+request+a+review+via+Pull+Request.%0A) [Create documentation issue](https://github.com/protocolbuffers/protocolbuffers.github.io/issues/new?title=Application%20Note:%20Field%20Presence) [Create project issue](https://github.com/protocolbuffers/protobuf/issues/new)\n\n-   [Background](#background)\n    -   [Presence Disciplines](#disciplines)\n    -   [Presence in *Tag-value stream* (Wire Format) Serialization](#presence-tag-value)\n    -   [Presence in *Named-field Mapping* Formats](#presence-named-field)\n    -   [Presence in Proto2 APIs](#presence-proto2)\n    -   [Presence in Proto3 APIs](#presence-proto3)\n    -   [Presence in Editions APIs](#presence-editions)\n-   [Semantic Differences](#semantic-differences)\n    -   [Considerations for Merging](#merging)\n    -   [Considerations for change-compatibility](#change-compatibility)\n-   [How to Enable *Explicit Presence* in Proto3](#enable-explicit-proto3)\n    -   [`.proto` File Changes](#proto-file-changes)\n    -   [`protoc` Invocation](#protoc-invocation)\n    -   [Using the Generated Code](#using-the-generated-code)\n-   [Cheat sheet](#cheat)\n\n1.  [Programming Guides](/programming-guides/)\n2.  Field Presence\n\n# Application Note: Field Presence\n\nExplains the various presence-tracking disciplines for protobuf fields. It also explains the behavior of explicit presence-tracking for singular proto3 fields with basic types.\n\n## Background\n\n*Field presence* is the notion of whether a protobuf field has a value. There are two different manifestations of presence for protobufs: *implicit presence*, where the generated message API stores field values (only), and *explicit presence*, where the API also stores whether or not a field has been set.\n\n#### Note\n\nWe recommend always adding the `optional` label for proto3 basic types. This provides a smoother path to editions, which uses explicit presence by default.\n\n### Presence Disciplines\n\n*Presence disciplines* define the semantics for translating between the *API representation* and the *serialized representation*. The *implicit presence* discipline relies upon the field value itself to make decisions at (de)serialization time, while the *explicit presence* discipline relies upon the explicit tracking state instead.\n\n### Presence in *Tag-value stream* (Wire Format) Serialization\n\nThe wire format is a stream of tagged, *self-delimiting* values. By definition, the wire format represents a sequence of *present* values. In other words, every value found within a serialization represents a *present* field; furthermore, the serialization contains no information about not-present values.\n\nThe generated API for a proto message includes (de)serialization definitions which translate between API types and a stream of definitionally *present* (tag, value) pairs. This translation is designed to be forward- and backward-compatible across changes to the message definition; however, this compatibility introduces some (perhaps surprising) considerations when deserializing wire-formatted messages:\n\n-   When serializing, fields with *implicit presence* are not serialized if they contain their default value.\n    -   For numeric types, the default is 0.\n    -   For enums, the default is the zero-valued enumerator.\n    -   For strings, bytes, and repeated fields, the default is the zero-length value.\n-   ‚ÄúEmpty‚Äù length-delimited values (such as empty strings) can be validly represented in serialized values: the field is ‚Äúpresent,‚Äù in the sense that it appears in the wire format. However, if the generated API does not track presence, then these values may not be re-serialized; i.e., the empty field may be ‚Äúnot present‚Äù after a serialization round-trip.\n-   When deserializing, duplicate field values may be handled in different ways depending on the field definition.\n    -   Duplicate `repeated` fields are typically appended to the field‚Äôs API representation. (Note that serializing a *packed* repeated field produces only one, length-delimited value in the tag stream.)\n    -   Duplicate `optional` field values follow the rule that ‚Äúthe last one wins.‚Äù\n-   `oneof` fields expose the API-level invariant that only one field is set at a time. However, the wire format may include multiple (tag, value) pairs which notionally belong to the `oneof`. Similar to `optional` fields, the generated API follows the ‚Äúlast one wins‚Äù rule.\n-   Out-of-range values are not returned for enum fields in generated proto2 APIs. However, out-of-range values may be stored as *unknown fields* in the API, even though the wire-format tag was recognized.\n\n### Presence in *Named-field Mapping* Formats\n\nProtobufs can be represented in human-readable, textual forms. Two notable formats are TextFormat (the output format produced by generated message `DebugString` methods) and JSON.\n\nThese formats have correctness requirements of their own, and are generally stricter than *tagged-value stream* formats. However, TextFormat more closely mimics the semantics of the wire format, and does, in certain cases, provide similar semantics (for example, appending repeated name-value mappings to a repeated field). In particular, similar to the wire format, TextFormat only includes fields which are present.\n\nJSON is a much stricter format, however, and cannot validly represent some semantics of the wire format or TextFormat.\n\n-   Notably, JSON *elements* are semantically unordered, and each member must have a unique name. This is different from TextFormat rules for repeated fields.\n-   JSON may include fields that are ‚Äúnot present,‚Äù unlike the *implicit presence* discipline for other formats:\n    -   JSON defines a `null` value, which may be used to represent a *defined but not-present field*.\n    -   Repeated field values may be included in the formatted output, even if they are equal to the default (an empty list).\n-   Because JSON elements are unordered, there is no way to unambiguously interpret the ‚Äúlast one wins‚Äù rule.\n    -   In most cases, this is fine: JSON elements must have unique names: repeated field values are not valid JSON, so they do not need to be resolved as they are for TextFormat.\n    -   However, this means that it may not be possible to interpret `oneof` fields unambiguously: if multiple cases are present, they are unordered.\n\nIn theory, JSON *can* represent presence in a semantic-preserving fashion. In practice, however, presence correctness can vary depending upon implementation choices, especially if JSON was chosen as a means to interoperate with clients not using protobufs.\n\n### Presence in Proto2 APIs\n\nThis table outlines whether presence is tracked for fields in proto2 APIs (both for generated APIs and using dynamic reflection):\n\nField type\n\nExplicit Presence\n\nSingular numeric (integer or floating point)\n\n‚úîÔ∏è\n\nSingular enum\n\n‚úîÔ∏è\n\nSingular string or bytes\n\n‚úîÔ∏è\n\nSingular message\n\n‚úîÔ∏è\n\nRepeated\n\nOneofs\n\n‚úîÔ∏è\n\nMaps\n\nSingular fields (of all types) track presence explicitly in the generated API. The generated message interface includes methods to query presence of fields. For example, the field `foo` has a corresponding `has_foo` method. (The specific name follows the same language-specific naming convention as the field accessors.) These methods are sometimes referred to as ‚Äúhazzers‚Äù within the protobuf implementation.\n\nSimilar to singular fields, `oneof` fields explicitly track which one of the members, if any, contains a value. For example, consider this example `oneof`:\n\n```protobuf\noneof foo {\n  int32 a = 1;\n  float b = 2;\n}\n```\n\nDepending on the target language, the generated API would generally include several methods:\n\n-   A hazzer for the oneof: `has_foo`\n-   A *oneof case* method: `foo`\n-   Hazzers for the members: `has_a`, `has_b`\n-   Getters for the members: `a`, `b`\n\nRepeated fields and maps do not track presence: there is no distinction between an *empty* and a *not-present* repeated field.\n\n### Presence in Proto3 APIs\n\nThis table outlines whether presence is tracked for fields in proto3 APIs (both for generated APIs and using dynamic reflection):\n\nField type\n\n`optional`\n\nExplicit Presence\n\nSingular numeric (integer or floating point)\n\nNo\n\nSingular numeric (integer or floating point)\n\nYes\n\n‚úîÔ∏è\n\nSingular enum\n\nNo\n\nSingular enum\n\nYes\n\n‚úîÔ∏è\n\nSingular string or bytes\n\nNo\n\nSingular string or bytes\n\nYes\n\n‚úîÔ∏è\n\nSingular message\n\nNo\n\n‚úîÔ∏è\n\nSingular message\n\nYes\n\n‚úîÔ∏è\n\nRepeated\n\nN/A\n\nOneofs\n\nN/A\n\n‚úîÔ∏è\n\nMaps\n\nN/A\n\nSimilar to proto2 APIs, proto3 does not track presence explicitly for repeated fields. Without the `optional` label, proto3 APIs do not track presence for basic types (numeric, string, bytes, and enums), either. Oneof fields affirmatively expose presence, although the same set of hazzer methods may not generated as in proto2 APIs.\n\nThis default behavior of not tracking presence without the `optional` label is different from the proto2 behavior. We recommend using the `optional` label with proto3 unless you have a specific reason not to.\n\nUnder the *implicit presence* discipline, the default value is synonymous with ‚Äúnot present‚Äù for purposes of serialization. To notionally ‚Äúclear‚Äù a field (so it won‚Äôt be serialized), an API user would set it to the default value.\n\nThe default value for enum-typed fields under *implicit presence* is the corresponding 0-valued enumerator. Under proto3 syntax rules, all enum types are required to have an enumerator value which maps to 0. By convention, this is an `UNKNOWN` or similarly-named enumerator. If the zero value is notionally outside the domain of valid values for the application, this behavior can be thought of as tantamount to *explicit presence*.\n\n### Presence in Editions APIs\n\nThis table outlines whether presence is tracked for fields in editions APIs (both for generated APIs and using dynamic reflection):\n\nField type\n\nExplicit Presence\n\nSingular numeric (integer or floating point)\n\n‚úîÔ∏è\n\nSingular enum\n\n‚úîÔ∏è\n\nSingular string or bytes\n\n‚úîÔ∏è\n\nSingular message‚Ä†\n\n‚úîÔ∏è\n\nRepeated\n\nOneofs‚Ä†\n\n‚úîÔ∏è\n\nMaps\n\n‚Ä† Messages and oneofs have never had implicit presence, and editions doesn‚Äôt allow you to set `field_presence = IMPLICIT`.\n\nEditions-based APIs track field presence explicitly, similarly to proto2, unless `features.field_presence` is set to `IMPLICIT`. Similar to proto2 APIs, editions-based APIs do not track presence explicitly for repeated fields.\n\n## Semantic Differences\n\nThe *implicit presence* serialization discipline results in visible differences from the *explicit presence* tracking discipline, when the default value is set. For a singular field with numeric, enum, or string type:\n\n-   *Implicit presence* discipline:\n    -   Default values are not serialized.\n    -   Default values are *not* merged-from.\n    -   To ‚Äúclear‚Äù a field, it is set to its default value.\n    -   The default value may mean:\n        -   the field was explicitly set to its default value, which is valid in the application-specific domain of values;\n        -   the field was notionally ‚Äúcleared‚Äù by setting its default; or\n        -   the field was never set.\n    -   `has_` methods are not generated (but see note after this list)\n-   *Explicit presence* discipline:\n    -   Explicitly set values are always serialized, including default values.\n    -   Un-set fields are never merged-from.\n    -   Explicitly set fields ‚Äì including default values ‚Äì *are* merged-from.\n    -   A generated `has_foo` method indicates whether or not the field `foo` has been set (and not cleared).\n    -   A generated `clear_foo` method must be used to clear (i.e., un-set) the value.\n\n#### Note\n\n`Has_` methods are not generated for implicit members in most cases. The exception to this behavior is Dart, which generates `has_` methods with proto3 proto schema files.\n\n### Considerations for Merging\n\nUnder the *implicit presence* rules, it is effectively impossible for a target field to merge-from its default value (using the protobuf‚Äôs API merging functions). This is because default values are skipped, similar to the *implicit presence* serialization discipline. Merging only updates the target (merged-to) message using the non-skipped values from the update (merged-from) message.\n\nThe difference in merging behavior has further implications for protocols which rely on partial ‚Äúpatch‚Äù updates. If field presence is not tracked, then an update patch alone cannot represent an update to the default value, because only non-default values are merged-from.\n\nUpdating to set a default value in this case requires some external mechanism, such as `FieldMask`. However, if presence *is* tracked, then all explicitly-set values ‚Äì even default values ‚Äì will be merged into the target.\n\n### Considerations for change-compatibility\n\nChanging a field between *explicit presence* and *implicit presence* is a binary-compatible change for serialized values in wire format. However, the serialized representation of the message may differ, depending on which version of the message definition was used for serialization. Specifically, when a ‚Äúsender‚Äù explicitly sets a field to its default value:\n\n-   The serialized value following *implicit presence* discipline does not contain the default value, even though it was explicitly set.\n-   The serialized value following *explicit presence* discipline contains every ‚Äúpresent‚Äù field, even if it contains the default value.\n\nThis change may or may not be safe, depending on the application‚Äôs semantics. For example, consider two clients with different versions of a message definition.\n\nClient A uses this definition of the message, which follows the *explicit presence* serialization discipline for field `foo`:\n\n```protobuf\nsyntax = \"proto3\";\nmessage Msg {\n  optional int32 foo = 1;\n}\n```\n\nClient B uses a definition of the same message, except that it follows the *no presence* discipline:\n\n```protobuf\nsyntax = \"proto3\";\nmessage Msg {\n  int32 foo = 1;\n}\n```\n\nNow, consider a scenario where client A observes `foo`‚Äôs presence as the clients repeatedly exchange the ‚Äúsame‚Äù message by deserializing and reserializing:\n\n```protobuf\n// Client A:\nMsg m_a;\nm_a.set_foo(1);                  // non-default value\nassert(m_a.has_foo());           // OK\nSend(m_a.SerializeAsString());   // to client B\n\n// Client B:\nMsg m_b;\nm_b.ParseFromString(Receive());  // from client A\nassert(m_b.foo() == 1);          // OK\nSend(m_b.SerializeAsString());   // to client A\n\n// Client A:\nm_a.ParseFromString(Receive());  // from client B\nassert(m_a.foo() == 1);          // OK\nassert(m_a.has_foo());           // OK\nm_a.set_foo(0);                  // default value\nSend(m_a.SerializeAsString());   // to client B\n\n// Client B:\nMsg m_b;\nm_b.ParseFromString(Receive());  // from client A\nassert(m_b.foo() == 0);          // OK\nSend(m_b.SerializeAsString());   // to client A\n\n// Client A:\nm_a.ParseFromString(Receive());  // from client B\nassert(m_a.foo() == 0);          // OK\nassert(m_a.has_foo());           // FAIL\n```\n\nIf client A depends on *explicit presence* for `foo`, then a ‚Äúround trip‚Äù through client B will be lossy from the perspective of client A. In the example, this is not a safe change: client A requires (by `assert`) that the field is present; even without any modifications through the API, that requirement fails in a value- and peer-dependent case.\n\n## How to Enable *Explicit Presence* in Proto3\n\nThese are the general steps to use field tracking support for proto3:\n\n1.  Add an `optional` field to a `.proto` file.\n2.  Run `protoc` (at least v3.15, or v3.12 using `--experimental_allow_proto3_optional` flag).\n3.  Use the generated ‚Äúhazzer‚Äù methods and ‚Äúclear‚Äù methods in application code, instead of comparing or setting default values.\n\n### `.proto` File Changes\n\nThis is an example of a proto3 message with fields which follow both *no presence* and *explicit presence* semantics:\n\n```protobuf\nsyntax = \"proto3\";\npackage example;\n\nmessage MyMessage {\n  // implicit presence:\n  int32 not_tracked = 1;\n\n  // Explicit presence:\n  optional int32 tracked = 2;\n}\n```\n\n### `protoc` Invocation\n\nPresence tracking for proto3 messages is enabled by default [since v3.15.0](https://github.com/protocolbuffers/protobuf/releases/tag/v3.15.0) release, formerly up until [v3.12.0](https://github.com/protocolbuffers/protobuf/releases/tag/v3.12.0) the `--experimental_allow_proto3_optional` flag was required when using presence tracking with protoc.\n\n### Using the Generated Code\n\nThe generated code for proto3 fields with *explicit presence* (the `optional` label) will be the same as it would be in a proto2 file.\n\nThis is the definition used in the ‚Äúimplicit presence‚Äù examples below:\n\n```protobuf\nsyntax = \"proto3\";\npackage example;\nmessage Msg {\n  int32 foo = 1;\n}\n```\n\nThis is the definition used in the ‚Äúexplicit presence‚Äù examples below:\n\n```protobuf\nsyntax = \"proto3\";\npackage example;\nmessage Msg {\n  optional int32 foo = 1;\n}\n```\n\nIn the examples, a function `GetProto` constructs and returns a message of type `Msg` with unspecified contents.\n\n#### C++ Example\n\nImplicit presence:\n\n```cpp\nMsg m = GetProto();\nif (m.foo() != 0) {\n  // \"Clear\" the field:\n  m.set_foo(0);\n} else {\n  // Default value: field may not have been present.\n  m.set_foo(1);\n}\n```\n\nExplicit presence:\n\n```c++\nMsg m = GetProto();\nif (m.has_foo()) {\n  // Clear the field:\n  m.clear_foo();\n} else {\n  // Field is not present, so set it.\n  m.set_foo(1);\n}\n```\n\n#### C# Example\n\nImplicit presence:\n\n```c#\nvar m = GetProto();\nif (m.Foo != 0) {\n  // \"Clear\" the field:\n  m.Foo = 0;\n} else {\n  // Default value: field may not have been present.\n  m.Foo = 1;\n}\n```\n\nExplicit presence:\n\n```c#\nvar m = GetProto();\nif (m.HasFoo) {\n  // Clear the field:\n  m.ClearFoo();\n} else {\n  // Field is not present, so set it.\n  m.Foo = 1;\n}\n```\n\n#### Go Example\n\nImplicit presence:\n\n```go\nm := GetProto()\nif m.Foo != 0 {\n  // \"Clear\" the field:\n  m.Foo = 0\n} else {\n  // Default value: field may not have been present.\n  m.Foo = 1\n}\n```\n\nExplicit presence:\n\n```go\nm := GetProto()\nif m.Foo != nil {\n  // Clear the field:\n  m.Foo = nil\n} else {\n  // Field is not present, so set it.\n  m.Foo = proto.Int32(1)\n}\n```\n\n#### Java Example\n\nThese examples use a `Builder` to demonstrate clearing. Simply checking presence and getting values from a `Builder` follows the same API as the message type.\n\nImplicit presence:\n\n```java\nMsg.Builder m = GetProto().toBuilder();\nif (m.getFoo() != 0) {\n  // \"Clear\" the field:\n  m.setFoo(0);\n} else {\n  // Default value: field may not have been present.\n  m.setFoo(1);\n}\n```\n\nExplicit presence:\n\n```java\nMsg.Builder m = GetProto().toBuilder();\nif (m.hasFoo()) {\n  // Clear the field:\n  m.clearFoo()\n} else {\n  // Field is not present, so set it.\n  m.setFoo(1);\n}\n```\n\n#### Python Example\n\nImplicit presence:\n\n```python\nm = example.Msg()\nif m.foo != 0:\n  # \"Clear\" the field:\n  m.foo = 0\nelse:\n  # Default value: field may not have been present.\n  m.foo = 1\n```\n\nExplicit presence:\n\n```python\nm = example.Msg()\nif m.HasField('foo'):\n  # Clear the field:\n  m.ClearField('foo')\nelse:\n  # Field is not present, so set it.\n  m.foo = 1\n```\n\n#### Ruby Example\n\nImplicit presence:\n\n```ruby\nm = Msg.new\nif m.foo != 0\n  # \"Clear\" the field:\n  m.foo = 0\nelse\n  # Default value: field may not have been present.\n  m.foo = 1\nend\n```\n\nExplicit presence:\n\n```ruby\nm = Msg.new\nif m.has_foo?\n  # Clear the field:\n  m.clear_foo\nelse\n  # Field is not present, so set it.\n  m.foo = 1\nend\n```\n\n#### Javascript Example\n\nImplicit presence:\n\n```js\nvar m = new Msg();\nif (m.getFoo() != 0) {\n  // \"Clear\" the field:\n  m.setFoo(0);\n} else {\n  // Default value: field may not have been present.\n  m.setFoo(1);\n}\n```\n\nExplicit presence:\n\n```js\nvar m = new Msg();\nif (m.hasFoo()) {\n  // Clear the field:\n  m.clearFoo()\n} else {\n  // Field is not present, so set it.\n  m.setFoo(1);\n}\n```\n\n#### Objective-C Example\n\nImplicit presence:\n\n```objective-c\nMsg *m = [Msg message];\nif (m.foo != 0) {\n  // \"Clear\" the field:\n  m.foo = 0;\n} else {\n  // Default value: field may not have been present.\n  m.foo = 1;\n}\n```\n\nExplicit presence:\n\n```objective-c\nMsg *m = [Msg message];\nif ([m hasFoo]) {\n  // Clear the field:\n  [m clearFoo];\n} else {\n  // Field is not present, so set it.\n  m.foo = 1;\n}\n```\n\n## Cheat sheet\n\n**Proto2:**\n\nIs field presence tracked?\n\nField type\n\nTracked?\n\nSingular field\n\nyes\n\nSingular message field\n\nyes\n\nField in a oneof\n\nyes\n\nRepeated field & map\n\nno\n\n**Proto3:**\n\nIs field presence tracked?\n\nField type\n\nTracked?\n\n*Other* singular field\n\nif defined as `optional`\n\nSingular message field\n\nyes\n\nField in a oneof\n\nyes\n\nRepeated field & map\n\nno\n\n**Edition 2023:**\n\nIs field presence tracked?\n\nField type (in descending prescendence)\n\nTracked?\n\nRepeated field & map\n\nno\n\nMessage and Oneof fields\n\nyes\n\nOther singular fields if `features.field_presence` set to `IMPLICIT`\n\nno\n\nAll other fields\n\nyes\n\n-   [](https://stackoverflow.com/questions/tagged/protocol-buffers)\n\n-   [](https://github.com/protocolbuffers/protobuf)\n-   [](https://groups.google.com/g/protobuf)\n\n¬© 2026 Google LLC All Rights Reserved [Privacy Policy](https://policies.google.com/privacy) Hosted by GitHub Pages. [GitHub Privacy Statement](https://docs.github.com/en/site-policy/privacy-policies/github-privacy-statement)",
            "title": "https://protobuf.dev/programming-guides/field_presence/ (text/html; charset=utf-8)",
            "metadata": {
              "truncated": false
            },
            "time": {
              "start": 1771212982874,
              "end": 1771212983275,
              "compacted": 1771213545697
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_01e5c65264d6e81601699290b6cad88194adc976ca65a79b91"
            }
          },
          "id": "prt_c64854a5900113MXAN6KpuuWGr",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648519a3001dVkoAXMkiGYiY8"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "b7933c744ec3328102c609519b642416c9b21d45",
          "cost": 0,
          "tokens": {
            "total": 32819,
            "input": 274,
            "output": 545,
            "reasoning": 436,
            "cache": {
              "read": 32000,
              "write": 0
            }
          },
          "id": "prt_c64854c55001SUPAuBIZSOmTGE",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648519a3001dVkoAXMkiGYiY8"
        },
        {
          "type": "patch",
          "hash": "9d6f15c7b06acb730f3f74807178e28dcff70941",
          "files": [
            "/Users/alex/repos/vfp/dark-factory/docs/designs/core_gen1.design.md"
          ],
          "id": "prt_c64854c85001MkNqz01yihG4U7",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648519a3001dVkoAXMkiGYiY8"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771212983434,
          "completed": 1771212989573
        },
        "parentID": "msg_c6484620d0011ltzji40BSbVp5",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 64813,
          "input": 64651,
          "output": 162,
          "reasoning": 45,
          "cache": {
            "read": 0,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "tool-calls",
        "id": "msg_c64854c8a001CSr0mCizL3kOBi",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "b7933c744ec3328102c609519b642416c9b21d45",
          "id": "prt_c64855506001WiKRREaXfaF2PH",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64854c8a001CSr0mCizL3kOBi"
        },
        {
          "type": "reasoning",
          "text": "**Locating Rust Protobuf Build Docs**",
          "metadata": {
            "openai": {
              "itemId": "rs_04f5ae31ff41b23901699290baedd88193805d373a9bb986a8",
              "reasoningEncryptedContent": "gAAAAABpkpC9fBSW884LPj1Nzmdk2ZHS4ODeaVlVA1SaMlYA0PQk7jrEMIhWEHsisnMkIDMDwThmx2Cz-mIXIN0Y2_JA-UhcSnQksqS_vXTSJGSzBe_N7DBwCuIPratSrmgt7KLu-EUTt6QrN3WovvUmp5F0vvZBtYqDWOkYpCmx14nT-wqCb6X_NiB-k5m165566WVcqvdMTTG8Di7AoNFHmdrgVuLZreprlJLKN4B4i5B-Ad70ExywuaqAMPFOxW-9f3V-dfXy9JnkRC9mk70PiiogRyqkh6Svc-ftwDfjCnV09V7_7iwGw_QpT7NKUNpXFdHR05mAIJSk5P6R5whk5RijzAIYR8vLDUMykHvEqm6aRih1n-isIlJND_iIEc5tGuNGQtc9sOVXjNyE-hpak1ErbwukzQYP0nAGa4YNPdrgavtw1zAtKfwwEktFGuoTDnBMa8GIjsJl9Ob-0zP_yR2_lvA_DHcLJqduZRZqyxI58dBFdC_I7z6W9JPB4WRWkthfJ1RbiqiZkA624yIx4c09WuYVNqu_FEg0ltqFeehcHFSB7xbfXuXUKGwMEtc3cQI4nTXX4y2wDlcz5xu4c5vUZVXGPTsTzB8f7adNZM-mqp_3KrSD-ofp2ux9yoH_kB_n986ceBaPseSGjDD-x-K7wqKCEvxPbEJEvDZQIiU3Rj3g-9o1p_zHBWEqDY0FY3ZpEtuMr5lSMOsvdlkYo44sndMWQKfmAQ4LsApomMvDV_-8mbuwU4YdpmyWN7VXIrlEn_jngj9awF7MT7GjFIfvvd4EpoDk4eFIu0ys4jWqf7WJ_GGAhyLcenrxx3eY5fo_fGNAeIwZNrUDTDUYEKnwHi7I8WxbMH7zIqcvKt2KCwPcoIDMCv9LSHlDrOfqNf5h8ZEvUL80yACC4i3GqGFi8Ea5-Tq5gADULhM4zv9LtN6QMwklj9J3o_-uKlRcrrkVgkxbuV8XnoPcuGPC4N88MrjwaOT3_stooMSCCH_8_UsINEstvt9bXqkHXXhHq_jsFvLvzcOozeHIcCQGaJ-xlhat9iQcsN8866_xCYS59nH-Gm4EKPemBTb0ewCSXGTxkgFT"
            }
          },
          "time": {
            "start": 1771212986969,
            "end": 1771212989193
          },
          "id": "prt_c64855a590013q0W28TI3WgyPv",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64854c8a001CSr0mCizL3kOBi"
        },
        {
          "type": "tool",
          "callID": "call_Q5ESBfKTkLjkt3manwQeuTZh",
          "tool": "webfetch",
          "state": {
            "status": "completed",
            "input": {
              "url": "https://protobuf.dev/reference/rust/building-rust-protos/",
              "format": "markdown"
            },
            "output": "Building Rust Protos | Protocol Buffers Documentation \n\n[Protocol Buffers Documentation](/)\n\n-   [Protocol Buffers](/)\n    -   [Overview](/overview/)\n    -   [Protoc Installation](/installation/ \"Protocol Buffer Compiler Installation\")\n    -   [News](/news/)\n    -   [Programming Guides](/programming-guides/)\n        -   [Language Guide (editions)](/programming-guides/editions/)\n        -   [Language Guide (proto 2)](/programming-guides/proto2/)\n        -   [Language Guide (proto 3)](/programming-guides/proto3/)\n        -   [Proto Limits](/programming-guides/proto-limits/)\n        -   [Style Guide](/programming-guides/style/)\n        -   [Enum Behavior](/programming-guides/enum/)\n        -   [Encoding](/programming-guides/encoding/)\n        -   [ProtoJSON Format](/programming-guides/json/)\n        -   [Techniques](/programming-guides/techniques/)\n        -   [Add-ons](/programming-guides/addons/ \"Third-Party Add-ons\")\n        -   [Extension Declarations](/programming-guides/extension_declarations/)\n        -   [Field Presence](/programming-guides/field_presence/ \"Application Note: Field Presence\")\n        -   [Proto Serialization Is Not Canonical](/programming-guides/serialization-not-canonical/)\n        -   [Deserializing Debug Proto Representations](/programming-guides/deserialize-debug/)\n    -   [Protobuf Editions](/editions/)\n        -   [Overview](/editions/overview/ \"Protobuf Editions Overview\")\n        -   [Feature Settings for Editions](/editions/features/)\n        -   [Implementing Editions Support](/editions/implementation/)\n    -   [Design Decisions](/design-decisions/ \"Protobuf Team Design Decisions\")\n        -   [No Nullable Setters/Getters Support](/design-decisions/nullable-getters-setters/)\n    -   [Proto Best Practices](/best-practices/)\n        -   [Avoid Cargo Culting](/best-practices/no-cargo-cults/)\n        -   [Proto Best Practices](/best-practices/dos-donts/)\n        -   [1-1-1 Best Practice](/best-practices/1-1-1/)\n    -   [Tutorials](/getting-started/)\n        -   [C++](/getting-started/cpptutorial/ \"Protocol Buffer Basics: C++\")\n        -   [C#](/getting-started/csharptutorial/ \"Protocol Buffer Basics: C#\")\n        -   [Dart](/getting-started/darttutorial/ \"Protocol Buffer Basics: Dart\")\n        -   [Go](/getting-started/gotutorial/ \"Protocol Buffer Basics: Go\")\n        -   [Java](/getting-started/javatutorial/ \"Protocol Buffer Basics: Java\")\n        -   [Kotlin](/getting-started/kotlintutorial/ \"Protocol Buffer Basics: Kotlin\")\n        -   [Python](/getting-started/pythontutorial/ \"Protocol Buffer Basics: Python\")\n    -   [Reference Guides](/reference/)\n        -   [C++](/reference/cpp/ \"C++ Reference\")\n            -   [Generated Code Guide](/reference/cpp/cpp-generated/ \"C++ Generated Code Guide\")\n            -   [String View APIs](/reference/cpp/string-view/)\n            -   [Arena Allocation Guide](/reference/cpp/arenas/ \"C++ Arena Allocation Guide\")\n            -   [Abseil Support](/reference/cpp/abseil/)\n            -   [C++ API](/reference/cpp/api-docs/)\n        -   [C#](/reference/csharp/ \"C# Reference\")\n            -   [Generated Code Guide](/reference/csharp/csharp-generated/ \"C# Generated Code Guide\")\n            -   [C# API](/reference/csharp/api-docs)\n        -   [Dart](/reference/dart/ \"Dart Reference\")\n            -   [Generated Code](/reference/dart/dart-generated/ \"Dart Generated Code\")\n            -   [Dart API](https://pub.dartlang.org/documentation/protobuf)\n        -   [Go](/reference/go/ \"Go Reference\")\n            -   [Generated Code Guide (Open)](/reference/go/go-generated/ \"Go Generated Code Guide (Open)\")\n            -   [Generated Code Guide (Opaque)](/reference/go/go-generated-opaque/ \"Go Generated Code Guide (Opaque)\")\n            -   [FAQ](/reference/go/faq/ \"Go FAQ\")\n            -   [Size Semantics](/reference/go/size/ \"Go Size Semantics\")\n            -   [Go API](https://pkg.go.dev/google.golang.org/protobuf/proto)\n            -   [Opaque API Migration](/reference/go/opaque-migration/ \"Go Opaque API Migration\")\n            -   [Opaque API: Manual Migration](/reference/go/opaque-migration-manual/ \"Go Opaque API: Manual Migration\")\n            -   [Opaque API FAQ](/reference/go/opaque-faq/ \"Go Opaque API FAQ\")\n        -   [Java](/reference/java/ \"Java Reference\")\n            -   [Generated Code Guide](/reference/java/java-generated/ \"Java Generated Code Guide\")\n            -   [Generated Proto Names](/reference/java/java-proto-names/ \"Java Proto Names\")\n            -   [Java API](/reference/java/api-docs/overview-summary.html)\n        -   [Kotlin](/reference/kotlin/ \"Kotlin Reference\")\n            -   [Kotlin](/reference/kotlin/api-docs/ \"Kotlin Reference\")\n            -   [Generated Code Guide](/reference/kotlin/kotlin-generated/ \"Kotlin Generated Code Guide\")\n        -   [Objective-C](/reference/objective-c/ \"Objective-C Reference\")\n            -   [Generated Code Guide](/reference/objective-c/objective-c-generated/ \"Objective-C Generated Code Guide\")\n        -   [PHP](/reference/php/ \"PHP Reference\")\n            -   [Generated Code Guide](/reference/php/php-generated/ \"PHP Generated Code Guide\")\n            -   [PHP API](/reference/php/api-docs/)\n        -   [Python](/reference/python/ \"Python Reference\")\n            -   [Generated Code Guide](/reference/python/python-generated/ \"Python Generated Code Guide\")\n            -   [Python Comparison](/reference/python/python-comparison/)\n            -   [Python API](https://googleapis.dev/python/protobuf/latest/)\n        -   [Ruby](/reference/ruby/ \"Ruby Reference\")\n            -   [Generated Code Guide](/reference/ruby/ruby-generated/ \"Ruby Generated Code Guide\")\n        -   [Rust](/reference/rust/ \"Rust Reference\")\n            -   [Generated Code Guide](/reference/rust/rust-generated/ \"Rust Generated Code Guide\")\n            -   [Redaction in Rust](/reference/rust/rust-redaction/)\n            -   [Building Rust Protos](/reference/rust/building-rust-protos/)\n            -   [Design Decisions](/reference/rust/rust-design-decisions/ \"Rust Proto Design Decisions\")\n        -   [Protocol Buffers](/reference/protobuf/ \"Protocol Buffers Reference\")\n            -   [2023 Language Specification](/reference/protobuf/edition-2023-spec/ \"Protocol Buffers Edition 2023 Language Specification\")\n            -   [Language Specification (Proto2 Syntax)](/reference/protobuf/proto2-spec/ \"Protocol Buffers Language Specification (Proto2 Syntax)\")\n            -   [2024 Language Specification](/reference/protobuf/edition-2024-spec/ \"Protocol Buffers Edition 2024 Language Specification\")\n            -   [Language Specification (Proto3)](/reference/protobuf/proto3-spec/ \"Protocol Buffers Language Specification (Proto3)\")\n            -   [Text Format Language Specification](/reference/protobuf/textformat-spec/)\n            -   [MIME Types](/reference/protobuf/mime-types/ \"Protocol Buffer MIME Types\")\n            -   [Well-Known Types](/reference/protobuf/google.protobuf/ \"Protocol Buffers Well-Known Types\")\n        -   [Other Languages](/reference/other/)\n    -   [Support](/support/)\n        -   [Version Support](/support/version-support/)\n        -   [Debugging](/support/debugging-playbook/)\n        -   [Migration Guide](/support/migration/)\n        -   [Cross-Version Runtime Guarantee](/support/cross-version-runtime-guarantee/)\n    -   [Downloads](/downloads/)\n    -   [History](/history/)\n    -   [Forum](https://groups.google.com/g/protobuf)\n    -   [](/navbar/)\n    -   [Search Results](/search/)\n\n[View page source](https://github.com/protocolbuffers/protocolbuffers.github.io/tree/main/content/reference/rust/building-rust-protos.md) [Edit this page](https://github.com/protocolbuffers/protocolbuffers.github.io/edit/main/content/reference/rust/building-rust-protos.md) [Create child page](https://github.com/protocolbuffers/protocolbuffers.github.io/new/main/content/reference/rust/building-rust-protos.md?filename=change-me.md&value=---%0Atitle%3A+%22Long+Page+Title%22%0AlinkTitle%3A+%22Short+Nav+Title%22%0Aweight%3A+100%0Adescription%3A+%3E-%0A+++++Page+description+for+heading+and+indexes.%0A---%0A%0A%23%23+Heading%0A%0AEdit+this+template+to+create+your+new+page.%0A%0A%2A+Give+it+a+good+name%2C+ending+in+%60.md%60+-+e.g.+%60getting-started.md%60%0A%2A+Edit+the+%22front+matter%22+section+at+the+top+of+the+page+%28weight+controls+how+its+ordered+amongst+other+pages+in+the+same+directory%3B+lowest+number+first%29.%0A%2A+Add+a+good+commit+message+at+the+bottom+of+the+page+%28%3C80+characters%3B+use+the+extended+description+field+for+more+detail%29.%0A%2A+Create+a+new+branch+so+you+can+preview+your+new+file+and+request+a+review+via+Pull+Request.%0A) [Create documentation issue](https://github.com/protocolbuffers/protocolbuffers.github.io/issues/new?title=Building%20Rust%20Protos) [Create project issue](https://github.com/protocolbuffers/protobuf/issues/new)\n\n-   [Cargo](#cargo)\n-   [Bazel](#bazel)\n\n1.  [Reference Guides](/reference/)\n2.  [Rust](/reference/rust/)\n3.  Building Rust Protos\n\n# Building Rust Protos\n\nDescribes how to build Rust protos using Cargo or Bazel.\n\n## Cargo\n\nSee the [protobuf-example](https://docs.rs/crate/protobuf-example/latest/source/) crate for an example of how to set up your build.\n\n## Bazel\n\nThe process of building a Rust library for a Protobuf definition is similar to other programming languages:\n\n1.  Use the language-agnostic `proto_library` rule:\n    \n    ```fallback\n    proto_library(\n        name = \"person_proto\",\n        srcs = [\"person.proto\"],\n    )\n    ```\n    \n2.  Create a Rust library:\n    \n    ```gdscript3\n    load(\"//third_party/protobuf/rust:defs.bzl\", \"rust_proto_library\")\n    \n    proto_library(\n        name = \"person_proto\",\n        srcs = [\"person.proto\"],\n    )\n    \n    rust_proto_library(\n        name = \"person_rust_proto\",\n        deps = [\":person_proto\"],\n    )\n    ```\n    \n3.  Use the library by including it in a Rust binary:\n    \n    ```gdscript3\n    load(\"//third_party/bazel_rules/rules_rust/rust:defs.bzl\", \"rust_binary\")\n    load(\"//third_party/protobuf/rust:defs.bzl\", \"rust_proto_library\")\n    \n    proto_library(\n        name = \"person_proto\",\n        srcs = [\"person.proto\"],\n    )\n    \n    rust_proto_library(\n        name = \"person_rust_proto\",\n        deps = [\":person_proto\"],\n    )\n    \n    rust_binary(\n        name = \"greet\",\n        srcs = [\"greet.rs\"],\n        deps = [\n            \":person_rust_proto\",\n        ],\n    )\n    ```\n    \n\n#### Note\n\nDon‚Äôt use `rust_upb_proto_library` or `rust_cc_proto_library` directly. `rust_proto_library` checks the global build flag to choose the appropriate backend for you.\n\n-   [](https://stackoverflow.com/questions/tagged/protocol-buffers)\n\n-   [](https://github.com/protocolbuffers/protobuf)\n-   [](https://groups.google.com/g/protobuf)\n\n¬© 2026 Google LLC All Rights Reserved [Privacy Policy](https://policies.google.com/privacy) Hosted by GitHub Pages. [GitHub Privacy Statement](https://docs.github.com/en/site-policy/privacy-policies/github-privacy-statement)",
            "title": "https://protobuf.dev/reference/rust/building-rust-protos/ (text/html; charset=utf-8)",
            "metadata": {
              "truncated": false
            },
            "time": {
              "start": 1771212989216,
              "end": 1771212989367,
              "compacted": 1771213545696
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_04f5ae31ff41b23901699290bd26848193a0abd796d82075f3"
            }
          },
          "id": "prt_c6485630c001xMe2vt736OLkvU",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64854c8a001CSr0mCizL3kOBi"
        },
        {
          "type": "tool",
          "callID": "call_LOz6lUQUCvL3h6d0WUgzNqez",
          "tool": "webfetch",
          "state": {
            "status": "completed",
            "input": {
              "url": "https://docs.rs/prost-build/latest/prost_build/",
              "format": "markdown"
            },
            "output": "prost\\_build - Rust\n\n  \n\n[Docs.rs](/)\n\n-   [prost-build-0.14.3](# \"Generate Prost annotated Rust types from Protocol Buffers files.\")\n    \n    -   prost-build 0.14.3\n    -   [Permalink](/prost-build/0.14.3/prost_build/ \"Get a link to this specific version\")\n    -   [Docs.rs crate page](/crate/prost-build/latest \"See prost-build in docs.rs\")\n    -   [Apache-2.0](https://spdx.org/licenses/Apache-2.0)\n    \n    -   Links\n    -   [Repository](https://github.com/tokio-rs/prost)\n    -   [crates.io](https://crates.io/crates/prost-build \"See prost-build in crates.io\")\n    -   [Source](/crate/prost-build/latest/source/ \"Browse source of prost-build-0.14.3\")\n    \n    -   Owners\n    -   [danburkert](https://crates.io/users/danburkert)\n    -   [github:tokio-rs:prost-core](https://crates.io/teams/github:tokio-rs:prost-core)\n    \n    -   Dependencies\n    -   -   [heck >=0.4, <=0.5 *normal*](/heck/%3E=0.4,%20%3C=0.5/)\n        -   [itertools >=0.10, <=0.14 *normal*](/itertools/%3E=0.10,%20%3C=0.14/)\n        -   [log ^0.4.4 *normal*](/log/^0.4.4/)\n        -   [multimap >=0.8, <=0.10 *normal*](/multimap/%3E=0.8,%20%3C=0.10/)\n        -   [petgraph ^0.8 *normal*](/petgraph/^0.8/)\n        -   [prettyplease ^0.2 *normal* *optional*](/prettyplease/^0.2/)\n        -   [prost ^0.14.3 *normal*](/prost/^0.14.3/)\n        -   [prost-types ^0.14.3 *normal*](/prost-types/^0.14.3/)\n        -   [pulldown-cmark ^0.13 *normal* *optional*](/pulldown-cmark/^0.13/)\n        -   [pulldown-cmark-to-cmark ^22 *normal* *optional*](/pulldown-cmark-to-cmark/^22/)\n        -   [regex ^1.8.1 *normal*](/regex/^1.8.1/)\n        -   [syn ^2 *normal* *optional*](/syn/^2/)\n        -   [tempfile ^3 *normal*](/tempfile/^3/)\n        -   [env\\_logger ^0.11 *dev*](/env_logger/^0.11/)\n        \n    \n    -   Versions\n    \n    -   [**97.06%** of the crate is documented](/crate/prost-build/latest)\n    \n-   [Platform](#)\n    -   [aarch64-apple-darwin](/crate/prost-build/latest/target-redirect/aarch64-apple-darwin/prost_build/)\n    -   [aarch64-unknown-linux-gnu](/crate/prost-build/latest/target-redirect/aarch64-unknown-linux-gnu/prost_build/)\n    -   [i686-pc-windows-msvc](/crate/prost-build/latest/target-redirect/i686-pc-windows-msvc/prost_build/)\n    -   [x86\\_64-pc-windows-msvc](/crate/prost-build/latest/target-redirect/x86_64-pc-windows-msvc/prost_build/)\n    -   [x86\\_64-unknown-linux-gnu](/crate/prost-build/latest/target-redirect/prost_build/)\n-   [Feature flags](/crate/prost-build/latest/features \"Browse available feature flags of prost-build-0.14.3\")\n\n-   [docs.rs](#)\n    -   [About docs.rs](/about)\n    -   [Badges](/about/badges)\n    -   [Builds](/about/builds)\n    -   [Metadata](/about/metadata)\n    -   [Shorthand URLs](/about/redirections)\n    -   [Download](/about/download)\n    -   [Rustdoc JSON](/about/rustdoc-json)\n    -   [Build queue](/releases/queue)\n    -   [Privacy policy](https://foundation.rust-lang.org/policies/privacy-policy/#docs.rs)\n\n-   [Rust](#)\n    -   [Rust website](https://www.rust-lang.org/)\n    -   [The Book](https://doc.rust-lang.org/book/)\n    -   [Standard Library API Reference](https://doc.rust-lang.org/std/)\n    -   [Rust by Example](https://doc.rust-lang.org/rust-by-example/)\n    -   [The Cargo Guide](https://doc.rust-lang.org/cargo/guide/)\n    -   [Clippy Documentation](https://doc.rust-lang.org/nightly/clippy)\n\n## [Crate prost\\_build](#)\n\n## [prost\\_build](../prost_build/index.html)0.14.3\n\n-   [All Items](all.html)\n\n### [Sections](#)\n\n-   [Example](#example \"Example\")\n-   [Feature Flags](#feature-flags \"Feature Flags\")\n    -   [Cleaning up Markdown in code docs](#cleaning-up-markdown-in-code-docs \"Cleaning up Markdown in code docs\")\n-   [Sourcing `protoc`](#sourcing-protoc \"Sourcing `protoc`\")\n    -   [Compiling `protoc` from source](#compiling-protoc-from-source \"Compiling `protoc` from source\")\n\n### [Crate Items](#structs)\n\n-   [Structs](#structs \"Structs\")\n-   [Traits](#traits \"Traits\")\n-   [Functions](#functions \"Functions\")\n\n# Crate prost\\_build¬†Copy item path\n\n[Source](../src/prost_build/lib.rs.html#1-628)\n\nExpand description\n\n`prost-build` compiles `.proto` files into Rust.\n\n`prost-build` is designed to be used for build-time code generation as part of a Cargo build-script.\n\n### [¬ß](#example)Example\n\nLet‚Äôs create a small library crate, `snazzy`, that defines a collection of snazzy new items in a protobuf file.\n\n```\n$ cargo new --lib snazzy && cd snazzy\n```\n\nFirst, add `prost-build` and `prost` as dependencies to `Cargo.toml`:\n\n```\n$ cargo add --build prost-build\n$ cargo add prost\n```\n\nNext, add `src/items.proto` to the project:\n\n```\nsyntax = \"proto3\";\n\npackage snazzy.items;\n\n// A snazzy new shirt!\nmessage Shirt {\n    // Label sizes\n    enum Size {\n        SMALL = 0;\n        MEDIUM = 1;\n        LARGE = 2;\n    }\n\n    // The base color\n    string color = 1;\n    // The size as stated on the label\n    Size size = 2;\n}\n```\n\nTo generate Rust code from `items.proto`, we use `prost-build` in the crate‚Äôs `build.rs` build-script:\n\n```\nuse std::io::Result;\nfn main() -> Result<()> {\n    prost_build::compile_protos(&[\"src/items.proto\"], &[\"src/\"])?;\n    Ok(())\n}\n```\n\nAnd finally, in `lib.rs`, include the generated code:\n\n[‚ìò](# \"This example is not tested\")\n\n```\n// Include the `items` module, which is generated from items.proto.\n// It is important to maintain the same structure as in the proto.\npub mod snazzy {\n    pub mod items {\n        include!(concat!(env!(\"OUT_DIR\"), \"/snazzy.items.rs\"));\n    }\n}\n\nuse snazzy::items;\n\n/// Returns a large shirt of the specified color\npub fn create_large_shirt(color: String) -> items::Shirt {\n    let mut shirt = items::Shirt::default();\n    shirt.color = color;\n    shirt.set_size(items::shirt::Size::Large);\n    shirt\n}\n```\n\nThat‚Äôs it! Run `cargo doc` to see documentation for the generated code. The full example project can be found on [GitHub](https://github.com/danburkert/snazzy).\n\n### [¬ß](#feature-flags)Feature Flags\n\n-   `format`: Format the generated output. This feature is enabled by default.\n-   `cleanup-markdown`: Clean up Markdown in protobuf docs. Enable this to clean up protobuf files from third parties.\n\n#### [¬ß](#cleaning-up-markdown-in-code-docs)Cleaning up Markdown in code docs\n\nIf you are using protobuf files from third parties, where the author of the protobuf is not treating comments as Markdown, or is, but has codeblocks in their docs, then you may need to clean up the documentation in order that `cargo test --doc` will not fail spuriously, and that `cargo doc` doesn‚Äôt attempt to render the codeblocks as Rust code.\n\nTo do this, in your `Cargo.toml`, add `features = [\"cleanup-markdown\"]` to the inclusion of the `prost-build` crate and when your code is generated, the code docs will automatically be cleaned up a bit.\n\n### [¬ß](#sourcing-protoc)Sourcing `protoc`\n\n`prost-build` depends on the Protocol Buffers compiler, `protoc`, to parse `.proto` files into a representation that can be transformed into Rust.\n\nThe easiest way for `prost-build` to find `protoc` is to install it in your `PATH`. This can be done by following the [`protoc` install instructions](https://github.com/protocolbuffers/protobuf#protocol-compiler-installation). `prost-build` will search the current path for `protoc` or `protoc.exe`.\n\nWhen `protoc` is installed in a different location, set `PROTOC` to the path of the executable. If set, `prost-build` uses the `PROTOC` for locating `protoc`. For example, on a macOS system where Protobuf is installed with Homebrew, set the environment variables to:\n\n```\nPROTOC=/usr/local/bin/protoc\n```\n\nAlternatively, the path to `protoc` executable can be explicitly set via [`Config::protoc_executable()`](struct.Config.html#method.protoc_executable \"method prost_build::Config::protoc_executable\").\n\nIf `prost-build` can not find `protoc` via these methods the `compile_protos` method will fail.\n\n#### [¬ß](#compiling-protoc-from-source)Compiling `protoc` from source\n\nTo compile `protoc` from source you can use the `protobuf-src` crate and set the correct environment variables.\n\n[‚ìò](# \"This example is not tested\")\n\n```\nstd::env::set_var(\"PROTOC\", protobuf_src::protoc());\n\n// Now compile your proto files via prost-build\n```\n\n## Structs[¬ß](#structs)\n\n[Comments](struct.Comments.html \"struct prost_build::Comments\")\n\nComments on a Protobuf item.\n\n[Config](struct.Config.html \"struct prost_build::Config\")\n\nConfiguration options for Protobuf code generation.\n\n[Method](struct.Method.html \"struct prost_build::Method\")\n\nA service method descriptor.\n\n[Module](struct.Module.html \"struct prost_build::Module\")\n\nA Rust module path for a Protobuf package.\n\n[Service](struct.Service.html \"struct prost_build::Service\")\n\nA service descriptor.\n\n## Traits[¬ß](#traits)\n\n[ServiceGenerator](trait.ServiceGenerator.html \"trait prost_build::ServiceGenerator\")\n\nA service generator takes a service descriptor and generates Rust code.\n\n## Functions[¬ß](#functions)\n\n[compile\\_fds](fn.compile_fds.html \"fn prost_build::compile_fds\")\n\nCompile a [`FileDescriptorSet`](https://docs.rs/prost-types/0.14.3/x86_64-unknown-linux-gnu/prost_types/protobuf/struct.FileDescriptorSet.html \"struct prost_types::protobuf::FileDescriptorSet\") into Rust files during a Cargo build.\n\n[compile\\_protos](fn.compile_protos.html \"fn prost_build::compile_protos\")\n\nCompile `.proto` files into Rust files during a Cargo build.\n\n[error\\_message\\_protoc\\_not\\_found](fn.error_message_protoc_not_found.html \"fn prost_build::error_message_protoc_not_found\")\n\n[protoc\\_from\\_env](fn.protoc_from_env.html \"fn prost_build::protoc_from_env\")\n\nReturns the path to the `protoc` binary.\n\n[protoc\\_include\\_from\\_env](fn.protoc_include_from_env.html \"fn prost_build::protoc_include_from_env\")\n\nReturns the path to the Protobuf include directory.",
            "title": "https://docs.rs/prost-build/latest/prost_build/ (text/html; charset=utf-8)",
            "metadata": {
              "truncated": false
            },
            "time": {
              "start": 1771212989241,
              "end": 1771212989440,
              "compacted": 1771213545696
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_04f5ae31ff41b23901699290bd26988193943c01aafa13ad9c"
            }
          },
          "id": "prt_c64856321001mxYXce63WCPmwt",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64854c8a001CSr0mCizL3kOBi"
        },
        {
          "type": "tool",
          "callID": "call_oXOOpe3I401yeHZzQ4vd4XFS",
          "tool": "webfetch",
          "state": {
            "status": "completed",
            "input": {
              "url": "https://docs.rs/tonic-prost-build/latest/tonic_prost_build/",
              "format": "markdown"
            },
            "output": "tonic\\_prost\\_build - Rust\n\n  \n\n[Docs.rs](/)\n\n-   [tonic-prost-build-0.14.4](# \"Prost build integration for tonic\")\n    \n    -   tonic-prost-build 0.14.4\n    -   [Permalink](/tonic-prost-build/0.14.4/tonic_prost_build/ \"Get a link to this specific version\")\n    -   [Docs.rs crate page](/crate/tonic-prost-build/latest \"See tonic-prost-build in docs.rs\")\n    -   [MIT](https://spdx.org/licenses/MIT)\n    \n    -   Links\n    -   [Homepage](https://github.com/hyperium/tonic)\n    -   [Repository](https://github.com/hyperium/tonic)\n    -   [crates.io](https://crates.io/crates/tonic-prost-build \"See tonic-prost-build in crates.io\")\n    -   [Source](/crate/tonic-prost-build/latest/source/ \"Browse source of tonic-prost-build-0.14.4\")\n    \n    -   Owners\n    -   [LucioFranco](https://crates.io/users/LucioFranco)\n    \n    -   Dependencies\n    -   -   [prettyplease ^0.2 *normal*](/prettyplease/^0.2/)\n        -   [proc-macro2 ^1.0 *normal*](/proc-macro2/^1.0/)\n        -   [prost-build ^0.14 *normal*](/prost-build/^0.14/)\n        -   [prost-types ^0.14 *normal*](/prost-types/^0.14/)\n        -   [quote ^1.0 *normal*](/quote/^1.0/)\n        -   [syn ^2.0 *normal*](/syn/^2.0/)\n        -   [tempfile ^3.0 *normal*](/tempfile/^3.0/)\n        -   [tonic-build ^0.14.0 *normal*](/tonic-build/^0.14.0/)\n        -   [tonic ^0.14.0 *dev*](/tonic/^0.14.0/)\n        \n    \n    -   Versions\n    \n    -   [**100%** of the crate is documented](/crate/tonic-prost-build/latest)\n    \n-   [Platform](#)\n    -   [aarch64-apple-darwin](/crate/tonic-prost-build/latest/target-redirect/aarch64-apple-darwin/tonic_prost_build/)\n    -   [aarch64-unknown-linux-gnu](/crate/tonic-prost-build/latest/target-redirect/aarch64-unknown-linux-gnu/tonic_prost_build/)\n    -   [i686-pc-windows-msvc](/crate/tonic-prost-build/latest/target-redirect/i686-pc-windows-msvc/tonic_prost_build/)\n    -   [x86\\_64-pc-windows-msvc](/crate/tonic-prost-build/latest/target-redirect/x86_64-pc-windows-msvc/tonic_prost_build/)\n    -   [x86\\_64-unknown-linux-gnu](/crate/tonic-prost-build/latest/target-redirect/tonic_prost_build/)\n-   [Feature flags](/crate/tonic-prost-build/latest/features \"Browse available feature flags of tonic-prost-build-0.14.4\")\n\n-   [docs.rs](#)\n    -   [About docs.rs](/about)\n    -   [Badges](/about/badges)\n    -   [Builds](/about/builds)\n    -   [Metadata](/about/metadata)\n    -   [Shorthand URLs](/about/redirections)\n    -   [Download](/about/download)\n    -   [Rustdoc JSON](/about/rustdoc-json)\n    -   [Build queue](/releases/queue)\n    -   [Privacy policy](https://foundation.rust-lang.org/policies/privacy-policy/#docs.rs)\n\n-   [Rust](#)\n    -   [Rust website](https://www.rust-lang.org/)\n    -   [The Book](https://doc.rust-lang.org/book/)\n    -   [Standard Library API Reference](https://doc.rust-lang.org/std/)\n    -   [Rust by Example](https://doc.rust-lang.org/rust-by-example/)\n    -   [The Cargo Guide](https://doc.rust-lang.org/cargo/guide/)\n    -   [Clippy Documentation](https://doc.rust-lang.org/nightly/clippy)\n\n[Skip to main content](#main-content)\n\n## [Crate tonic\\_prost\\_build](#)\n\n[![logo](https://raw.githubusercontent.com/tokio-rs/website/master/public/img/icons/tonic.svg)](../tonic_prost_build/index.html)\n\n## [tonic\\_prost\\_build](../tonic_prost_build/index.html)0.14.4\n\n-   [All Items](all.html)\n\n### [Sections](#)\n\n-   [Example](#example \"Example\")\n\n### [Crate Items](#modules)\n\n-   [Modules](#modules \"Modules\")\n-   [Structs](#structs \"Structs\")\n-   [Traits](#traits \"Traits\")\n-   [Functions](#functions \"Functions\")\n\n# Crate tonic\\_prost\\_build¬†Copy item path\n\n[Source](../src/tonic_prost_build/lib.rs.html#1-922)\n\nExpand description\n\nProst build integration for tonic.\n\nThis crate provides code generation for gRPC services using protobuf definitions via the [`prost`](https://github.com/tokio-rs/prost) ecosystem.\n\n## [¬ß](#example)Example\n\n[‚ìò](# \"This example is not tested\")\n\n```\nuse tonic_prost_build::configure;\n\nfn main() {\n    configure()\n        .compile_protos(&[\"proto/service.proto\"], &[\"proto\"])\n        .unwrap();\n}\n```\n\n## Modules[¬ß](#modules)\n\n[manual](manual/index.html \"mod tonic_prost_build::manual\")\n\nThis module provides utilities for generating `tonic` service stubs and clients purely in Rust without the need of `proto` files. It also enables you to set a custom `Codec` if you want to use a custom serialization format other than `protobuf`.\n\n## Structs[¬ß](#structs)\n\n[Builder](struct.Builder.html \"struct tonic_prost_build::Builder\")\n\nBuilder for configuring and generating code from `.proto` files.\n\n[Config](struct.Config.html \"struct tonic_prost_build::Config\")\n\nConfiguration options for Protobuf code generation.\n\n[FileDescriptorSet](struct.FileDescriptorSet.html \"struct tonic_prost_build::FileDescriptorSet\")\n\nThe protocol compiler can output a FileDescriptorSet containing the .proto files it parses.\n\n[TonicAttributes](struct.TonicAttributes.html \"struct tonic_prost_build::TonicAttributes\")\n\nAttributes that will be added to `mod` and `struct` items.\n\n## Traits[¬ß](#traits)\n\n[TonicMethod](trait.TonicMethod.html \"trait tonic_prost_build::TonicMethod\")\n\nMethod generation trait.\n\n[TonicService](trait.TonicService.html \"trait tonic_prost_build::TonicService\")\n\nService generation trait.\n\n## Functions[¬ß](#functions)\n\n[compile\\_fds](fn.compile_fds.html \"fn tonic_prost_build::compile_fds\")\n\nSimple file descriptor set compiling. Use [`configure`](fn.configure.html \"fn tonic_prost_build::configure\") instead if you need more options.\n\n[compile\\_protos](fn.compile_protos.html \"fn tonic_prost_build::compile_protos\")\n\nSimple `.proto` compiling. Use [`configure`](fn.configure.html \"fn tonic_prost_build::configure\") instead if you need more options.\n\n[configure](fn.configure.html \"fn tonic_prost_build::configure\")\n\nConfigure `tonic-prost-build` code generation.",
            "title": "https://docs.rs/tonic-prost-build/latest/tonic_prost_build/ (text/html; charset=utf-8)",
            "metadata": {
              "truncated": false
            },
            "time": {
              "start": 1771212989242,
              "end": 1771212989523
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_04f5ae31ff41b23901699290bd26a08193a073b35be434868a"
            }
          },
          "id": "prt_c6485633a001c6HYYJL2cyl7Ej",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64854c8a001CSr0mCizL3kOBi"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "5147fb7468d78f726061bbed9b56e547e848c4bd",
          "cost": 0,
          "tokens": {
            "total": 64813,
            "input": 64651,
            "output": 162,
            "reasoning": 45,
            "cache": {
              "read": 0,
              "write": 0
            }
          },
          "id": "prt_c64856454001SGLzUeHsg0Kdig",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64854c8a001CSr0mCizL3kOBi"
        },
        {
          "type": "patch",
          "hash": "b7933c744ec3328102c609519b642416c9b21d45",
          "files": [
            "/Users/alex/repos/vfp/dark-factory/scripts/scrape_moon_docs.sh.ts"
          ],
          "id": "prt_c648564810010ioF5VUCnTrlTb",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64854c8a001CSr0mCizL3kOBi"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771212989575,
          "completed": 1771212995432
        },
        "parentID": "msg_c6484620d0011ltzji40BSbVp5",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 72325,
          "input": 7555,
          "output": 130,
          "reasoning": 22,
          "cache": {
            "read": 64640,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "tool-calls",
        "id": "msg_c64856487001uDn5pXIeDWowQH",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "5147fb7468d78f726061bbed9b56e547e848c4bd",
          "id": "prt_c64856cfc001Jop5CtOeaMU16g",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64856487001uDn5pXIeDWowQH"
        },
        {
          "type": "reasoning",
          "text": "**Planning TypeScript plugin research**",
          "metadata": {
            "openai": {
              "itemId": "rs_0fa23fc9d8021c4c01699290c075c48194a5faa83a815a6e21",
              "reasoningEncryptedContent": "gAAAAABpkpDCe7dHtmuMNRbKx2iXXvNxP0TiUruYek9NKA9Lw9aM1xUDarHKMA5l8hXB3sIDyTUYhMmMrxkBAhVRpa1hqioAdCtmDi2eoEtHw7skK1lmbQeptAf1sYcWTt95Q1jRdT1wQI6ejppvqTzDcSJCeMiTX_ExSq6e5JUcebOyYYGY8AyGAy8uct6SI44k1OPuqGD4DTtc9Em8L6CN9OV3XOg0vqcUz4gafgiqcDlCPJjl4jy8A9vqDLzWJIgzcMkF7rWsjzCb9bm5dEUmmJfPEPzj5QyKCG5p0MfsT720YOpacXtQ_dllWDFyORUdywHuDcAPhd-ZmtZD_4y19V12VbtVvIE1rsk_fX0Rr76Fad01ppEOK-SRIrhLlspjOgzRjpfwMslAi6nXiM5t_LtEjpjdR8K9rOMNRZZ9y-_ptn-ZF7FhuOjkjwre6h48Rd97s6ZUqw_VUjnAsEio4BKsuuZW3mZ_RKnEz8p-2PjXDIyzB0Q_PMqjhl8z1zfRcL0IrrN3PDP3HlD-QnryLd6z3I-kopcxC3iA6y-MT3MamtDlVMsEuyidWk-2z2ys8dgfSY2mPpPa3klffSw4I40Wn5GgZHzJKm86t_8X-Rq3owpd6Kn0qKxVyfdKfXjhSQ2RJgCsqbQTu6KtFxsbVsTefoXLoRTrFsiGz3sql7H-LeBmho7hlovCaszc0jo7iTnyivJEMImwukH5vqBksIsyS43gPzZNcxh9-oLlBwvzbVh9YbZdAEqTuhbGVCRmTiArVAJ2NrSmQdjusLIZ_Rh-NgdnZYxvGpkltb9--1fCbb0vXOX8hFAEZUMZWoi2778VD5m6eOmpUFAgQXXbnpQlFXdpdTDmcRw18ok8DesMN98NFbDz6vKc-8Iaz-kMJqpyz0CZ81IYG0uqpfc0wmzHVncc0DcptMO8i7jfuBctt-0moJA="
            }
          },
          "time": {
            "start": 1771212992502,
            "end": 1771212994384
          },
          "id": "prt_c64856ff6001uyGHRCi35XY9Nd",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64856487001uDn5pXIeDWowQH"
        },
        {
          "type": "tool",
          "callID": "call_GJgyRtmi34srUeFre1SfIDnY",
          "tool": "webfetch",
          "state": {
            "status": "completed",
            "input": {
              "url": "https://github.com/stephenh/ts-proto",
              "format": "markdown"
            },
            "output": "                    GitHub - stephenh/ts-proto: An idiomatic protobuf generator for TypeScript                                             \n\n[Skip to content](#start-of-content)   \n\n## Navigation Menu\n\nToggle navigation\n\n[](/)\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fstephenh%2Fts-proto)\n\nAppearance settings\n\n  \n\n-   Platform\n    \n    -   AI CODE CREATION\n        \n        -   [\n            \n            GitHub CopilotWrite better code with AI\n            \n            ](https://github.com/features/copilot)\n        -   [\n            \n            GitHub SparkBuild and deploy intelligent apps\n            \n            ](https://github.com/features/spark)\n        -   [\n            \n            GitHub ModelsManage and compare prompts\n            \n            ](https://github.com/features/models)\n        -   [\n            \n            MCP RegistryNewIntegrate external tools\n            \n            ](https://github.com/mcp)\n        \n    -   DEVELOPER WORKFLOWS\n        \n        -   [\n            \n            ActionsAutomate any workflow\n            \n            ](https://github.com/features/actions)\n        -   [\n            \n            CodespacesInstant dev environments\n            \n            ](https://github.com/features/codespaces)\n        -   [\n            \n            IssuesPlan and track work\n            \n            ](https://github.com/features/issues)\n        -   [\n            \n            Code ReviewManage code changes\n            \n            ](https://github.com/features/code-review)\n        \n    -   APPLICATION SECURITY\n        \n        -   [\n            \n            GitHub Advanced SecurityFind and fix vulnerabilities\n            \n            ](https://github.com/security/advanced-security)\n        -   [\n            \n            Code securitySecure your code as you build\n            \n            ](https://github.com/security/advanced-security/code-security)\n        -   [\n            \n            Secret protectionStop leaks before they start\n            \n            ](https://github.com/security/advanced-security/secret-protection)\n        \n    -   EXPLORE\n        \n        -   [Why GitHub](https://github.com/why-github)\n        -   [Documentation](https://docs.github.com)\n        -   [Blog](https://github.blog)\n        -   [Changelog](https://github.blog/changelog)\n        -   [Marketplace](https://github.com/marketplace)\n        \n    \n    [View all features](https://github.com/features)\n    \n-   Solutions\n    \n    -   BY COMPANY SIZE\n        \n        -   [Enterprises](https://github.com/enterprise)\n        -   [Small and medium teams](https://github.com/team)\n        -   [Startups](https://github.com/enterprise/startups)\n        -   [Nonprofits](https://github.com/solutions/industry/nonprofits)\n        \n    -   BY USE CASE\n        \n        -   [App Modernization](https://github.com/solutions/use-case/app-modernization)\n        -   [DevSecOps](https://github.com/solutions/use-case/devsecops)\n        -   [DevOps](https://github.com/solutions/use-case/devops)\n        -   [CI/CD](https://github.com/solutions/use-case/ci-cd)\n        -   [View all use cases](https://github.com/solutions/use-case)\n        \n    -   BY INDUSTRY\n        \n        -   [Healthcare](https://github.com/solutions/industry/healthcare)\n        -   [Financial services](https://github.com/solutions/industry/financial-services)\n        -   [Manufacturing](https://github.com/solutions/industry/manufacturing)\n        -   [Government](https://github.com/solutions/industry/government)\n        -   [View all industries](https://github.com/solutions/industry)\n        \n    \n    [View all solutions](https://github.com/solutions)\n    \n-   Resources\n    \n    -   EXPLORE BY TOPIC\n        \n        -   [AI](https://github.com/resources/articles?topic=ai)\n        -   [Software Development](https://github.com/resources/articles?topic=software-development)\n        -   [DevOps](https://github.com/resources/articles?topic=devops)\n        -   [Security](https://github.com/resources/articles?topic=security)\n        -   [View all topics](https://github.com/resources/articles)\n        \n    -   EXPLORE BY TYPE\n        \n        -   [Customer stories](https://github.com/customer-stories)\n        -   [Events & webinars](https://github.com/resources/events)\n        -   [Ebooks & reports](https://github.com/resources/whitepapers)\n        -   [Business insights](https://github.com/solutions/executive-insights)\n        -   [GitHub Skills](https://skills.github.com)\n        \n    -   SUPPORT & SERVICES\n        \n        -   [Documentation](https://docs.github.com)\n        -   [Customer support](https://support.github.com)\n        -   [Community forum](https://github.com/orgs/community/discussions)\n        -   [Trust center](https://github.com/trust-center)\n        -   [Partners](https://github.com/partners)\n        \n    \n-   Open Source\n    \n    -   COMMUNITY\n        \n        -   [\n            \n            GitHub SponsorsFund open source developers\n            \n            ](https://github.com/sponsors)\n        \n    -   PROGRAMS\n        \n        -   [Security Lab](https://securitylab.github.com)\n        -   [Maintainer Community](https://maintainers.github.com)\n        -   [Accelerator](https://github.com/accelerator)\n        -   [Archive Program](https://archiveprogram.github.com)\n        \n    -   REPOSITORIES\n        \n        -   [Topics](https://github.com/topics)\n        -   [Trending](https://github.com/trending)\n        -   [Collections](https://github.com/collections)\n        \n    \n-   Enterprise\n    \n    -   ENTERPRISE SOLUTIONS\n        \n        -   [\n            \n            Enterprise platformAI-powered developer platform\n            \n            ](https://github.com/enterprise)\n        \n    -   AVAILABLE ADD-ONS\n        \n        -   [\n            \n            GitHub Advanced SecurityEnterprise-grade security features\n            \n            ](https://github.com/security/advanced-security)\n        -   [\n            \n            Copilot for BusinessEnterprise-grade AI features\n            \n            ](https://github.com/features/copilot/copilot-business)\n        -   [\n            \n            Premium SupportEnterprise-grade 24/7 support\n            \n            ](https://github.com/premium-support)\n        \n    \n-   [Pricing](https://github.com/pricing)\n\nSearch or jump to...\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch\n\nClear\n\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n\n# Provide feedback\n\nWe read every piece of feedback, and take your input very seriously.\n\n Include my email address so I can be contacted\n\nCancel Submit feedback\n\n# Saved searches\n\n## Use saved searches to filter your results more quickly\n\nName  \n\nQuery \n\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\n\nCancel Create saved search\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fstephenh%2Fts-proto)\n\n[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=stephenh%2Fts-proto)\n\nAppearance settings\n\nResetting focus\n\nYou signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\n\n[stephenh](/stephenh) / **[ts-proto](/stephenh/ts-proto)** Public\n\n-   [Notifications](/login?return_to=%2Fstephenh%2Fts-proto) You must be signed in to change notification settings\n-   [Fork 379](/login?return_to=%2Fstephenh%2Fts-proto)\n-   [Star 2.5k](/login?return_to=%2Fstephenh%2Fts-proto)\n    \n\nAn idiomatic protobuf generator for TypeScript\n\n### License\n\n[Apache-2.0 license](/stephenh/ts-proto/blob/main/LICENSE)\n\n[2.5k stars](/stephenh/ts-proto/stargazers) [379 forks](/stephenh/ts-proto/forks) [Branches](/stephenh/ts-proto/branches) [Tags](/stephenh/ts-proto/tags) [Activity](/stephenh/ts-proto/activity)\n\n[Star](/login?return_to=%2Fstephenh%2Fts-proto)\n\n[Notifications](/login?return_to=%2Fstephenh%2Fts-proto) You must be signed in to change notification settings\n\n-   [Code](/stephenh/ts-proto)\n-   [Issues 136](/stephenh/ts-proto/issues)\n-   [Pull requests 36](/stephenh/ts-proto/pulls)\n-   [Discussions](/stephenh/ts-proto/discussions)\n-   [Actions](/stephenh/ts-proto/actions)\n-   [Security 0](/stephenh/ts-proto/security)\n-   [Insights](/stephenh/ts-proto/pulse)\n\nAdditional navigation options\n\n-   [Code](/stephenh/ts-proto)\n-   [Issues](/stephenh/ts-proto/issues)\n-   [Pull requests](/stephenh/ts-proto/pulls)\n-   [Discussions](/stephenh/ts-proto/discussions)\n-   [Actions](/stephenh/ts-proto/actions)\n-   [Security](/stephenh/ts-proto/security)\n-   [Insights](/stephenh/ts-proto/pulse)\n\n# stephenh/ts-proto\n\n   \n\n¬†main\n\n[Branches](/stephenh/ts-proto/branches)[Tags](/stephenh/ts-proto/tags)\n\n[](/stephenh/ts-proto/branches)[](/stephenh/ts-proto/tags)\n\nGo to file\n\nCode\n\nOpen more actions menu\n\n## Folders and files\n\nName\n\nName\n\nLast commit message\n\nLast commit date\n\n## Latest commit\n\n## History\n\n[1,349 Commits](/stephenh/ts-proto/commits/main/)\n\n[](/stephenh/ts-proto/commits/main/)1,349 Commits\n\n[.github/workflows](/stephenh/ts-proto/tree/main/.github/workflows \"This path skips through empty directories\")\n\n[.github/workflows](/stephenh/ts-proto/tree/main/.github/workflows \"This path skips through empty directories\")\n\n[.yarn/releases](/stephenh/ts-proto/tree/main/.yarn/releases \"This path skips through empty directories\")\n\n[.yarn/releases](/stephenh/ts-proto/tree/main/.yarn/releases \"This path skips through empty directories\")\n\n[integration](/stephenh/ts-proto/tree/main/integration \"integration\")\n\n[integration](/stephenh/ts-proto/tree/main/integration \"integration\")\n\n[protos](/stephenh/ts-proto/tree/main/protos \"protos\")\n\n[protos](/stephenh/ts-proto/tree/main/protos \"protos\")\n\n[src](/stephenh/ts-proto/tree/main/src \"src\")\n\n[src](/stephenh/ts-proto/tree/main/src \"src\")\n\n[tests](/stephenh/ts-proto/tree/main/tests \"tests\")\n\n[tests](/stephenh/ts-proto/tree/main/tests \"tests\")\n\n[.gitattributes](/stephenh/ts-proto/blob/main/.gitattributes \".gitattributes\")\n\n[.gitattributes](/stephenh/ts-proto/blob/main/.gitattributes \".gitattributes\")\n\n[.gitignore](/stephenh/ts-proto/blob/main/.gitignore \".gitignore\")\n\n[.gitignore](/stephenh/ts-proto/blob/main/.gitignore \".gitignore\")\n\n[.nvmrc](/stephenh/ts-proto/blob/main/.nvmrc \".nvmrc\")\n\n[.nvmrc](/stephenh/ts-proto/blob/main/.nvmrc \".nvmrc\")\n\n[.prettierrc](/stephenh/ts-proto/blob/main/.prettierrc \".prettierrc\")\n\n[.prettierrc](/stephenh/ts-proto/blob/main/.prettierrc \".prettierrc\")\n\n[.yarnrc.yml](/stephenh/ts-proto/blob/main/.yarnrc.yml \".yarnrc.yml\")\n\n[.yarnrc.yml](/stephenh/ts-proto/blob/main/.yarnrc.yml \".yarnrc.yml\")\n\n[CHANGELOG.md](/stephenh/ts-proto/blob/main/CHANGELOG.md \"CHANGELOG.md\")\n\n[CHANGELOG.md](/stephenh/ts-proto/blob/main/CHANGELOG.md \"CHANGELOG.md\")\n\n[LICENSE](/stephenh/ts-proto/blob/main/LICENSE \"LICENSE\")\n\n[LICENSE](/stephenh/ts-proto/blob/main/LICENSE \"LICENSE\")\n\n[NESTJS.markdown](/stephenh/ts-proto/blob/main/NESTJS.markdown \"NESTJS.markdown\")\n\n[NESTJS.markdown](/stephenh/ts-proto/blob/main/NESTJS.markdown \"NESTJS.markdown\")\n\n[README.markdown](/stephenh/ts-proto/blob/main/README.markdown \"README.markdown\")\n\n[README.markdown](/stephenh/ts-proto/blob/main/README.markdown \"README.markdown\")\n\n[aliases.sh](/stephenh/ts-proto/blob/main/aliases.sh \"aliases.sh\")\n\n[aliases.sh](/stephenh/ts-proto/blob/main/aliases.sh \"aliases.sh\")\n\n[docker-compose.yml](/stephenh/ts-proto/blob/main/docker-compose.yml \"docker-compose.yml\")\n\n[docker-compose.yml](/stephenh/ts-proto/blob/main/docker-compose.yml \"docker-compose.yml\")\n\n[jest.config.js](/stephenh/ts-proto/blob/main/jest.config.js \"jest.config.js\")\n\n[jest.config.js](/stephenh/ts-proto/blob/main/jest.config.js \"jest.config.js\")\n\n[package.json](/stephenh/ts-proto/blob/main/package.json \"package.json\")\n\n[package.json](/stephenh/ts-proto/blob/main/package.json \"package.json\")\n\n[protoc-gen-ts\\_proto](/stephenh/ts-proto/blob/main/protoc-gen-ts_proto \"protoc-gen-ts_proto\")\n\n[protoc-gen-ts\\_proto](/stephenh/ts-proto/blob/main/protoc-gen-ts_proto \"protoc-gen-ts_proto\")\n\n[protoc.Dockerfile](/stephenh/ts-proto/blob/main/protoc.Dockerfile \"protoc.Dockerfile\")\n\n[protoc.Dockerfile](/stephenh/ts-proto/blob/main/protoc.Dockerfile \"protoc.Dockerfile\")\n\n[publish.sh](/stephenh/ts-proto/blob/main/publish.sh \"publish.sh\")\n\n[publish.sh](/stephenh/ts-proto/blob/main/publish.sh \"publish.sh\")\n\n[release.config.js](/stephenh/ts-proto/blob/main/release.config.js \"release.config.js\")\n\n[release.config.js](/stephenh/ts-proto/blob/main/release.config.js \"release.config.js\")\n\n[ts-proto.Dockerfile](/stephenh/ts-proto/blob/main/ts-proto.Dockerfile \"ts-proto.Dockerfile\")\n\n[ts-proto.Dockerfile](/stephenh/ts-proto/blob/main/ts-proto.Dockerfile \"ts-proto.Dockerfile\")\n\n[tsc-check.sh](/stephenh/ts-proto/blob/main/tsc-check.sh \"tsc-check.sh\")\n\n[tsc-check.sh](/stephenh/ts-proto/blob/main/tsc-check.sh \"tsc-check.sh\")\n\n[tsconfig.json](/stephenh/ts-proto/blob/main/tsconfig.json \"tsconfig.json\")\n\n[tsconfig.json](/stephenh/ts-proto/blob/main/tsconfig.json \"tsconfig.json\")\n\n[yarn.lock](/stephenh/ts-proto/blob/main/yarn.lock \"yarn.lock\")\n\n[yarn.lock](/stephenh/ts-proto/blob/main/yarn.lock \"yarn.lock\")\n\nView all files\n\n## Repository files navigation\n\n-   [README](#)\n-   [Apache-2.0 license](#)\n\n[![npm](https://camo.githubusercontent.com/52200b6591ccc098ee670dad3bcd751947c0868b4ec3b87910b5f58110954803/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f762f74732d70726f746f)](https://www.npmjs.com/package/ts-proto) [![build](https://github.com/stephenh/ts-proto/workflows/Build/badge.svg)](https://github.com/stephenh/ts-proto/actions)\n\n# ts-proto\n\n[](#ts-proto)\n\n> `ts-proto` transforms your `.proto` files into strongly-typed, idiomatic TypeScript files!\n\n## ts-proto 2.x Release Notes\n\n[](#ts-proto-2x-release-notes)\n\nThe 2.x release of ts-proto migrated the low-level Protobuf serializing that its `encode` and `decode` method use from the venerable, but aging & stagnant, `protobufjs` package to `@bufbuild/protobuf`.\n\nIf you only used the `encode` and `decode` methods, this should largely be a non-breaking change.\n\nHowever, if you used any code that used the old `protobufjs` `Writer` or `Reader` classes, you'll need to update your code to use the new `@bufbuild/protobuf` classes:\n\n```\nimport { BinaryReader, BinaryWriter } from \"@bufbuild/protobuf/wire\";\n```\n\nIf migrating to `@bufbuild/protobuf` is a blocker for you, you can pin your `ts-proto` version to `1.x`.\n\n**Disclaimer & apology:** I had intended to release ts-proto 2.x as an alpha release, but didn't get the semantic-release config correct, and so ts-proto 2.x was published as a major release without a proper alpha/beta cycle.\n\nIf you could file reports (or better PRs!) for any issues you come across while the release is still fresh, that would be greatly appreciated.\n\nAny tips or tricks for others on the migration would also be appreciated!\n\n## Table of contents\n\n[](#table-of-contents)\n\n-   [ts-proto](#ts-proto)\n    -   [Table of contents](#table-of-contents)\n-   [Overview](#overview)\n-   [QuickStart](#quickstart)\n    -   [Buf](#buf)\n    -   [ESM](#esm)\n-   [Goals](#goals)\n    -   [Non-Goals](#non-goals)\n-   [Example Types](#example-types)\n-   [Highlights](#highlights)\n-   [Auto-Batching / N+1 Prevention](#auto-batching--n1-prevention)\n-   [Usage](#usage)\n    -   [Supported options](#supported-options)\n    -   [NestJS Support](#nestjs-support)\n    -   [Watch Mode](#watch-mode)\n    -   [Basic gRPC implementation](#basic-grpc-implementation)\n-   [Sponsors](#sponsors)\n-   [Development](#development)\n-   [Assumptions](#assumptions)\n-   [Todo](#todo)\n-   [OneOf Handling](#oneof-handling)\n-   [Default values and unset fields](#default-values-and-unset-fields)\n-   [Well-Known Types](#well-known-types)\n    -   [Wrapper Types](#wrapper-types)\n    -   [JSON Types (Struct Types)](#json-types-struct-types)\n    -   [Timestamp](#timestamp)\n-   [Number Types](#number-types)\n-   [Current Status of Optional Values](#current-status-of-optional-values)\n\n# Overview\n\n[](#overview)\n\nts-proto generates TypeScript types from protobuf schemas.\n\nI.e. given a `person.proto` schema like:\n\nmessage Person {\n  string name \\= 1;\n}\n\nts-proto will generate a `person.ts` file like:\n\ninterface Person {\n  name: string\n}\n\nconst Person \\= {\n  encode(person): Writer { ... }\n  decode(reader): Person { ... }\n  toJSON(person): unknown { ... }\n  fromJSON(data): Person { ... }\n}\n\nIt also knows about services and will generate types for them as well, i.e.:\n\nexport interface PingService {\n  ping(request: PingRequest): Promise<PingResponse\\>;\n}\n\nIt will also generate client implementations of `PingService`; currently [Twirp](https://github.com/twitchtv/twirp), [grpc-web](/stephenh/ts-proto/blob/main/integration/grpc-web), [grpc-js](/stephenh/ts-proto/blob/main/integration/grpc-js) and [nestjs](/stephenh/ts-proto/blob/main/NESTJS.markdown) are supported.\n\n# QuickStart\n\n[](#quickstart)\n\n-   `npm install ts-proto`\n-   `protoc --plugin=./node_modules/.bin/protoc-gen-ts_proto --ts_proto_out=. ./simple.proto`\n    -   (Note that the output parameter name, `ts_proto_out`, is named based on the suffix of the plugin's name, i.e. \"ts\\_proto\" suffix in the `--plugin=./node_modules/.bin/protoc-gen-ts_proto` parameter becomes the `_out` prefix, per `protoc`'s CLI conventions.)\n    -   On Windows, use `protoc --plugin=protoc-gen-ts_proto=\".\\\\node_modules\\\\.bin\\\\protoc-gen-ts_proto.cmd\" --ts_proto_out=. ./simple.proto` (see [#93](https://github.com/stephenh/ts-proto/issues/93))\n    -   Ensure you're using a modern `protoc` (see [installation instructions for your platform](https://grpc.io/docs/protoc-installation/), i.e. `protoc` v`3.0.0` doesn't support the `_opt` flag\n\nThis will generate `*.ts` source files for the given `*.proto` types.\n\nIf you want to package these source files into an npm package to distribute to clients, just run `tsc` on them as usual to generate the `.js`/`.d.ts` files, and deploy the output as a regular npm package.\n\n## Buf\n\n[](#buf)\n\nIf you're using Buf, pass `strategy: all` in your `buf.gen.yaml` file ([docs](https://docs.buf.build/configuration/v1/buf-gen-yaml#strategy)).\n\nversion: v1\nplugins:\n  - name: ts\n    out: ../gen/ts\n    strategy: all\n    path: ../node\\_modules/ts-proto/protoc-gen-ts\\_proto\n\nTo prevent `buf push` from reading irrelevant `.proto` files, configure `buf.yaml` like so:\n\nbuild:\n  excludes: \\[node\\_modules\\]\n\nYou can also use the official plugin published to the Buf Registry.\n\nversion: v1\nplugins:\n  - plugin: buf.build/community/stephenh-ts-proto\n    out: ../gen/ts\n    opt:\n      - outputServices=...\n      - useExactTypes=...\n\n## ESM\n\n[](#esm)\n\nIf you're using a modern TS setup with either `esModuleInterop` or running in an ESM environment, you'll need to pass `ts_proto_opt`s of:\n\n-   `esModuleInterop=true` if using `esModuleInterop` in your `tsconfig.json`, and\n-   `importSuffix=.js` if executing the generated ts-proto code in an ESM environment\n\n# Goals\n\n[](#goals)\n\nIn terms of the code that `ts-proto` generates, the general goals are:\n\n-   Idiomatic TypeScript/ES6 types\n    -   `ts-proto` is a clean break from either the built-in Google/Java-esque JS code of `protoc` or the \"make `.d.ts` files the `*.js` comments\" approach of `protobufjs`\n    -   (Technically the `protobufjs/minimal` package is used for actually reading/writing bytes.)\n-   TypeScript-first output\n-   Interfaces over classes\n    -   As much as possible, types are just interfaces, so you can work with messages just like regular hashes/data structures.\n-   Only supports codegen `*.proto`\\-to-`*.ts` workflow, currently no runtime reflection/loading of dynamic `.proto` files\n\n## Non-Goals\n\n[](#non-goals)\n\nNote that ts-proto is not an out-of-the-box RPC framework; instead it's more of a swiss-army knife (as witnessed by its many config options), that lets you build *exactly* the RPC framework you'd like on top of it (i.e. that best integrates with your company's protobuf ecosystem; for better or worse, protobuf RPC is still a somewhat fragmented ecosystem).\n\nIf you'd like an out-of-the-box RPC framework built on top of ts-proto, there are a few examples:\n\n-   [nice-grpc](https://github.com/deeplay-io/nice-grpc)\n-   [starpc](https://github.com/aperturerobotics/starpc)\n\n(Note for potential contributors, if you develop other frameworks/mini-frameworks, or even blog posts/tutorials, on using `ts-proto`, we're happy to link to them.)\n\nWe also don't support clients for `google.api.http`\\-based [Google Cloud](https://cloud.google.com/endpoints/docs/grpc/transcoding) APIs, see [#948](https://github.com/stephenh/ts-proto/issues/948) if you'd like to submit a PR.\n\n# Example Types\n\n[](#example-types)\n\nThe generated types are \"just data\", i.e.:\n\nexport interface Simple {\n  name: string;\n  age: number;\n  createdAt: Date | undefined;\n  child: Child | undefined;\n  state: StateEnum;\n  grandChildren: Child\\[\\];\n  coins: number\\[\\];\n}\n\nAlong with `encode`/`decode` factory methods:\n\nexport const Simple \\= {\n  create(baseObject?: DeepPartial<Simple\\>): Simple {\n    ...\n  },\n\n  encode(message: Simple, writer: Writer \\= Writer.create()): Writer {\n    ...\n  },\n\n  decode(reader: Reader, length?: number): Simple {\n    ...\n  },\n\n  fromJSON(object: any): Simple {\n    ...\n  },\n\n  fromPartial(object: DeepPartial<Simple\\>): Simple {\n    ...\n  },\n\n  toJSON(message: Simple): unknown {\n    ...\n  },\n};\n\nThis allows idiomatic TS/JS usage like:\n\nconst bytes \\= Simple.encode({ name: ..., age: ..., ... }).finish();\nconst simple \\= Simple.decode(Reader.create(bytes));\nconst { name, age } \\= simple;\n\nWhich can dramatically ease integration when converting to/from other layers without creating a class and calling the right getters/setters.\n\n# Highlights\n\n[](#highlights)\n\n-   A poor man's attempt at \"please give us back optional types\"\n    \n    The canonical protobuf wrapper types, i.e. `google.protobuf.StringValue`, are mapped as optional values, i.e. `string | undefined`, which means for primitives we can kind of pretend the protobuf type system has optional types.\n    \n    (**Update**: ts-proto now also supports the proto3 `optional` keyword.)\n    \n-   Timestamps are mapped as `Date`\n    \n    (Configurable with the `useDate` parameter.)\n    \n-   `fromJSON`/`toJSON` use the [proto3 canonical JSON encoding format](https://developers.google.com/protocol-buffers/docs/proto3#json) (e.g. timestamps are ISO strings), unlike [`protobufjs`](https://github.com/protobufjs/protobuf.js/issues/1304).\n    \n-   ObjectIds can be mapped as `mongodb.ObjectId`\n    \n    (Configurable with the `useMongoObjectId` parameter.)\n    \n\n# Auto-Batching / N+1 Prevention\n\n[](#auto-batching--n1-prevention)\n\n(Note: this is currently only supported by the Twirp clients.)\n\nIf you're using ts-proto's clients to call backend micro-services, similar to the N+1 problem in SQL applications, it is easy for micro-service clients to (when serving an individual request) inadvertently trigger multiple separate RPC calls for \"get book 1\", \"get book 2\", \"get book 3\", that should really be batched into a single \"get books \\[1, 2, 3\\]\" (assuming the backend supports a batch-oriented RPC method).\n\nts-proto can help with this, and essentially auto-batch your individual \"get book\" calls into batched \"get books\" calls.\n\nFor ts-proto to do this, you need to implement your service's RPC methods with the batching convention of:\n\n-   A method name of `Batch<OperationName>`\n-   The `Batch<OperationName>` input type has a single repeated field (i.e. `repeated string ids = 1`)\n-   The `Batch<OperationName>` output type has either a:\n    -   A single repeated field (i.e. `repeated Foo foos = 1`) *where the output order is the same as the input `ids` order*, or\n    -   A map of the input to an output (i.e. `map<string, Entity> entities = 1;`)\n\nWhen ts-proto recognizes methods of this pattern, it will automatically create a \"non-batch\" version of `<OperationName>` for the client, i.e. `client.Get<OperationName>`, that takes a single id and returns a single result.\n\nThis provides the client code with the illusion that it can make individual `Get<OperationName>` calls (which is generally preferable/easier when implementing the client's business logic), but the actual implementation that ts-proto provides will end up making `Batch<OperationName>` calls to the backend service.\n\nYou also need to enable the `useContext=true` build-time parameter, which gives all client methods a Go-style `ctx` parameter, with a `getDataLoaders` method that lets ts-proto cache/resolve request-scoped [DataLoaders](https://github.com/graphql/dataloader), which provide the fundamental auto-batch detection/flushing behavior.\n\nSee the `batching.proto` file and related tests for examples/more details.\n\nBut the net effect is that ts-proto can provide SQL-/ORM-style N+1 prevention for clients calls, which can be critical especially in high-volume / highly-parallel implementations like GraphQL front-end gateways calling backend micro-services.\n\n# Usage\n\n[](#usage)\n\n`ts-proto` is a `protoc` plugin, so you run it by (either directly in your project, or more likely in your mono-repo schema pipeline, i.e. like [Ibotta](https://medium.com/building-ibotta/building-a-scaleable-protocol-buffers-grpc-artifact-pipeline-5265c5118c9d) or [Namely](https://medium.com/namely-labs/how-we-build-grpc-services-at-namely-52a3ae9e7c35)):\n\n-   Add `ts-proto` to your `package.json`\n-   Run `npm install` to download it\n-   Invoke `protoc` with a `plugin` parameter like:\n\nprotoc --plugin=node\\_modules/ts-proto/protoc-gen-ts\\_proto ./batching.proto -I.\n\n`ts-proto` can also be invoked with [Gradle](https://gradle.org) using the [protobuf-gradle-plugin](https://github.com/google/protobuf-gradle-plugin):\n\nprotobuf {\n    plugins {\n        // \\`ts\\` can be replaced by any unused plugin name, e.g. \\`tsproto\\`\n        ts {\n            path \\= 'path/to/plugin'\n        }\n    }\n\n    // This section only needed if you provide plugin options\n    generateProtoTasks {\n        all().each { task \\->\n            task.plugins {\n                // Must match plugin ID declared above\n                ts {\n                    option 'foo=bar'\n                }\n            }\n        }\n    }\n}\n\nGenerated code will be placed in the Gradle build directory.\n\n### Supported options\n\n[](#supported-options)\n\n-   With `--ts_proto_opt=globalThisPolyfill=true`, ts-proto will include a polyfill for globalThis.\n    \n    Defaults to `false`, i.e. we assume `globalThis` is available.\n    \n-   With `--ts_proto_opt=context=true`, the services will have a Go-style `ctx` parameter, which is useful for tracing/logging/etc. if you're not using node's `async_hooks` api due to performance reasons.\n    \n-   With `--ts_proto_opt=forceLong=long`, all 64-bit numbers will be parsed as instances of `Long` (using the [long](https://www.npmjs.com/package/long) library).\n    \n    With `--ts_proto_opt=forceLong=string`, all 64-bit numbers will be output as strings.\n    \n    With `--ts_proto_opt=forceLong=bigint`, all 64-bit numbers will be output as `BigInt`s. This option still uses the `long` library to encode/decode internally within `protobuf.js`, but then converts to/from `BigInt`s in the ts-proto-generated code.\n    \n    The default behavior is `forceLong=number`, which will internally still use the `long` library to encode/decode values on the wire (so you will still see a `util.Long = Long` line in your output), but will convert the `long` values to `number` automatically for you. Note that a runtime error is thrown if, while doing this conversion, a 64-bit value is larger than can be correctly stored as a `number`.\n    \n-   With `--ts_proto_opt=useJsTypeOverride`, 64-bit numbers will be output as the [FieldOption.JSType](https://protobuf.dev/reference/java/api-docs/com/google/protobuf/DescriptorProtos.FieldOptions.JSType) specified on the field. This takes precedence over the `forceLong` option provided.\n    \n-   With `--ts_proto_opt=esModuleInterop=true` changes output to be `esModuleInterop` compliant.\n    \n    Specifically the `Long` imports will be generated as `import Long from 'long'` instead of `import * as Long from 'long'`.\n    \n-   With `--ts_proto_opt=env=node` or `browser` or `both`, ts-proto will make environment-specific assumptions in your output. This defaults to `both`, which makes no environment-specific assumptions.\n    \n    Using `node` changes the types of `bytes` from `Uint8Array` to `Buffer` for easier integration with the node ecosystem which generally uses `Buffer`.\n    \n    Currently `browser` doesn't have any specific behavior other than being \"not `node`\". It probably will soon/at some point.\n    \n-   With `--ts_proto_opt=useOptionals=messages` (for message fields) or `--ts_proto_opt=useOptionals=all` (for message and scalar fields), fields are declared as optional keys, e.g. `field?: Message` instead of the default `field: Message | undefined`.\n    \n    ts-proto defaults to `useOptionals=none` because it:\n    \n    1.  Prevents typos when initializing messages, and\n    2.  Provides the most consistent API to readers\n    3.  Ensures production messages are properly initialized with all fields.\n    \n    For typo prevention, optional fields make it easy for extra fields to slip into a message (until we get [Exact Types](https://github.com/microsoft/TypeScript/issues/12936)), i.e.:\n    \n    interface SomeMessage {\n      firstName: string;\n      lastName: string;\n    }\n    // Declared with a typo\n    const data \\= { firstName: \"a\", lastTypo: \"b\" };\n    // With useOptionals=none, this correctly fails to compile; if \\`lastName\\` was optional, it would not\n    const message: SomeMessage \\= { ...data };\n    \n    For a consistent API, if `SomeMessage.lastName` is optional `lastName?`, then readers have to check *two* empty conditions: a) is `lastName` `undefined` (b/c it was created in-memory and left unset), or b) is `lastName` empty string (b/c we read `SomeMessage` off the wire and, per the proto3 spec, initialized `lastName` to empty string)?\n    \n    For ensuring proper initialization, if later `SomeMessage.middleInitial` is added, but it's marked as optional `middleInitial?`, you may have many call sites in production code that *should* now be passing `middleInitial` to create a valid `SomeMessage`, but are not.\n    \n    So, between typo-prevention, reader inconsistency, and proper initialization, ts-proto recommends using `useOptionals=none` as the \"most safe\" option.\n    \n    All that said, this approach does require writers/creators to set every field (although `fromPartial` and `create` are meant to address this), so if you still want to have optional keys, you can set `useOptionals=messages` or `useOptionals=all`.\n    \n    (See [this issue](https://github.com/stephenh/ts-proto/issues/120#issuecomment-678375833) and [this issue](https://github.com/stephenh/ts-proto/issues/397#issuecomment-977259118) for discussions on `useOptional`.)\n    \n-   With `--ts_proto_opt=exportCommonSymbols=false`, utility types like `DeepPartial` and `protobufPackage` won't be `export`d.\n    \n    This should make it possible to use create barrel imports of the generated output, i.e. `import * from ./foo` and `import * from ./bar`.\n    \n    Note that if you have the same message name used in multiple `*.proto` files, you will still get import conflicts.\n    \n-   With `--ts_proto_opt=oneof=unions`, `oneof` fields will be generated as ADTs.\n    \n    See the \"OneOf Handling\" section.\n    \n-   With `--ts_proto_opt=unrecognizedEnumName=<NAME>` enums will contain a key `<NAME>` with value of the `unrecognizedEnumValue` option.\n    \n    Defaults to `UNRECOGNIZED`.\n    \n-   With `--ts_proto_opt=unrecognizedEnumValue=<NUMBER>` enums will contain a key provided by the `unrecognizedEnumName` option with value of `<NUMBER>`.\n    \n    Defaults to `-1`.\n    \n-   With `--ts_proto_opt=unrecognizedEnum=false` enums will not contain an unrecognized enum key and value as provided by the `unrecognizedEnumName` and `unrecognizedEnumValue` options.\n    \n-   With `--ts_proto_opt=removeEnumPrefix=true` generated enums will have the enum name removed from members.\n    \n    `FooBar.FOO_BAR_BAZ = \"FOO_BAR_BAZ\"` will generate `FooBar.BAZ = \"FOO_BAR_BAZ\"`\n    \n    If any value in the enum would be made invalid by removing the enum name, the enum name will be present for all the values in the enum.\n    \n    `FooBar.FOO_BAR_1 = \"FOO_BAR_BAZ\"` will generate `FooBar.FOO_BAR_1 = \"FOO_BAR_BAZ\"`\n    \n    `FooBar.FOO_BAR_1A = \"FOO_BAR_BAZ\"` will generate `FooBar.FOO_BAR_1A = \"FOO_BAR_BAZ\"`\n    \n    `FooBar.FOO_BAR_Infinity = \"FOO_BAR_BAZ\"` will generate `FooBar.FOO_BAR_Infinity = \"FOO_BAR_BAZ\"` (this is technically valid but is likely to lead to downstream issues)\n    \n    `FooBar.FOO_BAR_INFINITY = \"FOO_BAR_BAZ\"` will generate `FooBar.INFINITY = \"FOO_BAR_BAZ\"`\n    \n-   With `--ts_proto_opt=lowerCaseServiceMethods=true`, the method names of service methods will be lowered/camel-case, i.e. `service.findFoo` instead of `service.FindFoo`.\n    \n-   With `--ts_proto_opt=snakeToCamel=false`, fields will be kept snake case in both the message keys and the `toJSON` / `fromJSON` methods.\n    \n    `snakeToCamel` can also be set as a `_`\\-delimited list of strings (comma is reserved as the flag delimited), i.e. `--ts_proto_opt=snakeToCamel=keys_json`, where including `keys` will make message keys be camel case and including `json` will make JSON keys be camel case.\n    \n    Empty string, i.e. `snakeToCamel=`, will keep both messages keys and `JSON` keys as snake case (it is the same as `snakeToCamel=false`).\n    \n    Note that to use the `json_name` attribute, you'll have to use the `json`.\n    \n    The default behavior is `keys_json`, i.e. both will be camel cased, and `json_name` will be used if set.\n    \n-   With `--ts_proto_opt=protoJsonFormat=true` (default), the `toJSON` and `fromJSON` methods follow the [protoJSON format](https://protobuf.dev/programming-guides/json). This means `toJSON` will output standard lowerCamelCase keys (or custom `json_name` if set). `fromJSON` will accept both the lowerCamelCase key (or `json_name`) AND the original proto field name. With `--ts_proto_opt=protoJsonFormat=false`, strict proto3 compliance is disabled. The JSON keys will simply follow the `snakeToCamel` option, and `fromJSON` will only accept that specific format.\n    \n-   With `--ts_proto_opt=outputEncodeMethods=false`, the `Message.encode` and `Message.decode` methods for working with protobuf-encoded/binary data will not be output.\n    \n    This is useful if you want \"only types\".\n    \n-   With `--ts_proto_opt=outputEncodeIncludeTypes=regex`, the `Message.encode` method will only be output for types whose name matches the provided regular expression.\n    \n    This is useful if you want to limit `encode` methods to only select types.\n    \n-   With `--ts_proto_opt=outputDecodeIncludeTypes=regex`, the `Message.decode` method will only be output for types whose name matches the provided regular expression.\n    \n    This is useful if you want to limit `decode` methods to only select types.\n    \n-   With `--ts_proto_opt=outputJsonMethods=false`, the `Message.fromJSON` and `Message.toJSON` methods for working with JSON-coded data will not be output.\n    \n    This is also useful if you want \"only types\".\n    \n-   With `--ts_proto_opt=outputJsonMethods=to-only` and `--ts_proto_opt=outputJsonMethods=from-only` you will be able to export only one between the `Message.toJSON` and `Message.fromJSON` methods.\n    \n    This is useful if you're using ts-proto just to `encode` or `decode` and not for both.\n    \n-   With `--ts_proto_opt=outputPartialMethods=false`, the `Message.fromPartial` and `Message.create` methods for accepting partially-formed objects/object literals will not be output.\n    \n-   With `--ts_proto_opt=stringEnums=true`, the generated enum types will be string-based instead of int-based.\n    \n    This is useful if you want \"only types\" and are using a gRPC REST Gateway configured to serialize enums as strings.\n    \n    (Requires `outputEncodeMethods=false`.)\n    \n-   With `--ts_proto_opt=outputClientImpl=false`, the client implementations, i.e. `FooServiceClientImpl`, that implement the client-side (in Twirp, see next option for `grpc-web`) RPC interfaces will not be output.\n    \n-   With `--ts_proto_opt=outputClientImpl=grpc-web`, the client implementations, i.e. `FooServiceClientImpl`, will use the [@improbable-eng/grpc-web](https://github.com/improbable-eng/grpc-web) library at runtime to send grpc messages to a grpc-web backend.\n    \n    (Note that this only uses the grpc-web runtime, you don't need to use any of their generated code, i.e. the ts-proto output replaces their `ts-protoc-gen` output.)\n    \n    You'll need to add the `@improbable-eng/grpc-web` and a transport to your project's `package.json`; see the `integration/grpc-web` directory for a working example. Also see [#504](https://github.com/stephenh/ts-proto/issues/504) for integrating with [grpc-web-devtools](https://github.com/SafetyCulture/grpc-web-devtools).\n    \n-   With `--ts_proto_opt=returnObservable=true`, the return type of service methods will be `Observable<T>` instead of `Promise<T>`.\n    \n-   With`--ts_proto_opt=addGrpcMetadata=true`, the last argument of service methods will accept the grpc `Metadata` type, which contains additional information with the call (i.e. access tokens/etc.).\n    \n    (Requires `nestJs=true`.)\n    \n-   With`--ts_proto_opt=addNestjsRestParameter=true`, the last argument of service methods will be a rest parameter with type any. This way you can use custom decorators you could normally use in nestjs.\n    \n    (Requires `nestJs=true`.)\n    \n-   With `--ts_proto_opt=nestJs=true`, the defaults will change to generate [NestJS protobuf](https://docs.nestjs.com/microservices/grpc) friendly types & service interfaces that can be used in both the client-side and server-side of NestJS protobuf implementations. See the [nestjs readme](/stephenh/ts-proto/blob/main/NESTJS.markdown) for more information and implementation examples.\n    \n    Specifically `outputEncodeMethods`, `outputJsonMethods`, and `outputClientImpl` will all be false, `lowerCaseServiceMethods` will be true and `outputServices` will be ignored.\n    \n    Note that `addGrpcMetadata`, `addNestjsRestParameter` and `returnObservable` will still be false.\n    \n-   With `--ts_proto_opt=useDate=false`, fields of type `google.protobuf.Timestamp` will not be mapped to type `Date` in the generated types. See [Timestamp](#timestamp) for more details.\n    \n-   With `--ts_proto_opt=useMongoObjectId=true`, fields of a type called ObjectId where the message is constructed to have on field called value that is a string will be mapped to type `mongodb.ObjectId` in the generated types. This will require your project to install the mongodb npm package. See [ObjectId](#objectid) for more details.\n    \n-   With `--ts_proto_opt=annotateFilesWithVersion=false`, the generated files will not contain the versions of `protoc` and `ts-proto` used to generate the file. This option is normally set to `true`, such that files list the versions used.\n    \n-   With `--ts_proto_opt=outputSchema=true`, meta typings will be generated that can later be used in other code generators.\n    \n-   With `--ts_proto_opt=outputSchema=no-file-descriptor`, meta typings will be generated, but we do not include the file descriptor in the generated schema. This is useful if you are trying to minimize the size of the generated schema.\n    \n-   With `--ts_proto_opt=outputSchema=const`, meta typings will be generated `as const`, allowing type-safe access to all its properties. (only works with TypeScript 4.9 and up, because it also uses the [`satisfies`](https://www.typescriptlang.org/docs/handbook/release-notes/typescript-4-9.html#the-satisfies-operator) operator). Can be combined with the `no-file-descriptor` option (`outputSchema=const,outputSchema=no-file-descriptor`) to not include the file descriptor in the generated schema.\n    \n-   With `--ts_proto_opt=outputTypeAnnotations=true`, each message will be given a `$type` field containing its fully-qualified name. You can use `--ts_proto_opt=outputTypeAnnotations=static-only` to omit it from the `interface` declaration, or `--ts_proto_opt=outputTypeAnnotations=optional` to make it an optional property on the `interface` definition. The latter option may be useful if you want to use the `$type` field for runtime type checking on responses from a server.\n    \n-   With `--ts_proto_opt=outputTypeRegistry=true`, the type registry will be generated that can be used to resolve message types by fully-qualified name. Also, each message will be given a `$type` field containing its fully-qualified name.\n    \n-   With `--ts_proto_opt=outputServices=grpc-js`, ts-proto will output service definitions and server / client stubs in [grpc-js](https://github.com/grpc/grpc-node/tree/master/packages/grpc-js) format.\n    \n-   With `--ts_proto_opt=outputServices=generic-definitions`, ts-proto will output generic (framework-agnostic) service definitions. These definitions contain descriptors for each method with links to request and response types, which allows to generate server and client stubs at runtime, and also generate strong types for them at compile time. An example of a library that uses this approach is [nice-grpc](https://github.com/deeplay-io/nice-grpc).\n    \n-   With `--ts_proto_opt=outputServices=nice-grpc`, ts-proto will output server and client stubs for [nice-grpc](https://github.com/deeplay-io/nice-grpc). This should be used together with generic definitions, i.e. you should specify two options: `outputServices=nice-grpc,outputServices=generic-definitions`.\n    \n-   With `--ts_proto_opt=metadataType=Foo@./some-file`, ts-proto add a generic (framework-agnostic) metadata field to the generic service definition.\n    \n-   With `--ts_proto_opt=outputServices=generic-definitions,outputServices=default`, ts-proto will output both generic definitions and interfaces. This is useful if you want to rely on the interfaces, but also have some reflection capabilities at runtime.\n    \n-   With `--ts_proto_opt=outputServices=false`, or `=none`, ts-proto will output NO service definitions.\n    \n-   With `--ts_proto_opt=rpcBeforeRequest=true`, ts-proto will add a function definition to the Rpc interface definition with the signature: `beforeRequest(service: string, message: string, request: <RequestType>)`. It will also automatically set `outputServices=default`. Each of the Service's methods will call `beforeRequest` before performing its request.\n    \n-   With `--ts_proto_opt=rpcAfterResponse=true`, ts-proto will add a function definition to the Rpc interface definition with the signature: `afterResponse(service: string, message: string, response: <ResponseType>)`. It will also automatically set `outputServices=default`. Each of the Service's methods will call `afterResponse` before returning the response.\n    \n-   With `--ts_proto_opt=rpcErrorHandler=true`, ts-proto will add a function definition to the Rpc interface definition with the signature: `handleError(service: string, message: string, error: Error)`. It will also automatically set `outputServices=default`.\n    \n-   With `--ts_proto_opt=useAbortSignal=true`, the generated services will accept an `AbortSignal` to cancel RPC calls.\n    \n-   With `--ts_proto_opt=useAsyncIterable=true`, the generated services will use `AsyncIterable` instead of `Observable`.\n    \n-   With `--ts_proto_opt=emitImportedFiles=false`, ts-proto will not emit `google/protobuf/*` files unless you explicit add files to `protoc` like this `protoc --plugin=./node_modules/.bin/protoc-gen-ts_proto my_message.proto google/protobuf/duration.proto`\n    \n-   With `--ts_proto_opt=fileSuffix=<SUFFIX>`, ts-proto will emit generated files using the specified suffix. A `helloworld.proto` file with `fileSuffix=.pb` would be generated as `helloworld.pb.ts`. This is common behavior in other protoc plugins and provides a way to quickly glob all the generated files.\n    \n-   With `--ts_proto_opt=importSuffix=<SUFFIX>`, ts-proto will emit file imports using the specified suffix. An import of `helloworld.ts` with `fileSuffix=.js` would generate `import \"helloworld.js\"`. The default is to import without a file extension. Supported by TypeScript 4.7.x and up.\n    \n-   With `--ts_proto_opt=enumsAsLiterals=true`, the generated enum types will be enum-ish object with `as const`.\n    \n-   With `--ts_proto_opt=useExactTypes=false`, the generated `fromPartial` and `create` methods will not use Exact types.\n    \n    The default behavior is `useExactTypes=true`, which makes `fromPartial` and `create` use Exact type for its argument to make TypeScript reject any unknown properties.\n    \n-   With `--ts_proto_opt=unknownFields=true`, all unknown fields will be parsed and output as arrays of buffers.\n    \n-   With `--ts_proto_opt=onlyTypes=true`, only types will be emitted, and imports for `long` and `protobufjs/minimal` will be excluded.\n    \n    This is the same as setting `outputJsonMethods=false,outputEncodeMethods=false,outputClientImpl=false,nestJs=false`\n    \n-   With `--ts_proto_opt=usePrototypeForDefaults=true`, the generated code will wrap new objects with `Object.create`.\n    \n    This allows code to do hazzer checks to detect when default values have been applied, which due to proto3's behavior of not putting default values on the wire, is typically only useful for interacting with proto2 messages.\n    \n    When enabled, default values are inherited from a prototype, and so code can use Object.keys().includes(\"someField\") to detect if someField was actually decoded or not.\n    \n    Note that, as indicated, this means Object.keys will not include set-by-default fields, so if you have code that iterates over messages keys in a generic fashion, it will have to also iterate over keys inherited from the prototype.\n    \n-   With `--ts_proto_opt=useJsonName=true`, `json_name` defined in protofiles will be used instead of message field names.\n    \n-   With `--ts_proto_opt=useJsonWireFormat=true`, the generated code will reflect the JSON representation of Protobuf messages.\n    \n    Requires `onlyTypes=true`. Implies `useDate=string` and `stringEnums=true`. This option is to generate types that can be directly used with marshalling/unmarshalling Protobuf messages serialized as JSON. You may also want to set `useOptionals=all`, as gRPC gateways are not required to send default value for scalar values.\n    \n-   With `--ts_proto_opt=useNumericEnumForJson=true`, the JSON converter (`toJSON`) will encode enum values as int, rather than a string literal.\n    \n-   With `--ts_proto_opt=initializeFieldsAsUndefined=false`, all optional field initializers will be omitted from the generated base instances. This can be useful if you're using Next.js and `getServerSideProps`, see [#492](https://github.com/stephenh/ts-proto/issues/492). The default is `true` to ideally get the best v8 performance by avoiding \"changing shapes\" as fields are incrementally set.\n    \n-   With `--ts_proto_opt=disableProto2Optionals=true`, all optional fields on proto2 files will not be set to be optional. Please note that this flag is primarily for preserving ts-proto's legacy handling of proto2 files, to avoid breaking changes, and as a result, it is not intended to be used moving forward.\n    \n-   With `--ts_proto_opt=disableProto2DefaultValues=true`, all fields in proto2 files that specify a default value will not actually use that default value. Please note that this flag is primarily for preserving ts-proto's legacy handling of proto2 files, to avoid breaking changes, and as a result, it is not intended to be used moving forward.\n    \n-   With `--ts_proto_opt=Mgoogle/protobuf/empty.proto=./google3/protobuf/empty`, ('M' means 'importMapping', similar to [protoc-gen-go](https://developers.google.com/protocol-buffers/docs/reference/go-generated#package)), the generated code import path for `./google/protobuf/empty.ts` will reflect the overridden value:\n    \n    -   `Mfoo/bar.proto=@myorg/some-lib` will map `foo/bar.proto` imports into `import ... from '@myorg/some-lib'`.\n    -   `Mfoo/bar.proto=./some/local/lib` will map `foo/bar.proto` imports into `import ... from './some/local/lib'`.\n    -   `Mfoo/bar.proto=some-modules/some-lib` will map `foo/bar.proto` imports into `import ... from 'some-module/some-lib'`.\n    -   **Note**: Uses are accumulated, so multiple values are expected in the form of `--ts_proto_opt=M... --ts_proto_opt=M...` (one `ts_proto_opt` per mapping).\n    -   **Note**: Proto files that match mapped imports **will not be generated**.\n-   With `--ts_proto_opt=useMapType=true`, the generated code for protobuf `map<key_type, value_type>` will become `Map<key_type, value_type>` that uses JavaScript Map type.\n    \n    The default behavior is `useMapType=false`, which makes it generate the code for protobuf `map<key_type, value_type` with the key-value pair like `{[key: key_type]: value_type}`.\n    \n-   With `--ts_proto_opt=useReadonlyTypes=true`, the generated types will be declared as immutable using typescript's `readonly` modifier.\n    \n-   With `--ts_proto_opt=useSnakeTypeName=false` will remove snake casing from types.\n    \n    Example Protobuf\n    \n    message Box {\n        message Element {\n              message Image {\n                    enum Alignment {\n                          LEFT \\= 1;\n                          CENTER \\= 2;\n                          RIGHT \\= 3;\n                    }\n              }\n          }\n    }\n    \n    by default this is enabled which would generate a type of `Box_Element_Image_Alignment`. By disabling this option the type that is generated would be `BoxElementImageAlignment`.\n    \n-   With `--ts_proto_opt=outputExtensions=true`, the generated code will include proto2 extensions\n    \n    Extension encode/decode methods are compliant with the `outputEncodeMethods` option, and if `unknownFields=true`, the `setExtension` and `getExtension` methods will be created for extendable messages, also compliant with `outputEncodeMethods` (setExtension = encode, getExtension = decode).\n    \n-   With `--ts_proto_opt=outputIndex=true`, index files will be generated based on the proto package namespaces.\n    \n    This will disable `exportCommonSymbols` to avoid name collisions on the common symbols.\n    \n-   With `--ts_proto_opt=emitDefaultValues=json-methods`, the generated toJSON method will emit scalars like `0` and `\"\"` as json fields.\n    \n-   With `--ts_proto_opt=comments=false`, comments won't be copied from the proto files to the generated code.\n    \n\n...27391 bytes truncated...\n\nThe tool call succeeded but the output was truncated. Full output saved to: /Users/alex/.local/share/opencode/tool-output/tool_c64857b370013I98rsUw6yYMVh\nUse the Task tool to have explore agent process this file with Grep and Read (with offset/limit). Do NOT read the full file yourself - delegate to save context.",
            "title": "https://github.com/stephenh/ts-proto (text/html; charset=utf-8)",
            "metadata": {
              "truncated": true,
              "outputPath": "/Users/alex/.local/share/opencode/tool-output/tool_c64857b370013I98rsUw6yYMVh"
            },
            "time": {
              "start": 1771212994407,
              "end": 1771212995384
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_0fa23fc9d8021c4c01699290c258b48194882449f041e1af2a"
            }
          },
          "id": "prt_c64857751001s4bxOoUg3k3HN7",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64856487001uDn5pXIeDWowQH"
        },
        {
          "type": "tool",
          "callID": "call_RFtPA8kuFxy0dOhyvrVrI4KB",
          "tool": "webfetch",
          "state": {
            "status": "completed",
            "input": {
              "url": "https://github.com/timostamm/protobuf-ts",
              "format": "markdown"
            },
            "output": "                    GitHub - timostamm/protobuf-ts: Protobuf and RPC for TypeScript                                             \n\n[Skip to content](#start-of-content)   \n\n## Navigation Menu\n\nToggle navigation\n\n[](/)\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftimostamm%2Fprotobuf-ts)\n\nAppearance settings\n\n  \n\n-   Platform\n    \n    -   AI CODE CREATION\n        \n        -   [\n            \n            GitHub CopilotWrite better code with AI\n            \n            ](https://github.com/features/copilot)\n        -   [\n            \n            GitHub SparkBuild and deploy intelligent apps\n            \n            ](https://github.com/features/spark)\n        -   [\n            \n            GitHub ModelsManage and compare prompts\n            \n            ](https://github.com/features/models)\n        -   [\n            \n            MCP RegistryNewIntegrate external tools\n            \n            ](https://github.com/mcp)\n        \n    -   DEVELOPER WORKFLOWS\n        \n        -   [\n            \n            ActionsAutomate any workflow\n            \n            ](https://github.com/features/actions)\n        -   [\n            \n            CodespacesInstant dev environments\n            \n            ](https://github.com/features/codespaces)\n        -   [\n            \n            IssuesPlan and track work\n            \n            ](https://github.com/features/issues)\n        -   [\n            \n            Code ReviewManage code changes\n            \n            ](https://github.com/features/code-review)\n        \n    -   APPLICATION SECURITY\n        \n        -   [\n            \n            GitHub Advanced SecurityFind and fix vulnerabilities\n            \n            ](https://github.com/security/advanced-security)\n        -   [\n            \n            Code securitySecure your code as you build\n            \n            ](https://github.com/security/advanced-security/code-security)\n        -   [\n            \n            Secret protectionStop leaks before they start\n            \n            ](https://github.com/security/advanced-security/secret-protection)\n        \n    -   EXPLORE\n        \n        -   [Why GitHub](https://github.com/why-github)\n        -   [Documentation](https://docs.github.com)\n        -   [Blog](https://github.blog)\n        -   [Changelog](https://github.blog/changelog)\n        -   [Marketplace](https://github.com/marketplace)\n        \n    \n    [View all features](https://github.com/features)\n    \n-   Solutions\n    \n    -   BY COMPANY SIZE\n        \n        -   [Enterprises](https://github.com/enterprise)\n        -   [Small and medium teams](https://github.com/team)\n        -   [Startups](https://github.com/enterprise/startups)\n        -   [Nonprofits](https://github.com/solutions/industry/nonprofits)\n        \n    -   BY USE CASE\n        \n        -   [App Modernization](https://github.com/solutions/use-case/app-modernization)\n        -   [DevSecOps](https://github.com/solutions/use-case/devsecops)\n        -   [DevOps](https://github.com/solutions/use-case/devops)\n        -   [CI/CD](https://github.com/solutions/use-case/ci-cd)\n        -   [View all use cases](https://github.com/solutions/use-case)\n        \n    -   BY INDUSTRY\n        \n        -   [Healthcare](https://github.com/solutions/industry/healthcare)\n        -   [Financial services](https://github.com/solutions/industry/financial-services)\n        -   [Manufacturing](https://github.com/solutions/industry/manufacturing)\n        -   [Government](https://github.com/solutions/industry/government)\n        -   [View all industries](https://github.com/solutions/industry)\n        \n    \n    [View all solutions](https://github.com/solutions)\n    \n-   Resources\n    \n    -   EXPLORE BY TOPIC\n        \n        -   [AI](https://github.com/resources/articles?topic=ai)\n        -   [Software Development](https://github.com/resources/articles?topic=software-development)\n        -   [DevOps](https://github.com/resources/articles?topic=devops)\n        -   [Security](https://github.com/resources/articles?topic=security)\n        -   [View all topics](https://github.com/resources/articles)\n        \n    -   EXPLORE BY TYPE\n        \n        -   [Customer stories](https://github.com/customer-stories)\n        -   [Events & webinars](https://github.com/resources/events)\n        -   [Ebooks & reports](https://github.com/resources/whitepapers)\n        -   [Business insights](https://github.com/solutions/executive-insights)\n        -   [GitHub Skills](https://skills.github.com)\n        \n    -   SUPPORT & SERVICES\n        \n        -   [Documentation](https://docs.github.com)\n        -   [Customer support](https://support.github.com)\n        -   [Community forum](https://github.com/orgs/community/discussions)\n        -   [Trust center](https://github.com/trust-center)\n        -   [Partners](https://github.com/partners)\n        \n    \n-   Open Source\n    \n    -   COMMUNITY\n        \n        -   [\n            \n            GitHub SponsorsFund open source developers\n            \n            ](https://github.com/sponsors)\n        \n    -   PROGRAMS\n        \n        -   [Security Lab](https://securitylab.github.com)\n        -   [Maintainer Community](https://maintainers.github.com)\n        -   [Accelerator](https://github.com/accelerator)\n        -   [Archive Program](https://archiveprogram.github.com)\n        \n    -   REPOSITORIES\n        \n        -   [Topics](https://github.com/topics)\n        -   [Trending](https://github.com/trending)\n        -   [Collections](https://github.com/collections)\n        \n    \n-   Enterprise\n    \n    -   ENTERPRISE SOLUTIONS\n        \n        -   [\n            \n            Enterprise platformAI-powered developer platform\n            \n            ](https://github.com/enterprise)\n        \n    -   AVAILABLE ADD-ONS\n        \n        -   [\n            \n            GitHub Advanced SecurityEnterprise-grade security features\n            \n            ](https://github.com/security/advanced-security)\n        -   [\n            \n            Copilot for BusinessEnterprise-grade AI features\n            \n            ](https://github.com/features/copilot/copilot-business)\n        -   [\n            \n            Premium SupportEnterprise-grade 24/7 support\n            \n            ](https://github.com/premium-support)\n        \n    \n-   [Pricing](https://github.com/pricing)\n\nSearch or jump to...\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch\n\nClear\n\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n\n# Provide feedback\n\nWe read every piece of feedback, and take your input very seriously.\n\n Include my email address so I can be contacted\n\nCancel Submit feedback\n\n# Saved searches\n\n## Use saved searches to filter your results more quickly\n\nName  \n\nQuery \n\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\n\nCancel Create saved search\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftimostamm%2Fprotobuf-ts)\n\n[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=timostamm%2Fprotobuf-ts)\n\nAppearance settings\n\nResetting focus\n\nYou signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\n\n[timostamm](/timostamm) / **[protobuf-ts](/timostamm/protobuf-ts)** Public\n\n-   [Notifications](/login?return_to=%2Ftimostamm%2Fprotobuf-ts) You must be signed in to change notification settings\n-   [Fork 149](/login?return_to=%2Ftimostamm%2Fprotobuf-ts)\n-   [Star 1.3k](/login?return_to=%2Ftimostamm%2Fprotobuf-ts)\n    \n\nProtobuf and RPC for TypeScript\n\n### License\n\n[Apache-2.0 license](/timostamm/protobuf-ts/blob/main/LICENSE)\n\n[1.3k stars](/timostamm/protobuf-ts/stargazers) [149 forks](/timostamm/protobuf-ts/forks) [Branches](/timostamm/protobuf-ts/branches) [Tags](/timostamm/protobuf-ts/tags) [Activity](/timostamm/protobuf-ts/activity)\n\n[Star](/login?return_to=%2Ftimostamm%2Fprotobuf-ts)\n\n[Notifications](/login?return_to=%2Ftimostamm%2Fprotobuf-ts) You must be signed in to change notification settings\n\n-   [Code](/timostamm/protobuf-ts)\n-   [Issues 61](/timostamm/protobuf-ts/issues)\n-   [Pull requests 9](/timostamm/protobuf-ts/pulls)\n-   [Discussions](/timostamm/protobuf-ts/discussions)\n-   [Actions](/timostamm/protobuf-ts/actions)\n-   [Security 0](/timostamm/protobuf-ts/security)\n-   [Insights](/timostamm/protobuf-ts/pulse)\n\nAdditional navigation options\n\n-   [Code](/timostamm/protobuf-ts)\n-   [Issues](/timostamm/protobuf-ts/issues)\n-   [Pull requests](/timostamm/protobuf-ts/pulls)\n-   [Discussions](/timostamm/protobuf-ts/discussions)\n-   [Actions](/timostamm/protobuf-ts/actions)\n-   [Security](/timostamm/protobuf-ts/security)\n-   [Insights](/timostamm/protobuf-ts/pulse)\n\n# timostamm/protobuf-ts\n\n   \n\n¬†main\n\n[Branches](/timostamm/protobuf-ts/branches)[Tags](/timostamm/protobuf-ts/tags)\n\n[](/timostamm/protobuf-ts/branches)[](/timostamm/protobuf-ts/tags)\n\nGo to file\n\nCode\n\nOpen more actions menu\n\n## Folders and files\n\nName\n\nName\n\nLast commit message\n\nLast commit date\n\n## Latest commit\n\n## History\n\n[817 Commits](/timostamm/protobuf-ts/commits/main/)\n\n[](/timostamm/protobuf-ts/commits/main/)817 Commits\n\n[.github](/timostamm/protobuf-ts/tree/main/.github \".github\")\n\n[.github](/timostamm/protobuf-ts/tree/main/.github \".github\")\n\n[packages](/timostamm/protobuf-ts/tree/main/packages \"packages\")\n\n[packages](/timostamm/protobuf-ts/tree/main/packages \"packages\")\n\n[scripts](/timostamm/protobuf-ts/tree/main/scripts \"scripts\")\n\n[scripts](/timostamm/protobuf-ts/tree/main/scripts \"scripts\")\n\n[.gitignore](/timostamm/protobuf-ts/blob/main/.gitignore \".gitignore\")\n\n[.gitignore](/timostamm/protobuf-ts/blob/main/.gitignore \".gitignore\")\n\n[.nvmrc](/timostamm/protobuf-ts/blob/main/.nvmrc \".nvmrc\")\n\n[.nvmrc](/timostamm/protobuf-ts/blob/main/.nvmrc \".nvmrc\")\n\n[CONTRIBUTING.md](/timostamm/protobuf-ts/blob/main/CONTRIBUTING.md \"CONTRIBUTING.md\")\n\n[CONTRIBUTING.md](/timostamm/protobuf-ts/blob/main/CONTRIBUTING.md \"CONTRIBUTING.md\")\n\n[LICENSE](/timostamm/protobuf-ts/blob/main/LICENSE \"LICENSE\")\n\n[LICENSE](/timostamm/protobuf-ts/blob/main/LICENSE \"LICENSE\")\n\n[MANUAL.md](/timostamm/protobuf-ts/blob/main/MANUAL.md \"MANUAL.md\")\n\n[MANUAL.md](/timostamm/protobuf-ts/blob/main/MANUAL.md \"MANUAL.md\")\n\n[README.md](/timostamm/protobuf-ts/blob/main/README.md \"README.md\")\n\n[README.md](/timostamm/protobuf-ts/blob/main/README.md \"README.md\")\n\n[buf.yaml](/timostamm/protobuf-ts/blob/main/buf.yaml \"buf.yaml\")\n\n[buf.yaml](/timostamm/protobuf-ts/blob/main/buf.yaml \"buf.yaml\")\n\n[package-lock.json](/timostamm/protobuf-ts/blob/main/package-lock.json \"package-lock.json\")\n\n[package-lock.json](/timostamm/protobuf-ts/blob/main/package-lock.json \"package-lock.json\")\n\n[package.json](/timostamm/protobuf-ts/blob/main/package.json \"package.json\")\n\n[package.json](/timostamm/protobuf-ts/blob/main/package.json \"package.json\")\n\n[turbo.json](/timostamm/protobuf-ts/blob/main/turbo.json \"turbo.json\")\n\n[turbo.json](/timostamm/protobuf-ts/blob/main/turbo.json \"turbo.json\")\n\nView all files\n\n## Repository files navigation\n\n-   [README](#)\n-   [Contributing](#)\n-   [Apache-2.0 license](#)\n\n# protobuf-ts [![npm](https://camo.githubusercontent.com/6bbffe91a3a3234a844d44bd4f6191d0a766df4e30230f1617592e9ae872658c/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f762f4070726f746f6275662d74732f706c7567696e3f78)](https://www.npmjs.com/package/@protobuf-ts/plugin)\n\n[](#protobuf-ts-)\n\n[Protocol buffers](https://developers.google.com/protocol-buffers) and [RPC](https://en.wikipedia.org/wiki/Remote_procedure_call) for Node.js and the Web Browser. Pure TypeScript.\n\nFor the following `.proto` file:\n\nsyntax \\= \"proto3\";\n\nmessage Person {\n    string name \\= 1;\n    uint64 id \\= 2;\n    int32 years \\= 3;\n    optional bytes data \\= 5;\n}\n\n`protobuf-ts` generates code that can be used like this:\n\nlet pete: Person \\= {\n    name: \"pete\", \n    id: 123n, // it's a bigint\n    years: 30\n    // data: new Uint8Array(\\[0xDE, 0xAD, 0xBE, 0xEF\\]);\n};\n\nlet bytes \\= Person.toBinary(pete);\npete \\= Person.fromBinary(bytes);\n\npete \\= Person.fromJsonString('{\"name\":\"pete\", \"id\":\"123\", \"years\": 30}')\n\n### What are protocol buffers?\n\n[](#what-are-protocol-buffers)\n\nProtocol buffers is an [interface definition language](https://en.wikipedia.org/wiki/Interface_description_language) and binary serialization format.  \nData structures defined in `.proto` files are platform-independent and can be used in many languages.  \nTo learn more about the capabilities, please check the official [language guide](https://developers.google.com/protocol-buffers/docs/overview).\n\n### Quickstart\n\n[](#quickstart)\n\n-   `npm install --save-dev @protobuf-ts/plugin protoc`\n    \n    > installs the plugin and the compiler \"protoc\"\n    \n-   download the example file [msg-readme.proto](https://raw.githubusercontent.com/timostamm/protobuf-ts/main/packages/proto/msg-readme.proto) and place it into a `protos/` directory\n    \n-   `npx protoc --ts_out . --proto_path protos protos/msg-readme.proto`\n    \n    > generates msg-readme.ts  \n    > if your protoc version asks for it, add the flag \"--experimental\\_allow\\_proto3\\_optional\"\n    \n\n### Features\n\n[](#features)\n\n-    implements the [canonical proto3 JSON format](/timostamm/protobuf-ts/blob/main/MANUAL.md#json-format)\n-    implements the [binary format](/timostamm/protobuf-ts/blob/main/MANUAL.md#binary-format) and respects [unknown fields](/timostamm/protobuf-ts/blob/main/MANUAL.md#unknown-field-handling)\n-    strictly [conforms to the protobuf spec](/timostamm/protobuf-ts/blob/main/MANUAL.md#conformance)\n-    generates clients that can be used with the [gRPC web](/timostamm/protobuf-ts/blob/main/MANUAL.md#grpc-web-transport), [Twirp](/timostamm/protobuf-ts/blob/main/MANUAL.md#twirp-transport) or [gRPC](/timostamm/protobuf-ts/blob/main/MANUAL.md#grpc-transport) protocol\n-    generates [native gRPC servers](/timostamm/protobuf-ts/blob/main/MANUAL.md#native-grpc-server) and [clients](/timostamm/protobuf-ts/blob/main/MANUAL.md#native-grpc-client) for usage with `@grpc/grpc-js`\n-    supported by [Twirp-TS](https://github.com/hopin-team/twirp-ts) for Twirp servers running on Node.js\n-    can optimize for [speed or code size](/timostamm/protobuf-ts/blob/main/MANUAL.md#code-size-vs-speed)\n-    supports [proto3 optionals](/timostamm/protobuf-ts/blob/main/MANUAL.md#proto3-optionals)\n-    [supports bigint](/timostamm/protobuf-ts/blob/main/MANUAL.md#bigint-support) for 64 bit integers\n-    every [message type](/timostamm/protobuf-ts/blob/main/MANUAL.md#imessagetype) has methods to compare, clone, merge and type guard messages\n-    provides [reflection information](/timostamm/protobuf-ts/blob/main/MANUAL.md#reflection), including [custom options](/timostamm/protobuf-ts/blob/main/MANUAL.md#custom-options)\n-    supports all [well-known-types](/timostamm/protobuf-ts/blob/main/MANUAL.md#well-known-types) with custom JSON representation and helper methods\n-    uses standard [TypeScript enums](/timostamm/protobuf-ts/blob/main/MANUAL.md#enum-representation)\n-    runs [in the Web Browser](/timostamm/protobuf-ts/blob/main/MANUAL.md#running-in-the-web-browser) and in [Node.js](/timostamm/protobuf-ts/blob/main/MANUAL.md#running-in-nodejs)\n-    uses an [algebraic data type for oneof](/timostamm/protobuf-ts/blob/main/MANUAL.md#oneof-representation) groups\n-    can generate TypeScript [or JavaScript](/timostamm/protobuf-ts/blob/main/MANUAL.md#outputting-javascript)\n-    available as a [plugin on the BSR](https://github.com/timostamm/protobuf-ts/tree/master/packages/bsr-plugin)\n-    can be [used with buf](https://github.com/timostamm/protobuf-ts/issues/93)\n\nRead the [MANUAL](/timostamm/protobuf-ts/blob/main/MANUAL.md) to learn more.\n\n### Copyright\n\n[](#copyright)\n\n-   The [code to decode UTF8](/timostamm/protobuf-ts/blob/main/packages/runtime/src/protobufjs-utf8.ts) is Copyright 2016 by Daniel Wirtz, licensed under BSD-3-Clause.\n-   The [code to encode and decode varint](/timostamm/protobuf-ts/blob/main/packages/runtime/src/goog-varint.ts) is Copyright 2008 Google Inc., licensed under BSD-3-Clause.\n-   The [gRPC status codes](/timostamm/protobuf-ts/blob/main/packages/grpcweb-transport/src/goog-grpc-status-code.ts) are Copyright 2016 gRPC authors, licensed under Apache-2.0.\n-   The [Twirp error codes](/timostamm/protobuf-ts/blob/main/packages/twirp-transport/src/twitch-twirp-error-code.ts) are Copyright 2018 Twitch Interactive, Inc., licensed under Apache-2.0.\n-   The proto files in [proto/google](/timostamm/protobuf-ts/blob/main/packages/proto/google) are Copyright Google Inc. / Google LLC, licensed under Apache-2.0 / BSD-3-Clause.\n-   All other files are licensed under Apache-2.0, see [LICENSE](/timostamm/protobuf-ts/blob/main/LICENSE).\n\n### Support\n\n[](#support)\n\n[![Buy Me A Coffee](https://camo.githubusercontent.com/0cf29a542375e1a46e84d8bf5805a4e5c0a6ee98b6547ccdc0c55eed49d99c69/68747470733a2f2f63646e2e6275796d6561636f666665652e636f6d2f627574746f6e732f76322f64656661756c742d79656c6c6f772e706e67)](https://www.buymeacoffee.com/timostamm)\n\n## About\n\nProtobuf and RPC for TypeScript\n\n### Topics\n\n[reflection](/topics/reflection \"Topic: reflection\") [typescript](/topics/typescript \"Topic: typescript\") [protobuf](/topics/protobuf \"Topic: protobuf\") [protocol-buffers](/topics/protocol-buffers \"Topic: protocol-buffers\") [bigint](/topics/bigint \"Topic: bigint\") [grpc-server](/topics/grpc-server \"Topic: grpc-server\") [grpc-web](/topics/grpc-web \"Topic: grpc-web\") [grpc-client](/topics/grpc-client \"Topic: grpc-client\") [custom-options](/topics/custom-options \"Topic: custom-options\") [twirp](/topics/twirp \"Topic: twirp\") [code-size](/topics/code-size \"Topic: code-size\") [well-known-types](/topics/well-known-types \"Topic: well-known-types\") [strict-conformance](/topics/strict-conformance \"Topic: strict-conformance\")\n\n### Resources\n\n[Readme](#readme-ov-file)\n\n### License\n\n[Apache-2.0 license](#Apache-2.0-1-ov-file)\n\n### Contributing\n\n[Contributing](#contributing-ov-file)\n\n### Uh oh!\n\nThere was an error while loading. Please reload this page.\n\n[Activity](/timostamm/protobuf-ts/activity)\n\n### Stars\n\n[**1.3k** stars](/timostamm/protobuf-ts/stargazers)\n\n### Watchers\n\n[**13** watching](/timostamm/protobuf-ts/watchers)\n\n### Forks\n\n[**149** forks](/timostamm/protobuf-ts/forks)\n\n[Report repository](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Ftimostamm%2Fprotobuf-ts&report=timostamm+%28user%29)\n\n## [Releases 60](/timostamm/protobuf-ts/releases)\n\n[\n\nv2.11.1 Latest\n\nJun 18, 2025\n\n\n\n](/timostamm/protobuf-ts/releases/tag/v2.11.1)\n\n[\\+ 59 releases](/timostamm/protobuf-ts/releases)\n\n## [Used by 5.9k](/timostamm/protobuf-ts/network/dependents)\n\n[\n\n-   ![@jocelynthode](https://avatars.githubusercontent.com/u/3967312?s=64&v=4)\n-   ![@kevin-mind](https://avatars.githubusercontent.com/u/68553846?s=64&v=4)\n-   ![@firetop0011](https://avatars.githubusercontent.com/u/121939987?s=64&v=4)\n-   ![@Refina123](https://avatars.githubusercontent.com/u/103622500?s=64&v=4)\n-   ![@dpk](https://avatars.githubusercontent.com/u/378375?s=64&v=4)\n-   ![@Akusher23](https://avatars.githubusercontent.com/u/128720144?s=64&v=4)\n-   ![@Hexlet](https://avatars.githubusercontent.com/u/2685047?s=64&v=4)\n-   ![@mroi](https://avatars.githubusercontent.com/u/1226345?s=64&v=4)\n\n\\+ 5,900](/timostamm/protobuf-ts/network/dependents)\n\n## [Contributors 42](/timostamm/protobuf-ts/graphs/contributors)\n\n-   [![@timostamm](https://avatars.githubusercontent.com/u/4289451?s=64&v=4)](https://github.com/timostamm)\n-   [![@dependabot[bot]](https://avatars.githubusercontent.com/in/29110?s=64&v=4)](https://github.com/apps/dependabot)\n-   [![@jcready](https://avatars.githubusercontent.com/u/358876?s=64&v=4)](https://github.com/jcready)\n-   [![@smaye81](https://avatars.githubusercontent.com/u/911455?s=64&v=4)](https://github.com/smaye81)\n-   [![@dependabot-preview[bot]](https://avatars.githubusercontent.com/in/2141?s=64&v=4)](https://github.com/apps/dependabot-preview)\n-   [![@be9](https://avatars.githubusercontent.com/u/920?s=64&v=4)](https://github.com/be9)\n-   [![@vicb](https://avatars.githubusercontent.com/u/248818?s=64&v=4)](https://github.com/vicb)\n-   [![@kskalski](https://avatars.githubusercontent.com/u/775012?s=64&v=4)](https://github.com/kskalski)\n-   [![@dimo414](https://avatars.githubusercontent.com/u/1885701?s=64&v=4)](https://github.com/dimo414)\n-   [![@sessfeld](https://avatars.githubusercontent.com/u/7796724?s=64&v=4)](https://github.com/sessfeld)\n-   [![@GoGurtPrime](https://avatars.githubusercontent.com/u/10246886?s=64&v=4)](https://github.com/GoGurtPrime)\n-   [![@whs](https://avatars.githubusercontent.com/u/345483?s=64&v=4)](https://github.com/whs)\n-   [![@lqs](https://avatars.githubusercontent.com/u/501269?s=64&v=4)](https://github.com/lqs)\n-   [![@stefanvanburen](https://avatars.githubusercontent.com/u/622527?s=64&v=4)](https://github.com/stefanvanburen)\n\n[\\+ 28 contributors](/timostamm/protobuf-ts/graphs/contributors)\n\n## Languages\n\n-   [TypeScript 99.9%](/timostamm/protobuf-ts/search?l=typescript)\n-   Other 0.1%\n\n## Footer\n\n[](https://github.com)¬© 2026 GitHub,¬†Inc.\n\n### Footer navigation\n\n-   [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n-   [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n-   [Security](https://github.com/security)\n-   [Status](https://www.githubstatus.com/)\n-   [Community](https://github.community/)\n-   [Docs](https://docs.github.com/)\n-   [Contact](https://support.github.com?tags=dotcom-footer)\n-   Manage cookies\n-   Do not share my personal information\n\nYou can‚Äôt perform that action at this time.",
            "title": "https://github.com/timostamm/protobuf-ts (text/html; charset=utf-8)",
            "metadata": {
              "truncated": false
            },
            "time": {
              "start": 1771212994428,
              "end": 1771212995244
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_0fa23fc9d8021c4c01699290c258c48194b6eaa4308dcada71"
            }
          },
          "id": "prt_c64857767001VBmoo00lMFNytx",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64856487001uDn5pXIeDWowQH"
        },
        {
          "type": "tool",
          "callID": "call_xfHO3to9iu2DQmziS0RH9qln",
          "tool": "webfetch",
          "state": {
            "status": "error",
            "input": {
              "url": "https://www.npmjs.com/package/ts-proto",
              "format": "markdown"
            },
            "error": "Error: Request failed with status code: 403",
            "time": {
              "start": 1771212994430,
              "end": 1771212994740
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_0fa23fc9d8021c4c01699290c258cc8194bc57e5e45799d8fa"
            }
          },
          "id": "prt_c6485777d0011rushhTiwY8LHh",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64856487001uDn5pXIeDWowQH"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "5147fb7468d78f726061bbed9b56e547e848c4bd",
          "cost": 0,
          "tokens": {
            "total": 72325,
            "input": 7555,
            "output": 130,
            "reasoning": 22,
            "cache": {
              "read": 64640,
              "write": 0
            }
          },
          "id": "prt_c64857b3a001V7nZ11caoQV2ib",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64856487001uDn5pXIeDWowQH"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771212995434,
          "completed": 1771213009504
        },
        "parentID": "msg_c6484620d0011ltzji40BSbVp5",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 91907,
          "input": 19062,
          "output": 653,
          "reasoning": 619,
          "cache": {
            "read": 72192,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "tool-calls",
        "id": "msg_c64857b6a001ebLiNCtMnknqZV",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "5147fb7468d78f726061bbed9b56e547e848c4bd",
          "id": "prt_c6485837b001RmJN8B1n6A92Q3",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64857b6a001ebLiNCtMnknqZV"
        },
        {
          "type": "reasoning",
          "text": "**Gathering protoc usage details**",
          "metadata": {
            "openai": {
              "itemId": "rs_0340425095c0c74501699290c660188195965ba8c0ea931143",
              "reasoningEncryptedContent": "gAAAAABpkpDRAAcIVIaP4D8xEDjvIrHz81U7BU7yMYYdfx-O4C0LP4nv0ukb1OKO_d4wcxxSlpsitxIn6AnBGuxhmpxM6YbqzRoT7Y4lcqKZNFUCeYp6rAyo4L3pjxCb-oZtigGqJF1G5POjtqLMwhfSWY-2a8QuZmtpiun-r6kCumRkSCQ8BmSNhK1VbmofPbdFz051qWfO_C81csK9CeTx69PLGI7KLGeS0iNWF1QgmF4f7yNv3nLra04SK-bGpOPJjxMd0zfvRGlBQD-IOs4nlen8jxrsEt-y0NILd-0ysqhkU6X7dirtPeJ1wPM240PwfdGICx11ZTRULMZl4A4--mthaTfmJ4FK5p1ZdsC-fuHPPjfILEQQUbkSL3IYgXPyKiRijhql53O_WO0-xUQXYgw_VfnPRyxv0Wl2i8D-uwlIlOxiCWOtvQ1Q-NyAOx5hzWduF9iYImooT2PjVkEV39lWz8fgpdt_wQrLIy3y9ZK9lYzkrjJ57Va_3BWyaGujWoHb8PzFvWyeZq2_1HeduxO8OuoER0-DUtMNUbP56r1twghBZAtPj_6im7I7geWeoEyOIvT_bKmpkpdY2AbLAK0DxpmfMKnxR4nvEVfC7KqvVQOfbFjT8cWwF7fMWwYiqVGSFPH2Sn_zapk7toFJhhit-eCVCuYEJYiEl-7l1IeJJFizvP0akU6KTJOIXMa_YPBRgeuFQtm2gNd3XIk2ghBEfDVxxcL3RXVqGWyMJ1_q7xmL2iz05RsgrEa6YSsRAoJysUqx4Q3vqS8QAKqCLiWF77oKBg_S1cRVkW_sAz40lSdYYp8-_OOCWcNL47IE0sCuHTaEtU25GBSwIPJn85QCwg_4o1k7bnEuHHVL8WM6JX1PGUKU04Zd-X54A8_EXn6ZaEJs2cvu4d3RHiIoSx98N37ZZGmUlhGfg_wWLn6D_grKRxEndurY9XAiN8r6GQZZI-7lssVJlLPofkern_2zW11NkNcg2w3WLgeW0D4CzTcKRz1_ygXoV49ObmSIqqDVfhmQO7Sqj1ZZUgUzGSxCmUiGo9orCBPzecK33PijbV8ALL2-YWfiDWlScfmJkR_ydUMDPshKJEQ_KCSVQ_F1NzSDh6C5BgXm0Xq8c7BmvSpKSAzES9q0AmVcNx6YDj1eENo48Wn9iDIExqTWHWUM7bg5BB5YXYc5VZwx7zTqcnN1X2uwpQrrpQhCvrf74KJjKUpPRoyEdavH3UMtKhSQjMudmc2ueAVCYowTjGsEDmhmQxB31wJvULOvBLyLmZs-gsp6MaAESkBWZuG-cPX3n3GjfTKxtoLCwx_a5yNY3gnK3BO4LbO-WJPHE9ZMSk-KuVqCYKPNZy5XN27KGFjY00PCmh9pBDNqf4f-75e1P14c9SmzuUv7no3vGpkwopY6cSLVPGvmqhLw5BHJSv5BQ-dwRXn0mgRaep7elcdAmXQ96G3f21QcQ717scmhByX_IB8lJP4t6cX33iLkINvGfhgTDeTL22IuZ6Y5opPBT0bbc2Xb0pPWNG9q20AMTmtKz5r_kAlRBjG6nBQbJXawGlAlXC1Azdf7HHr2CaB1woGTA1vBsPlMd1-IePf3F-OhgfcSWaMIUgrSCdwGaiwt2aSounSo3pGlEbegbLNaWsrymvaT9e8iG4fZd4j5TKd5N0a6Uz2zT7Svb2ZdFJhu-HtVAsR3SH80paLouPSQsxjDLuLfoCnXZ9_6OIjS98tTKFYsD66czQjiW3WxfcWt66UdEOVe1yu8RwGUL5vVJaPqkMbv0dIe6K8FyfGH5FZN3L1PmEMrbTMZZyuGsWvSeHUGJ8F9vgu1FuE6oyeNigNGs_QpwmQqlNAGX-Ku9V7wGWUE-JJ4UIGzshvnH0plD_sMJ_WG2zInHohNlbA8JjPZayRecsL9ta4J7hNXJNs29adtKYo-k61rCUJKcOAhk2JQwGx3JU2TT3Xh3ployuvSKYJbeLAVMjZE_wW047AKSxCEHVdcrIN1hCjoARqe5SowKMOxTscQHkWKnSP-Uz50WGrtHkmmA4FiH9At3GqHRzsDG-pbzg-R3GEPbANVvL7lgbgBQoWpqV6RDBbZIKoby68MYOfZ0QD9AXSrwIsDHgnzhLFg9JVeJPZlt1wByfc-Z1BnZSICvBPcLhj_PY19kDNIMAs4f4kycXvU1TA47SjZjED3D7g7BB4b_jDLjhuYiymNup_CqWdKFMC_wvpOMfqilF-8257nYUJ0PT8bU9EzID2_rd0Ox4o_BWQBGmKSYoySy8NsReXVX4WE-dtUli5PVMteBxUFhXZan7Hd8jKpx8BU-JojuN6bUVOED1oKTX4pcg3zOkv9faA-pHtlI4jcQV7qP8zLi5XE82UzioUvVNocp8bGM0Kximy2wHXbyJFlX4kw762_ITA_76LfqiL5U-wUdN5_cMYcXoJX7uQkbZ9paQT74SS9U9_mdnN_r8g3vO6neXkaLF9SSUfWOMzLnnI-YCYL1YnaMumv0nWpHhU0NNNJO-uPjTQ3T1FqIx1hwqdpu_p-NSEO_XxqRTnlyiTzysCVMsfm4jOW-CoKClqBreEHJoYBTJMhYmeY4R9JHvkvHZYa2UNLfxIqAr7uvJv3-BGFSc075bO6jxOOwpN1Y3gnc0ou-jN76g6otJpxsfkVwMWrsanVBlrclfeu2Vp85zQZDvWhkwQDxXJst6PstApjAHtc_OvoyJiwCVYYh_F0UEIhlNAHxRHWs4xvQ_pxxGaVAz6tNfLbhga8t49OzmWasfxLCt3ryUc7QhdY2koZAKrEUcPiq76jSYJY1AQ3XLQhe-cRsYji5BxV4Kt6U77mnkqysGtpwYr7ECBeeEczKzQmBaWUt_hlBUY1ck9StWhNhdT5fyb_cpCzwvrGze-J6PA1F-Z7Po9Uh-NDbxzwe2gadFOIE_EOYMhCXBDbOmjw4FfWzwHKhzA7UxZIProVsYEztKP30l1h2lQRJGDk-DEyG2aINu9FNxb0Kkhhjj7CAr6dgWUUs12aRHYsY46fLrNJracxXIT8RNfaEa0dpOBhn491Ih7B2fR3oHE_R8lV8RsqIsc-GUaTFpqG0rHGwJb-TrquVChUjtHVW4dvq4CdK0p-iWEsZ_1OHErspSlqwoDCYmMZv2NbdpNRSAByeGGIWN73vrN5h1iQGOxdg03AvuB2uNelCBjjRBUCwp2BzHOHOWMCyOBlap66nkjoFAlq4k56Y4jvBNsNEdz69o3vP1gHpRLj_KBI0ucAptZ6cHazTQd0ZLl9r0vMZibNbGnvl6f2RwrCIgy1TvlODr7TZ_QKbQVywLFh4UJeuGDbeFC6i8CKNJ_Sa3dmt0A14CODALFfuziir9V11fXpkfQ2up6ocGLYlCohiwoRK0f6HW-gu7316bjaHfpoqxzhSEaxZ7Gc-2YtzefWaGa7oncULMiKmp_of3n_-yN-e9f7ZeCpMb-r6ycWZnEBEq-Gu-o_N-UPqa9tLwJIHqxSmbxuCkxip_CdOehji3m7bGb0YoiInS49Ce8EhBQ8cH82MWKP2-TCJyEzFs4bowUcu8CrJQQw8HUWvjqgbdSwa5FI_ZMVbWBmuoRxx_VVxG2zf0twHjPXEalDnzMJeBKShcJwqQifr-6YQU0EWrXKkAErz6S7iCl1D8mGoWIdenPLlE1XdIgPPy37tjJO1TvJgSQw4g-OwBrIzirRNRk-W0s4-Q06lZ4vSNHUo8OeiXd-WPAjrrlgzyD_029R4FODpSKDfAtbMj1mClplwLYqZu9Q_r744Au7AyY1bNi3-dErSkEyEOcqWhQfpSNUQ1Y8S3xKEkPwLMWd_n95OaN8LhOhK4Rekcnfbc3-HfNZYSxqLsEWDVM1NxWDag22-Ga0_RwgL64FriAZvUcKDWjXj3GhVkafPsQ5wI0GEXwo-qt5aHXJw0ff2XUODWsp1FEA6h4EQJGsXpCkgAskp-OQqqW06vFCzftbiMJtz5B6VTA14Yf9twib56HxKgW1G4HNnId252cPENTQx24z3loBSemQgmz6LdF1RZGiBKZy8Dkn7j9uQqUKsqXek4L1BZveRA8XCIkWYuvKBoSWb4FBbwOu_0l5-e1WPoMberPXgBCba3zAgyg8_QbdXR9dUVt51T_uySz9Om2p8hcFR8MHX1-SMdgn8hZVThnfcjSfjTMkBSVDxsNp5C4mGNfF6gHZLyR9Lxc7U0FGzAoBBnkPbDhw3uVvpC-1ETwjUykNfIUEELExGL_4OtQF-CeY0zAeqNjVVp8197Aq8wrlkl_t2lxuqDBSjXYWX3-BIbqjSkWVe1x0bYVs6lOMVoKmbF4tJKf17nEd2t5E-LcnlkB7QsedFXsLJ_iTcUJUGudNk7HoRC_V0NQDxaNYicuw55Z69HHBH__Axp6b2Jg6rZfHOXJieM0srvwa9AhWJZTBJp2APp8lMUW8FvhzH2x0Zkcr8d0kR4pKb5PxuSI-H7BnW-kIYcfLJsJVIvR5JjB834CSrivrB1t7SdKXv4wu4UxKDdl2jrdYkPakAbol3B8_gg1QVAT4jqvDCzvanRfrAuRyOVirsIzDaF6iQCiLNrcOWt6ZIMJezZXW38m4vIPa1h0tpSCCdHAESsjkVHvD8FAyi6KhRoY46QAWwYfwkFYasPUybWOoRpmJRqU_cPXym4-8yOmvLmDvPcLC0J3GtmdCzrNViCz08d1eIZ8ieh39hY3Fgdg5GWVZvdPr7hCQonQ1Z0b5T2_oMbqjprMpLKyRMi7AhWjpsmdYP2vcokPfmCFrUJJ-HgUUiApFeFKOqd3_ns5DXl9RGADsFHs1oY5HBtrG9KOCyLkwmDt6xOPBbSJc__VrlJKScwY="
            }
          },
          "time": {
            "start": 1771212998406,
            "end": 1771213009101
          },
          "id": "prt_c64858706001UFDhphdQgFhBHr",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64857b6a001ebLiNCtMnknqZV"
        },
        {
          "type": "tool",
          "callID": "call_3JlYf7Z5xVnk0mTDoaydlVob",
          "tool": "webfetch",
          "state": {
            "status": "completed",
            "input": {
              "url": "https://protobuf.dev/reference/rust/rust-generated/",
              "format": "markdown"
            },
            "output": "Rust Generated Code Guide | Protocol Buffers Documentation \n\n[Protocol Buffers Documentation](/)\n\n-   [Protocol Buffers](/)\n    -   [Overview](/overview/)\n    -   [Protoc Installation](/installation/ \"Protocol Buffer Compiler Installation\")\n    -   [News](/news/)\n    -   [Programming Guides](/programming-guides/)\n        -   [Language Guide (editions)](/programming-guides/editions/)\n        -   [Language Guide (proto 2)](/programming-guides/proto2/)\n        -   [Language Guide (proto 3)](/programming-guides/proto3/)\n        -   [Proto Limits](/programming-guides/proto-limits/)\n        -   [Style Guide](/programming-guides/style/)\n        -   [Enum Behavior](/programming-guides/enum/)\n        -   [Encoding](/programming-guides/encoding/)\n        -   [ProtoJSON Format](/programming-guides/json/)\n        -   [Techniques](/programming-guides/techniques/)\n        -   [Add-ons](/programming-guides/addons/ \"Third-Party Add-ons\")\n        -   [Extension Declarations](/programming-guides/extension_declarations/)\n        -   [Field Presence](/programming-guides/field_presence/ \"Application Note: Field Presence\")\n        -   [Proto Serialization Is Not Canonical](/programming-guides/serialization-not-canonical/)\n        -   [Deserializing Debug Proto Representations](/programming-guides/deserialize-debug/)\n    -   [Protobuf Editions](/editions/)\n        -   [Overview](/editions/overview/ \"Protobuf Editions Overview\")\n        -   [Feature Settings for Editions](/editions/features/)\n        -   [Implementing Editions Support](/editions/implementation/)\n    -   [Design Decisions](/design-decisions/ \"Protobuf Team Design Decisions\")\n        -   [No Nullable Setters/Getters Support](/design-decisions/nullable-getters-setters/)\n    -   [Proto Best Practices](/best-practices/)\n        -   [Avoid Cargo Culting](/best-practices/no-cargo-cults/)\n        -   [Proto Best Practices](/best-practices/dos-donts/)\n        -   [1-1-1 Best Practice](/best-practices/1-1-1/)\n    -   [Tutorials](/getting-started/)\n        -   [C++](/getting-started/cpptutorial/ \"Protocol Buffer Basics: C++\")\n        -   [C#](/getting-started/csharptutorial/ \"Protocol Buffer Basics: C#\")\n        -   [Dart](/getting-started/darttutorial/ \"Protocol Buffer Basics: Dart\")\n        -   [Go](/getting-started/gotutorial/ \"Protocol Buffer Basics: Go\")\n        -   [Java](/getting-started/javatutorial/ \"Protocol Buffer Basics: Java\")\n        -   [Kotlin](/getting-started/kotlintutorial/ \"Protocol Buffer Basics: Kotlin\")\n        -   [Python](/getting-started/pythontutorial/ \"Protocol Buffer Basics: Python\")\n    -   [Reference Guides](/reference/)\n        -   [C++](/reference/cpp/ \"C++ Reference\")\n            -   [Generated Code Guide](/reference/cpp/cpp-generated/ \"C++ Generated Code Guide\")\n            -   [String View APIs](/reference/cpp/string-view/)\n            -   [Arena Allocation Guide](/reference/cpp/arenas/ \"C++ Arena Allocation Guide\")\n            -   [Abseil Support](/reference/cpp/abseil/)\n            -   [C++ API](/reference/cpp/api-docs/)\n        -   [C#](/reference/csharp/ \"C# Reference\")\n            -   [Generated Code Guide](/reference/csharp/csharp-generated/ \"C# Generated Code Guide\")\n            -   [C# API](/reference/csharp/api-docs)\n        -   [Dart](/reference/dart/ \"Dart Reference\")\n            -   [Generated Code](/reference/dart/dart-generated/ \"Dart Generated Code\")\n            -   [Dart API](https://pub.dartlang.org/documentation/protobuf)\n        -   [Go](/reference/go/ \"Go Reference\")\n            -   [Generated Code Guide (Open)](/reference/go/go-generated/ \"Go Generated Code Guide (Open)\")\n            -   [Generated Code Guide (Opaque)](/reference/go/go-generated-opaque/ \"Go Generated Code Guide (Opaque)\")\n            -   [FAQ](/reference/go/faq/ \"Go FAQ\")\n            -   [Size Semantics](/reference/go/size/ \"Go Size Semantics\")\n            -   [Go API](https://pkg.go.dev/google.golang.org/protobuf/proto)\n            -   [Opaque API Migration](/reference/go/opaque-migration/ \"Go Opaque API Migration\")\n            -   [Opaque API: Manual Migration](/reference/go/opaque-migration-manual/ \"Go Opaque API: Manual Migration\")\n            -   [Opaque API FAQ](/reference/go/opaque-faq/ \"Go Opaque API FAQ\")\n        -   [Java](/reference/java/ \"Java Reference\")\n            -   [Generated Code Guide](/reference/java/java-generated/ \"Java Generated Code Guide\")\n            -   [Generated Proto Names](/reference/java/java-proto-names/ \"Java Proto Names\")\n            -   [Java API](/reference/java/api-docs/overview-summary.html)\n        -   [Kotlin](/reference/kotlin/ \"Kotlin Reference\")\n            -   [Kotlin](/reference/kotlin/api-docs/ \"Kotlin Reference\")\n            -   [Generated Code Guide](/reference/kotlin/kotlin-generated/ \"Kotlin Generated Code Guide\")\n        -   [Objective-C](/reference/objective-c/ \"Objective-C Reference\")\n            -   [Generated Code Guide](/reference/objective-c/objective-c-generated/ \"Objective-C Generated Code Guide\")\n        -   [PHP](/reference/php/ \"PHP Reference\")\n            -   [Generated Code Guide](/reference/php/php-generated/ \"PHP Generated Code Guide\")\n            -   [PHP API](/reference/php/api-docs/)\n        -   [Python](/reference/python/ \"Python Reference\")\n            -   [Generated Code Guide](/reference/python/python-generated/ \"Python Generated Code Guide\")\n            -   [Python Comparison](/reference/python/python-comparison/)\n            -   [Python API](https://googleapis.dev/python/protobuf/latest/)\n        -   [Ruby](/reference/ruby/ \"Ruby Reference\")\n            -   [Generated Code Guide](/reference/ruby/ruby-generated/ \"Ruby Generated Code Guide\")\n        -   [Rust](/reference/rust/ \"Rust Reference\")\n            -   [Generated Code Guide](/reference/rust/rust-generated/ \"Rust Generated Code Guide\")\n            -   [Redaction in Rust](/reference/rust/rust-redaction/)\n            -   [Building Rust Protos](/reference/rust/building-rust-protos/)\n            -   [Design Decisions](/reference/rust/rust-design-decisions/ \"Rust Proto Design Decisions\")\n        -   [Protocol Buffers](/reference/protobuf/ \"Protocol Buffers Reference\")\n            -   [2023 Language Specification](/reference/protobuf/edition-2023-spec/ \"Protocol Buffers Edition 2023 Language Specification\")\n            -   [Language Specification (Proto2 Syntax)](/reference/protobuf/proto2-spec/ \"Protocol Buffers Language Specification (Proto2 Syntax)\")\n            -   [2024 Language Specification](/reference/protobuf/edition-2024-spec/ \"Protocol Buffers Edition 2024 Language Specification\")\n            -   [Language Specification (Proto3)](/reference/protobuf/proto3-spec/ \"Protocol Buffers Language Specification (Proto3)\")\n            -   [Text Format Language Specification](/reference/protobuf/textformat-spec/)\n            -   [MIME Types](/reference/protobuf/mime-types/ \"Protocol Buffer MIME Types\")\n            -   [Well-Known Types](/reference/protobuf/google.protobuf/ \"Protocol Buffers Well-Known Types\")\n        -   [Other Languages](/reference/other/)\n    -   [Support](/support/)\n        -   [Version Support](/support/version-support/)\n        -   [Debugging](/support/debugging-playbook/)\n        -   [Migration Guide](/support/migration/)\n        -   [Cross-Version Runtime Guarantee](/support/cross-version-runtime-guarantee/)\n    -   [Downloads](/downloads/)\n    -   [History](/history/)\n    -   [Forum](https://groups.google.com/g/protobuf)\n    -   [](/navbar/)\n    -   [Search Results](/search/)\n\n[View page source](https://github.com/protocolbuffers/protocolbuffers.github.io/tree/main/content/reference/rust/rust-generated.md) [Edit this page](https://github.com/protocolbuffers/protocolbuffers.github.io/edit/main/content/reference/rust/rust-generated.md) [Create child page](https://github.com/protocolbuffers/protocolbuffers.github.io/new/main/content/reference/rust/rust-generated.md?filename=change-me.md&value=---%0Atitle%3A+%22Long+Page+Title%22%0AlinkTitle%3A+%22Short+Nav+Title%22%0Aweight%3A+100%0Adescription%3A+%3E-%0A+++++Page+description+for+heading+and+indexes.%0A---%0A%0A%23%23+Heading%0A%0AEdit+this+template+to+create+your+new+page.%0A%0A%2A+Give+it+a+good+name%2C+ending+in+%60.md%60+-+e.g.+%60getting-started.md%60%0A%2A+Edit+the+%22front+matter%22+section+at+the+top+of+the+page+%28weight+controls+how+its+ordered+amongst+other+pages+in+the+same+directory%3B+lowest+number+first%29.%0A%2A+Add+a+good+commit+message+at+the+bottom+of+the+page+%28%3C80+characters%3B+use+the+extended+description+field+for+more+detail%29.%0A%2A+Create+a+new+branch+so+you+can+preview+your+new+file+and+request+a+review+via+Pull+Request.%0A) [Create documentation issue](https://github.com/protocolbuffers/protocolbuffers.github.io/issues/new?title=Rust%20Generated%20Code%20Guide) [Create project issue](https://github.com/protocolbuffers/protobuf/issues/new)\n\n-   [Protobuf Rust](#rust)\n-   [Packages](#packages)\n-   [Messages](#messages)\n    -   [Associated Functions](#associated-functions)\n    -   [Traits](#traits)\n    -   [Fluently Create New Instances](#proto-macro)\n    -   [Message Proxy Types](#message-proxy-types)\n-   [Nested Types](#nested-types)\n-   [Fields](#fields)\n    -   [Fields with Explicit Presence](#explicit-presence)\n    -   [Fields with Implicit Presence (proto3 and Editions)](#implicit-presence)\n    -   [Singular String and Bytes Fields with Cord Support](#singular-string-bytes)\n    -   [Repeated Fields](#repeated-fields)\n    -   [Map Fields](#map)\n-   [Any](#any)\n-   [Oneof](#oneof)\n-   [Enumerations](#enumerations)\n-   [Extensions (proto2 only)](#extensions)\n-   [Arena Allocation](#arena)\n-   [Services](#services)\n\n1.  [Reference Guides](/reference/)\n2.  [Rust](/reference/rust/)\n3.  Generated Code Guide\n\n# Rust Generated Code Guide\n\nDescribes the API of message objects that the protocol buffer compiler generates for any given protocol definition.\n\nThis page describes exactly what Rust code the protocol buffer compiler generates for any given protocol definition.\n\nThis document covers how the protocol buffer compiler generates Rust code for proto2, proto3, and protobuf editions. Any differences between proto2, proto3, and editions generated code are highlighted. You should read the [proto2 language guide](/programming-guides/proto2), [proto3 language guide](/programming-guides/proto3), or [editions guide](/programming-guides/editions) before reading this document.\n\n## Protobuf Rust\n\nProtobuf Rust is an implementation of protocol buffers designed to be able to sit on top of other existing protocol buffer implementations that we refer to as ‚Äòkernels‚Äô.\n\nThe decision to support multiple non-Rust kernels has significantly influenced our public API, including the choice to use custom types like `ProtoStr` over Rust std types like `str`. See [Rust Proto Design Decisions](/reference/rust/rust-design-decisions) for more on this topic.\n\n## Packages\n\nUnlike in most other languages, the `package` declarations in the `.proto` files are not used in Rust codegen.\n\nWhen `rust_proto_library` is used, the library will correspond to one crate. The name of the target is used as the crate name. Choose your library name correspondingly.\n\nWhen using Cargo, we recommend you `include!` the `generated.rs` entry point in a mod of an appropriate name, as in our [Example Crate](https://docs.rs/crate/protobuf-example).\n\n## Messages\n\nGiven the message declaration:\n\n```proto\nmessage Foo {}\n```\n\nThe compiler generates a struct named `Foo`. The `Foo` struct defines the following associated functions and methods:\n\n### Associated Functions\n\n-   `fn new() -> Self`: Creates a new instance of `Foo`.\n\n### Traits\n\nFor a number of reasons, including gencode size, name collision problems, and gencode stability, most common functionality on messages is implemented on traits instead of as inherent implementations.\n\nMost users should import our prelude, which only includes traits and our `proto!` macro and no other types (`use protobuf::prelude::*`). If you would rather avoid preludes, you can always import the specific traits as needed (see the\n\n[documentation here](https://docs.rs/protobuf/4.33.5-release/protobuf/trait.Message.html) for the names and definitions of the traits if you want to import them directly).\n\n-   `fn parse(data: &[u8]) -> Result<Self, ParseError>`: Parses a new instance of a message.\n-   `fn parse_dont_enforce_required(data: &[u8]) -> Result<Self, ParseError>`: Same as `parse` but does not fail on missing proto2 `required` fields.\n-   `fn clear(&mut self)`: Clears message.\n-   `fn clear_and_parse(&mut self, data: &[u8]) -> Result<(), ParseError>`: Clearing and parsing into an existing instance.\n-   `fn clear_and_parse_dont_enforce_required(&mut self, data: &[u8]) -> Result<(), ParseError>`: Same as `parse` but does not fail on missing proto2 `required` fields.\n-   `fn serialize(&self) -> Result<Vec<u8>, SerializeError>`: Serializes the message to Protobuf wire format. Serialization can fail but rarely will. Failure reasons include if the representation exceeds the maximum encoded message size (must be less than 2 GiB), and `required` fields (proto2) that are unset.\n-   `fn take_from(&mut self, other)`: Moves `other` into `self`, discarding any previous state that `self` contained.\n-   `fn copy_from(&mut self, other)`: Copies `other` into `self`, discarding any previous state that `self` contained. `other` is unmodified.\n-   `fn merge_from(&mut self, other)`: Merges `other` into `self`.\n-   `fn as_view(&self) -> FooView<'_>`: Returns an immutable handle (view) to `Foo`. This is further covered in the section on proxy types.\n-   `fn as_mut(&mut self) -> FooMut<'_>`: Returns a mutable handle (mut) to `Foo`. This is further covered in the section on proxy types.\n\n`Foo` additionally implements the following std traits:\n\n-   `std::fmt::Debug`\n-   `std::default::Default`\n-   `std::clone::Clone`\n-   `std::marker::Send`\n-   `std::marker::Sync`\n\n### Fluently Create New Instances\n\nThe API design of setters follows our established Protobuf idioms, but the verbosity when constructing new instances is a mild pain point in certain other languages. To mitigate this, we offer a `proto!` macro, which can be used to more-succinctly/fluently create new instances.\n\nFor example, instead of writing this:\n\n```fallback\nlet mut msg = SomeMsg::new();\nmsg.set_x(1);\nmsg.set_y(\"hello\");\nmsg.some_submessage_mut().set_z(42);\n```\n\nThis macro can be used to write it as follows:\n\n```fallback\nlet msg = proto!(SomeMsg {\n  x: 1,\n  y: \"hello\",\n  some_submsg: SomeSubmsg {\n    z: 42\n  }\n});\n```\n\n### Message Proxy Types\n\nFor a number of technical reasons, we have chosen to avoid using native Rust references (`&T` and `&mut T`) in certain cases. Instead, we need to express these concepts using types - `View`s and `Mut`s. These situations are shared and mutable references to:\n\n-   Messages\n-   Repeated fields\n-   Map fields\n\nFor example, the compiler emits structs `FooView<'a>` and `FooMut<'msg>` alongside `Foo`. These types are used in place of `&Foo` and `&mut Foo`, and they behave the same as native Rust references in terms of borrow checker behavior. Just like native borrows, Views are `Copy` and the borrow checker will enforce that you can either have any number of Views or at most one Mut live at a given time.\n\nFor the purposes of this documentation, we focus on describing all methods emitted for the owned message type (`Foo`). A subset of these functions with `&self` receiver will also be included on the `FooView<'msg>`. A subset of these functions with either `&self` or `&mut self` will also be included on the `FooMut<'msg>`.\n\nTo create an owned message type from a View / Mut type call `to_owned()`, which creates a deep copy.\n\nSee the corresponding section in our [design decisions](/reference/rust/rust-design-decisions#view-mut-proxy-types) documentation for more discussion about why this choice was made.\n\n## Nested Types\n\nGiven the message declaration:\n\n```proto\nmessage Foo {\n  message Bar {\n      enum Baz { ... }\n  }\n}\n```\n\nIn addition to the struct named `Foo`, a module named `foo` is created to contain the struct for `Bar`. And similarly a nested module named `bar` to contain the deeply nested enum `Baz`:\n\n```rs\npub struct Foo {}\n\npub mod foo {\n   pub struct Bar {}\n   pub mod bar {\n      pub struct Baz { ... }\n   }\n}\n```\n\n## Fields\n\nIn addition to the methods described in the previous section, the protocol buffer compiler generates a set of accessor methods for each field defined within the message in the `.proto` file.\n\nFollowing Rust style, the methods are in lower-case/snake-case, such as `has_foo()` and `clear_foo()`. Note that the capitalization of the field name portion of the accessor maintains the style from the original .proto file, which in turn should be lower-case/snake-case per the [.proto file style guide](/programming-guides/style).\n\n### Fields with Explicit Presence\n\nExplicit presence means that a field distinguishes between the default value and no value set. In proto2, `optional` fields have explicit presence. In proto3, only message fields and `oneof` or `optional` fields have explicit presence. Presence is set using the [`features.field_presence`](/editions/features#field_presence) option in editions.\n\n#### Numeric Fields\n\nFor this field definition:\n\n```proto\nint32 foo = 1;\n```\n\nThe compiler generates the following accessor methods:\n\n-   `fn has_foo(&self) -> bool`: Returns `true` if the field is set.\n-   `fn foo(&self) -> i32`: Returns the current value of the field. If the field is not set, it returns the default value.\n-   fn foo\\_opt(&self) -> protobuf::Optional`: Returns an optional with the variant`Set(value)`if the field is set or`Unset(default value)`if it's unset. See [`Optional\\` rustdoc\\]([https://docs.rs/protobuf/4.33.5-release/protobuf/enum.Optional.html](https://docs.rs/protobuf/4.33.5-release/protobuf/enum.Optional.html))\n-   `fn set_foo(&mut self, val: i32)`: Sets the value of the field. After calling this, `has_foo()` will return `true` and `foo()` will return `value`.\n-   `fn clear_foo(&mut self)`: Clears the value of the field. After calling this, `has_foo()` will return `false` and `foo()` will return the default value.\n\nFor other numeric field types (including `bool`), `int32` is replaced with the corresponding Rust type according to the [scalar value types table](/programming-guides/proto3#scalar).\n\n#### String and Bytes Fields\n\nFor these field definitions:\n\n```proto\nstring foo = 1;\nbytes foo = 1;\n```\n\nThe compiler generates the following accessor methods:\n\n-   `fn has_foo(&self) -> bool`: Returns `true` if the field is set.\n-   `fn foo(&self) -> &protobuf::ProtoStr`: Returns the current value of the field. If the field is not set, it returns the default value. See [`ProtoStr` rustdoc](https://docs.rs/protobuf/4.33.5-release/protobuf/struct.ProtoStr.html).\n-   `fn foo_opt(&self) -> protobuf::Optional<&ProtoStr>`: Returns an optional with the variant `Set(value)` if the field is set or `Unset(default value)` if it‚Äôs unset.\n-   `fn set_foo(&mut self, val: impl IntoProxied<ProtoString>)`: Sets the value of the field. `&str`, `String`, `&ProtoStr` and `ProtoString` all implelement `IntoProxied` and can be passed to this method.\n-   `fn clear_foo(&mut self)`: Clears the value of the field. After calling this, `has_foo()` will return `false` and `foo()` will return the default value.\n\nFor fields of type `bytes` the compiler will generate the `ProtoBytes` type instead.\n\n#### Enum Fields\n\nGiven this enum definition in any proto syntax version:\n\n```proto\nenum Bar {\n  BAR_UNSPECIFIED = 0;\n  BAR_VALUE = 1;\n  BAR_OTHER_VALUE = 2;\n}\n```\n\nThe compiler generates a struct where each variant is an associated constant:\n\n```rust\n#[derive(Clone, Copy, PartialEq, Eq, Hash)]\n#[repr(transparent)]\npub struct Bar(i32);\n\nimpl Bar {\n  pub const Unspecified: Bar = Bar(0);\n  pub const Value: Bar = Bar(1);\n  pub const OtherValue: Bar = Bar(2);\n}\n```\n\nFor this field definition:\n\n```proto\nBar foo = 1;\n```\n\nThe compiler generates the following accessor methods:\n\n-   `fn has_foo(&self) -> bool`: Returns `true` if the field is set.\n-   `fn foo(&self) -> Bar`: Returns the current value of the field. If the field is not set, it returns the default value.\n-   `fn foo_opt(&self) -> Optional<Bar>`: Returns an optional with the variant `Set(value)` if the field is set or `Unset(default value)` if it‚Äôs unset.\n-   `fn set_foo(&mut self, val: Bar)`: Sets the value of the field. After calling this, `has_foo()` will return `true` and `foo()` will return `value`.\n-   `fn clear_foo(&mut self)`: Clears the value of the field. After calling this, `has_foo()` will return false and `foo()` will return the default value.\n\n#### Embedded Message Fields\n\nGiven the message type `Bar` from any proto syntax version:\n\n```proto\nmessage Bar {}\n```\n\nFor any of these field definitions:\n\n```proto\n\nmessage MyMessage {\n  Bar foo = 1;\n}\n```\n\nThe compiler will generate the following accessor methods:\n\n-   `fn foo(&self) -> BarView<'_>`: Returns a view of the current value of the field. If the field is not set it returns an empty message.\n-   `fn foo_mut(&mut self) -> BarMut<'_>`: Returns a mutable handle to the current value of the field. Sets the field if it is not set. After calling this method, `has_foo()` returns true.\n-   `fn foo_opt(&self) -> protobuf::Optional<BarView>`: If the field is set, returns the variant `Set` with its `value`. Else returns the variant `Unset` with the default value.\n-   `fn set_foo(&mut self, value: impl protobuf::IntoProxied<Bar>)`: Sets the field to `value`. After calling this method, `has_foo()` returns `true`.\n-   `fn has_foo(&self) -> bool`: Returns `true` if the field is set.\n-   `fn clear_foo(&mut self)`: Clears the field. After calling this method `has_foo()` returns `false`.\n\n### Fields with Implicit Presence (proto3 and Editions)\n\nImplicit presence means that a field does not distinguish between the default value and no value set. In proto3, fields have implicit presence by default. In editions, you can declare a field with implicit presence by setting the `field_presence` feature to `IMPLICIT`.\n\n#### Numeric Fields\n\nFor these field definitions:\n\n```proto\n// proto3\nint32 foo = 1;\n\n// editions\nmessage MyMessage {\n  int32 foo = 1 [features.field_presence = IMPLICIT];\n}\n```\n\nThe compiler generates the following accessor methods:\n\n-   `fn foo(&self) -> i32`: Returns the current value of the field. If the field is not set, it returns `0`.\n-   `fn set_foo(&mut self, val: i32)`: Sets the value of the field.\n\nFor other numeric field types (including `bool`), `int32` is replaced with the corresponding Rust type according to the [scalar value types table](/programming-guides/proto3#scalar).\n\n#### String and Bytes Fields\n\nFor these field definitions:\n\n```proto\n// proto3\nstring foo = 1;\nbytes foo = 1;\n\n// editions\nstring foo = 1 [features.field_presence = IMPLICIT];\nbytes bar = 2 [features.field_presence = IMPLICIT];\n```\n\nThe compiler will generate the following accessor methods:\n\n-   `fn foo(&self) -> &ProtoStr`: Returns the current value of the field. If the field is not set, returns the empty string/empty bytes. See [`ProtoStr` rustdoc](https://docs.rs/protobuf/4.33.5-release/protobuf/struct.ProtoStr.html).\n-   `fn set_foo(&mut self, value: IntoProxied<ProtoString>)`: Sets the field to `value`.\n\nFor fields of type `bytes` the compiler will generate the `ProtoBytes` type instead.\n\n### Singular String and Bytes Fields with Cord Support\n\n`[ctype = CORD]` enables bytes and strings to be stored as an [absl::Cord](https://github.com/abseil/abseil-cpp/blob/master/absl/strings/cord.h) in C++ Protobufs. `absl::Cord` currently does not have an equivalent type in Rust . Protobuf Rust uses an enum to represent a cord field:\n\n```proto\nenum ProtoStringCow<'a> {\n  Owned(ProtoString),\n  Borrowed(&'a ProtoStr)\n}\n```\n\nIn the common case, for small strings, an `absl::Cord` stores its data as a contiguous string. In this case cord accessors return `ProtoStringCow::Borrowed`. If the underlying `absl::Cord` is non-contiguous, the accessor copies the data from the cord into an owned `ProtoString` and returns `ProtoStringCow::Owned`. The `ProtoStringCow` implements `Deref<Target=ProtoStr>`.\n\nFor any of these field definitions:\n\n```proto\noptional string foo = 1 [ctype = CORD];\nstring foo = 1 [ctype = CORD];\noptional bytes foo = 1 [ctype = CORD];\nbytes foo = 1 [ctype = CORD];\n```\n\nThe compiler generates the following accessor methods:\n\n-   `fn my_field(&self) -> ProtoStringCow<'_>`: Returns the current value of the field. If the field is not set, returns the empty string/empty bytes.\n-   `fn set_my_field(&mut self, value: IntoProxied<ProtoString>)`: Sets the field to `value`. After calling this function `foo()` returns `value` and `has_foo()` returns `true`.\n-   `fn has_foo(&self) -> bool`: Returns `true` if the field is set.\n-   `fn clear_foo(&mut self)`: Clears the value of the field. After calling this, `has_foo()` returns `false` and `foo()` returns the default value. Cords have not been implemented yet.\n\nFor fields of type `bytes` the compiler generates the `ProtoBytesCow` type instead.\n\nThe compiler generates the following accessor methods:\n\n-   `fn foo(&self) -> &ProtoStr`: Returns the current value of the field. If the field is not set, returns the empty string/empty bytes.\n-   `fn set_foo(&mut self, value: impl IntoProxied<ProtoString>)`: Sets the field to `value`.\n\n#### Enum Fields\n\nGiven the enum type:\n\n```proto\nenum Bar {\n  BAR_UNSPECIFIED = 0;\n  BAR_VALUE = 1;\n  BAR_OTHER_VALUE = 2;\n}\n```\n\nThe compiler generates a struct where each variant is an associated constant:\n\n```rust\n#[derive(Clone, Copy, PartialEq, Eq, Hash)]\n#[repr(transparent)]\npub struct Bar(i32);\n\nimpl Bar {\n  pub const Unspecified: Bar = Bar(0);\n  pub const Value: Bar = Bar(1);\n  pub const OtherValue: Bar = Bar(2);\n}\n```\n\nFor these field definitions:\n\n```proto\n// proto3\nBar foo = 1;\n\n// editions\nmessage MyMessage {\n Bar foo = 1 [features.field_presence = IMPLICIT];\n}\n```\n\nThe compiler will generate the following accessor methods:\n\n-   `fn foo(&self) -> Bar`: Returns the current value of the field. If the field is not set, it returns the default value.\n-   `fn set_foo(&mut self, value: Bar)`: Sets the value of the field. After calling this, `has_foo()` will return `true` and `foo()` will return `value`.\n\n### Repeated Fields\n\nFor any repeated field definition the compiler will generate the same three accessor methods that deviate only in the field type.\n\nIn editions, you can control the wire format encoding of repeated primitive fields using the [`repeated_field_encoding`](/editions/features#repeated_field_encoding) feature.\n\n```proto\n// proto2\nrepeated int32 foo = 1; // EXPANDED by default\n\n// proto3\nrepeated int32 foo = 1; // PACKED by default\n\n// editions\nrepeated int32 foo = 1 [features.repeated_field_encoding = PACKED];\nrepeated int32 bar = 2 [features.repeated_field_encoding = EXPANDED];\n```\n\nGiven any of the above field definitions, the compiler generates the following accessor methods:\n\n-   `fn foo(&self) -> RepeatedView<'_, i32>`: Returns a view of the underlying repeated field. See [`RepeatedView` rustdoc](https://docs.rs/protobuf/4.33.5-release/protobuf/struct.RepeatedView.html).\n-   `fn foo_mut(&mut self) -> RepeatedMut<'_, i32>`: Returns a mutable handle to the underlying repeated field. See [`RepeatedMut` rustdoc](https://docs.rs/protobuf/4.33.5-release/protobuf/struct.RepeatedMut.html).\n-   `fn set_foo(&mut self, src: impl IntoProxied<Repeated<i32>>)`: Sets the underlying repeated field to a new repeated field provided in `src`. Accepts a `RepeatedView`, `RepeatedMut` or `Repeated`. See [`Repeated` rustdoc](https://docs.rs/protobuf/4.33.5-release/protobuf/struct.Repeated.html).\n\nFor different field types only the respective generic types of the `RepeatedView`, `RepeatedMut` and `Repeated` types will change. For example, given a field of type `string` the `foo()` accessor would return a `RepeatedView<'_, ProtoString>`.\n\n### Map Fields\n\nFor this map field definition:\n\n```proto\nmap<int32, int32> weight = 1;\n```\n\nThe compiler will generate the following 3 accessor methods:\n\n-   `fn weight(&self) -> protobuf::MapView<'_, i32, i32>`: Returns an immutable view of the underlying map. See [`MapView` rustdoc](https://docs.rs/protobuf/4.33.5-release/protobuf/struct.MapView.html).\n-   `fn weight_mut(&mut self) -> protobuf::MapMut<'_, i32, i32>`: Returns a mutable handle to the underlying map. See [`MapMut` rustdoc](https://docs.rs/protobuf/4.33.5-release/protobuf/struct.MapView.html).\n-   `fn set_weight(&mut self, src: protobuf::IntoProxied<Map<i32, i32>>)`: Sets the underlying map to `src`. Accepts a `MapView`, `MapMut` or `Map`. See [`Map` rustdoc](https://docs.rs/protobuf/4.33.5-release/protobuf/struct.Map.html).\n\nFor different field types only the respective generic types of the `MapView`, `MapMut` and `Map` types will change. For example, given a field of type `string` the `foo()` accessor would return a `MapView<'_, int32, ProtoString>`.\n\n## Any\n\nAny is not special-cased by Rust Protobuf at this time; it will behave as though it was a simple message with this definition:\n\n```proto\nmessage Any {\n  string type_url = 1;\n  bytes value = 2;\n}\n```\n\n## Oneof\n\nGiven a oneof definition like this:\n\n```proto\noneof example_name {\n    int32 foo_int = 4;\n    string foo_string = 9;\n    ...\n}\n```\n\nThe compiler will generate accessors (getters, setters, hazzers) for every field as if the same field was declared as an `optional` field outside of the oneof. So you can work with oneof fields like regular fields, but setting one will clear the other fields in the oneof block. In addition, the following types are emitted for the `oneof` block:\n\n```rust\n  #[non_exhaustive]\n  #[derive(Debug, Clone, Copy)]\n\n  pub enum ExampleNameOneof<'msg> {\n    FooInt(i32) = 4,\n    FooString(&'msg protobuf::ProtoStr) = 9,\n    not_set(std::marker::PhantomData<&'msg ()>) = 0\n  }\n```\n\n```rust\n  #[derive(Debug, Copy, Clone, PartialEq, Eq)]\n\n  pub enum ExampleNameCase {\n    FooInt = 4,\n    FooString = 9,\n    not_set = 0\n  }\n```\n\nAdditionally, it will generate the two accessors:\n\n-   `fn example_name(&self) -> ExampleNameOneof<_>`: Returns the enum variant indicating which field is set and the field‚Äôs value. Returns `not_set` if no field is set.\n-   `fn example_name_case(&self) -> ExampleNameCase`: Returns the enum variant indicating which field is set. Returns `not_set` if no field is set.\n\n## Enumerations\n\nGiven an enum definition like:\n\n```proto\nenum FooBar {\n  FOO_BAR_UNKNOWN = 0;\n  FOO_BAR_A = 1;\n  FOO_B = 5;\n  VALUE_C = 1234;\n}\n```\n\nThe compiler will generate:\n\n```rust\n  #[derive(Clone, Copy, PartialEq, Eq, Hash)]\n  #[repr(transparent)]\n  pub struct FooBar(i32);\n\n  impl FooBar {\n    pub const Unknown: FooBar = FooBar(0);\n    pub const A: FooBar = FooBar(1);\n    pub const FooB: FooBar = FooBar(5);\n    pub const ValueC: FooBar = FooBar(1234);\n  }\n```\n\nNote that for values with a prefix that matches the enum, the prefix will be stripped; this is done to improve ergonomics. Enum values are commonly prefixed with the enum name to avoid name collisions between sibling enums (which follow the semantics of C++ enums where the values are not scoped by their containing enum). Since the generated Rust consts are scoped within the `impl`, the additional prefix, which is beneficial to add in .proto files, would be redundant in Rust.\n\n## Extensions (proto2 only)\n\nA Rust API for extensions is currently a work in progress. Extension fields will be maintained through parse/serialize, and in a C++ interop case any extensions set will be retained if the message is accessed from Rust (and propagated in the case of a message copy or merge).\n\n## Arena Allocation\n\nA Rust API for arena allocated messages has not yet been implemented.\n\nInternally, Protobuf Rust on upb kernel uses arenas, but on C++ kernels it doesn‚Äôt. However, references (both const and mutable) to messages that were arena allocated in C++ can be safely passed to Rust to be accessed or mutated.\n\n## Services\n\nA Rust API for services has not yet been implemented.\n\n-   [](https://stackoverflow.com/questions/tagged/protocol-buffers)\n\n-   [](https://github.com/protocolbuffers/protobuf)\n-   [](https://groups.google.com/g/protobuf)\n\n¬© 2026 Google LLC All Rights Reserved [Privacy Policy](https://policies.google.com/privacy) Hosted by GitHub Pages. [GitHub Privacy Statement](https://docs.github.com/en/site-policy/privacy-policies/github-privacy-statement)",
            "title": "https://protobuf.dev/reference/rust/rust-generated/ (text/html; charset=utf-8)",
            "metadata": {
              "truncated": false
            },
            "time": {
              "start": 1771213009279,
              "end": 1771213009451
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_0340425095c0c74501699290d10c588195ac638d7adb236ee4"
            }
          },
          "id": "prt_c6485b0cf001w5zEVuBBREfofH",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64857b6a001ebLiNCtMnknqZV"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "62625fe158b4cd4dc48be5b45ccb5cc80cbaca19",
          "cost": 0,
          "tokens": {
            "total": 91907,
            "input": 19062,
            "output": 653,
            "reasoning": 619,
            "cache": {
              "read": 72192,
              "write": 0
            }
          },
          "id": "prt_c6485b22d001Wd5uSwiQQr645q",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64857b6a001ebLiNCtMnknqZV"
        },
        {
          "type": "patch",
          "hash": "5147fb7468d78f726061bbed9b56e547e848c4bd",
          "files": [
            "/Users/alex/repos/vfp/dark-factory/scripts/scrape_moon_docs.sh.ts"
          ],
          "id": "prt_c6485b25d001YvK06jnExJL1vT",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64857b6a001ebLiNCtMnknqZV"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771213009506,
          "completed": 1771213024570
        },
        "parentID": "msg_c6484620d0011ltzji40BSbVp5",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 100567,
          "input": 8493,
          "output": 298,
          "reasoning": 244,
          "cache": {
            "read": 91776,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "tool-calls",
        "id": "msg_c6485b262001Vhwojv4JZEZrB7",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "62625fe158b4cd4dc48be5b45ccb5cc80cbaca19",
          "id": "prt_c6485bb25001izYKh1fTv5C0aX",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6485b262001Vhwojv4JZEZrB7"
        },
        {
          "type": "reasoning",
          "text": "**Clarifying Rust protoc usage**",
          "metadata": {
            "openai": {
              "itemId": "rs_0d57fefead1e138901699290d5d810819681776c072d069458",
              "reasoningEncryptedContent": "gAAAAABpkpDbn1wOczg6YQIp0yqTdn4kdrTT8uZ_5xU0ShuMoCjvCmJ5f6e3uiH7Swdw7-L0i5sag26UPBtng6l5JnD5N-trrS8TnByr5jaBmMtwTQWHMt0fg6mUufcKPGKSLzWCs8opEApQwFNKxjoXzgMpKAVr1zK5BoHj-1Mc8_8YA-ZiuBR8D4yAebpuzFl-qua5vl5QImzix6c9MDgq5bVYJDYh3cmUhWeduGY0PNPUTLpxawBUK5iSWeHBJydTuhRAHsWKba39Qmsf06v2vQap5adwt6UvFoKOCsmWuQ3Bg-_LP4uHzPDBv-hBxQ3FYKf4KI46rhRQ_RUFxjNnafOIN3nCEuFketOEiN9-J8E0YHKVMMnqKOnnzXqeLsML9tjfx_p4mrU2ogyKnsmKhuNVpvUV7mlArydBqCpQZPSqb3dK0XKENFi6V_Ji8JMuEC5BTg6gX7KfrnJKDPwRl74JXecQQcQBDdbN8pNe4LcQabVQWFYZOZZzVzWbpJHE0Crvq3oFJh85o7kkCCaxCYO5qJ_4TCTVcSusvKzOT1KaO33xfUqwz0JooGK88q_huBlRKBT0DnYVJLR5iH9RX4xP_vINHlVv5cZ775N6mkqvNWMFtLi1LA-T1Kvh5hAU5L1zDRogAPCCu5s5YEWnYoNZAXH02QLSDcLROmCtEdiRF--VPnGaWbS-RSWh5l4KWm1lKcSBerS7HcaT32ANC8grmxjM6v5shY-H0pCqEDOsaDbH299WfL2qW8n3-jwPRUK2iq9aAmEFWNuAEMSvo84hiniW6V90b5CVq2KurNumY4185LbjO6-FSnuQBx7s20eap-Sr_uH84o-iK0dFR3-568Tc6EmlMG8teVIQpeGwNLZ87fSC3Y9ldwpq-xusoBVbxDsvXkXWoOVQ9Kca-pMm1aB7FDfl7apCElNHBIUtPRqF9HW1OT4x58GNAHQDl14RkdiGANzaP6nBTBnVSZDeR6KFs4gcml6f_Bw62PtIANOyCl38KTpcOoir5o9boiSO8puqRPKQiKK0XXgDdwTXbc3PDoYdVJCPbmHdHfkcSCzq22lgOAxT5HBDqqEaP2S7W4BokDKwCPq17n86kFuyCkJu532drnfDgmCG4kiTepFfUfyw6KeLK2yxbNLuLLWt9XcdslILpkrAQlXfe3HfQhRrcGpglQs7DDbMQPUqdXBHGiyTcckE-WISBB_ACgvwRvVKKSLswSokX0wkxpKN24DriNwVLQaVWRXbpeebywKqfaihBmWx4EnkM-qJvQqe0jcWtq7BHTTweUdboLEF3py6qoC2zwZbxZJlY_W7_8hJhBK1bbQ3aFEcAm_9q6Mi3BAJIDjMHduKuROMyixs8OmQuiMUuiN7cUnEbU41popAZHSIrah3I7gYuR1AbvAmFlBsWf0Ssv3YmcD2bMAtMw4Tbbw7gaK7S48KnsQjoxKIFP0E3R9HAtu89WagEdNJgODEAoBaq-6O01qlJ-9u_lQv1oSVAOIv2sVF_Bu_dgk2B6_1F1NH7l1zwUabQuzDu8GDfx0wuhFr4Ok0w5YV5HPDxpz3fIqg84W0MILQTeR2JaAS6-Xh6BQn4jp4GfiyaYZnbITsn5dW9d8SBvIEirNIC57_7SQh2nFkARJ2iWR0OneDJ5g4mfU8BqY_YjdPizf2xPaVVJUvAiBpujODS7uH5w2LyRccE8vONhap45IpTS6LgaFnKdJacLx8UcQDdgpu6rvdAR9VjwyKCEImC958JjU7EAaU9O9GDEryXt_vdDQER1l3PNOB1c4RSVCRDONP2jlvKTrv2pkFw6SyWueeEf-kZy0xU18h_cltl8JmLEXmhdEqRC056V2YzdQMKfEzqoKEOZvIvLfstPKSTR7Vxi5bp56A0SOPS0lcpkI3R6hICGkcubq8TUEuriqB3bdlHbW75QVlwA8m2Km-xd97ONbuXM45JO3WyRTbRY_SZ7N4iw1y-KsvBlev3PKuaLCKiMgQVt3CI_5hQwyP0mAfnHWl5Xjw7pTblkxODZMN0bZ5u1O7o2eDtWMtWAf7lqBd0DiVBQ1NB29WLCs2ASRUsPzibJxDNumvbkFkRWaTBtzbs3BnhtQOrbOxUf7owt7SNJkajo9o0VgchAp_H64tcpK6AAPl5tMGxk9T_-8D6ydsITdKbG3mvCtBTtK2s72tZG7aH_NmsYbcIx8-OmDP_5n-g3_8Lcd_2eLECfrnCJ2Pd0-00X9AERk4DgM0dY-CDHT7NtgjDOqr3gZEDoAUZZ48KoLFUzRzfgMOVFcF9h_ZMNeZKGSU8E_3gH0LvmuCY8EmdMO0tfs95ofq3u2fScqQ1F1Ke9KE0IUdAFtAFLcOnjsddLGBtyCx5Jl9AIWB7vgV4eDJ7fFEvIeRbhGmMYCVJUCqS71R7qlz4BRyJ3Jl49vOQyD2Un33AX_q9XI6et_ByPqQSHu7guh2cbsIDw=="
            }
          },
          "time": {
            "start": 1771213013876,
            "end": 1771213019144
          },
          "id": "prt_c6485c3740010aQtYMlit74KDH",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6485b262001Vhwojv4JZEZrB7"
        },
        {
          "type": "tool",
          "callID": "call_mj9IW5diLFdtkoZSvXWhdKqN",
          "tool": "websearch_web_search_exa",
          "state": {
            "status": "completed",
            "input": {
              "query": "protobuf protoc --rust_out official rust generated code command",
              "numResults": 5,
              "livecrawl": "preferred",
              "type": "auto",
              "contextMaxCharacters": 8000
            },
            "output": "Title: Serialize and Deserialize Protobuf in Rust\nAuthor: Serialize and Deserialize Data in Programming Languages\nURL: https://ssojet.com/serialize-and-deserialize/serialize-and-deserialize-protobuf-in-rust\nText: Serialize and Deserialize Protobuf in Rust | SSOJet[skip to content] \n[![SSOJet]![SSOJet]] \n[Sign in] [Start 30-day free trial] \n[Back to Serialize and Deserialize Glossary] # Serialize and Deserialize Protobuf in Rust\nHandling data serialization and deserialization efficiently is crucial for efficient inter-process communication and data storage. This guide dives into using Protocol Buffers (Protobuf) with Rust to achieve just that. You‚Äôll learn how to define your message structures using `.proto` files and generate Rust code for seamless serialization into compact binary formats and deserialization back into Rust structs. By the end, you&#39;ll be equipped to integrate Protobuf into your Rust applications for faster, more robust data handling.\n## Defining Your Protocol Buffers Schema\nProtocol Buffers relies on a clear schema definition to serialize and deserialize data. You define these structures using`.proto`files, which act as the blueprint for your messages. This explicit definition is the absolute bedrock of your data's structure, ensuring consistency across different languages and systems implementing your application.\nHere's a simple example defining a`Person`message:\n```\n`// person.protosyntax =&quot;proto3&quot;;messagePerson{stringname =1;int32id =2;stringemail =3;\n}`\n```\nA common pitfall is forgetting to assign unique, positive integer field numbers \n\nTitle: Building Rust Protos\nAuthor: \nURL: https://protobuf.dev/reference/rust/building-rust-protos/\nText: Building Rust Protos | Protocol Buffers Documentation\n[**View page source] [**Edit this page] [**Create child page] [**Create documentation issue] [**Create project issue] \n# Building Rust Protos\nDescribes how to build Rust protos using Cargo or Bazel.\n## Cargo\nSee the[protobuf-example] crate\nfor an example of how to set up your build.\n## Bazel\nThe process of building a Rust library for a Protobuf definition is similar to\nother programming languages:\n1. Use the language-agnostic`proto\\_library`rule:\n```\n`proto\\_library(name = &#34;&#34;person\\_proto&#34;&#34;,srcs = [&#34;person.proto&#34;],)`\n```\n2. Create a Rust library:\n```\n`load(&#34;&#34;//third\\_party/protobuf/rust:defs.bzl&#34;&#34;,&#34;&#34;rust\\_proto\\_library&#34;&#34;)proto\\_library(name=&#34;&#34;person\\_proto&#34;&#34;,srcs=[&#34;person.proto&#34;],)rust\\_proto\\_library(name=&#34;&#34;person\\_rust\\_proto&#34;&#34;,deps=[&#34;&#34;:person\\_proto&#34;&#34;],)`\n```\n3. Use the library by including it in a Rust binary:\n```\n`load(&#34;&#34;//third\\_party/bazel\\_rules/rules\\_rust/rust:defs.bzl&#34;&#34;,&#34;&#34;rust\\_binary&#34;&#34;)load(&#34;&#34;//third\\_party/protobuf/rust:defs.bzl&#34;&#34;,&#34;&#34;rust\\_proto\\_library&#34;&#34;)proto\\_library(name=&#34;&#34;person\\_proto&#34;&#34;,srcs=[&#34;person.proto&#34;],)rust\\_proto\\_library(name=&#34;&#34;person\\_rust\\_proto&#34;&#34;,deps=[&#34;&#34;:person\\_proto&#34;&#34;],)rust\\_binary(name=&#34;greet&#34;,srcs=[&#34;greet.rs&#34;],deps=[&#34;&#34;:person\\\n\nTitle: protobuf-codegen - crates.io: Rust Package Registry\nAuthor: honglooker\nURL: https://crates.io/crates/protobuf-codegen/2.28.0\nText: # protobuf-codegen v2.28.0\n\nCode generator for Rust Protocol Buffers bindings\n\n- Latest version: 4.34.0-rc.2\n- License: MIT\n- Crate size: 39.9 KB\n- Downloads: 29,086,854\n- Recent downloads (90d): 4,805,145\n- Reverse dependencies: 122\n- Created: 2018-05-11\n- Updated: 2026-02-06\n\n## Owners\n\n- honglooker\n- esrauchg\n\n---\n\n## README\n\n# Protobuf code generator\n\nThis crate contains protobuf code generator implementation and a `protoc-gen-rust` `protoc` plugin.\n\nThis crate:\n\n- provides `protoc-gen-rust` plugin for `protoc` command\n- implement protobuf codegen\n\nThis crate is not meant to be used directly, in fact, it does not provide any public API (except for `protoc-gen-rust` binary).\n\nCode can be generated with either:\n\n- `protoc-gen-rust` plugin for `protoc` or\n- [`protoc-rust`] crate (code generator which depends on `protoc` binary for parsing of `.proto` files)\n- [`protobuf-codegen-pure`] crate, similar API to `protoc-rust`, but uses pure rust parser of `.proto` files.\n\n# `protoc-gen-rust` plugin for `protoc`\n\nWhen non-cargo build system is used, consider using standard protobuf code generation pattern: `protoc` command does all the work of handling paths and parsing `.proto` files. When `protoc` is invoked with `--rust_out=` option, it invokes `protoc-gen-rust` plugin. provided by this crate.\n\nWhen building with cargo, consider using `protoc-rust` or `protobuf-codegen-pure` crates.\n\n## How to use `protoc-gen-rust` if you have to\n\n(Note `p\n\nTitle: Codegen in protobuf_codegen - Rust\nAuthor: \nPublished Date: 2025-07-02T00:00:00.000Z\nURL: https://docs.rs/protobuf-codegen/latest/protobuf_codegen/struct.Codegen.html\nText: Codegen in protobuf\\_codegen - Rust\n[Docs.rs] \n* [protobuf-codegen-3.7.2] \n* protobuf-codegen 3.7.2\n* [Permalink] \n* [Docs.rs crate page] \n* [MIT] \n* Links\n* [Homepage] \n* [Repository] \n* [crates.io] \n* [Source] \n* Owners\n* [honglooker] \n* [esrauchg] \n* [github:protocolbuffers:protobuf-team] \n* Dependencies\n* * [anyhow ^1.0.53*normal*] \n* [once\\_cell ^1.10.0*normal*] \n* [protobuf =3.7.2*normal*] \n* [protobuf-parse =3.7.2*normal*] \n* [regex ^1.5.5*normal*] \n* [tempfile ^3*normal*] \n* [thiserror ^1.0.30*normal*] \n* Versions\n* * [**40%**of the crate is documented] \n* [Platform] \n* [i686-pc-windows-msvc] \n* [i686-unknown-linux-gnu] \n* [x86\\_64-apple-darwin] \n* [x86\\_64-pc-windows-msvc] \n* [x86\\_64-unknown-linux-gnu] \n* [Feature flags] \n* [docs.rs] \n* [About docs.rs] \n* [Badges] \n* [Builds] \n* [Metadata] \n* [Shorthand URLs] \n* [Download] \n* [Rustdoc JSON] \n* [Build queue] \n* [Privacy policy] \n* [Rust] \n* [Rust website] \n* [The Book] \n* [Standard Library API Reference] \n* [Rust by Example] \n* [The Cargo Guide] \n* [Clippy Documentation] \n## [Codegen] \n[protobuf\\_codegen] \n# StructCodegenCopy item path\n[Source] \n```\n`pub struct Codegen {/\\* private fields \\*/}`\n```\nExpand description\nEntry point for`.proto`to`.rs`code generation.\nThis is similar to`protoc --rs\\_out...`.\n## Implementations[¬ß] \n[Source] [¬ß] ### impl[Codegen] \n[Source] #### pub fn[new] () -&gt; Self\nCreate new codegen object.\nUses`protoc`f\n\nTitle: experimental-codegen=enabled does not work with\nAuthor: Hay1tsme\nURL: https://github.com/protocolbuffers/protobuf/issues/13346\nText: GitHub ¬∑Where software is built\n[Skip to content] \n## Navigation Menu\nToggle navigation\n[] \n[Sign in] \nAppearance settings\nSearch or jump to...\n# Search code, repositories, users, issues, pull requests...\n \nSearch\nClear\n[Search syntax tips] \n# Provide feedback\n \nWe read every piece of feedback, and take your input very seriously.\nInclude my email address so I can be contacted\nCancelSubmit feedback\n# Saved searches\n## Use saved searches to filter your results more quickly\n \nName\nQuery\nTo see all available qualifiers, see our[documentation].\nCancelCreate saved search\n[Sign in] \n[Sign up] \nAppearance settings\nResetting focus\nYou signed in with another tab or window.[Reload] to refresh your session.You signed out in another tab or window.[Reload] to refresh your session.You switched accounts on another tab or window.[Reload] to refresh your session.Dismiss alert\n{{ message }}\n[protocolbuffers] /**[protobuf] **Public\n* [Notifications] You must be signed in to change notification settings\n* [Fork16k] \n* [Star70k] \n# experimental-codegen=enabled does not work with --rust\\_out#13346\n[New issue] \nCopy link\n[New issue] \nCopy link\nClosed\nClosed\n[experimental-codegen=enabled does not work with --rust\\_out] #13346\nCopy link\n[![@Hay1tsme]] \n## Description\n[![@Hay1tsme]] \n[Hay1tsme] \nopened[onJul 18, 2023] \nIssue body actions\n**What version of protobuf and what language are you using?**\nlibprotoc 23.4\nLanguage: Rust\n**What operating system (Linux, W\n\n",
            "title": "",
            "metadata": {
              "truncated": false
            },
            "time": {
              "start": 1771213019492,
              "end": 1771213024488
            },
            "attachments": []
          },
          "metadata": {
            "openai": {
              "itemId": "fc_0d57fefead1e138901699290db1b1c8196a80ae344da4b2170"
            }
          },
          "id": "prt_c6485d80b001wheE5v6VILS60m",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6485b262001Vhwojv4JZEZrB7"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "62625fe158b4cd4dc48be5b45ccb5cc80cbaca19",
          "cost": 0,
          "tokens": {
            "total": 100567,
            "input": 8493,
            "output": 298,
            "reasoning": 244,
            "cache": {
              "read": 91776,
              "write": 0
            }
          },
          "id": "prt_c6485ecea001IMP1T0QpY7181W",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6485b262001Vhwojv4JZEZrB7"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771213024573,
          "completed": 1771213030850
        },
        "parentID": "msg_c6484620d0011ltzji40BSbVp5",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 103035,
          "input": 2435,
          "output": 120,
          "reasoning": 90,
          "cache": {
            "read": 100480,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "tool-calls",
        "id": "msg_c6485ed3d0012kdcP2VbBvPTeF",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "62625fe158b4cd4dc48be5b45ccb5cc80cbaca19",
          "id": "prt_c6485f5d00018PZwbPG7r497yK",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6485ed3d0012kdcP2VbBvPTeF"
        },
        {
          "type": "reasoning",
          "text": "**Evaluating Rust protobuf codegen options**",
          "metadata": {
            "openai": {
              "itemId": "rs_0d70e458a4721a5601699290e356c88196acb37d88cf8d1e36",
              "reasoningEncryptedContent": "gAAAAABpkpDm2GYQurF_Rdm1zoThiPm_MlbIE0t6CKf53lidscLFlVYciiNLO21RrMi3ebQA-Nx8OynJ01UHULvupq1GFOXvIgsTG2mgaDRy6piGgSTxdEL2pwjCI4rmijZkxlQMxJCu7whtJd6-Yz-eCTrLJBwFEtZrBD0ip9bVDCl9sklK0WfwJx9873b-c9NZhriGevRyhuJc7GHGxPPLpXBPDLHykC6tMeVovlGS_AfWTxRrY_DNeGg-tFFCKJqsRy_VKeYO2A8v8zS9U2-2Fg_ORJssMaocGZmEQ4eKp3nEv9GyuN1SB5ehhiPzoRSAWj1gcU-tphWJxpoAnC3ufa5ktp3LbENoARBLJ6TCSZyUASe2ko72dmAMRqVDC0ZUhyaIwxjxEqNFh4MVjsohOHKIlfz4-egzOtqxFIaoTaBH-sukUXHwTMKO83n3_5y9R4u1kLfv0j2INYkTrzIPyNZhoGLCf0zrmMo_VUAeWIJ7Hz5bSV-3JFYMldaWjocliREA48epKezIVUPVnR_nEoOGOtzRpjGLj3uLybSpJpq5NPoXcvY_orC0RucrO6Mr4lAk9EDZP7jRMfCjRLtRqt4eL2nTKNaMzZIUBD1OleK0_-qU7IP5uu6fgJ-FL0rIYn9lYPVCfODLHLox8OPlu-zHt9U3knpNzoQq3iubI2s61EQO80Y0v7KFoDV-Vi5p46LxJF1WsMRbhQGf38R9p-TiW9ARwydn0Xd-0SDcQH13fzQUt0fuWEl7H4O_S7da2YkZQH5mqNoeQUMEsDdvW7lCba5nku-j4PY5IW69YO08gf5yqLMy0G7c-5dijFcj1AdUdi_r4IVi1lKzSWilTjEugk98xmTT1-hDst4ph6nxbaKQMiK5Wj4umPAbV-bfYWpbCsO_Lew-R9Hu29hhXHvW3le3cXvd-mUJ6Zn9UZYazrJXMWQj1Ei0qVCJuBv4gGnTFefZOQrQjlGLWp62Erl6qMZyumXoW8jozAzyAM2kYANU-XRrbIaw5MLBNRULBA8Nb6DZJPy3iESPN6KWHkbFHunSMlOPWsKN0hAoMvcnwklcXwOJjy9pc5RC-bQlbSPso0RMgjhUDIM8QGOXWJa6uC8NlsqWxFdmVQou9-MnqMJLcH9MknHVNDGoK_I53yHa4wtRcgJXdFw7vFRTojcqXYG3Pc1lcEkA7uwPmLvwQxhZ6H4l7TaT87DW1OWglG5GZ3qMJKcmENhXv8xcztQ1foX5UaAYw2sGFZOs6Y2R87qb1eToAN3wjYCpEYbpY7dbyOt6PwJZt8iqzqI-kAKOnHmNVXBknRQQbNsGQczZBWlcHC8ZRSuaXzQ-rtFsLY-tTVe3sJp9O3uORB2bjH-G8oVuIDG4U5AUCvWls46YeECyXduwdM2UaGXGmZdNY--oVi4RlQsvhK3pN3nTnFr-wgDZ3TmwIkj4ppRQSHXnRheATtk="
            }
          },
          "time": {
            "start": 1771213027370,
            "end": 1771213030389
          },
          "id": "prt_c6485f82a001X1rAxsZwoj5XTC",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6485ed3d0012kdcP2VbBvPTeF"
        },
        {
          "type": "tool",
          "callID": "call_iwUY1TQxKszRDtZTvX0JcwwJ",
          "tool": "webfetch",
          "state": {
            "status": "completed",
            "input": {
              "url": "https://protobuf.dev/installation/",
              "format": "markdown"
            },
            "output": "Protocol Buffer Compiler Installation | Protocol Buffers Documentation \n\n[Protocol Buffers Documentation](/)\n\n-   [Protocol Buffers](/)\n    -   [Overview](/overview/)\n    -   [Protoc Installation](/installation/ \"Protocol Buffer Compiler Installation\")\n    -   [News](/news/)\n    -   [Programming Guides](/programming-guides/)\n        -   [Language Guide (editions)](/programming-guides/editions/)\n        -   [Language Guide (proto 2)](/programming-guides/proto2/)\n        -   [Language Guide (proto 3)](/programming-guides/proto3/)\n        -   [Proto Limits](/programming-guides/proto-limits/)\n        -   [Style Guide](/programming-guides/style/)\n        -   [Enum Behavior](/programming-guides/enum/)\n        -   [Encoding](/programming-guides/encoding/)\n        -   [ProtoJSON Format](/programming-guides/json/)\n        -   [Techniques](/programming-guides/techniques/)\n        -   [Add-ons](/programming-guides/addons/ \"Third-Party Add-ons\")\n        -   [Extension Declarations](/programming-guides/extension_declarations/)\n        -   [Field Presence](/programming-guides/field_presence/ \"Application Note: Field Presence\")\n        -   [Proto Serialization Is Not Canonical](/programming-guides/serialization-not-canonical/)\n        -   [Deserializing Debug Proto Representations](/programming-guides/deserialize-debug/)\n    -   [Protobuf Editions](/editions/)\n        -   [Overview](/editions/overview/ \"Protobuf Editions Overview\")\n        -   [Feature Settings for Editions](/editions/features/)\n        -   [Implementing Editions Support](/editions/implementation/)\n    -   [Design Decisions](/design-decisions/ \"Protobuf Team Design Decisions\")\n        -   [No Nullable Setters/Getters Support](/design-decisions/nullable-getters-setters/)\n    -   [Proto Best Practices](/best-practices/)\n        -   [Avoid Cargo Culting](/best-practices/no-cargo-cults/)\n        -   [Proto Best Practices](/best-practices/dos-donts/)\n        -   [1-1-1 Best Practice](/best-practices/1-1-1/)\n    -   [Tutorials](/getting-started/)\n        -   [C++](/getting-started/cpptutorial/ \"Protocol Buffer Basics: C++\")\n        -   [C#](/getting-started/csharptutorial/ \"Protocol Buffer Basics: C#\")\n        -   [Dart](/getting-started/darttutorial/ \"Protocol Buffer Basics: Dart\")\n        -   [Go](/getting-started/gotutorial/ \"Protocol Buffer Basics: Go\")\n        -   [Java](/getting-started/javatutorial/ \"Protocol Buffer Basics: Java\")\n        -   [Kotlin](/getting-started/kotlintutorial/ \"Protocol Buffer Basics: Kotlin\")\n        -   [Python](/getting-started/pythontutorial/ \"Protocol Buffer Basics: Python\")\n    -   [Reference Guides](/reference/)\n        -   [C++](/reference/cpp/ \"C++ Reference\")\n            -   [Generated Code Guide](/reference/cpp/cpp-generated/ \"C++ Generated Code Guide\")\n            -   [String View APIs](/reference/cpp/string-view/)\n            -   [Arena Allocation Guide](/reference/cpp/arenas/ \"C++ Arena Allocation Guide\")\n            -   [Abseil Support](/reference/cpp/abseil/)\n            -   [C++ API](/reference/cpp/api-docs/)\n        -   [C#](/reference/csharp/ \"C# Reference\")\n            -   [Generated Code Guide](/reference/csharp/csharp-generated/ \"C# Generated Code Guide\")\n            -   [C# API](/reference/csharp/api-docs)\n        -   [Dart](/reference/dart/ \"Dart Reference\")\n            -   [Generated Code](/reference/dart/dart-generated/ \"Dart Generated Code\")\n            -   [Dart API](https://pub.dartlang.org/documentation/protobuf)\n        -   [Go](/reference/go/ \"Go Reference\")\n            -   [Generated Code Guide (Open)](/reference/go/go-generated/ \"Go Generated Code Guide (Open)\")\n            -   [Generated Code Guide (Opaque)](/reference/go/go-generated-opaque/ \"Go Generated Code Guide (Opaque)\")\n            -   [FAQ](/reference/go/faq/ \"Go FAQ\")\n            -   [Size Semantics](/reference/go/size/ \"Go Size Semantics\")\n            -   [Go API](https://pkg.go.dev/google.golang.org/protobuf/proto)\n            -   [Opaque API Migration](/reference/go/opaque-migration/ \"Go Opaque API Migration\")\n            -   [Opaque API: Manual Migration](/reference/go/opaque-migration-manual/ \"Go Opaque API: Manual Migration\")\n            -   [Opaque API FAQ](/reference/go/opaque-faq/ \"Go Opaque API FAQ\")\n        -   [Java](/reference/java/ \"Java Reference\")\n            -   [Generated Code Guide](/reference/java/java-generated/ \"Java Generated Code Guide\")\n            -   [Generated Proto Names](/reference/java/java-proto-names/ \"Java Proto Names\")\n            -   [Java API](/reference/java/api-docs/overview-summary.html)\n        -   [Kotlin](/reference/kotlin/ \"Kotlin Reference\")\n            -   [Kotlin](/reference/kotlin/api-docs/ \"Kotlin Reference\")\n            -   [Generated Code Guide](/reference/kotlin/kotlin-generated/ \"Kotlin Generated Code Guide\")\n        -   [Objective-C](/reference/objective-c/ \"Objective-C Reference\")\n            -   [Generated Code Guide](/reference/objective-c/objective-c-generated/ \"Objective-C Generated Code Guide\")\n        -   [PHP](/reference/php/ \"PHP Reference\")\n            -   [Generated Code Guide](/reference/php/php-generated/ \"PHP Generated Code Guide\")\n            -   [PHP API](/reference/php/api-docs/)\n        -   [Python](/reference/python/ \"Python Reference\")\n            -   [Generated Code Guide](/reference/python/python-generated/ \"Python Generated Code Guide\")\n            -   [Python Comparison](/reference/python/python-comparison/)\n            -   [Python API](https://googleapis.dev/python/protobuf/latest/)\n        -   [Ruby](/reference/ruby/ \"Ruby Reference\")\n            -   [Generated Code Guide](/reference/ruby/ruby-generated/ \"Ruby Generated Code Guide\")\n        -   [Rust](/reference/rust/ \"Rust Reference\")\n            -   [Generated Code Guide](/reference/rust/rust-generated/ \"Rust Generated Code Guide\")\n            -   [Redaction in Rust](/reference/rust/rust-redaction/)\n            -   [Building Rust Protos](/reference/rust/building-rust-protos/)\n            -   [Design Decisions](/reference/rust/rust-design-decisions/ \"Rust Proto Design Decisions\")\n        -   [Protocol Buffers](/reference/protobuf/ \"Protocol Buffers Reference\")\n            -   [2023 Language Specification](/reference/protobuf/edition-2023-spec/ \"Protocol Buffers Edition 2023 Language Specification\")\n            -   [Language Specification (Proto2 Syntax)](/reference/protobuf/proto2-spec/ \"Protocol Buffers Language Specification (Proto2 Syntax)\")\n            -   [2024 Language Specification](/reference/protobuf/edition-2024-spec/ \"Protocol Buffers Edition 2024 Language Specification\")\n            -   [Language Specification (Proto3)](/reference/protobuf/proto3-spec/ \"Protocol Buffers Language Specification (Proto3)\")\n            -   [Text Format Language Specification](/reference/protobuf/textformat-spec/)\n            -   [MIME Types](/reference/protobuf/mime-types/ \"Protocol Buffer MIME Types\")\n            -   [Well-Known Types](/reference/protobuf/google.protobuf/ \"Protocol Buffers Well-Known Types\")\n        -   [Other Languages](/reference/other/)\n    -   [Support](/support/)\n        -   [Version Support](/support/version-support/)\n        -   [Debugging](/support/debugging-playbook/)\n        -   [Migration Guide](/support/migration/)\n        -   [Cross-Version Runtime Guarantee](/support/cross-version-runtime-guarantee/)\n    -   [Downloads](/downloads/)\n    -   [History](/history/)\n    -   [Forum](https://groups.google.com/g/protobuf)\n    -   [](/navbar/)\n    -   [Search Results](/search/)\n\n[View page source](https://github.com/protocolbuffers/protocolbuffers.github.io/tree/main/content/installation.md) [Edit this page](https://github.com/protocolbuffers/protocolbuffers.github.io/edit/main/content/installation.md) [Create child page](https://github.com/protocolbuffers/protocolbuffers.github.io/new/main/content/installation.md?filename=change-me.md&value=---%0Atitle%3A+%22Long+Page+Title%22%0AlinkTitle%3A+%22Short+Nav+Title%22%0Aweight%3A+100%0Adescription%3A+%3E-%0A+++++Page+description+for+heading+and+indexes.%0A---%0A%0A%23%23+Heading%0A%0AEdit+this+template+to+create+your+new+page.%0A%0A%2A+Give+it+a+good+name%2C+ending+in+%60.md%60+-+e.g.+%60getting-started.md%60%0A%2A+Edit+the+%22front+matter%22+section+at+the+top+of+the+page+%28weight+controls+how+its+ordered+amongst+other+pages+in+the+same+directory%3B+lowest+number+first%29.%0A%2A+Add+a+good+commit+message+at+the+bottom+of+the+page+%28%3C80+characters%3B+use+the+extended+description+field+for+more+detail%29.%0A%2A+Create+a+new+branch+so+you+can+preview+your+new+file+and+request+a+review+via+Pull+Request.%0A) [Create documentation issue](https://github.com/protocolbuffers/protocolbuffers.github.io/issues/new?title=Protocol%20Buffer%20Compiler%20Installation) [Create project issue](https://github.com/protocolbuffers/protobuf/issues/new)\n\n-   -   [Install Pre-compiled Binaries (Any OS)](#binary-install)\n    -   [Install Using a Package Manager](#package-manager)\n    -   [Other Installation Options](#other)\n\n1.  Protoc Installation\n\n# Protocol Buffer Compiler Installation\n\nHow to install the protocol buffer compiler.\n\nThe protocol buffer compiler, `protoc`, is used to compile `.proto` files, which contain service and message definitions. Choose one of the methods given below to install `protoc`.\n\n### Install Pre-compiled Binaries (Any OS)\n\nTo install the latest release of the protocol compiler from pre-compiled binaries, follow these instructions:\n\n1.  From [https://github.com/google/protobuf/releases](https://github.com/google/protobuf/releases), manually download the zip file corresponding to your operating system and computer architecture (`protoc-<version>-<os>-<arch>.zip`), or fetch the file using commands such as the following:\n    \n    ```sh\n    PB_REL=\"https://github.com/protocolbuffers/protobuf/releases\"\n    curl -LO $PB_REL/download/v30.2/protoc-30.2-linux-x86_64.zip\n    ```\n    \n2.  Unzip the file under `$HOME/.local` or a directory of your choice. For example:\n    \n    ```sh\n    unzip protoc-30.2-linux-x86_64.zip -d $HOME/.local\n    ```\n    \n3.  Update your environment‚Äôs path variable to include the path to the `protoc` executable. For example:\n    \n    ```sh\n    export PATH=\"$PATH:$HOME/.local/bin\"\n    ```\n    \n\n### Install Using a Package Manager\n\n#### Warning\n\nRun `protoc --version` to check the version of `protoc` after using a package manager for installation to ensure that it is sufficiently recent. The versions of `protoc` installed by some package managers can be quite dated. See the [Version Support page](https://protobuf.dev/support/version-support) to compare the output of the version check to the minor version number of the supported version of the language(s) you are using.\n\nYou can install the protocol compiler, `protoc`, with a package manager under Linux, macOS, or Windows using the following commands.\n\n-   Linux, using `apt` or `apt-get`, for example:\n    \n    ```sh\n    apt install -y protobuf-compiler\n    protoc --version  # Ensure compiler version is 3+\n    ```\n    \n-   MacOS, using [Homebrew](https://brew.sh):\n    \n    ```sh\n    brew install protobuf\n    protoc --version  # Ensure compiler version is 3+\n    ```\n    \n-   Windows, using [Winget](https://learn.microsoft.com/en-us/windows/package-manager/winget/)\n    \n    ```sh\n    > winget install protobuf\n    > protoc --version # Ensure compiler version is 3+\n    ```\n    \n\n### Other Installation Options\n\nIf you‚Äôd like to build the protocol compiler from sources, or access older versions of the pre-compiled binaries, see [Download Protocol Buffers](https://protobuf.dev/downloads).\n\n-   [](https://stackoverflow.com/questions/tagged/protocol-buffers)\n\n-   [](https://github.com/protocolbuffers/protobuf)\n-   [](https://groups.google.com/g/protobuf)\n\n¬© 2026 Google LLC All Rights Reserved [Privacy Policy](https://policies.google.com/privacy) Hosted by GitHub Pages. [GitHub Privacy Statement](https://docs.github.com/en/site-policy/privacy-policies/github-privacy-statement)",
            "title": "https://protobuf.dev/installation/ (text/html; charset=utf-8)",
            "metadata": {
              "truncated": false
            },
            "time": {
              "start": 1771213030536,
              "end": 1771213030797
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_0d70e458a4721a5601699290e6597c819689514950033e3555"
            }
          },
          "id": "prt_c648603f6001tYd9Yy3NJXIrMg",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6485ed3d0012kdcP2VbBvPTeF"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "0078d4e53cc1364054c37f47ef8616804a7a4271",
          "cost": 0,
          "tokens": {
            "total": 103035,
            "input": 2435,
            "output": 120,
            "reasoning": 90,
            "cache": {
              "read": 100480,
              "write": 0
            }
          },
          "id": "prt_c6486058f001ivk0SJgTvF3v36",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6485ed3d0012kdcP2VbBvPTeF"
        },
        {
          "type": "patch",
          "hash": "62625fe158b4cd4dc48be5b45ccb5cc80cbaca19",
          "files": [
            "/Users/alex/repos/vfp/dark-factory/docs/designs/core_gen1.design.md",
            "/Users/alex/repos/vfp/dark-factory/docs/external/moonrepo/moonrepo_docs.ext.md"
          ],
          "id": "prt_c648605bf0017Vx1N0VHqOdfJ5",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6485ed3d0012kdcP2VbBvPTeF"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771213030853,
          "completed": 1771213053430
        },
        "parentID": "msg_c6484620d0011ltzji40BSbVp5",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 107319,
          "input": 3190,
          "output": 1217,
          "reasoning": 1066,
          "cache": {
            "read": 102912,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "tool-calls",
        "id": "msg_c648605c50018lmf9h9cuSeDBi",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "0078d4e53cc1364054c37f47ef8616804a7a4271",
          "id": "prt_c64860dca001R0IJ7FEhbWcBIf",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648605c50018lmf9h9cuSeDBi"
        },
        {
          "type": "reasoning",
          "text": "**Planning protobuf skill and docs**",
          "metadata": {
            "openai": {
              "itemId": "rs_0ecc9b9c8f5cb89501699290e9322c819398444e05706ba8b1",
              "reasoningEncryptedContent": "gAAAAABpkpD7-2IzNCEhRNVZGYqpgTkPyOnZ0Mho6BFtNBZqAOt-DMXHMxP86_gdq54mgiA1BQJTCeCbNY07Cb4ovhpxykH-vtwsssQimRO9s1pXE6Z6JeEHmoLn_BwifGCpTmKJc2Vw38RjHeHKuxUooWu5Xww_V59cXwx9h-QjsyPzbzumpiWfEbQnlp-FsZh0adDSMntNLhg_zVl8nCKgLTgJFx3ZcclGuSAmKrGSOo1P2C5xMTNGnA2DcR82UggyvccxbwLTR-Mcc7A2-zXE70XXqoUP7K7cZX6fRnHPDLwJTDLlokuk1bBe_Zz9Otvf0DjJKSee4EuvrsKPQdFw_cOB8-JoVRlx-NnLRFwAB_SWW9CKHm_jRKR216DXXeBdLtcpC5ZEfBctTmL7F9Alba8kyL2rz6wygUpbDBimKLh7l6E-Eg5Iui6T0xMTsn26QoercOGWeRRRGg4UxCEtyVSf9Kj5OENsPB7qKRJ7jsKQKVfNgbsYXLPyHw7W_ESfa9-vFK6TAyImyc9HYE7MSiJmPLf4ZzT8drjBmYw4rlU4mILj5UlvmRxzSrB3QePJ3hQyz-rR_lesGqYrpZhPKoUosa264QdOeor37Xn8fkRJLcNiicY21bMTEra_M34fj06A1iZJ5wLh0Ui47cIqbXOLaOwqcRl4nffoccVNziKj6iuk5gsIHzfDORGtspxQkQDA1U773YFkwS-xl_swF3LI9S1jye1tbkQQboVJL2ubBVRR9HMyMVgorTrQEOLuysXopq7SPhhOW4zkmWSGdARyjc9IBZGewrGMCljUq1IMi_0vaWoKGFCs8LO81AcnFt6xe_e7lXa8xD4jifQumQKbNqbrzw4KPAbG0CG2oobkORoFEP787q3Oku0NtDl0mfs2J5XinuMkXOC_1mMkz8kBlI_uBnpYgcNwHfvt_hxPnlnyODXfrqb4YWfCm1oW4Y7GCCBK6_v7SoAZZThJn8SZCkYDA60OgI4zcDIuw874etMwlxAu4HU7wPFOf58XnV-1SC0UKYNVik419r6G-N0xHpNpsV886pgn5AOHUGK-hJ5hMl0RS4zAW7UDNOYUQZnwbnDYazj7OkOAE2n7krRtMD9RvwqDf-hnMEbZj4IwxhKgUuOqblq26BTF561AaTQ_XcUGpfUOs6IB_zXa-8kkN-9Rfx2ha-djDh9W4P9BovZjE4ZLpgJrL8ZZgRdz-tJcP8sM1RZCuQCGtoEkoQ38k2rPY-nK57Bdh5cJdJVbmiwJ5BSRDZj3XUfpas0BOIhwow1OmD3kCWUgVKybCAfXwZ_m9BLofrNJJ-DcV239d2LuIMq-6S3gJO-VQtZ_QftFRxS0sGeWBi7AcfqPafd50JIZ6ajU2G5rkxOm8iVwFyMelQYIy-gZQwN78ZdCcW3bhSHNMiev-U00MUYy_FLTOJb1eMW1jNrRmE8zBddULH8Xxc5o91kSdT5hpiBVRb5jvdVyEsLdgOO860G5x3ekkgbWiJs2GFpSz6y7cEI7MwKHQGkPOUEBnAKWjNTODwwE78zZ_OTyr-69LYKwYT3VV8EDfU56InRm6JdUn2ZAOJTYBGrulVV_Rsx32pb30jnljjhMlp4dW2h8GoakEDn_Ds34ICaSXFkEA2BBlb8HYP0Pd8IOrnfLI9oQvjX8ExY9qKVXXlA0J3cqLgX6XCpRParHBSI4NWeZxKyxtVvBYyeV0UEEH59JL1uf5jbSv0wej_vCrRfKk5D8IoBwfT0zlFs7FF0iqwz8kdYkIxJAyG2Ec26d_qMIxnA5sq9k5Fzw75heEWpeSIRljWOkCTfDYWb-r9SbtZveXMjQV0HOjk2Zd-kYrxwESiYDy3ocBsmQp77okaXgAMZ_zF90jNN5Z9eH4wnVJxaimdkbRdRZxM9Dg2Lxvs4a61tRupJC_npUSDRvKfigxELxZaT660vyyzc7h53dy-mmizDSwz-b6ahUfqfIvMteyCwpk6zcm9JODNUvLlt-V2cCex4somhL2cHV9pwHR_oyKwfaYLZ2xtmhkA5KK7__fnuqP5b5Nuc9auXQAesSIFFEVXGBOXP38gCLfykL1Ff5oBfyc3iJ1s5IUGaltkCjWvNusGf4f1tar2zZokzfHzJi0Ls-QZS-JWiZa3I9-x0biMdc91tXYR4fXYuYwg4pNeNfMcr6Ofkqb_XCQGjyxbjTzDiyNo-XqLyKOwXjw_uRHJRcJwaCBGO47u4-pcOgcCyMF8q3gU5SsiP8-Nh9fIQYsyFItZSDsqImmfw9PzVoWDg3uuWRvusGz5yyl2M-XwBexR5z73ZL6ic-MrA1_gV0DNKxIVszmV7UTB8j7IghA807ZfnQCJx37PQauSvJdWOmWdLGvEPm_nffS0psLXlBF_aOL8FIar5BiYQFSPwSrYpAG_GYBBknkIoWpui81iElYHOtdMfYXZmtcnn3HBjk5nFcfwi0M0oAafQrXwMkbXocM1fXzhDwtSZoiiu5VlXPeICL_3vR7OLJYy-EmqL1npEno_9D-oipRGyXHivMFPaLh6EYahFA8Nc2Om-nEarfMDwBtIKaZ9xMAF372y66KaEFNVMgeNE826tzwuptiuwFzc4kReKFKEbF53PGG160_OWTwEKeH_WIcL1GOybjojddsaqc_vIXicQEWs6cayxZH_I6fjRwwH2FpuiSzFZ8fSPqgbCffof9-pkBMLOO4v_INNtBjodvyusMLQnk5uEj5yEBJ3_UcPuNdfGYI9DCQkZ5E5aIMQckWjnjCQ2eja-hVMc1jqslOmNyC-7y7sNyzJUC8xUsksETlnsVXjtL6SjA8c4c9yylM8MI9WF571nnIVq4a6VdlZSeGPUX8Q-Y_YKLnEZPtKHG9_ESe0G4n-8WN13zu-uIyzQ-Erd0VJgKKfyTycYIzmlsTUjDAwz1mR9lyj7hreFt4z_By_mRncsgYboIzjhQQqeBo1O1VqxZdxbSuFWqtsu28fgJL1Ci3MT10n8t3j1s3Z7Hala5oKeSUCQrgAvs5vfJnqxboQFXw3A2s2hdikInRk3SHW7GHvYVEWoEnZ8h-vKDN38vx_mBhi6bgLzTpX9F_YhFai0SOvNPzcCoZnTF7yqrOtvhOTNaIIVwbGqsp6T2rKY8GMLWXpJYLQGZyW1Rja4SLKhuvyKu5Vm_i1TSlZxLcIyRt0GYsi70pgzEajVcKc68o18lS3vvCwpFwl2PnldtZir_Mz19Lwv-TnlV-Ks1AFMaOIyrjvRbf3Re2GtXXOsAB0dUYfbiy2vbE7F6dGbZE4wkS3yAN12HAnLpWlJKjAjIZ3PLtwsK5HMZV1ePTXRHiDKG1dUCB9zw3zuT1rQwXS20GWgxhZGkwWCmSqtFvPptyuFyV9j_SnO8xgYKgFl-ChS8jz33lXks53XzMYaM1g3swzA8TniWo-z-Dvr89t56XuDoSGnskQgCd7FhQVhs_ePgYqCaU6z165Q8Iu1OMVcJmk8arsWpbdayXPbL62f4BkAllmZwTeoB6l4bj7k_IZnS7haFuBbdbMtM1z8TDhv4UgybQQ3aecWRsl_9QA2J0cYa5BjI1wDOVn4Ot4-8aoWp4twePWw3RQfbPj_-EORgv1H3y-Xd0kBAzrOoxBKSPhO2CfUmrrOQlfAjoMgQP1qxOuVD422RkaU__6oodlTuPz8R5yaoDSmsOq7I1KoeFPpXB4zdrh-C5hSHSBW_etZ6ggY_oQo76lU_-RR8tPgTLMtyeNZIKWzVYDgbHPg7k_8wrWm7Gq5TjGjGmUwiOsnrqsWz7khsIzXDDDfT5RuSh_UPfDyVwO37J_gCfS-k2kygl4WjXx9ZCVji9Xirr6HvM_zrQH62NXEifE3km23Qhduw3RtthKMfmJU2omXdIsv_H1VG5IQnzuCr-4DZFhLozNvSvy30R2vMTLNb8cixpf1o1U9bPExus1A_Sz_3hLY7nld5YecNOSjXkDc5VTeu2h2JB8pPv52Q6UdHVC-AWHoeDBLaesJ7GZ69NYKvYeq6lfp70P8Q5ESxD683ufINnV7YUqYsqkWK1WqhfYOOSmwPyd0wwfDf7m1yEkTOnl68kRkOlFjHN_cJrEmwTKFsyDK-s5ESdPzSjFVY3ksFjDVlwPFVSGvmCBDSsMKquVoaWQqn0qX06aoLtHre_rEHbyGiy3gPBYLrikjxAK13sUIy1B9N9OWcJqx9Nv_Yl3CLYdjFtB7Jh9bQ3UBaZp4NZdWHqq56E1_7p4weEypDJzRNh4rd10oLFqflAayybUYcuDtaVoTshhIhALa0Sx3myuR9NkR8qi76AoAIcrX5tFCGE5BaiGqYj1LnTCZx7BlheCqmmezTa8mP0GQAg2_euMxDDsPNitLTdCj8K1uNUOkPe0c5K5AvbXLBwf9WZsmbBPbcgXNtHQRmfI-hl0bejwtkw9Hw33tJwfF_TLX5bQAx-zH62zN3vmSqhdM-Ds0vRq9P5HTAe4KLJy-_jW2BfDm4ze7aAEBiCMHRzMeAhbm7Sq9-1iL954nFuYDDaMwNBqRfIPC_e63rOwYX8JDQmweQZ1-VAgLjN9qJUVWeoeTEGXCgXttjQbP7VQ97o2zEpqkU-ZU-R5G0O0MhfS9fdySEBZ7v5Yzgu21wlm2ERjnHmlEcwkvxgU4O4ynUx6fV2NCR__-1cUe-l3MQg04oN6WqbqiyBVa-JLxb07U366-XgOfsqmbR8mxK_2IJB5kqLRK-YjHfZMJNRCOu14u0RIRbbvHziqoeKItCxSNC_Sqt8CjwUp59Mz6vJrI__UN-jnTMsT3OKBIWBy2c8io5eN8N0_cnQuOReh_FfACXNXWAmsRT5IYvGe1uIvDgS7e_dfEbxF8Hbrx_RmtOjrjH6QtlUJxLubxcniEcmPvsjXdCBc8B1SIVwES1loOyYSZjz78cKXfsuZv9INA67JH2yWQfz0iwGPNTLRVWvCoqeb-2HtDcuk5pwtkLQcMLr8qBGBXNwnnFeoQijTLwqR_neULa0EcQ63YX_G5XJ23QNrkU7kF2BZ3TxglHh3Lh3vRFpmWbK-kQHb6uHaV6u22bZJ_2smU0SLXVUUdVrCyXU1i6bxpD8EBzYkBh2LtT-PXYYu5GtIzMjou7OJUN2nTv4zOqaiHLQVt1FFSGje2FjlGPNIY4pkytKrVFEgw3kcboBEFffWLu68tMlT-PY2ickBtESWp4DfpCQ8iWXtbkZZqyYOCnLLuatrFT8CF7sG4YmnGmGIWW1EjksmtHNO-ugwmjzB_c1AwZ0Y0veyd2eMOkOpb2DoJOVKYZ3bjUWUk8OCKfduStDHP4PomkGCsdRcZCb8vajzBGepfWX0TKbRqcvRRA-CRbv1Ivwa90ZDarqWUHUhKscuBdQu902X-6bm2BUwMgVSVxSJFmCsKAMDSDMb_yQKp7cVrWgPyDFPUzKv9XyHk6pbliIRvUbo5KthbD2CAacre4a9dzWVHgEAGoLaypDQ65q0qFcrh5OQ2ZQiYEAZqWKi2BOCLkoxRotJ9IP6BPFshZCu__1WGslqhgc5laAovFdwx7b_HqQnkrL0COQ2u61jhfD0947M5tQs0NhY6RxRwSZl4IGXTKQ8kXabyxN5945Ey_GrdKCVoaPQcnC5KA6ecCImoHGWWd0YI0TDBbMd6ZlfvXNrWGBALYkywXEQuv3rwDqK1Pb-8q6pwEFUqLqunA7hBw6megAwckrs5S-J7E6uWDMu79f--7ucxTW_GcTLrzYY80wTWEv4DagdgTr-AfZZXiETO-UjrAKb2EcphN7nix_cfAVvJexH5dAP2cRrYqn_R3Xc1dyF65Pob-Y_HG8SWE1v6YVbIPWOCKkfw0KMF8XXAOEB4zrLLKi6GnCvx3Xuzbjmq09HdDcHrX5udcLGpTIdqSxOX2cA02Cs0GwSrJncQ-njrIWDQGcjJUlNo-tlbRNn0_7LQK0f4oLgo6frIi8edM5MYNqPa8j2GrrsCeIjRPU5mgKsq_HiCw5PJd23ybZ3BzUjb9m68hganeU97gRNXZsOHOUs-6TkJzj7JQDNCPk0YJFOAxwP1Ry9OxxActSnIkWl3yjyvR58gIkLpFTwnv0MkLiRVuuhWHL1-GAxiy9_vHaOOx_sst-_h2dVVLLDMddO6522tv61yXsvaoq7M0M5JQ9CZ-eYfJ3TE1srwbLHqGnqv_NvuB074-eNEe8S1Kyp-8i5lR09KSho-0ErgZPEaXm3kO_0AloKYPK6_9vdwIoGsjcmfgO74gynrX5rRqXatfmbtvtBAxKCZJsvDdVaO_58D8IO1MGm8E_Q5sOf4oFolv-2oEVjvK28QzPBBaPkl6lo47iQOIsxve_PDGZ9CXh4sGByyU_js0XQYdls3mz_1phy_p6qGNRMpf-1dYXczJH0G1tpvFzW_IYT5QG2fZsP1hi6byXXH4DTA_HIjL222qEcOdUDs-_DogkJ3DA30e-TrYN2qVSrQg7EQ4jK3fjjZ-CDnCVyzWc-0DfpsCZhKc7dv2fgqSLLMawTx7mEPQ0tBk3nOGJXrSCcqx-4Zm7KmoSln5D0ipZ9g21wFhCk46oOoOv0Uh4299TVy4tW3y1JYSR3HpMi2LV-APdiRPT35QvMleXqP1uSsxrPgNfxK7Euqw97IE-QTwO2_ZoRk3991iZDYBLjCdpmvdbLy3zZEwe2KMkyv76W5BQlSUftIBr2pR0zSjM0cXFTUjRjG8cXuuCA5UetkA0MHlvfINYHYgic0QlMVCMeLvc9UV9tjaxt0j3g_96psW5B7JvIXpokLSa3KzwTpGJA4PVVxhRLckI0--4lU9Eu3sj4pKHKDoEOQlz-R3zT0SrUf2fmodWTSOwO2ffc4anw796xZkBKCWg-CpxKLVdjXkFAPgQDENALs8kPWL3wyGZmM_jRCeDnYjygMTqd06u34trhSMnHY4Oh8J3afuselcf0ei2jBikp32NyKkG6sYiX6eqV-h3bKT1UC463M2849Uvo-3PRanFl4sYTkzg1vX7zDKg1XVLY-nL0oXFbLfaZZHptXW34v9pDpPdHwWhfwRtoMxXeE1BqAdk_NDtwd0nfD7-kNmJiuk9G4ODVn5ElqZKlDsBYa1j_WbNHe15wHbfslgu1BgHVrmzUkTVLi7tulOxUwvypy74FJxSc0_UhImuZ022V_qUSiOv2GLk_9P157Hrp6IJd1hzCjsS-_GGDZ_P6jO01pbdgHEEfPs0JlMlGufcVU-6WYYZPQMF6SXlmu16r2hHF30mc07fxTE3DN68WR4Enl83TGYAso7mepfmtTmdTAd7f5dY3JsHHZtvYd7W4vuWbpWKRi-Jd33NG9LNQu1_Sy9_a-3bNQ-EJUq2-2VRPgTb9ainW57ku6BfqCN71eHd_G4CYplxK0OHA3l42ukYBo3FZimyHW8SXOBVe3WSOPVmx8k394YF56pdMhcae5bQFlaZ44f2Mw4zhrMHiZjpYcbF0qrLHzrJLfuv-n_E67G2a0gHmu1wNeSaUiokD98-WmW6FGkrovYzWXDz5sD2yuZovPiLVvTzscGm8FrJHI="
            }
          },
          "time": {
            "start": 1771213033226,
            "end": 1771213051501
          },
          "id": "prt_c64860f0a0011A3XMRU8HZuPmX",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648605c50018lmf9h9cuSeDBi"
        },
        {
          "type": "tool",
          "callID": "call_gCftUybV6Uop40G76dCuZy1u",
          "tool": "todowrite",
          "state": {
            "status": "completed",
            "input": {
              "todos": [
                {
                  "content": "Collect authoritative web references for proto2/proto3 differences and protoc usage",
                  "status": "completed",
                  "priority": "high"
                },
                {
                  "content": "Write research notes under docs/ covering schema design, v2/v3 differences, and Rust/TypeScript generation",
                  "status": "in_progress",
                  "priority": "high"
                },
                {
                  "content": "Create new OpenCode skill under .opencode/skills for protobuf schema authoring workflow",
                  "status": "pending",
                  "priority": "high"
                },
                {
                  "content": "Update AGENTS.md skill inventory to mention the new protobuf schema skill",
                  "status": "pending",
                  "priority": "medium"
                },
                {
                  "content": "Verify resulting files and summarize deliverables",
                  "status": "pending",
                  "priority": "medium"
                }
              ]
            },
            "output": "[\n  {\n    \"content\": \"Collect authoritative web references for proto2/proto3 differences and protoc usage\",\n    \"status\": \"completed\",\n    \"priority\": \"high\"\n  },\n  {\n    \"content\": \"Write research notes under docs/ covering schema design, v2/v3 differences, and Rust/TypeScript generation\",\n    \"status\": \"in_progress\",\n    \"priority\": \"high\"\n  },\n  {\n    \"content\": \"Create new OpenCode skill under .opencode/skills for protobuf schema authoring workflow\",\n    \"status\": \"pending\",\n    \"priority\": \"high\"\n  },\n  {\n    \"content\": \"Update AGENTS.md skill inventory to mention the new protobuf schema skill\",\n    \"status\": \"pending\",\n    \"priority\": \"medium\"\n  },\n  {\n    \"content\": \"Verify resulting files and summarize deliverables\",\n    \"status\": \"pending\",\n    \"priority\": \"medium\"\n  }\n]",
            "title": "4 todos",
            "metadata": {
              "todos": [
                {
                  "content": "Collect authoritative web references for proto2/proto3 differences and protoc usage",
                  "status": "completed",
                  "priority": "high"
                },
                {
                  "content": "Write research notes under docs/ covering schema design, v2/v3 differences, and Rust/TypeScript generation",
                  "status": "in_progress",
                  "priority": "high"
                },
                {
                  "content": "Create new OpenCode skill under .opencode/skills for protobuf schema authoring workflow",
                  "status": "pending",
                  "priority": "high"
                },
                {
                  "content": "Update AGENTS.md skill inventory to mention the new protobuf schema skill",
                  "status": "pending",
                  "priority": "medium"
                },
                {
                  "content": "Verify resulting files and summarize deliverables",
                  "status": "pending",
                  "priority": "medium"
                }
              ],
              "truncated": false
            },
            "time": {
              "start": 1771213053335,
              "end": 1771213053336
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_0ecc9b9c8f5cb89501699290fb71b08193a68227e5df0c5ae4"
            }
          },
          "id": "prt_c6486566e001Sxbw5KCqsYDx4t",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648605c50018lmf9h9cuSeDBi"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "0078d4e53cc1364054c37f47ef8616804a7a4271",
          "cost": 0,
          "tokens": {
            "total": 107319,
            "input": 3190,
            "output": 1217,
            "reasoning": 1066,
            "cache": {
              "read": 102912,
              "write": 0
            }
          },
          "id": "prt_c64865dba001OCCLg8xOp1C7HT",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648605c50018lmf9h9cuSeDBi"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771213053433,
          "completed": 1771213057600
        },
        "parentID": "msg_c6484620d0011ltzji40BSbVp5",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 107608,
          "input": 392,
          "output": 80,
          "reasoning": 46,
          "cache": {
            "read": 107136,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "tool-calls",
        "id": "msg_c64865df90012htSb5LhDh5wxu",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "0078d4e53cc1364054c37f47ef8616804a7a4271",
          "id": "prt_c6486660f001D12DEPlrx01bF8",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64865df90012htSb5LhDh5wxu"
        },
        {
          "type": "reasoning",
          "text": "**Inspecting agents file**",
          "metadata": {
            "openai": {
              "itemId": "rs_0a24bc74d899c06001699290ffdaa48190bec662dbe89e30e9",
              "reasoningEncryptedContent": "gAAAAABpkpEBSTUmzyiKPnNwt-ZYhSuu8_jXY_vxnnz2JV3xp6MNfE04A_v2nvvuvQjpDDsBOL9x7RczNfmXDatEEE_NwXnYmBTlOW5XI1JfvxnKlSdzwPKxaQT_J4jiACix2GQVnZ6RgaG2r85u6F00gqvjILH8c66hJJQND5Y40cgVITM2oayXU5TrchEh_jPDwqrmosFv6irgVYeMcxNd-_gHazxb8urcarAdH6GE6Ab3zA5agJhppHuQ76nSS4QjJdF44p1efEDE27MVtcum8Qq-RWYLrfjkikjaQHFBS825oCvChQpXtI3N1L3qwuFeQs1ImTEK8WUsuNabL5VyjCy-4UGc6ste9lFu12BVFQ1Zyne8iu-yQrU73kUsqNANSRZ_6gfUsfYS-tQqujznCoMqWzD6Hk9LI78Zu3YcUVOk_JW_rWtKjrSEPYUl_KW-6Q3d1U7Iq1NHG4KYwkT7XlBoAPRGub9QUTP_htUSZyBJbuQiX_2Mp09QLlySxEoJg3gDSMusma-iCz4UlUqDGCjXK3GR9RpaZntpeRbMb1BpBwOLM7wFu5j3-fjBggdaxrUJFaS7tZwpa2cxf4ysuk7V6KWZW9VzHUV-S8xTVnh8CG6Q0LWsMKGleuDSP8Pi_ahh20wF4rOAE2MMSRAIlwcK1d42Ja7pHDbBObRiUHehUY0jWhIzoMrfmg4v5E0wAsThSnXn2mAhiMim7O-EOsSNLh1fvAONkIqgE2abcGyxLi7sEu8y2rN8r3SHc4b540DKUnCyndHC8PAMNEMJxMuHFs4THSLutXOD0kNeCUeCFhIeONNrRisLXw4wpXaI8jeVUush0pMtCVVglRApmzvl-1UtvAGhox1LxBDBeXpZafr-VcZR8gVL4WOI1AG_fIUaazFxF4trQTVSZD0_JN3RsIK1IyFOu92tsnTAWmSOTY_0vBpbLFbe1PMR8Th31z1v5JW4aqsG2igl2SDXfquNrKTns_Cijf97SUfDQBjFy_F2qyjDcNOxg_8sGrT-7HvrpwQGUSNb-8yJNNpeYq-sFSj_RuxIYRYESrM_giyTh0h-RYwBUmr_GKqhbJiRxFFEFCdhaREEMKLUO8_GcSvIehot1xuzx2S-dtxMttDVTXupPuo="
            }
          },
          "time": {
            "start": 1771213055945,
            "end": 1771213057181
          },
          "id": "prt_c648667c9001Va3AbmUQhFw2Dj",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64865df90012htSb5LhDh5wxu"
        },
        {
          "type": "tool",
          "callID": "call_aEoimjSR8LYWS6aPuOYaOIBz",
          "tool": "read",
          "state": {
            "status": "completed",
            "input": {
              "filePath": "/Users/alex/repos/vfp/dark-factory/AGENTS.md"
            },
            "output": "<path>/Users/alex/repos/vfp/dark-factory/AGENTS.md</path>\n<type>file</type>\n<content>1: # Dark Factory - Agent Operating Guide\n2: \n3: This file is for coding agents working in `dark-factory`.\n4: It reflects only what is currently true in this repository.\n5: \n6: ## 1) Current Repository Context\n7: \n8: - The repo is early-stage and mostly docs/config right now.\n9: - Tracked project files currently include:\n10:   - `README.md`\n11:   - `TODO.md`\n12:   - `AGENTS.md`\n13:   - `opencode.jsonc`\n14:   - `.opencode/agents/gitter.md`\n15:   - `.opencode/skills/gitter-commit/SKILL.md`\n16: - No application code tree is committed yet (`src/`, `apps/`, `crates/`, etc.).\n17: \n18: ## 2) Build/Lint/Test Status (Current Truth)\n19: \n20: - There are no validated build, lint, typecheck, or test commands yet.\n21: - Do not invent or assume project commands in commits or PR notes.\n22: - If new tooling is added, document only commands that are verified in this repo.\n23: \n24: ## 3) Cursor and Copilot Rules\n25: \n26: - Checked and currently absent:\n27:   - `.cursor/rules/`\n28:   - `.cursorrules`\n29:   - `.github/copilot-instructions.md`\n30: - If any of these files appear later, treat them as authoritative and update this guide.\n31: \n32: ## 4) Coding Style (Minimal Baseline)\n33: \n34: Until language/tool-specific configs exist, follow pragmatic defaults:\n35: \n36: - Favor readable, explicit code over clever shortcuts.\n37: - Keep functions focused and avoid hidden side effects.\n38: - Avoid dead code, unused imports, and speculative abstractions.\n39: - Keep naming consistent (`PascalCase` types, `camelCase` values/functions, `UPPER_SNAKE_CASE` constants).\n40: - Handle errors with context; do not swallow exceptions silently.\n41: - Never log secrets or credentials.\n42: - Log messages should follow: `System // Optional Sub system // Message (Metadata)`.\n43:   - Example: `Core // HTTP // Listening (env=development,host=127.0.0.1,port=4150)`.\n44: \n45: ## 5) Git Workflow\n46: \n47: - Commit meaningful units of work; avoid giant mixed commits.\n48: - Do not push unless the user explicitly requests it.\n49: - Commit message format:\n50:   - `{Component/Meta} // {Optional Addition} // {Short Description} (Optional,Tags)`\n51: - Examples:\n52:   - `Docs // Added converted PDF docs`\n53:   - `Pipelines // ODM // Added initial ODM pipeline (WIP)`\n54: - In commit body, add a short rationale and signature when possible:\n55:   - `// Chappie/Model (your model if known)`\n56: \n57: ## 6) OpenCode Integration\n58: \n59: - `.opencode/agents/gitter.md` is the git-focused subagent.\n60: - `.opencode/skills/gitter-commit/SKILL.md` documents when to route commit tasks to `@gitter`.\n61: - `.opencode/skills/proto-install/SKILL.md` documents standardized script-based `proto install` usage.\n62: - `.opencode/skills/script-authoring/SKILL.md` documents how to build reusable Bun scripts from prompt/example/bash/context.\n63: - Use `@gitter` when the user asks for commit support or cleanup.\n64: \n65: ## 7) Local Fork Workflow (`elysia-protobuf`)\n66: \n67: - `elysia-protobuf` is also cloned locally at `~/repos/vfp/elysia-protobuf`.\n68: - If Core hits a bug in that dependency, patch it in the local fork repo, push the fork, then update the pinned git ref in `core/package.json` and refresh `core/bun.lock`.\n69: - Core currently tracks `elysia-protobuf` from the fork `master` branch in `core/package.json`; after pushing fork changes, refresh `core/bun.lock` in this repo.\n70: \n71: ## 8) Script Conventions\n72: \n73: - Project scripts use shebanged Bun TypeScript files (`#!/usr/bin/env bun`) under `scripts/`.\n74: - Script naming uses `*.sh.ts` to indicate executable shell-style Bun scripts.\n75: - Shared script helpers live under `scripts/helpers/`.\n76: - `scripts/install.sh.ts` runs a reusable ordered list of install steps.\n77: - `scripts/proto_install.sh.ts` runs `proto install` from repository root.\n78: - After a new command sequence succeeds in a conversation, suggest capturing it into a reusable script via `.opencode/commands/capture_script_from_context.md`.\n79: \n80: ## 9) Keep This File Updated\n81: \n82: - Update this file when real code, tooling, or CI is added.\n83: - Keep instructions tied to verified repository behavior.\n84: - Prefer short, accurate guidance over aspirational process docs.\n85: \n\n(End of file - total 85 lines)\n</content>",
            "title": "AGENTS.md",
            "metadata": {
              "preview": "# Dark Factory - Agent Operating Guide\n\nThis file is for coding agents working in `dark-factory`.\nIt reflects only what is currently true in this repository.\n\n## 1) Current Repository Context\n\n- The repo is early-stage and mostly docs/config right now.\n- Tracked project files currently include:\n  - `README.md`\n  - `TODO.md`\n  - `AGENTS.md`\n  - `opencode.jsonc`\n  - `.opencode/agents/gitter.md`\n  - `.opencode/skills/gitter-commit/SKILL.md`\n- No application code tree is committed yet (`src/`, `apps/`, `crates/`, etc.).\n\n## 2) Build/Lint/Test Status (Current Truth)\n\n- There are no validated build, lint, typecheck, or test commands yet.",
              "truncated": false,
              "loaded": []
            },
            "time": {
              "start": 1771213057372,
              "end": 1771213057376
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_0a24bc74d899c060016992910104d0819089c96995530a6c50"
            }
          },
          "id": "prt_c64866c9f001K6VitJIfvlTRHI",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64865df90012htSb5LhDh5wxu"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "0078d4e53cc1364054c37f47ef8616804a7a4271",
          "cost": 0,
          "tokens": {
            "total": 107608,
            "input": 392,
            "output": 80,
            "reasoning": 46,
            "cache": {
              "read": 107136,
              "write": 0
            }
          },
          "id": "prt_c64866df9001GH6LUd57geoDhk",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64865df90012htSb5LhDh5wxu"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771213057604,
          "completed": 1771213073307
        },
        "parentID": "msg_c6484620d0011ltzji40BSbVp5",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 109481,
          "input": 1263,
          "output": 698,
          "reasoning": 664,
          "cache": {
            "read": 107520,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "tool-calls",
        "id": "msg_c64866e440016VjetLLOSqOWvF",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "0078d4e53cc1364054c37f47ef8616804a7a4271",
          "id": "prt_c64867660001xSHis0qFWX4OXx",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64866e440016VjetLLOSqOWvF"
        },
        {
          "type": "reasoning",
          "text": "**Drafting comprehensive proto notes**",
          "metadata": {
            "openai": {
              "itemId": "rs_0537c721e67a9d5c01699291040d8c8195a0a9bad0c78c5bfb",
              "reasoningEncryptedContent": "gAAAAABpkpEQbleQZsyMl7SsPvOsoR1L9PdxejYLuv9A7847miV1gj0-9FKif-Ubg3GOAcXFSacKd7oqcIZlZzCuEMcf0sizY2LhBrlnjuztn17X2rSOJ8Q5gKDjF7nnN4e8XJFM01BBhqH7xXZQh2SQ3obdQPdBeNVxzuYVq32mQ5C_5ZU-cbIfImFK0ljkp5v2Von_iv-ieqIGH47P3xLqnoY_rRO7imAUwPp1JRbcYjXR0RY1D_W_zO-IiSvQ0UwV3jViJGmNfuyZCd-HRe8DLITdgkEbNz-eikiXYm1Hge0cMmCVLA75MEC4mbaAJKgvqo1b3yvaRXNWU8s0K2tY1ksmHef9US5FiIoKXnWP21n046oL6ERDaukX9t-bo--38xIHm52y_JaFol3ui0FRDZLY38Fq5WOvZnBlyrm4-xwY03T3QThm07wOZjZaZ4RwWPlzAJCKTIdARX1UHaA5FKjfEwgjVRDONeUw5y82KaPSOC7baIhM4kHFE9bFUE1SAaj3LwtLn4JUYZhpybKI72yp5B2xF3tE9AUmMFDs4X6UvU7EAq2jIDGlrndcWh91hKT5cpSgkDPkEIPIhZrrzxsfYREx0EB2oP8qX2QMeo4bVHguxeq3q9x5OjomLRZx5xaEL4C3UNfUqQEyuUb4NAai26RImjnBcX5wWzc315_fHX2cnLQiOS9nsaEKDYS5-aVqZpsV4R6McnI0kCyF01OILmQJrNVjmYtjM5NHC62Ljx9LgS07tmaeffWIULlHnFChe84hsIC1y5J8W6Osic6YcKp8uKrxBmchT6L6PjzCs7wrUfA36sYmLhig1jc9aX5On6H_HazaMPGD1eY5626LKkXV8J6m3YRPS_EkQAj8IWbWBd5gLGonGtITjG-VtVgYo88V5JkUkSE7WfonuwA4yhJq6KxEaEFI4aLLzvf3Q3sKVF0TVAkwycwR_rzzAw7R62f88sjQNRSIQlcMYxEZHpVtXumGJtONjB8J88KVfz3JHlPHQdXsAmLz6vJg0OtwmNlliIhHDpXw5gNFWUf8n24pkqNoqhV1uLCwZdv7zLMdAH8aDUGwYfHfYgqO0RkCCHpL4cDjydcHh9NH7Lm_yHHKsmfG34y8C2WexEmzxlDsS2kdPdsQgxhg23yDSlMBsHblitcJmIVCBz7WuoWUjGHJpjkuG4Z5O6ja-U4mKlDX7-j9vfkyMUngKnCly0XjrtRl9zi-18ARfSHXH2TugHMI9QUDMjkxAJIYMvCBVfUurn6-Za6wK9SQM_T9FX1pKj4vJoUWKvn82R53oY8uiwc2c7aaNSIYY15kieL_aI-nd2F2vQAyDx832EtUibq38E6L8MGxWzSH75GyHDljoCP-A5ifKP-Zp5x9ax5N3i8IhlFERexoZdXoVMt_EFRuLVUEe8vsE4L5uNmtDMWXpaB44RIt-Pj1nb6Imfe3MkuWaqljdSEgstcAMXkY9HwFtfcEZy_WTBDp1S-2hIrVscCJDV973qMUX5pf-XdjPTH9MhPHBiYHqstEyakW2P_9kLASSyY9YlzNRc4VBS_osZ602GUOvZT31cHJacNqm-ZHZQuhjwP1jKy5HQmG1_nVNR5SujwXpQzoON4QDDH3jQt3vkoVvEIeb58iK0NlntQWKQqA3fzMrgANqxIjnUTpGQwMfPxfGyeXaPDdhlN-_AotDH_CB7nP6al1vRuDtwRivDIKqE3CmptymMldk0EYZXeS3mRCcabEOfsCQFLrbJsZoKk-fbn7thqeyshoZvUXxukXfMp7SYJWV7ImjwXdI-2X8lwXLsrVxgmlgwkcLPUSyakMloBdoGZjzagrB5ArtbcjZJt0ok9sIP4U0yZegd8jvDD4NM4Bn5aBdM88KCl9OPIvP85grhyqNuscl4HwnIX67Bs1YZu_NxDAjJVHJbIQgKzpK25Ld-u82Fm9VEaWfqmFgbXlyweQfEyjc3We3E6-RucjelTQauO1oIeMu4OLmJq-7IUKFqH5Xz0VfJYKSA_QyNHjDGUZSOYadGG7gXaEAHrE9KKKAW0kqhkTcMQARyUVSgrAHQjezz3KzDBQe2pllgdXxIQGaOmnoPGwWNB1huSeGl38WUdJtRQEi3BkSTjHkXp_NyJohnrJBu46cMb-Wnaa_pwbPINm-RaudOPYT7BUtIdHbaVXI9sovg1mRRapPLaFNyE_AsO6zxk5H357Ptnw-ow1cLKripUMp9yrAqOYQtkYo_mtpYfGtBhIeMLTLR6yAJwFl2Y7WJOHeF_bzZzeeS-bEIkkbY0MilE2-hvmjW60uXrxwvLu0z8b3BVzlBsMDorDACWzking29nieQxQZY3TshT7Y6rkk-a_XnxDAcSvFTKkF67kVCZZ-oWm4IDYwlFP3RE4Do5O8daNwhexwgiS6OTl4jqzY2yL0r2YfQptIcH0f0zIspuyxik_k773bf1GTtz-A99EmFkBBwcAK1pK_D24hAa_UirVakfQNcFf3neHMkiOFTG7o4qLq5Ay8pVLhUBACnL8kU90cQegR109aKpKNb2xTDCJCgbvpj7USenRVAj_7DXHwAR6Z1_7XyeehC8OOH0258OKIeUbNp7DO9c5UloXvjdxaKNh0_H7dxwX5iwDT6rR9NoFxDmoXj3RsZ6zj_oiX_lha-HNvatxRe7TBO1IpfTOxbRYCWu5iaxeu6IJDI36h7xrfUiKie_xB2YvYxPxpNn8QqOcdFqkdAp3Ubu3QIUlfONhVP9xwABStPU66PdEEcimDN3BnB6kMzyh-dFIUULPwiEInB11HEtkYqP7bxU-CCJvdaPIN6EbcfbeQqM9ROxl9dn1H9FmEDpHkhxhkLKyOvRB5T5B2vTGzn6e8ZxRCRgteZIQnfadzbUZtnUwjhpr0gQFGR_9n1PgESA-woa-ExUVPx2DJZX_-HUFOPjHZ8eyqIL47DW4V0PZfcCcP9djlpaEjD0jQJjYDw8cj_M3NurnlkjJYMnSjki3m3QDSkw_rzMaJCH7MzDOGyY2PBT2jGkiflxOSZqSrUX6TWz-XsUOW8P6R5tQ-EY7afm80xtGEIlxlaUngUMNvQKj3bI1Z_s3m6tZWEraxb4ouLEH87PArl966EDPhF9sMnNevwBfqKy97LkBAPxCM1PZoJEhdqc-3K8EBiECS20k8bXBqIIHENrswanFsHSSNWFqFUVgnCtTxAj0sEZ3ImElXAKQ85e4SR5fZqCMpfh00sd6eZ-fIuctYwCpvCUuVfyfys30mV9MAhj7eiGifm0HL_tFb9tfqoz8WSyFCuJzjg0D4N4hDIexp4HPe7Nx43chYzlwf3rLnX8aqhN85sZbul5PxSPh54pCaZjvPw-FNeZD2oXNi1hXPGuhVSnBjDX7CZHAyapfT8Ia8FxaKeTYSEEwIojR1uWHyvVGD6GKLY5zspcVKViPGYPpSrBOHGHKV6EnXg7CAcz_5TG-dMd315idDHWhLVW0nYNHSJovZhoBlcu5qlCKtCiboRYivAVhPmA_kfUSUgrxyioCR3e43Q5xlehhF4SWbnhJD2HA-LMyUAxww2E0jlJaB3bUkUzjgdS8_XQOshwkr6fu7f4TIoRkDp2gziEWd-eUuNruxZXh9mbCzqBn-mLzxZQ1VTzj5wpFjzmj34_OImEOl8_shPJJmpugRhr2eHIM3njPNFP5EZU8RpgMnOToJa0RD7uK8um6QQHUNOXUED8HPVfZT629RPnnkePICFEqA5C3bcadJFmKSSc7IAGBuhJfhhui5tfFaBSHH1qj6lDodXgvbo9aN0WBuK1UQp8QM4QUbnW_x1pTAe_zo3ihKIpuG59-6Z6QJS1yxpMvs4gRNzP3dG3o0Wj7_wniL8o9nbPMsy-JIbYtGzgrMlLXTaOqxRPSTcnOnFG1CjKVABhWGePOQraSJM3o7tcQCn3NhFHhmjy1BzKTfPurfb924NeNvZpBUM7jjnbIXKfe2DmhGJoq_f7dfVE8qFgJ_8Z25N0ojfMDkrPqiLHqMiLoe49zwnBQ6Hu4Uh8QA7DopDQLE5w_eYsbibhtjcb7Te9zrUXZjH2WSJY2Tk2Bs3q-nTJx0Z-wy6CS51ubAc4qKeGKBA3paNH66tXBon6QsdgQvUCtxTwh5tYlv0whVODVi5CDs5rbG1qOAv4vW9qPehHHtb7-G-WeHnx0SPK0CfkUTrsLBewMGdkKoOia4cSEebtYLV3TVF3dtTz7abezqDyTJNM5lslETYGNQTBko7B9WChyENLoVTNqWCqWV1iPIhzeuJ8ttL-vgwOHUlBkUpCZEpUT682gxlWuSnJhZcbAudiJ8nmZy3Ny_5PvUed3QS5gIH-djcbFrNGd74QKGPYeiZDEPIdM6PvxvvHnN-5BaCdjZaUPh2-x-7y81j8KAFjngmZJeAK741JXY0rqBxkJJ461wCail2a_xSOmIb2UBgVpyPfosMvYRQsro1ThDdIY0AeLJn8azcmFowPFnhQaYidIo6gnfFnpiJPofmIM2JJBbEsl9OPc4n5u0OjXesB90-ABav3zIpQerLuyinfk4zv7CkBwoweyNkrDoKd4Is-CEqqRd7Lsrnhs53EoRwOliSU3eTwhqmYT89X9slDA0YFfGBRfBJWV3oROnlbnxuDA9OM6ZaZEK3QSgDqTSTCgylGdYRgK2ZMqHTSTAlPgRsKTtpjAD668qDcnieOQZTG1xIAD9zyMJyO-_W8Jc43ONWSWuDmHYfXbmLH0eG7Oc-gsWtv8H1S_5tQuCw5xyHbbBl16xO3O0Bo-N6tiaCqhxbH6BCuFX6rnTd3HL9Iap-aNCVT-WUcAZ3r3UbcR6pM2Wn7J4FxqGN2tP983eayD-yRJZuso8k6skPNYVrZ7hUPjnJm8boUd69HZUcucQfAqli2Ch4yWcQw7LXu0Enjj42u7FBpZluQAwt3soSQAKQHpYB8f5frm3mOeuGqOUu-yz8BOPLYoL4cqc482RKQ-t0ntss-2znvfFYfbULsDVhdHZi-E4kXDDDLVn6ZgNBrUzSXPI3qUngnJ4NDyO7d8kqQ="
            }
          },
          "time": {
            "start": 1771213060141,
            "end": 1771213072770
          },
          "id": "prt_c6486782d0017E59GZMr2pwcuz",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64866e440016VjetLLOSqOWvF"
        },
        {
          "type": "tool",
          "callID": "call_tll9t3aJtD25Obhq8jSreLly",
          "tool": "webfetch",
          "state": {
            "status": "completed",
            "input": {
              "url": "https://crates.io/crates/protobuf-codegen",
              "format": "markdown"
            },
            "output": "   crates.io: Rust Package Registry                  \n\nFor full functionality of this site it is necessary to enable JavaScript.",
            "title": "https://crates.io/crates/protobuf-codegen (text/html; charset=utf-8)",
            "metadata": {
              "truncated": false
            },
            "time": {
              "start": 1771213073015,
              "end": 1771213073249
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_0537c721e67a9d5c0169929110b6c881958837a2af20e7c9f6"
            }
          },
          "id": "prt_c6486a983001E9m5FLtvYcbS5a",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64866e440016VjetLLOSqOWvF"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "0078d4e53cc1364054c37f47ef8616804a7a4271",
          "cost": 0,
          "tokens": {
            "total": 109481,
            "input": 1263,
            "output": 698,
            "reasoning": 664,
            "cache": {
              "read": 107520,
              "write": 0
            }
          },
          "id": "prt_c6486ab62001deUpaAH8pnKQt4",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64866e440016VjetLLOSqOWvF"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771213073311,
          "completed": 1771213078647
        },
        "parentID": "msg_c6484620d0011ltzji40BSbVp5",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 109663,
          "input": 203,
          "output": 148,
          "reasoning": 113,
          "cache": {
            "read": 109312,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "tool-calls",
        "id": "msg_c6486ab9f001IkQ6XkJO22b6eT",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "0078d4e53cc1364054c37f47ef8616804a7a4271",
          "id": "prt_c6486b40d001M0sz36RXNe5WPu",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6486ab9f001IkQ6XkJO22b6eT"
        },
        {
          "type": "reasoning",
          "text": "**Evaluating Rust protobuf build approaches**",
          "metadata": {
            "openai": {
              "itemId": "rs_01ecc94c37ef91260169929113ccc8819382455059227e9751",
              "reasoningEncryptedContent": "gAAAAABpkpEWoxZFPjL38f6eqxQj8LMGVzqfUa9-CC-aU2xX0Kehjym0UkhbkpzeonLbYwjCt113GobNwqkOSW3Is7n30h2v4gQBCHcPetWRPcQ5UxzmCyjIY6KDzMtJ2M21YL3PN4lo4chEMMfBoV724fZu8iGhUcdrBSORjdmCSrxiQq-CZexKvrCwWutRhoWbMxiAVNmrrqWGUGrAy9-g_BzyJsYn3j1fzsSlL5NSA7aEyvTjSmJZrPFaIXr8LiVggFqLJl2sPC2jVQCgNm05XeBd-BtACfHINgj3wedocGbxoxMUeOzXROMF95uAGAfixqaGAbU-orMKGecGQB8PGK0YhTGOlj2xEBim5pg66kGq570Wd1H13RpjHlv05g78Jx5YG4jYWJsptZAnOsnPL4CpTqESW4Qs03uK4J0JUgeBpgJ_Vrgz5tVUZ2TTsRnK2LAsiHHB30WmNxkuZtY8JXLMz_izwwc_q_zaduJm5hyWZUTbBtNQLm2n8ZnphJEtDUV_FMzlkEgCTEGONfaIGF9sU5P2CCsZ4yFreu38fB4fKLGVapM8yuFm5eLnIWsFQFVSCDw8S9x1Wq-SG9gwtDoYTh6LngCfa6yipFlzm72qKWeJkbXK9NmrtArJfYJeTmK-dqF33W2b4yReEdz3JROEaXyAhbxGJx4zcL80o1lLwaDKMZmjIeFYm3luTMG-qap7JLOyKWoedRNMpbzIKNyAc_eSNZlkVfc4ASp4t27Pk6A_EBJQwvWKwezAC8omIBYKoYtTxfsdn_8mhwc4QuaLOwfjqa2lgIAibr6L31LV7Q5M28nzD_Cb8LxrC5ByUsCKxpY_Cwjl-OU2MUBxlWP5_Wql-Z8Ic-mJbzdU7lQqSFFyRomGRmVnuqhv2IJmH9kWSu3DejNJysMTtjibEfMNkb1S5Hf-vz2g0BXWylcvvmyPN66wxjprfItAvRv61J8y52a1ZYHaYjXsN_w-HqxwYYd14tIijt30Hryi8rWtX68UlVUernplZn1M5_h-yR-F1r8It4FV9R9dhTS9LL0qJ9l9Ilf1L7v1yDJut6JzRCeUPRrw1VyL_TqLRZwvS16CHntQmih5GeXYD7-OrfmRHT-cdQKQ9G5EObauAnRkQffX17Dhp59g2kVf7Y-fDqsukERQafD3dymjxUobgoWFLfZgztm4hECybb4KH5_GlPOCugS5FmFKGXG5MfCf9kqWTESVxP7LGVhJNQ8SDn3yKQA8rf85uoVSbkM5xOzdqy5uUiAgWAiA-DRcVnspDmxv1sDvXT-zJBz-24o0vQJlDXJGvhIPjDsrXdgBgFMaasCQjM4sQg89-ZcvjmTiQ4-PXArTsrJ_2o3PacfNdg0MegvmbBMvtKYcvwsQDJqGlYEOHpmu9_R6pm5dBEJnFJyqy5pjHfpvkEqpd98n2YU0Me9iJkMILQhk6Ss-by-nB2wogH9LUvzeizaZj1HKHfBLIIc_tGMSi1jIZAvDX15MSDtTv011w9MC3lLiBzUFsWjaW1EYe-Oo4q7hWk4ixG423hdpqFtasYLbI1T5XVp_AyXRhQiYcDMoPMUlNyIFC727hLY="
            }
          },
          "time": {
            "start": 1771213075862,
            "end": 1771213078326
          },
          "id": "prt_c6486b596001mDgPssbAdzn2IX",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6486ab9f001IkQ6XkJO22b6eT"
        },
        {
          "type": "tool",
          "callID": "call_sqgnPJ8SBJFLvMjeriF3GVAa",
          "tool": "webfetch",
          "state": {
            "status": "completed",
            "input": {
              "url": "https://docs.rs/crate/protobuf-example/latest/source/",
              "format": "markdown"
            },
            "output": "      protobuf-example 4.34.0-rc.2 - Docs.rs\n\n[Docs.rs](/)\n\n-   [protobuf-example-4.34.0-rc.2](/crate/protobuf-example/latest \"Example use of Rust Protocol Buffers bindings\")\n\n-   [docs.rs](#)\n    -   [About docs.rs](/about)\n    -   [Badges](/about/badges)\n    -   [Builds](/about/builds)\n    -   [Metadata](/about/metadata)\n    -   [Shorthand URLs](/about/redirections)\n    -   [Download](/about/download)\n    -   [Rustdoc JSON](/about/rustdoc-json)\n    -   [Build queue](/releases/queue)\n    -   [Privacy policy](https://foundation.rust-lang.org/policies/privacy-policy/#docs.rs)\n\n-   [Rust](#)\n    -   [Rust website](https://www.rust-lang.org/)\n    -   [The Book](https://doc.rust-lang.org/book/)\n    -   [Standard Library API Reference](https://doc.rust-lang.org/std/)\n    -   [Rust by Example](https://doc.rust-lang.org/rust-by-example/)\n    -   [The Cargo Guide](https://doc.rust-lang.org/cargo/guide/)\n    -   [Clippy Documentation](https://doc.rust-lang.org/nightly/clippy)\n\n# protobuf-example 4.34.0-rc.2\n\nExample use of Rust Protocol Buffers bindings\n\n-   [Crate](/crate/protobuf-example/latest)\n-   [Source](/crate/protobuf-example/latest/source/)\n-   [Builds](/crate/protobuf-example/latest/builds)\n-   [Feature flags](/crate/protobuf-example/latest/features)\n\n-   [proto](./proto/)\n-   [src](./src/)\n-   [build.rs](./build.rs)\n-   [Cargo.lock](./Cargo.lock)\n-   [Cargo.toml](./Cargo.toml)\n-   [Cargo.toml.orig](./Cargo.toml.orig)\n-   [LICENSE](./LICENSE)\n-   [README.md](./README.md)",
            "title": "https://docs.rs/crate/protobuf-example/latest/source/ (text/html; charset=utf-8)",
            "metadata": {
              "truncated": false
            },
            "time": {
              "start": 1771213078538,
              "end": 1771213078582
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_01ecc94c37ef912601699291164aa8819382d8d17a95305563"
            }
          },
          "id": "prt_c6486bf38001SGpvC15SVoB8ye",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6486ab9f001IkQ6XkJO22b6eT"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "0078d4e53cc1364054c37f47ef8616804a7a4271",
          "cost": 0,
          "tokens": {
            "total": 109663,
            "input": 203,
            "output": 148,
            "reasoning": 113,
            "cache": {
              "read": 109312,
              "write": 0
            }
          },
          "id": "prt_c6486c03d001jdCXagkZtVb4us",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6486ab9f001IkQ6XkJO22b6eT"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771213078650,
          "completed": 1771213083338
        },
        "parentID": "msg_c6484620d0011ltzji40BSbVp5",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 110190,
          "input": 563,
          "output": 59,
          "reasoning": 23,
          "cache": {
            "read": 109568,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "tool-calls",
        "id": "msg_c6486c07a001nGwlSCBm9lJy36",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "0078d4e53cc1364054c37f47ef8616804a7a4271",
          "id": "prt_c6486cc4b001yoFpy2olVbeYA6",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6486c07a001nGwlSCBm9lJy36"
        },
        {
          "type": "reasoning",
          "text": "**Considering source path retrieval**",
          "metadata": {
            "openai": {
              "itemId": "rs_0814c2e078b1a26c016992911a27d88197800547508b379bc6",
              "reasoningEncryptedContent": "gAAAAABpkpEaSq8NxXhdL76fRFt8wNID02l4TXti4BTS91xli05SFwOCZvhEpueXXJSfC-n9c58mHpFrC1sn06d1EuoMorO0ky7mIp-Exsgn-Um026hG_Y-Opz2NZaqfjF0L6smJPC3t5SkMJ1ZlX1xa47JLLmnsr8EncNKL6lTfUMpS1g3Qkavev-sBFCIxJctgMM6ky85cduwnE_Nx1Yo0xpNmfyIATNfk9WtbpN4VczBkTOXgifwAKCtWu4CEn-WHQl-IUpsQubmyteYOPXSY546gA7fWGIcqiwMBYUp5xYV9sM7aJYq1tTUzJ3uZfUlp5EcGfxggAaF4M7N9udRicyApN6B0V6m4djrzRjDCS-xoaxskqcFn1OIsfzrrQCHgYHtF2DC_nmv0e_-M-r1rzCZp3EKmUCJv9BTMM-dMVxvJJoNMoeo0dPjUGpj4gLYqVgOZtijsLm-vHuvtMl_KOsXNt4WcE0FaO9johWACtEEKD6sfWh5aOWsHZGghFK9jqjP4sQdJgAznEotN7iQjTog5Jj0rwN1cUu4FjG7hnevmSoDSFs4VQAWVBt9iNVLmd63sP9XvUK0-2KxhHwZ-optbEl04SwEPpO8HXvL_hhTPI_BdXjTYNchKELCvwIZzH-pHzrh_fRJ-xCqQEAYd12Re8ePDH4-5ywgRhTWhE8a0tpMJZFINX8Q1WRgQEIa2jVowb-N6XWR86PWBEipXQhqLEaXiVYoQMd_cM-COIGT92BfXYcY2DJhLTmybfJHmU-OC7PbKb_itQ9abmaJzBShx_BNaf-lH9oh-CUen1dsplM09rgTjBInD1tMjC7Ci_G7YqmInN5T36isEThlaDs102taY2zn27ZAOI2bsY8_dElPtZ2zNkvUo-gFF4fmvaIBBlqWslon0_HIjdslCU6eWpb8Qyomm30trEH1QQvJTZYh4jefahez3l6nylzQ6MIwdm390"
            }
          },
          "time": {
            "start": 1771213082187,
            "end": 1771213082805
          },
          "id": "prt_c6486ce4b001HF4uByNVZ33n8z",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6486c07a001nGwlSCBm9lJy36"
        },
        {
          "type": "tool",
          "callID": "call_1L2DZ67FYwszH8sXrL3evfFM",
          "tool": "webfetch",
          "state": {
            "status": "completed",
            "input": {
              "url": "https://docs.rs/crate/protobuf-example/latest/source/build.rs",
              "format": "markdown"
            },
            "output": "      protobuf-example 4.34.0-rc.2 - Docs.rs\n\n[Docs.rs](/)\n\n-   [protobuf-example-4.34.0-rc.2](/crate/protobuf-example/latest \"Example use of Rust Protocol Buffers bindings\")\n\n-   [docs.rs](#)\n    -   [About docs.rs](/about)\n    -   [Badges](/about/badges)\n    -   [Builds](/about/builds)\n    -   [Metadata](/about/metadata)\n    -   [Shorthand URLs](/about/redirections)\n    -   [Download](/about/download)\n    -   [Rustdoc JSON](/about/rustdoc-json)\n    -   [Build queue](/releases/queue)\n    -   [Privacy policy](https://foundation.rust-lang.org/policies/privacy-policy/#docs.rs)\n\n-   [Rust](#)\n    -   [Rust website](https://www.rust-lang.org/)\n    -   [The Book](https://doc.rust-lang.org/book/)\n    -   [Standard Library API Reference](https://doc.rust-lang.org/std/)\n    -   [Rust by Example](https://doc.rust-lang.org/rust-by-example/)\n    -   [The Cargo Guide](https://doc.rust-lang.org/cargo/guide/)\n    -   [Clippy Documentation](https://doc.rust-lang.org/nightly/clippy)\n\n# protobuf-example 4.34.0-rc.2\n\nExample use of Rust Protocol Buffers bindings\n\n-   [Crate](/crate/protobuf-example/latest)\n-   [Source](/crate/protobuf-example/latest/source/build.rs)\n-   [Builds](/crate/protobuf-example/latest/builds)\n-   [Feature flags](/crate/protobuf-example/latest/features)\n\n-   Hide files\n-   [proto](./proto/)\n-   [src](./src/)\n-   [build.rs](./build.rs)\n-   [Cargo.lock](./Cargo.lock)\n-   [Cargo.toml](./Cargo.toml)\n-   [Cargo.toml.orig](./Cargo.toml.orig)\n-   [LICENSE](./LICENSE)\n-   [README.md](./README.md)\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n```\n\n```\nuse protobuf_codegen::CodeGen;\n\nfn main() {\n    CodeGen::new()\n        .inputs([\"proto_example/foo.proto\", \"proto_example/bar/bar.proto\"])\n        .include(\"proto\")\n        .dependency(protobuf_well_known_types::get_dependency(\"protobuf_well_known_types\"))\n        .generate_and_compile()\n        .unwrap();\n}\n```",
            "title": "https://docs.rs/crate/protobuf-example/latest/source/build.rs (text/html; charset=utf-8)",
            "metadata": {
              "truncated": false
            },
            "time": {
              "start": 1771213083209,
              "end": 1771213083277
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_0814c2e078b1a26c016992911ac4a08197a72eb8012416bd34"
            }
          },
          "id": "prt_c6486d0b6001ZAjntbNpI5A7ud",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6486c07a001nGwlSCBm9lJy36"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "0078d4e53cc1364054c37f47ef8616804a7a4271",
          "cost": 0,
          "tokens": {
            "total": 110190,
            "input": 563,
            "output": 59,
            "reasoning": 23,
            "cache": {
              "read": 109568,
              "write": 0
            }
          },
          "id": "prt_c6486d28e001k6FhtvnFzWHFQB",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6486c07a001nGwlSCBm9lJy36"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771213083342,
          "completed": 1771213131096
        },
        "parentID": "msg_c6484620d0011ltzji40BSbVp5",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 113479,
          "input": 681,
          "output": 2718,
          "reasoning": 1132,
          "cache": {
            "read": 110080,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "tool-calls",
        "id": "msg_c6486d2ce001aFhPCeKUXstSE1",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "0078d4e53cc1364054c37f47ef8616804a7a4271",
          "id": "prt_c6486db39001ojLF2w5ve74g3B",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6486d2ce001aFhPCeKUXstSE1"
        },
        {
          "type": "reasoning",
          "text": "**Planning protobuf authoring skill**",
          "metadata": {
            "openai": {
              "itemId": "rs_0eb356b33027a0aa016992911de3b481978cc69bd9ece64f22",
              "reasoningEncryptedContent": "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"
            }
          },
          "time": {
            "start": 1771213085921,
            "end": 1771213104243
          },
          "id": "prt_c6486dce1001SCELi5Z2K0Pbus",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6486d2ce001aFhPCeKUXstSE1"
        },
        {
          "type": "tool",
          "callID": "call_jpyNf5RIoKJqaNGOHVPwQeAR",
          "tool": "apply_patch",
          "state": {
            "status": "completed",
            "input": {
              "patchText": "*** Begin Patch\n*** Add File: docs/readmes/protobuf-schema-research.md\n+# Protobuf Schema Research Notes\n+\n+Last reviewed: 2026-02-15\n+\n+## Scope\n+\n+- Capture practical notes for authoring new `.proto` schemas.\n+- Support both `proto2` and `proto3` workflows.\n+- Document `protoc` usage for Rust and TypeScript generation paths.\n+\n+## Primary web sources\n+\n+- OpenCode skills docs: https://opencode.ai/docs/skills/\n+- Protoc install docs: https://protobuf.dev/installation/\n+- Proto2 guide: https://protobuf.dev/programming-guides/proto2/\n+- Proto3 guide: https://protobuf.dev/programming-guides/proto3/\n+- Field presence note: https://protobuf.dev/programming-guides/field_presence/\n+- Rust generated code guide: https://protobuf.dev/reference/rust/rust-generated/\n+- Rust build reference: https://protobuf.dev/reference/rust/building-rust-protos/\n+- `prost-build` docs: https://docs.rs/prost-build/latest/prost_build/\n+- `tonic-prost-build` docs: https://docs.rs/tonic-prost-build/latest/tonic_prost_build/\n+- `ts-proto` README: https://github.com/stephenh/ts-proto\n+- `protobuf-ts` README: https://github.com/timostamm/protobuf-ts\n+\n+## Proto2 vs proto3 (what matters most)\n+\n+- **Syntax line**\n+  - `proto2`: `syntax = \"proto2\";`\n+  - `proto3`: `syntax = \"proto3\";`\n+- **Cardinality labels**\n+  - `proto2`: `optional`, `required` (strongly discouraged), `repeated`, `map`.\n+  - `proto3`: `optional` (recommended), implicit singular (legacy style), `repeated`, `map`.\n+- **Required fields**\n+  - `proto2` only, but strongly discouraged for new schemas.\n+  - Not available in `proto3`.\n+- **Scalar default overrides**\n+  - `proto2`: supports `[default = ...]` on singular non-message fields.\n+  - `proto3`: no custom scalar defaults; language defaults apply.\n+- **Field presence**\n+  - `proto2`: explicit presence for singular fields.\n+  - `proto3`: explicit presence only with `optional` (or oneof/message); otherwise implicit for basic scalars.\n+  - Proto docs recommend using `optional` in proto3 for smoother compatibility.\n+- **Enum zero value**\n+  - `proto3`: first enum value must be `0`.\n+  - `proto2`: first value is default; using `_UNSPECIFIED = 0` is still safest.\n+- **Extensions and groups**\n+  - `proto2`: supports extensions; groups exist but are deprecated.\n+  - `proto3`: no general extension fields/groups in the same way.\n+- **Repeated scalar packing**\n+  - `proto2`: use `[packed = true]` for new repeated numeric fields.\n+  - `proto3`: repeated scalar numerics are packed by default.\n+- **Unknown fields**\n+  - Preserved in both proto2 and proto3 (binary format).\n+- **Interop note**\n+  - Proto2 and proto3 messages can interoperate across imports, but proto2 enums cannot be used directly in proto3 syntax.\n+\n+## Safe schema evolution checklist\n+\n+- Never renumber existing fields.\n+- Never reuse deleted field numbers.\n+- Reserve removed field numbers and names using `reserved`.\n+- Prefer additive changes: add new fields, do not mutate existing wire meaning.\n+- Avoid `required` for new work.\n+- Use `oneof` when exactly one field must be present.\n+\n+## Protoc usage basics\n+\n+- Verify installation:\n+\n+```bash\n+protoc --version\n+```\n+\n+- General compile shape:\n+\n+```bash\n+protoc -I proto --<LANG>_out=gen/<lang> proto/path/to/file.proto\n+```\n+\n+- Validate schema and emit descriptor set (useful for CI checks):\n+\n+```bash\n+protoc -I proto --include_imports --descriptor_set_out=gen/schema.pb proto/path/to/file.proto\n+```\n+\n+## Rust generation patterns\n+\n+Rust codegen is commonly done in `build.rs` wrappers that call `protoc` for you.\n+\n+- `prost-build` example (`build.rs`):\n+\n+```rust\n+fn main() -> std::io::Result<()> {\n+    prost_build::compile_protos(&[\"proto/service.proto\"], &[\"proto\"])?;\n+    Ok(())\n+}\n+```\n+\n+- `tonic-prost-build` example (`build.rs`):\n+\n+```rust\n+fn main() {\n+    tonic_prost_build::configure()\n+        .compile_protos(&[\"proto/service.proto\"], &[\"proto\"])\n+        .unwrap();\n+}\n+```\n+\n+- `protobuf` crate ecosystem example (`build.rs`, from protobuf-example):\n+\n+```rust\n+use protobuf_codegen::CodeGen;\n+\n+fn main() {\n+    CodeGen::new()\n+        .inputs([\"proto_example/foo.proto\", \"proto_example/bar/bar.proto\"])\n+        .include(\"proto\")\n+        .dependency(protobuf_well_known_types::get_dependency(\"protobuf_well_known_types\"))\n+        .generate_and_compile()\n+        .unwrap();\n+}\n+```\n+\n+## TypeScript generation patterns\n+\n+TypeScript typically uses `protoc` plugins.\n+\n+- `ts-proto` quickstart:\n+\n+```bash\n+protoc \\\n+  --plugin=./node_modules/.bin/protoc-gen-ts_proto \\\n+  --ts_proto_out=gen/ts \\\n+  --ts_proto_opt=esModuleInterop=true \\\n+  -I proto \\\n+  proto/path/to/file.proto\n+```\n+\n+- `@protobuf-ts/plugin` quickstart:\n+\n+```bash\n+npx protoc --ts_out gen/ts --proto_path proto proto/path/to/file.proto\n+```\n+\n+## Agent defaults for new schema requests\n+\n+- Ask which syntax to use: `proto2` or `proto3`.\n+- If unspecified, recommend `proto3` with explicit `optional` for scalar presence.\n+- Ask which TypeScript generator to target: `ts-proto` or `@protobuf-ts/plugin`.\n+- If unspecified, recommend `ts-proto` for idiomatic TS interfaces and flexible options.\n+- Always call out features that are syntax-specific (for example `required`/extensions/default overrides in proto2).\n*** End Patch"
            },
            "output": "Success. Updated the following files:\nA docs/readmes/protobuf-schema-research.md",
            "title": "Success. Updated the following files:\nA docs/readmes/protobuf-schema-research.md",
            "metadata": {
              "diff": "Index: /Users/alex/repos/vfp/dark-factory/docs/readmes/protobuf-schema-research.md\n===================================================================\n--- /Users/alex/repos/vfp/dark-factory/docs/readmes/protobuf-schema-research.md\n+++ /Users/alex/repos/vfp/dark-factory/docs/readmes/protobuf-schema-research.md\n@@ -0,0 +1,151 @@\n+# Protobuf Schema Research Notes\n+\n+Last reviewed: 2026-02-15\n+\n+## Scope\n+\n+- Capture practical notes for authoring new `.proto` schemas.\n+- Support both `proto2` and `proto3` workflows.\n+- Document `protoc` usage for Rust and TypeScript generation paths.\n+\n+## Primary web sources\n+\n+- OpenCode skills docs: https://opencode.ai/docs/skills/\n+- Protoc install docs: https://protobuf.dev/installation/\n+- Proto2 guide: https://protobuf.dev/programming-guides/proto2/\n+- Proto3 guide: https://protobuf.dev/programming-guides/proto3/\n+- Field presence note: https://protobuf.dev/programming-guides/field_presence/\n+- Rust generated code guide: https://protobuf.dev/reference/rust/rust-generated/\n+- Rust build reference: https://protobuf.dev/reference/rust/building-rust-protos/\n+- `prost-build` docs: https://docs.rs/prost-build/latest/prost_build/\n+- `tonic-prost-build` docs: https://docs.rs/tonic-prost-build/latest/tonic_prost_build/\n+- `ts-proto` README: https://github.com/stephenh/ts-proto\n+- `protobuf-ts` README: https://github.com/timostamm/protobuf-ts\n+\n+## Proto2 vs proto3 (what matters most)\n+\n+- **Syntax line**\n+  - `proto2`: `syntax = \"proto2\";`\n+  - `proto3`: `syntax = \"proto3\";`\n+- **Cardinality labels**\n+  - `proto2`: `optional`, `required` (strongly discouraged), `repeated`, `map`.\n+  - `proto3`: `optional` (recommended), implicit singular (legacy style), `repeated`, `map`.\n+- **Required fields**\n+  - `proto2` only, but strongly discouraged for new schemas.\n+  - Not available in `proto3`.\n+- **Scalar default overrides**\n+  - `proto2`: supports `[default = ...]` on singular non-message fields.\n+  - `proto3`: no custom scalar defaults; language defaults apply.\n+- **Field presence**\n+  - `proto2`: explicit presence for singular fields.\n+  - `proto3`: explicit presence only with `optional` (or oneof/message); otherwise implicit for basic scalars.\n+  - Proto docs recommend using `optional` in proto3 for smoother compatibility.\n+- **Enum zero value**\n+  - `proto3`: first enum value must be `0`.\n+  - `proto2`: first value is default; using `_UNSPECIFIED = 0` is still safest.\n+- **Extensions and groups**\n+  - `proto2`: supports extensions; groups exist but are deprecated.\n+  - `proto3`: no general extension fields/groups in the same way.\n+- **Repeated scalar packing**\n+  - `proto2`: use `[packed = true]` for new repeated numeric fields.\n+  - `proto3`: repeated scalar numerics are packed by default.\n+- **Unknown fields**\n+  - Preserved in both proto2 and proto3 (binary format).\n+- **Interop note**\n+  - Proto2 and proto3 messages can interoperate across imports, but proto2 enums cannot be used directly in proto3 syntax.\n+\n+## Safe schema evolution checklist\n+\n+- Never renumber existing fields.\n+- Never reuse deleted field numbers.\n+- Reserve removed field numbers and names using `reserved`.\n+- Prefer additive changes: add new fields, do not mutate existing wire meaning.\n+- Avoid `required` for new work.\n+- Use `oneof` when exactly one field must be present.\n+\n+## Protoc usage basics\n+\n+- Verify installation:\n+\n+```bash\n+protoc --version\n+```\n+\n+- General compile shape:\n+\n+```bash\n+protoc -I proto --<LANG>_out=gen/<lang> proto/path/to/file.proto\n+```\n+\n+- Validate schema and emit descriptor set (useful for CI checks):\n+\n+```bash\n+protoc -I proto --include_imports --descriptor_set_out=gen/schema.pb proto/path/to/file.proto\n+```\n+\n+## Rust generation patterns\n+\n+Rust codegen is commonly done in `build.rs` wrappers that call `protoc` for you.\n+\n+- `prost-build` example (`build.rs`):\n+\n+```rust\n+fn main() -> std::io::Result<()> {\n+    prost_build::compile_protos(&[\"proto/service.proto\"], &[\"proto\"])?;\n+    Ok(())\n+}\n+```\n+\n+- `tonic-prost-build` example (`build.rs`):\n+\n+```rust\n+fn main() {\n+    tonic_prost_build::configure()\n+        .compile_protos(&[\"proto/service.proto\"], &[\"proto\"])\n+        .unwrap();\n+}\n+```\n+\n+- `protobuf` crate ecosystem example (`build.rs`, from protobuf-example):\n+\n+```rust\n+use protobuf_codegen::CodeGen;\n+\n+fn main() {\n+    CodeGen::new()\n+        .inputs([\"proto_example/foo.proto\", \"proto_example/bar/bar.proto\"])\n+        .include(\"proto\")\n+        .dependency(protobuf_well_known_types::get_dependency(\"protobuf_well_known_types\"))\n+        .generate_and_compile()\n+        .unwrap();\n+}\n+```\n+\n+## TypeScript generation patterns\n+\n+TypeScript typically uses `protoc` plugins.\n+\n+- `ts-proto` quickstart:\n+\n+```bash\n+protoc \\\n+  --plugin=./node_modules/.bin/protoc-gen-ts_proto \\\n+  --ts_proto_out=gen/ts \\\n+  --ts_proto_opt=esModuleInterop=true \\\n+  -I proto \\\n+  proto/path/to/file.proto\n+```\n+\n+- `@protobuf-ts/plugin` quickstart:\n+\n+```bash\n+npx protoc --ts_out gen/ts --proto_path proto proto/path/to/file.proto\n+```\n+\n+## Agent defaults for new schema requests\n+\n+- Ask which syntax to use: `proto2` or `proto3`.\n+- If unspecified, recommend `proto3` with explicit `optional` for scalar presence.\n+- Ask which TypeScript generator to target: `ts-proto` or `@protobuf-ts/plugin`.\n+- If unspecified, recommend `ts-proto` for idiomatic TS interfaces and flexible options.\n+- Always call out features that are syntax-specific (for example `required`/extensions/default overrides in proto2).\n\n",
              "files": [
                {
                  "filePath": "/Users/alex/repos/vfp/dark-factory/docs/readmes/protobuf-schema-research.md",
                  "relativePath": "docs/readmes/protobuf-schema-research.md",
                  "type": "add",
                  "diff": "Index: /Users/alex/repos/vfp/dark-factory/docs/readmes/protobuf-schema-research.md\n===================================================================\n--- /Users/alex/repos/vfp/dark-factory/docs/readmes/protobuf-schema-research.md\n+++ /Users/alex/repos/vfp/dark-factory/docs/readmes/protobuf-schema-research.md\n@@ -0,0 +1,151 @@\n+# Protobuf Schema Research Notes\n+\n+Last reviewed: 2026-02-15\n+\n+## Scope\n+\n+- Capture practical notes for authoring new `.proto` schemas.\n+- Support both `proto2` and `proto3` workflows.\n+- Document `protoc` usage for Rust and TypeScript generation paths.\n+\n+## Primary web sources\n+\n+- OpenCode skills docs: https://opencode.ai/docs/skills/\n+- Protoc install docs: https://protobuf.dev/installation/\n+- Proto2 guide: https://protobuf.dev/programming-guides/proto2/\n+- Proto3 guide: https://protobuf.dev/programming-guides/proto3/\n+- Field presence note: https://protobuf.dev/programming-guides/field_presence/\n+- Rust generated code guide: https://protobuf.dev/reference/rust/rust-generated/\n+- Rust build reference: https://protobuf.dev/reference/rust/building-rust-protos/\n+- `prost-build` docs: https://docs.rs/prost-build/latest/prost_build/\n+- `tonic-prost-build` docs: https://docs.rs/tonic-prost-build/latest/tonic_prost_build/\n+- `ts-proto` README: https://github.com/stephenh/ts-proto\n+- `protobuf-ts` README: https://github.com/timostamm/protobuf-ts\n+\n+## Proto2 vs proto3 (what matters most)\n+\n+- **Syntax line**\n+  - `proto2`: `syntax = \"proto2\";`\n+  - `proto3`: `syntax = \"proto3\";`\n+- **Cardinality labels**\n+  - `proto2`: `optional`, `required` (strongly discouraged), `repeated`, `map`.\n+  - `proto3`: `optional` (recommended), implicit singular (legacy style), `repeated`, `map`.\n+- **Required fields**\n+  - `proto2` only, but strongly discouraged for new schemas.\n+  - Not available in `proto3`.\n+- **Scalar default overrides**\n+  - `proto2`: supports `[default = ...]` on singular non-message fields.\n+  - `proto3`: no custom scalar defaults; language defaults apply.\n+- **Field presence**\n+  - `proto2`: explicit presence for singular fields.\n+  - `proto3`: explicit presence only with `optional` (or oneof/message); otherwise implicit for basic scalars.\n+  - Proto docs recommend using `optional` in proto3 for smoother compatibility.\n+- **Enum zero value**\n+  - `proto3`: first enum value must be `0`.\n+  - `proto2`: first value is default; using `_UNSPECIFIED = 0` is still safest.\n+- **Extensions and groups**\n+  - `proto2`: supports extensions; groups exist but are deprecated.\n+  - `proto3`: no general extension fields/groups in the same way.\n+- **Repeated scalar packing**\n+  - `proto2`: use `[packed = true]` for new repeated numeric fields.\n+  - `proto3`: repeated scalar numerics are packed by default.\n+- **Unknown fields**\n+  - Preserved in both proto2 and proto3 (binary format).\n+- **Interop note**\n+  - Proto2 and proto3 messages can interoperate across imports, but proto2 enums cannot be used directly in proto3 syntax.\n+\n+## Safe schema evolution checklist\n+\n+- Never renumber existing fields.\n+- Never reuse deleted field numbers.\n+- Reserve removed field numbers and names using `reserved`.\n+- Prefer additive changes: add new fields, do not mutate existing wire meaning.\n+- Avoid `required` for new work.\n+- Use `oneof` when exactly one field must be present.\n+\n+## Protoc usage basics\n+\n+- Verify installation:\n+\n+```bash\n+protoc --version\n+```\n+\n+- General compile shape:\n+\n+```bash\n+protoc -I proto --<LANG>_out=gen/<lang> proto/path/to/file.proto\n+```\n+\n+- Validate schema and emit descriptor set (useful for CI checks):\n+\n+```bash\n+protoc -I proto --include_imports --descriptor_set_out=gen/schema.pb proto/path/to/file.proto\n+```\n+\n+## Rust generation patterns\n+\n+Rust codegen is commonly done in `build.rs` wrappers that call `protoc` for you.\n+\n+- `prost-build` example (`build.rs`):\n+\n+```rust\n+fn main() -> std::io::Result<()> {\n+    prost_build::compile_protos(&[\"proto/service.proto\"], &[\"proto\"])?;\n+    Ok(())\n+}\n+```\n+\n+- `tonic-prost-build` example (`build.rs`):\n+\n+```rust\n+fn main() {\n+    tonic_prost_build::configure()\n+        .compile_protos(&[\"proto/service.proto\"], &[\"proto\"])\n+        .unwrap();\n+}\n+```\n+\n+- `protobuf` crate ecosystem example (`build.rs`, from protobuf-example):\n+\n+```rust\n+use protobuf_codegen::CodeGen;\n+\n+fn main() {\n+    CodeGen::new()\n+        .inputs([\"proto_example/foo.proto\", \"proto_example/bar/bar.proto\"])\n+        .include(\"proto\")\n+        .dependency(protobuf_well_known_types::get_dependency(\"protobuf_well_known_types\"))\n+        .generate_and_compile()\n+        .unwrap();\n+}\n+```\n+\n+## TypeScript generation patterns\n+\n+TypeScript typically uses `protoc` plugins.\n+\n+- `ts-proto` quickstart:\n+\n+```bash\n+protoc \\\n+  --plugin=./node_modules/.bin/protoc-gen-ts_proto \\\n+  --ts_proto_out=gen/ts \\\n+  --ts_proto_opt=esModuleInterop=true \\\n+  -I proto \\\n+  proto/path/to/file.proto\n+```\n+\n+- `@protobuf-ts/plugin` quickstart:\n+\n+```bash\n+npx protoc --ts_out gen/ts --proto_path proto proto/path/to/file.proto\n+```\n+\n+## Agent defaults for new schema requests\n+\n+- Ask which syntax to use: `proto2` or `proto3`.\n+- If unspecified, recommend `proto3` with explicit `optional` for scalar presence.\n+- Ask which TypeScript generator to target: `ts-proto` or `@protobuf-ts/plugin`.\n+- If unspecified, recommend `ts-proto` for idiomatic TS interfaces and flexible options.\n+- Always call out features that are syntax-specific (for example `required`/extensions/default overrides in proto2).\n",
                  "before": "",
                  "after": "# Protobuf Schema Research Notes\n\nLast reviewed: 2026-02-15\n\n## Scope\n\n- Capture practical notes for authoring new `.proto` schemas.\n- Support both `proto2` and `proto3` workflows.\n- Document `protoc` usage for Rust and TypeScript generation paths.\n\n## Primary web sources\n\n- OpenCode skills docs: https://opencode.ai/docs/skills/\n- Protoc install docs: https://protobuf.dev/installation/\n- Proto2 guide: https://protobuf.dev/programming-guides/proto2/\n- Proto3 guide: https://protobuf.dev/programming-guides/proto3/\n- Field presence note: https://protobuf.dev/programming-guides/field_presence/\n- Rust generated code guide: https://protobuf.dev/reference/rust/rust-generated/\n- Rust build reference: https://protobuf.dev/reference/rust/building-rust-protos/\n- `prost-build` docs: https://docs.rs/prost-build/latest/prost_build/\n- `tonic-prost-build` docs: https://docs.rs/tonic-prost-build/latest/tonic_prost_build/\n- `ts-proto` README: https://github.com/stephenh/ts-proto\n- `protobuf-ts` README: https://github.com/timostamm/protobuf-ts\n\n## Proto2 vs proto3 (what matters most)\n\n- **Syntax line**\n  - `proto2`: `syntax = \"proto2\";`\n  - `proto3`: `syntax = \"proto3\";`\n- **Cardinality labels**\n  - `proto2`: `optional`, `required` (strongly discouraged), `repeated`, `map`.\n  - `proto3`: `optional` (recommended), implicit singular (legacy style), `repeated`, `map`.\n- **Required fields**\n  - `proto2` only, but strongly discouraged for new schemas.\n  - Not available in `proto3`.\n- **Scalar default overrides**\n  - `proto2`: supports `[default = ...]` on singular non-message fields.\n  - `proto3`: no custom scalar defaults; language defaults apply.\n- **Field presence**\n  - `proto2`: explicit presence for singular fields.\n  - `proto3`: explicit presence only with `optional` (or oneof/message); otherwise implicit for basic scalars.\n  - Proto docs recommend using `optional` in proto3 for smoother compatibility.\n- **Enum zero value**\n  - `proto3`: first enum value must be `0`.\n  - `proto2`: first value is default; using `_UNSPECIFIED = 0` is still safest.\n- **Extensions and groups**\n  - `proto2`: supports extensions; groups exist but are deprecated.\n  - `proto3`: no general extension fields/groups in the same way.\n- **Repeated scalar packing**\n  - `proto2`: use `[packed = true]` for new repeated numeric fields.\n  - `proto3`: repeated scalar numerics are packed by default.\n- **Unknown fields**\n  - Preserved in both proto2 and proto3 (binary format).\n- **Interop note**\n  - Proto2 and proto3 messages can interoperate across imports, but proto2 enums cannot be used directly in proto3 syntax.\n\n## Safe schema evolution checklist\n\n- Never renumber existing fields.\n- Never reuse deleted field numbers.\n- Reserve removed field numbers and names using `reserved`.\n- Prefer additive changes: add new fields, do not mutate existing wire meaning.\n- Avoid `required` for new work.\n- Use `oneof` when exactly one field must be present.\n\n## Protoc usage basics\n\n- Verify installation:\n\n```bash\nprotoc --version\n```\n\n- General compile shape:\n\n```bash\nprotoc -I proto --<LANG>_out=gen/<lang> proto/path/to/file.proto\n```\n\n- Validate schema and emit descriptor set (useful for CI checks):\n\n```bash\nprotoc -I proto --include_imports --descriptor_set_out=gen/schema.pb proto/path/to/file.proto\n```\n\n## Rust generation patterns\n\nRust codegen is commonly done in `build.rs` wrappers that call `protoc` for you.\n\n- `prost-build` example (`build.rs`):\n\n```rust\nfn main() -> std::io::Result<()> {\n    prost_build::compile_protos(&[\"proto/service.proto\"], &[\"proto\"])?;\n    Ok(())\n}\n```\n\n- `tonic-prost-build` example (`build.rs`):\n\n```rust\nfn main() {\n    tonic_prost_build::configure()\n        .compile_protos(&[\"proto/service.proto\"], &[\"proto\"])\n        .unwrap();\n}\n```\n\n- `protobuf` crate ecosystem example (`build.rs`, from protobuf-example):\n\n```rust\nuse protobuf_codegen::CodeGen;\n\nfn main() {\n    CodeGen::new()\n        .inputs([\"proto_example/foo.proto\", \"proto_example/bar/bar.proto\"])\n        .include(\"proto\")\n        .dependency(protobuf_well_known_types::get_dependency(\"protobuf_well_known_types\"))\n        .generate_and_compile()\n        .unwrap();\n}\n```\n\n## TypeScript generation patterns\n\nTypeScript typically uses `protoc` plugins.\n\n- `ts-proto` quickstart:\n\n```bash\nprotoc \\\n  --plugin=./node_modules/.bin/protoc-gen-ts_proto \\\n  --ts_proto_out=gen/ts \\\n  --ts_proto_opt=esModuleInterop=true \\\n  -I proto \\\n  proto/path/to/file.proto\n```\n\n- `@protobuf-ts/plugin` quickstart:\n\n```bash\nnpx protoc --ts_out gen/ts --proto_path proto proto/path/to/file.proto\n```\n\n## Agent defaults for new schema requests\n\n- Ask which syntax to use: `proto2` or `proto3`.\n- If unspecified, recommend `proto3` with explicit `optional` for scalar presence.\n- Ask which TypeScript generator to target: `ts-proto` or `@protobuf-ts/plugin`.\n- If unspecified, recommend `ts-proto` for idiomatic TS interfaces and flexible options.\n- Always call out features that are syntax-specific (for example `required`/extensions/default overrides in proto2).\n",
                  "additions": 151,
                  "deletions": 0
                }
              ],
              "diagnostics": {},
              "truncated": false
            },
            "time": {
              "start": 1771213131013,
              "end": 1771213131027
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_0eb356b33027a0aa0169929130335481979c5cfa971412aebc"
            }
          },
          "id": "prt_c64872475001X1LY7M5DBCRW3C",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6486d2ce001aFhPCeKUXstSE1"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "19c5089de435342262b4ffc46f59fbfc3533018b",
          "cost": 0,
          "tokens": {
            "total": 113479,
            "input": 681,
            "output": 2718,
            "reasoning": 1132,
            "cache": {
              "read": 110080,
              "write": 0
            }
          },
          "id": "prt_c64878d26001NFDxhQCN5wLmFE",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6486d2ce001aFhPCeKUXstSE1"
        },
        {
          "type": "patch",
          "hash": "0078d4e53cc1364054c37f47ef8616804a7a4271",
          "files": [
            "/Users/alex/repos/vfp/dark-factory/AGENTS.md",
            "/Users/alex/repos/vfp/dark-factory/README.md",
            "/Users/alex/repos/vfp/dark-factory/docs/designs/core_gen1.design.md",
            "/Users/alex/repos/vfp/dark-factory/docs/external/moonrepo/moonrepo_docs.ext.md",
            "/Users/alex/repos/vfp/dark-factory/docs/readmes/protobuf-schema-research.md",
            "/Users/alex/repos/vfp/dark-factory/scripts/scrape_moon_docs.sh.ts"
          ],
          "id": "prt_c64878d540011JdWyY7pJfcwEP",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6486d2ce001aFhPCeKUXstSE1"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771213131099,
          "completed": 1771213151726
        },
        "parentID": "msg_c6484620d0011ltzji40BSbVp5",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 114547,
          "input": 98304,
          "output": 1011,
          "reasoning": 9,
          "cache": {
            "read": 15232,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "tool-calls",
        "id": "msg_c64878d5b001WkJhPUxuljB0b0",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "19c5089de435342262b4ffc46f59fbfc3533018b",
          "id": "prt_c64879606001elbgO0hUywS2j1",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64878d5b001WkJhPUxuljB0b0"
        },
        {
          "type": "reasoning",
          "text": "**Adding skill file**",
          "metadata": {
            "openai": {
              "itemId": "rs_06fc134f73f55e00016992914fa5b48195843f8586468aeb2c",
              "reasoningEncryptedContent": "gAAAAABpkpFQrlcBroJddyegJ-9njB2Iui52CyGQiVNWsEkt-rAKOgATKZg1pptlxvUHQoiHnuMQ8jMVpRa-XnyKUk14mA1tTxfFsLLR675TUiCsQ9mhhlW2IhNIzU0IfN6UdQBzY30Ivb1vB3uq1t7CLIqle2dN1IeZXkw4XFg4l1tPBtRzSJP0wwL5zI5Xv-E6WN53HPLGN7qmehDZqAiLaAFj5sP-32aLYkCoatkvN4itt8yVizTwRLz7emUzJ2Qx1e6utUi916IcvOaNBT5mnndllSM_MDfYJYJ0e8lw065WAOVEv45x9RzY6uZ0BiTNO19YKzfturMt4MpUnTYT4lshj1YaXqnFrx__Tfs1PMJKAwuz7yIZ4gQjwB15h0ktGbLBdns29lEUCp3nYK6X5CiSB3oEpxhoXpv-FU4KxpSJodVpKLCP0TlFXMsOGCfp_swL49ksgvbeOBXW9oSpJ3XYaIunZY21LaN_N7HBcPFwXLB_7sPbpNY9srUL5yq9ou0qI3yWlXMKZNNyWnGA6j8e-n8XsPXPbAiFNnfuHJuWmWTkVrR7GwpwV3VomRjvzrUHxjPk-F1_J3vKonp2LuAtNUyO5qiDAMU7f04bdo3JY75RNUrt7YD_XqqlPfKo4zBwE7ETp2yQkVEOqGVfhVRgGxe_Ato4Lz--3eY_oQ9WuQlty0A21GLQmu4xKFSxeFMQqJvxtG6UEOs5lkLURp1ELCevF81iEGZ0C8NFkYul7hHmDUFLVm_0sIQocj_xqDrSTYfOXlqAW9YJTRfWBAiXsp1Fdebw0haXZpAxyHPmOTt7Ponbh8LQ1DbZyW3rgcjszBogBcUm3gm1069wmvoPoHNvCv4FYkISKsuMPOLD6u2vEnA="
            }
          },
          "time": {
            "start": 1771213135678,
            "end": 1771213136160
          },
          "id": "prt_c64879f3e001Re8Io19jxWr6WE",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64878d5b001WkJhPUxuljB0b0"
        },
        {
          "type": "tool",
          "callID": "call_5ACvXSUfpQrP1c4o5tOLPpux",
          "tool": "apply_patch",
          "state": {
            "status": "completed",
            "input": {
              "patchText": "*** Begin Patch\n*** Add File: .opencode/skills/protobuf-schema-authoring/SKILL.md\n+---\n+name: protobuf-schema-authoring\n+description: Author proto2/proto3 schemas and provide protoc generation workflows for Rust and TypeScript.\n+---\n+\n+## What I do\n+\n+- Turn user requirements into clear, evolvable `.proto` schemas.\n+- Support both `proto2` and `proto3` syntax.\n+- Ask for syntax preference when not explicitly provided, and explain version-specific constraints.\n+- Provide practical `protoc` workflows for Rust and TypeScript.\n+\n+## When to use me\n+\n+Use this when the task includes any of the following:\n+\n+- Create a new protobuf schema from product or API requirements.\n+- Update an existing `.proto` safely.\n+- Explain if a feature is `proto2`-only or `proto3`-only.\n+- Generate Rust or TypeScript artifacts from `.proto` files.\n+\n+## Required clarification flow\n+\n+If not already specified, ask these in order:\n+\n+1. Which schema syntax should be used: `proto2` or `proto3`?\n+   - Recommended default: `proto3` with explicit `optional` on scalar fields when presence matters.\n+2. For TypeScript generation, which plugin should be targeted: `ts-proto` or `@protobuf-ts/plugin`?\n+   - Recommended default: `ts-proto`.\n+\n+When answering, always note version-specific features involved in the request.\n+\n+## Proto2 vs proto3 guardrails\n+\n+- `required` fields are proto2-only and should be avoided for new design.\n+- Explicit scalar defaults (`[default = ...]`) are proto2-only.\n+- Extensions are proto2-oriented; not a general proto3 field pattern.\n+- Groups are deprecated legacy proto2 and should not be introduced.\n+- Proto3 enums must start with a zero-valued first entry.\n+- Proto3 scalar presence should use `optional` when presence semantics are needed.\n+- Repeated scalar numerics are packed-by-default in proto3; in proto2, use `[packed = true]` for new fields.\n+\n+## Schema authoring workflow\n+\n+1. Confirm syntax version and target language outputs.\n+2. Propose package and file layout.\n+3. Define messages/enums/services with stable field numbering.\n+4. Add comments only where semantics are non-obvious.\n+5. Reserve removed field numbers and names.\n+6. Validate with `protoc` descriptor output when possible.\n+7. Provide generation commands for Rust and TypeScript.\n+\n+## Command templates\n+\n+- Validate schema and emit descriptor:\n+\n+```bash\n+protoc -I proto --include_imports --descriptor_set_out=gen/schema.pb proto/path/to/file.proto\n+```\n+\n+- Rust via `prost-build` (`build.rs`):\n+\n+```rust\n+fn main() -> std::io::Result<()> {\n+    prost_build::compile_protos(&[\"proto/service.proto\"], &[\"proto\"])?;\n+    Ok(())\n+}\n+```\n+\n+- Rust via `tonic-prost-build` (`build.rs`):\n+\n+```rust\n+fn main() {\n+    tonic_prost_build::configure()\n+        .compile_protos(&[\"proto/service.proto\"], &[\"proto\"])\n+        .unwrap();\n+}\n+```\n+\n+- TypeScript via `ts-proto`:\n+\n+```bash\n+protoc \\\n+  --plugin=./node_modules/.bin/protoc-gen-ts_proto \\\n+  --ts_proto_out=gen/ts \\\n+  --ts_proto_opt=esModuleInterop=true \\\n+  -I proto \\\n+  proto/path/to/file.proto\n+```\n+\n+- TypeScript via `@protobuf-ts/plugin`:\n+\n+```bash\n+npx protoc --ts_out gen/ts --proto_path proto proto/path/to/file.proto\n+```\n+\n+## Output expectations\n+\n+- Deliver the requested `.proto` file(s) and a short note on compatibility choices.\n+- Explicitly call out any use of proto2-only/proto3-only features.\n+- Include exact generation commands for the selected Rust and TypeScript toolchains.\n*** End Patch"
            },
            "output": "Success. Updated the following files:\nA .opencode/skills/protobuf-schema-authoring/SKILL.md",
            "title": "Success. Updated the following files:\nA .opencode/skills/protobuf-schema-authoring/SKILL.md",
            "metadata": {
              "diff": "Index: /Users/alex/repos/vfp/dark-factory/.opencode/skills/protobuf-schema-authoring/SKILL.md\n===================================================================\n--- /Users/alex/repos/vfp/dark-factory/.opencode/skills/protobuf-schema-authoring/SKILL.md\n+++ /Users/alex/repos/vfp/dark-factory/.opencode/skills/protobuf-schema-authoring/SKILL.md\n@@ -0,0 +1,101 @@\n+---\n+name: protobuf-schema-authoring\n+description: Author proto2/proto3 schemas and provide protoc generation workflows for Rust and TypeScript.\n+---\n+\n+## What I do\n+\n+- Turn user requirements into clear, evolvable `.proto` schemas.\n+- Support both `proto2` and `proto3` syntax.\n+- Ask for syntax preference when not explicitly provided, and explain version-specific constraints.\n+- Provide practical `protoc` workflows for Rust and TypeScript.\n+\n+## When to use me\n+\n+Use this when the task includes any of the following:\n+\n+- Create a new protobuf schema from product or API requirements.\n+- Update an existing `.proto` safely.\n+- Explain if a feature is `proto2`-only or `proto3`-only.\n+- Generate Rust or TypeScript artifacts from `.proto` files.\n+\n+## Required clarification flow\n+\n+If not already specified, ask these in order:\n+\n+1. Which schema syntax should be used: `proto2` or `proto3`?\n+   - Recommended default: `proto3` with explicit `optional` on scalar fields when presence matters.\n+2. For TypeScript generation, which plugin should be targeted: `ts-proto` or `@protobuf-ts/plugin`?\n+   - Recommended default: `ts-proto`.\n+\n+When answering, always note version-specific features involved in the request.\n+\n+## Proto2 vs proto3 guardrails\n+\n+- `required` fields are proto2-only and should be avoided for new design.\n+- Explicit scalar defaults (`[default = ...]`) are proto2-only.\n+- Extensions are proto2-oriented; not a general proto3 field pattern.\n+- Groups are deprecated legacy proto2 and should not be introduced.\n+- Proto3 enums must start with a zero-valued first entry.\n+- Proto3 scalar presence should use `optional` when presence semantics are needed.\n+- Repeated scalar numerics are packed-by-default in proto3; in proto2, use `[packed = true]` for new fields.\n+\n+## Schema authoring workflow\n+\n+1. Confirm syntax version and target language outputs.\n+2. Propose package and file layout.\n+3. Define messages/enums/services with stable field numbering.\n+4. Add comments only where semantics are non-obvious.\n+5. Reserve removed field numbers and names.\n+6. Validate with `protoc` descriptor output when possible.\n+7. Provide generation commands for Rust and TypeScript.\n+\n+## Command templates\n+\n+- Validate schema and emit descriptor:\n+\n+```bash\n+protoc -I proto --include_imports --descriptor_set_out=gen/schema.pb proto/path/to/file.proto\n+```\n+\n+- Rust via `prost-build` (`build.rs`):\n+\n+```rust\n+fn main() -> std::io::Result<()> {\n+    prost_build::compile_protos(&[\"proto/service.proto\"], &[\"proto\"])?;\n+    Ok(())\n+}\n+```\n+\n+- Rust via `tonic-prost-build` (`build.rs`):\n+\n+```rust\n+fn main() {\n+    tonic_prost_build::configure()\n+        .compile_protos(&[\"proto/service.proto\"], &[\"proto\"])\n+        .unwrap();\n+}\n+```\n+\n+- TypeScript via `ts-proto`:\n+\n+```bash\n+protoc \\\n+  --plugin=./node_modules/.bin/protoc-gen-ts_proto \\\n+  --ts_proto_out=gen/ts \\\n+  --ts_proto_opt=esModuleInterop=true \\\n+  -I proto \\\n+  proto/path/to/file.proto\n+```\n+\n+- TypeScript via `@protobuf-ts/plugin`:\n+\n+```bash\n+npx protoc --ts_out gen/ts --proto_path proto proto/path/to/file.proto\n+```\n+\n+## Output expectations\n+\n+- Deliver the requested `.proto` file(s) and a short note on compatibility choices.\n+- Explicitly call out any use of proto2-only/proto3-only features.\n+- Include exact generation commands for the selected Rust and TypeScript toolchains.\n\n",
              "files": [
                {
                  "filePath": "/Users/alex/repos/vfp/dark-factory/.opencode/skills/protobuf-schema-authoring/SKILL.md",
                  "relativePath": ".opencode/skills/protobuf-schema-authoring/SKILL.md",
                  "type": "add",
                  "diff": "Index: /Users/alex/repos/vfp/dark-factory/.opencode/skills/protobuf-schema-authoring/SKILL.md\n===================================================================\n--- /Users/alex/repos/vfp/dark-factory/.opencode/skills/protobuf-schema-authoring/SKILL.md\n+++ /Users/alex/repos/vfp/dark-factory/.opencode/skills/protobuf-schema-authoring/SKILL.md\n@@ -0,0 +1,101 @@\n+---\n+name: protobuf-schema-authoring\n+description: Author proto2/proto3 schemas and provide protoc generation workflows for Rust and TypeScript.\n+---\n+\n+## What I do\n+\n+- Turn user requirements into clear, evolvable `.proto` schemas.\n+- Support both `proto2` and `proto3` syntax.\n+- Ask for syntax preference when not explicitly provided, and explain version-specific constraints.\n+- Provide practical `protoc` workflows for Rust and TypeScript.\n+\n+## When to use me\n+\n+Use this when the task includes any of the following:\n+\n+- Create a new protobuf schema from product or API requirements.\n+- Update an existing `.proto` safely.\n+- Explain if a feature is `proto2`-only or `proto3`-only.\n+- Generate Rust or TypeScript artifacts from `.proto` files.\n+\n+## Required clarification flow\n+\n+If not already specified, ask these in order:\n+\n+1. Which schema syntax should be used: `proto2` or `proto3`?\n+   - Recommended default: `proto3` with explicit `optional` on scalar fields when presence matters.\n+2. For TypeScript generation, which plugin should be targeted: `ts-proto` or `@protobuf-ts/plugin`?\n+   - Recommended default: `ts-proto`.\n+\n+When answering, always note version-specific features involved in the request.\n+\n+## Proto2 vs proto3 guardrails\n+\n+- `required` fields are proto2-only and should be avoided for new design.\n+- Explicit scalar defaults (`[default = ...]`) are proto2-only.\n+- Extensions are proto2-oriented; not a general proto3 field pattern.\n+- Groups are deprecated legacy proto2 and should not be introduced.\n+- Proto3 enums must start with a zero-valued first entry.\n+- Proto3 scalar presence should use `optional` when presence semantics are needed.\n+- Repeated scalar numerics are packed-by-default in proto3; in proto2, use `[packed = true]` for new fields.\n+\n+## Schema authoring workflow\n+\n+1. Confirm syntax version and target language outputs.\n+2. Propose package and file layout.\n+3. Define messages/enums/services with stable field numbering.\n+4. Add comments only where semantics are non-obvious.\n+5. Reserve removed field numbers and names.\n+6. Validate with `protoc` descriptor output when possible.\n+7. Provide generation commands for Rust and TypeScript.\n+\n+## Command templates\n+\n+- Validate schema and emit descriptor:\n+\n+```bash\n+protoc -I proto --include_imports --descriptor_set_out=gen/schema.pb proto/path/to/file.proto\n+```\n+\n+- Rust via `prost-build` (`build.rs`):\n+\n+```rust\n+fn main() -> std::io::Result<()> {\n+    prost_build::compile_protos(&[\"proto/service.proto\"], &[\"proto\"])?;\n+    Ok(())\n+}\n+```\n+\n+- Rust via `tonic-prost-build` (`build.rs`):\n+\n+```rust\n+fn main() {\n+    tonic_prost_build::configure()\n+        .compile_protos(&[\"proto/service.proto\"], &[\"proto\"])\n+        .unwrap();\n+}\n+```\n+\n+- TypeScript via `ts-proto`:\n+\n+```bash\n+protoc \\\n+  --plugin=./node_modules/.bin/protoc-gen-ts_proto \\\n+  --ts_proto_out=gen/ts \\\n+  --ts_proto_opt=esModuleInterop=true \\\n+  -I proto \\\n+  proto/path/to/file.proto\n+```\n+\n+- TypeScript via `@protobuf-ts/plugin`:\n+\n+```bash\n+npx protoc --ts_out gen/ts --proto_path proto proto/path/to/file.proto\n+```\n+\n+## Output expectations\n+\n+- Deliver the requested `.proto` file(s) and a short note on compatibility choices.\n+- Explicitly call out any use of proto2-only/proto3-only features.\n+- Include exact generation commands for the selected Rust and TypeScript toolchains.\n",
                  "before": "",
                  "after": "---\nname: protobuf-schema-authoring\ndescription: Author proto2/proto3 schemas and provide protoc generation workflows for Rust and TypeScript.\n---\n\n## What I do\n\n- Turn user requirements into clear, evolvable `.proto` schemas.\n- Support both `proto2` and `proto3` syntax.\n- Ask for syntax preference when not explicitly provided, and explain version-specific constraints.\n- Provide practical `protoc` workflows for Rust and TypeScript.\n\n## When to use me\n\nUse this when the task includes any of the following:\n\n- Create a new protobuf schema from product or API requirements.\n- Update an existing `.proto` safely.\n- Explain if a feature is `proto2`-only or `proto3`-only.\n- Generate Rust or TypeScript artifacts from `.proto` files.\n\n## Required clarification flow\n\nIf not already specified, ask these in order:\n\n1. Which schema syntax should be used: `proto2` or `proto3`?\n   - Recommended default: `proto3` with explicit `optional` on scalar fields when presence matters.\n2. For TypeScript generation, which plugin should be targeted: `ts-proto` or `@protobuf-ts/plugin`?\n   - Recommended default: `ts-proto`.\n\nWhen answering, always note version-specific features involved in the request.\n\n## Proto2 vs proto3 guardrails\n\n- `required` fields are proto2-only and should be avoided for new design.\n- Explicit scalar defaults (`[default = ...]`) are proto2-only.\n- Extensions are proto2-oriented; not a general proto3 field pattern.\n- Groups are deprecated legacy proto2 and should not be introduced.\n- Proto3 enums must start with a zero-valued first entry.\n- Proto3 scalar presence should use `optional` when presence semantics are needed.\n- Repeated scalar numerics are packed-by-default in proto3; in proto2, use `[packed = true]` for new fields.\n\n## Schema authoring workflow\n\n1. Confirm syntax version and target language outputs.\n2. Propose package and file layout.\n3. Define messages/enums/services with stable field numbering.\n4. Add comments only where semantics are non-obvious.\n5. Reserve removed field numbers and names.\n6. Validate with `protoc` descriptor output when possible.\n7. Provide generation commands for Rust and TypeScript.\n\n## Command templates\n\n- Validate schema and emit descriptor:\n\n```bash\nprotoc -I proto --include_imports --descriptor_set_out=gen/schema.pb proto/path/to/file.proto\n```\n\n- Rust via `prost-build` (`build.rs`):\n\n```rust\nfn main() -> std::io::Result<()> {\n    prost_build::compile_protos(&[\"proto/service.proto\"], &[\"proto\"])?;\n    Ok(())\n}\n```\n\n- Rust via `tonic-prost-build` (`build.rs`):\n\n```rust\nfn main() {\n    tonic_prost_build::configure()\n        .compile_protos(&[\"proto/service.proto\"], &[\"proto\"])\n        .unwrap();\n}\n```\n\n- TypeScript via `ts-proto`:\n\n```bash\nprotoc \\\n  --plugin=./node_modules/.bin/protoc-gen-ts_proto \\\n  --ts_proto_out=gen/ts \\\n  --ts_proto_opt=esModuleInterop=true \\\n  -I proto \\\n  proto/path/to/file.proto\n```\n\n- TypeScript via `@protobuf-ts/plugin`:\n\n```bash\nnpx protoc --ts_out gen/ts --proto_path proto proto/path/to/file.proto\n```\n\n## Output expectations\n\n- Deliver the requested `.proto` file(s) and a short note on compatibility choices.\n- Explicitly call out any use of proto2-only/proto3-only features.\n- Include exact generation commands for the selected Rust and TypeScript toolchains.\n",
                  "additions": 101,
                  "deletions": 0
                }
              ],
              "diagnostics": {},
              "truncated": false
            },
            "time": {
              "start": 1771213151620,
              "end": 1771213151660
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_06fc134f73f55e0001699291501a208195aadf7a4c23fee297"
            }
          },
          "id": "prt_c6487a121001nT3VKut1LpVDkD",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64878d5b001WkJhPUxuljB0b0"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "ef7c88dd3456ac1f44cca818a644bb0a19dc1e60",
          "cost": 0,
          "tokens": {
            "total": 114547,
            "input": 98304,
            "output": 1011,
            "reasoning": 9,
            "cache": {
              "read": 15232,
              "write": 0
            }
          },
          "id": "prt_c6487ddb5001ZdyDokagLwFk0D",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64878d5b001WkJhPUxuljB0b0"
        },
        {
          "type": "patch",
          "hash": "19c5089de435342262b4ffc46f59fbfc3533018b",
          "files": [
            "/Users/alex/repos/vfp/dark-factory/.opencode/skills/protobuf-schema-authoring/SKILL.md"
          ],
          "id": "prt_c6487dde6001XGJrnifbjQinpg",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64878d5b001WkJhPUxuljB0b0"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771213151732,
          "completed": 1771213157219
        },
        "parentID": "msg_c6484620d0011ltzji40BSbVp5",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 114768,
          "input": 148,
          "output": 188,
          "reasoning": 13,
          "cache": {
            "read": 114432,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "tool-calls",
        "id": "msg_c6487ddf4001BVpBv1mzk92vMY",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "ef7c88dd3456ac1f44cca818a644bb0a19dc1e60",
          "id": "prt_c6487e5d600148Cx2hE07mhMkx",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6487ddf4001BVpBv1mzk92vMY"
        },
        {
          "type": "reasoning",
          "text": "**Updating agent registration**",
          "metadata": {
            "openai": {
              "itemId": "rs_0ce5b41c552baf22016992916245308194af342cc911ab245d",
              "reasoningEncryptedContent": "gAAAAABpkpFi5A2Q0XffMknTDLY7s-ca2OZ6AJYv0x942KxtE1o1aq4KTVyjSRN4cjVFRWqTgkxCqOGqNoCkr4LW5_RKWedOhjj9595DLAQFXrfY0P4b8YsAk1nM_Lq_4rfny6EGJ9dXz_w5zdVRldxQp6B0Z9VxGiRcenl9jhgrj1YL4oPUm0Cowf6CWg9n1dlqu3lRhD8JCEZY9IR9Ud-6VoC13WwQLLYwFN74P9GS2lQa3KgE_8ggFynVr72INgZERU8mbqajUswiO0cvMPBlDFJ71xhZrenKUHhdbfeCbHIznbVZfTsCY06bCq0s_dMLr_H15sdCIcDNyS10MVnX99KxwzR7gPhXA_h7nkUjnyyMYUIRCDBsXFH5_K8-8SYiBN4G5LNsJ-hjY82enm8M_UQ2OiAD3ppO-rjkqf17YpdchNcp3576IQyfqwE-xGqQafztaxcavY1GE4lVxKzTYVsuGTClp8OHHVEYwFFtSIjvR06gcbDYPxmIpoKNNBTD1fCzdRNZrRFJvVbcJNHxaTa4Y9WtkCVIApzsVJv8INKYCt-T7CfI-OXVzjGxX--gwyOcg0DVoL3ze1GlpDYuUlV98yzEsU7KDNLShMT2K6LUNyJTXvFJQs71VuilDNn9tFAvFgY6DhxNuNxpSbx4C_Vms2A2NIDC37a_0Im7PC8qCvqY_SKnB9XyhREo0Q-RutCU_5Q_QLqbUOtGfFAXhe7SURPdF_QB7kliLfewBfAUM0QkzvIDCbFdTGW-eJ6ILnyakRFasQrqivDEkNEa327dicHPagWhKbNQeWhTVHEMRzg88z39X3l6BjXGgU4eYTV153L5S_l75XjXtqCqCUWPzaC5I9qbeIfDbDcL4lchb5bnnehTghTsJ28Epuwh_8YMCpD9"
            }
          },
          "time": {
            "start": 1771213154303,
            "end": 1771213155037
          },
          "id": "prt_c6487e7ff001rw28evDC6uz98n",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6487ddf4001BVpBv1mzk92vMY"
        },
        {
          "type": "tool",
          "callID": "call_6j0KTIGuKYwPNAYoN0ljDzcN",
          "tool": "apply_patch",
          "state": {
            "status": "completed",
            "input": {
              "patchText": "*** Begin Patch\n*** Update File: AGENTS.md\n@@\n - `.opencode/skills/gitter-commit/SKILL.md` documents when to route commit tasks to `@gitter`.\n - `.opencode/skills/proto-install/SKILL.md` documents standardized script-based `proto install` usage.\n+- `.opencode/skills/protobuf-schema-authoring/SKILL.md` documents how to author proto2/proto3 schemas and provide Rust/TypeScript codegen workflows.\n - `.opencode/skills/script-authoring/SKILL.md` documents how to build reusable Bun scripts from prompt/example/bash/context.\n - Use `@gitter` when the user asks for commit support or cleanup.\n*** End Patch"
            },
            "output": "Success. Updated the following files:\nM AGENTS.md",
            "title": "Success. Updated the following files:\nM AGENTS.md",
            "metadata": {
              "diff": "Index: /Users/alex/repos/vfp/dark-factory/AGENTS.md\n===================================================================\n--- /Users/alex/repos/vfp/dark-factory/AGENTS.md\n+++ /Users/alex/repos/vfp/dark-factory/AGENTS.md\n@@ -58,8 +58,9 @@\n \n - `.opencode/agents/gitter.md` is the git-focused subagent.\n - `.opencode/skills/gitter-commit/SKILL.md` documents when to route commit tasks to `@gitter`.\n - `.opencode/skills/proto-install/SKILL.md` documents standardized script-based `proto install` usage.\n+- `.opencode/skills/protobuf-schema-authoring/SKILL.md` documents how to author proto2/proto3 schemas and provide Rust/TypeScript codegen workflows.\n - `.opencode/skills/script-authoring/SKILL.md` documents how to build reusable Bun scripts from prompt/example/bash/context.\n - Use `@gitter` when the user asks for commit support or cleanup.\n \n ## 7) Local Fork Workflow (`elysia-protobuf`)\n\n",
              "files": [
                {
                  "filePath": "/Users/alex/repos/vfp/dark-factory/AGENTS.md",
                  "relativePath": "AGENTS.md",
                  "type": "update",
                  "diff": "Index: /Users/alex/repos/vfp/dark-factory/AGENTS.md\n===================================================================\n--- /Users/alex/repos/vfp/dark-factory/AGENTS.md\n+++ /Users/alex/repos/vfp/dark-factory/AGENTS.md\n@@ -58,8 +58,9 @@\n \n - `.opencode/agents/gitter.md` is the git-focused subagent.\n - `.opencode/skills/gitter-commit/SKILL.md` documents when to route commit tasks to `@gitter`.\n - `.opencode/skills/proto-install/SKILL.md` documents standardized script-based `proto install` usage.\n+- `.opencode/skills/protobuf-schema-authoring/SKILL.md` documents how to author proto2/proto3 schemas and provide Rust/TypeScript codegen workflows.\n - `.opencode/skills/script-authoring/SKILL.md` documents how to build reusable Bun scripts from prompt/example/bash/context.\n - Use `@gitter` when the user asks for commit support or cleanup.\n \n ## 7) Local Fork Workflow (`elysia-protobuf`)\n",
                  "before": "# Dark Factory - Agent Operating Guide\n\nThis file is for coding agents working in `dark-factory`.\nIt reflects only what is currently true in this repository.\n\n## 1) Current Repository Context\n\n- The repo is early-stage and mostly docs/config right now.\n- Tracked project files currently include:\n  - `README.md`\n  - `TODO.md`\n  - `AGENTS.md`\n  - `opencode.jsonc`\n  - `.opencode/agents/gitter.md`\n  - `.opencode/skills/gitter-commit/SKILL.md`\n- No application code tree is committed yet (`src/`, `apps/`, `crates/`, etc.).\n\n## 2) Build/Lint/Test Status (Current Truth)\n\n- There are no validated build, lint, typecheck, or test commands yet.\n- Do not invent or assume project commands in commits or PR notes.\n- If new tooling is added, document only commands that are verified in this repo.\n\n## 3) Cursor and Copilot Rules\n\n- Checked and currently absent:\n  - `.cursor/rules/`\n  - `.cursorrules`\n  - `.github/copilot-instructions.md`\n- If any of these files appear later, treat them as authoritative and update this guide.\n\n## 4) Coding Style (Minimal Baseline)\n\nUntil language/tool-specific configs exist, follow pragmatic defaults:\n\n- Favor readable, explicit code over clever shortcuts.\n- Keep functions focused and avoid hidden side effects.\n- Avoid dead code, unused imports, and speculative abstractions.\n- Keep naming consistent (`PascalCase` types, `camelCase` values/functions, `UPPER_SNAKE_CASE` constants).\n- Handle errors with context; do not swallow exceptions silently.\n- Never log secrets or credentials.\n- Log messages should follow: `System // Optional Sub system // Message (Metadata)`.\n  - Example: `Core // HTTP // Listening (env=development,host=127.0.0.1,port=4150)`.\n\n## 5) Git Workflow\n\n- Commit meaningful units of work; avoid giant mixed commits.\n- Do not push unless the user explicitly requests it.\n- Commit message format:\n  - `{Component/Meta} // {Optional Addition} // {Short Description} (Optional,Tags)`\n- Examples:\n  - `Docs // Added converted PDF docs`\n  - `Pipelines // ODM // Added initial ODM pipeline (WIP)`\n- In commit body, add a short rationale and signature when possible:\n  - `// Chappie/Model (your model if known)`\n\n## 6) OpenCode Integration\n\n- `.opencode/agents/gitter.md` is the git-focused subagent.\n- `.opencode/skills/gitter-commit/SKILL.md` documents when to route commit tasks to `@gitter`.\n- `.opencode/skills/proto-install/SKILL.md` documents standardized script-based `proto install` usage.\n- `.opencode/skills/script-authoring/SKILL.md` documents how to build reusable Bun scripts from prompt/example/bash/context.\n- Use `@gitter` when the user asks for commit support or cleanup.\n\n## 7) Local Fork Workflow (`elysia-protobuf`)\n\n- `elysia-protobuf` is also cloned locally at `~/repos/vfp/elysia-protobuf`.\n- If Core hits a bug in that dependency, patch it in the local fork repo, push the fork, then update the pinned git ref in `core/package.json` and refresh `core/bun.lock`.\n- Core currently tracks `elysia-protobuf` from the fork `master` branch in `core/package.json`; after pushing fork changes, refresh `core/bun.lock` in this repo.\n\n## 8) Script Conventions\n\n- Project scripts use shebanged Bun TypeScript files (`#!/usr/bin/env bun`) under `scripts/`.\n- Script naming uses `*.sh.ts` to indicate executable shell-style Bun scripts.\n- Shared script helpers live under `scripts/helpers/`.\n- `scripts/install.sh.ts` runs a reusable ordered list of install steps.\n- `scripts/proto_install.sh.ts` runs `proto install` from repository root.\n- `scripts/scrape_moon_docs.sh.ts` scrapes moonrepo docs into `docs/external/moonrepo/*.ext.md`.\n- After a new command sequence succeeds in a conversation, suggest capturing it into a reusable script via `.opencode/commands/capture_script_from_context.md`.\n\n## 9) Keep This File Updated\n\n- Update this file when real code, tooling, or CI is added.\n- Keep instructions tied to verified repository behavior.\n- Prefer short, accurate guidance over aspirational process docs.\n",
                  "after": "# Dark Factory - Agent Operating Guide\n\nThis file is for coding agents working in `dark-factory`.\nIt reflects only what is currently true in this repository.\n\n## 1) Current Repository Context\n\n- The repo is early-stage and mostly docs/config right now.\n- Tracked project files currently include:\n  - `README.md`\n  - `TODO.md`\n  - `AGENTS.md`\n  - `opencode.jsonc`\n  - `.opencode/agents/gitter.md`\n  - `.opencode/skills/gitter-commit/SKILL.md`\n- No application code tree is committed yet (`src/`, `apps/`, `crates/`, etc.).\n\n## 2) Build/Lint/Test Status (Current Truth)\n\n- There are no validated build, lint, typecheck, or test commands yet.\n- Do not invent or assume project commands in commits or PR notes.\n- If new tooling is added, document only commands that are verified in this repo.\n\n## 3) Cursor and Copilot Rules\n\n- Checked and currently absent:\n  - `.cursor/rules/`\n  - `.cursorrules`\n  - `.github/copilot-instructions.md`\n- If any of these files appear later, treat them as authoritative and update this guide.\n\n## 4) Coding Style (Minimal Baseline)\n\nUntil language/tool-specific configs exist, follow pragmatic defaults:\n\n- Favor readable, explicit code over clever shortcuts.\n- Keep functions focused and avoid hidden side effects.\n- Avoid dead code, unused imports, and speculative abstractions.\n- Keep naming consistent (`PascalCase` types, `camelCase` values/functions, `UPPER_SNAKE_CASE` constants).\n- Handle errors with context; do not swallow exceptions silently.\n- Never log secrets or credentials.\n- Log messages should follow: `System // Optional Sub system // Message (Metadata)`.\n  - Example: `Core // HTTP // Listening (env=development,host=127.0.0.1,port=4150)`.\n\n## 5) Git Workflow\n\n- Commit meaningful units of work; avoid giant mixed commits.\n- Do not push unless the user explicitly requests it.\n- Commit message format:\n  - `{Component/Meta} // {Optional Addition} // {Short Description} (Optional,Tags)`\n- Examples:\n  - `Docs // Added converted PDF docs`\n  - `Pipelines // ODM // Added initial ODM pipeline (WIP)`\n- In commit body, add a short rationale and signature when possible:\n  - `// Chappie/Model (your model if known)`\n\n## 6) OpenCode Integration\n\n- `.opencode/agents/gitter.md` is the git-focused subagent.\n- `.opencode/skills/gitter-commit/SKILL.md` documents when to route commit tasks to `@gitter`.\n- `.opencode/skills/proto-install/SKILL.md` documents standardized script-based `proto install` usage.\n- `.opencode/skills/protobuf-schema-authoring/SKILL.md` documents how to author proto2/proto3 schemas and provide Rust/TypeScript codegen workflows.\n- `.opencode/skills/script-authoring/SKILL.md` documents how to build reusable Bun scripts from prompt/example/bash/context.\n- Use `@gitter` when the user asks for commit support or cleanup.\n\n## 7) Local Fork Workflow (`elysia-protobuf`)\n\n- `elysia-protobuf` is also cloned locally at `~/repos/vfp/elysia-protobuf`.\n- If Core hits a bug in that dependency, patch it in the local fork repo, push the fork, then update the pinned git ref in `core/package.json` and refresh `core/bun.lock`.\n- Core currently tracks `elysia-protobuf` from the fork `master` branch in `core/package.json`; after pushing fork changes, refresh `core/bun.lock` in this repo.\n\n## 8) Script Conventions\n\n- Project scripts use shebanged Bun TypeScript files (`#!/usr/bin/env bun`) under `scripts/`.\n- Script naming uses `*.sh.ts` to indicate executable shell-style Bun scripts.\n- Shared script helpers live under `scripts/helpers/`.\n- `scripts/install.sh.ts` runs a reusable ordered list of install steps.\n- `scripts/proto_install.sh.ts` runs `proto install` from repository root.\n- `scripts/scrape_moon_docs.sh.ts` scrapes moonrepo docs into `docs/external/moonrepo/*.ext.md`.\n- After a new command sequence succeeds in a conversation, suggest capturing it into a reusable script via `.opencode/commands/capture_script_from_context.md`.\n\n## 9) Keep This File Updated\n\n- Update this file when real code, tooling, or CI is added.\n- Keep instructions tied to verified repository behavior.\n- Prefer short, accurate guidance over aspirational process docs.\n",
                  "additions": 1,
                  "deletions": 0
                }
              ],
              "diagnostics": {},
              "truncated": false
            },
            "time": {
              "start": 1771213157132,
              "end": 1771213157159
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_0ce5b41c552baf220169929162e9748194a9705b1f4776cbfe"
            }
          },
          "id": "prt_c6487eade001wDNd5oFWyZX3am",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6487ddf4001BVpBv1mzk92vMY"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "6fcaf1d4f278d8c8334034c54e2c27d3628e959a",
          "cost": 0,
          "tokens": {
            "total": 114768,
            "input": 148,
            "output": 188,
            "reasoning": 13,
            "cache": {
              "read": 114432,
              "write": 0
            }
          },
          "id": "prt_c6487f329001PsW4MbplubmVTJ",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6487ddf4001BVpBv1mzk92vMY"
        },
        {
          "type": "patch",
          "hash": "ef7c88dd3456ac1f44cca818a644bb0a19dc1e60",
          "files": [
            "/Users/alex/repos/vfp/dark-factory/AGENTS.md"
          ],
          "id": "prt_c6487f35e001LdDx74JyCo1nne",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6487ddf4001BVpBv1mzk92vMY"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771213157224,
          "completed": 1771213164268
        },
        "parentID": "msg_c6484620d0011ltzji40BSbVp5",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 114983,
          "input": 114826,
          "output": 157,
          "reasoning": 29,
          "cache": {
            "read": 0,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "tool-calls",
        "id": "msg_c6487f3680010GhG8BR06BxlDi",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "6fcaf1d4f278d8c8334034c54e2c27d3628e959a",
          "id": "prt_c6487fc5b001W3ZGumRjfc8K5E",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6487f3680010GhG8BR06BxlDi"
        },
        {
          "type": "reasoning",
          "text": "**Planning todo status update**",
          "metadata": {
            "openai": {
              "itemId": "rs_00e918ad6c52f3c00169929169eb3c81959c5482aa0df489cc",
              "reasoningEncryptedContent": "gAAAAABpkpFsJ44cEGdSfTeMpG5V8XxJd_D19zRORWneB7Hp9O02hFtvA0dtog45Pl8HBL7LAg4Uhpx52uzS_o1I9waQLlGovc2Dy9jgcHWiX91d2MZjYrNTkk5-61P3QvyHluZkb-TUHHTZ9iux2Ausur_eaMykm7MMz5yhbB5AWvW_jrYKTRfjfRoSI16EM6mQXGL34gdjnu1E2OgvCO7cNjpz2keTte5_zU_iI7Tj0NeU-l2XIWdljBF1buB1QNAEv7wJrimglhXfQV_s5iJUZg7Xmmzsw5qV9vR63vHMaOwYzO883XYzoH_MNZO3Xd74CHPGy9eAc6guebrMCPBg1XIuuDB8tikBpU3hFtOzpClGCUsByb-cUof-NcBQfJtxum1dniCYNm7wv3E5QBotfa7lvufCr4pSImy06NpdKBegRaJHWUqiiTGpnzmbg88KmO9gCUvBiVpvpomHPwDnL5EC3jf4Xc1Mp33B5YdS0Be_Ib4bULgpNPsjq4DZmhdC50G3dEkdBK4qmrOATYch0JXDBrV0YgtqyDg3M_91G16bzlNEcDv7OtKb9K-1Y-27zOoxrkKzVmkKuXADixrftkbdnMhTk6CrVbOTk1CWVeaqA310IY0XrpS1afXmfjuZzZVM-oip10PmdrGbS1TWLLDmO6li1elyGHepk4QFhhqn-8nM5h6TUrowa_-OZd-03OinDrrKBtD-4TQql_KAUyfiZD25iY5V2GQtqPg6Cl3-KdGf2JswO-N2NZKPuAXh1Qo9YFnqWjkItoOIjmVcgLsMYWnidq31v7XkMvljfH_vqi8NWIsUvHFLZNsT-SsLKJWBXTJgPYn-T9nm1upFI7J5zpcaQPCsysD8q4rhdodOGkPNy8JPYpwQmHe4qEVNjcwVx8I5dewfLrIEGArtJ-p0a47trsw_55ktxWVcRTmrzJp9V7k5GXNoIMsOFZoiHX9AGLrtMXtmlYn3_3CEqzrkTgQssF6w2d1RcnamE5MK1XDkhSc09G21r4ewr1PpmmF2FMKX"
            }
          },
          "time": {
            "start": 1771213161948,
            "end": 1771213164097
          },
          "id": "prt_c648805dc001rWAAfsCZ3kWrxc",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6487f3680010GhG8BR06BxlDi"
        },
        {
          "type": "tool",
          "callID": "call_3gqOIQi4tplGlCdZGhZ9gC20",
          "tool": "read",
          "state": {
            "status": "completed",
            "input": {
              "filePath": "/Users/alex/repos/vfp/dark-factory/docs/readmes/protobuf-schema-research.md"
            },
            "output": "<path>/Users/alex/repos/vfp/dark-factory/docs/readmes/protobuf-schema-research.md</path>\n<type>file</type>\n<content>1: # Protobuf Schema Research Notes\n2: \n3: Last reviewed: 2026-02-15\n4: \n5: ## Scope\n6: \n7: - Capture practical notes for authoring new `.proto` schemas.\n8: - Support both `proto2` and `proto3` workflows.\n9: - Document `protoc` usage for Rust and TypeScript generation paths.\n10: \n11: ## Primary web sources\n12: \n13: - OpenCode skills docs: https://opencode.ai/docs/skills/\n14: - Protoc install docs: https://protobuf.dev/installation/\n15: - Proto2 guide: https://protobuf.dev/programming-guides/proto2/\n16: - Proto3 guide: https://protobuf.dev/programming-guides/proto3/\n17: - Field presence note: https://protobuf.dev/programming-guides/field_presence/\n18: - Rust generated code guide: https://protobuf.dev/reference/rust/rust-generated/\n19: - Rust build reference: https://protobuf.dev/reference/rust/building-rust-protos/\n20: - `prost-build` docs: https://docs.rs/prost-build/latest/prost_build/\n21: - `tonic-prost-build` docs: https://docs.rs/tonic-prost-build/latest/tonic_prost_build/\n22: - `ts-proto` README: https://github.com/stephenh/ts-proto\n23: - `protobuf-ts` README: https://github.com/timostamm/protobuf-ts\n24: \n25: ## Proto2 vs proto3 (what matters most)\n26: \n27: - **Syntax line**\n28:   - `proto2`: `syntax = \"proto2\";`\n29:   - `proto3`: `syntax = \"proto3\";`\n30: - **Cardinality labels**\n31:   - `proto2`: `optional`, `required` (strongly discouraged), `repeated`, `map`.\n32:   - `proto3`: `optional` (recommended), implicit singular (legacy style), `repeated`, `map`.\n33: - **Required fields**\n34:   - `proto2` only, but strongly discouraged for new schemas.\n35:   - Not available in `proto3`.\n36: - **Scalar default overrides**\n37:   - `proto2`: supports `[default = ...]` on singular non-message fields.\n38:   - `proto3`: no custom scalar defaults; language defaults apply.\n39: - **Field presence**\n40:   - `proto2`: explicit presence for singular fields.\n41:   - `proto3`: explicit presence only with `optional` (or oneof/message); otherwise implicit for basic scalars.\n42:   - Proto docs recommend using `optional` in proto3 for smoother compatibility.\n43: - **Enum zero value**\n44:   - `proto3`: first enum value must be `0`.\n45:   - `proto2`: first value is default; using `_UNSPECIFIED = 0` is still safest.\n46: - **Extensions and groups**\n47:   - `proto2`: supports extensions; groups exist but are deprecated.\n48:   - `proto3`: no general extension fields/groups in the same way.\n49: - **Repeated scalar packing**\n50:   - `proto2`: use `[packed = true]` for new repeated numeric fields.\n51:   - `proto3`: repeated scalar numerics are packed by default.\n52: - **Unknown fields**\n53:   - Preserved in both proto2 and proto3 (binary format).\n54: - **Interop note**\n55:   - Proto2 and proto3 messages can interoperate across imports, but proto2 enums cannot be used directly in proto3 syntax.\n56: \n57: ## Safe schema evolution checklist\n58: \n59: - Never renumber existing fields.\n60: - Never reuse deleted field numbers.\n61: - Reserve removed field numbers and names using `reserved`.\n62: - Prefer additive changes: add new fields, do not mutate existing wire meaning.\n63: - Avoid `required` for new work.\n64: - Use `oneof` when exactly one field must be present.\n65: \n66: ## Protoc usage basics\n67: \n68: - Verify installation:\n69: \n70: ```bash\n71: protoc --version\n72: ```\n73: \n74: - General compile shape:\n75: \n76: ```bash\n77: protoc -I proto --<LANG>_out=gen/<lang> proto/path/to/file.proto\n78: ```\n79: \n80: - Validate schema and emit descriptor set (useful for CI checks):\n81: \n82: ```bash\n83: protoc -I proto --include_imports --descriptor_set_out=gen/schema.pb proto/path/to/file.proto\n84: ```\n85: \n86: ## Rust generation patterns\n87: \n88: Rust codegen is commonly done in `build.rs` wrappers that call `protoc` for you.\n89: \n90: - `prost-build` example (`build.rs`):\n91: \n92: ```rust\n93: fn main() -> std::io::Result<()> {\n94:     prost_build::compile_protos(&[\"proto/service.proto\"], &[\"proto\"])?;\n95:     Ok(())\n96: }\n97: ```\n98: \n99: - `tonic-prost-build` example (`build.rs`):\n100: \n101: ```rust\n102: fn main() {\n103:     tonic_prost_build::configure()\n104:         .compile_protos(&[\"proto/service.proto\"], &[\"proto\"])\n105:         .unwrap();\n106: }\n107: ```\n108: \n109: - `protobuf` crate ecosystem example (`build.rs`, from protobuf-example):\n110: \n111: ```rust\n112: use protobuf_codegen::CodeGen;\n113: \n114: fn main() {\n115:     CodeGen::new()\n116:         .inputs([\"proto_example/foo.proto\", \"proto_example/bar/bar.proto\"])\n117:         .include(\"proto\")\n118:         .dependency(protobuf_well_known_types::get_dependency(\"protobuf_well_known_types\"))\n119:         .generate_and_compile()\n120:         .unwrap();\n121: }\n122: ```\n123: \n124: ## TypeScript generation patterns\n125: \n126: TypeScript typically uses `protoc` plugins.\n127: \n128: - `ts-proto` quickstart:\n129: \n130: ```bash\n131: protoc \\\n132:   --plugin=./node_modules/.bin/protoc-gen-ts_proto \\\n133:   --ts_proto_out=gen/ts \\\n134:   --ts_proto_opt=esModuleInterop=true \\\n135:   -I proto \\\n136:   proto/path/to/file.proto\n137: ```\n138: \n139: - `@protobuf-ts/plugin` quickstart:\n140: \n141: ```bash\n142: npx protoc --ts_out gen/ts --proto_path proto proto/path/to/file.proto\n143: ```\n144: \n145: ## Agent defaults for new schema requests\n146: \n147: - Ask which syntax to use: `proto2` or `proto3`.\n148: - If unspecified, recommend `proto3` with explicit `optional` for scalar presence.\n149: - Ask which TypeScript generator to target: `ts-proto` or `@protobuf-ts/plugin`.\n150: - If unspecified, recommend `ts-proto` for idiomatic TS interfaces and flexible options.\n151: - Always call out features that are syntax-specific (for example `required`/extensions/default overrides in proto2).\n152: \n\n(End of file - total 152 lines)\n</content>",
            "title": "docs/readmes/protobuf-schema-research.md",
            "metadata": {
              "preview": "# Protobuf Schema Research Notes\n\nLast reviewed: 2026-02-15\n\n## Scope\n\n- Capture practical notes for authoring new `.proto` schemas.\n- Support both `proto2` and `proto3` workflows.\n- Document `protoc` usage for Rust and TypeScript generation paths.\n\n## Primary web sources\n\n- OpenCode skills docs: https://opencode.ai/docs/skills/\n- Protoc install docs: https://protobuf.dev/installation/\n- Proto2 guide: https://protobuf.dev/programming-guides/proto2/\n- Proto3 guide: https://protobuf.dev/programming-guides/proto3/\n- Field presence note: https://protobuf.dev/programming-guides/field_presence/\n- Rust generated code guide: https://protobuf.dev/reference/rust/rust-generated/\n- Rust build reference: https://protobuf.dev/reference/rust/building-rust-protos/\n- `prost-build` docs: https://docs.rs/prost-build/latest/prost_build/",
              "truncated": false,
              "loaded": []
            },
            "time": {
              "start": 1771213164120,
              "end": 1771213164126
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_00e918ad6c52f3c0016992916c0f1081959689cecbbe6b583c"
            }
          },
          "id": "prt_c64880e42001VtfqHs6uJv8cHE",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6487f3680010GhG8BR06BxlDi"
        },
        {
          "type": "tool",
          "callID": "call_K5syO95tLuXKKNC7cMvsh6y5",
          "tool": "read",
          "state": {
            "status": "completed",
            "input": {
              "filePath": "/Users/alex/repos/vfp/dark-factory/.opencode/skills/protobuf-schema-authoring/SKILL.md"
            },
            "output": "<path>/Users/alex/repos/vfp/dark-factory/.opencode/skills/protobuf-schema-authoring/SKILL.md</path>\n<type>file</type>\n<content>1: ---\n2: name: protobuf-schema-authoring\n3: description: Author proto2/proto3 schemas and provide protoc generation workflows for Rust and TypeScript.\n4: ---\n5: \n6: ## What I do\n7: \n8: - Turn user requirements into clear, evolvable `.proto` schemas.\n9: - Support both `proto2` and `proto3` syntax.\n10: - Ask for syntax preference when not explicitly provided, and explain version-specific constraints.\n11: - Provide practical `protoc` workflows for Rust and TypeScript.\n12: \n13: ## When to use me\n14: \n15: Use this when the task includes any of the following:\n16: \n17: - Create a new protobuf schema from product or API requirements.\n18: - Update an existing `.proto` safely.\n19: - Explain if a feature is `proto2`-only or `proto3`-only.\n20: - Generate Rust or TypeScript artifacts from `.proto` files.\n21: \n22: ## Required clarification flow\n23: \n24: If not already specified, ask these in order:\n25: \n26: 1. Which schema syntax should be used: `proto2` or `proto3`?\n27:    - Recommended default: `proto3` with explicit `optional` on scalar fields when presence matters.\n28: 2. For TypeScript generation, which plugin should be targeted: `ts-proto` or `@protobuf-ts/plugin`?\n29:    - Recommended default: `ts-proto`.\n30: \n31: When answering, always note version-specific features involved in the request.\n32: \n33: ## Proto2 vs proto3 guardrails\n34: \n35: - `required` fields are proto2-only and should be avoided for new design.\n36: - Explicit scalar defaults (`[default = ...]`) are proto2-only.\n37: - Extensions are proto2-oriented; not a general proto3 field pattern.\n38: - Groups are deprecated legacy proto2 and should not be introduced.\n39: - Proto3 enums must start with a zero-valued first entry.\n40: - Proto3 scalar presence should use `optional` when presence semantics are needed.\n41: - Repeated scalar numerics are packed-by-default in proto3; in proto2, use `[packed = true]` for new fields.\n42: \n43: ## Schema authoring workflow\n44: \n45: 1. Confirm syntax version and target language outputs.\n46: 2. Propose package and file layout.\n47: 3. Define messages/enums/services with stable field numbering.\n48: 4. Add comments only where semantics are non-obvious.\n49: 5. Reserve removed field numbers and names.\n50: 6. Validate with `protoc` descriptor output when possible.\n51: 7. Provide generation commands for Rust and TypeScript.\n52: \n53: ## Command templates\n54: \n55: - Validate schema and emit descriptor:\n56: \n57: ```bash\n58: protoc -I proto --include_imports --descriptor_set_out=gen/schema.pb proto/path/to/file.proto\n59: ```\n60: \n61: - Rust via `prost-build` (`build.rs`):\n62: \n63: ```rust\n64: fn main() -> std::io::Result<()> {\n65:     prost_build::compile_protos(&[\"proto/service.proto\"], &[\"proto\"])?;\n66:     Ok(())\n67: }\n68: ```\n69: \n70: - Rust via `tonic-prost-build` (`build.rs`):\n71: \n72: ```rust\n73: fn main() {\n74:     tonic_prost_build::configure()\n75:         .compile_protos(&[\"proto/service.proto\"], &[\"proto\"])\n76:         .unwrap();\n77: }\n78: ```\n79: \n80: - TypeScript via `ts-proto`:\n81: \n82: ```bash\n83: protoc \\\n84:   --plugin=./node_modules/.bin/protoc-gen-ts_proto \\\n85:   --ts_proto_out=gen/ts \\\n86:   --ts_proto_opt=esModuleInterop=true \\\n87:   -I proto \\\n88:   proto/path/to/file.proto\n89: ```\n90: \n91: - TypeScript via `@protobuf-ts/plugin`:\n92: \n93: ```bash\n94: npx protoc --ts_out gen/ts --proto_path proto proto/path/to/file.proto\n95: ```\n96: \n97: ## Output expectations\n98: \n99: - Deliver the requested `.proto` file(s) and a short note on compatibility choices.\n100: - Explicitly call out any use of proto2-only/proto3-only features.\n101: - Include exact generation commands for the selected Rust and TypeScript toolchains.\n102: \n\n(End of file - total 102 lines)\n</content>",
            "title": ".opencode/skills/protobuf-schema-authoring/SKILL.md",
            "metadata": {
              "preview": "---\nname: protobuf-schema-authoring\ndescription: Author proto2/proto3 schemas and provide protoc generation workflows for Rust and TypeScript.\n---\n\n## What I do\n\n- Turn user requirements into clear, evolvable `.proto` schemas.\n- Support both `proto2` and `proto3` syntax.\n- Ask for syntax preference when not explicitly provided, and explain version-specific constraints.\n- Provide practical `protoc` workflows for Rust and TypeScript.\n\n## When to use me\n\nUse this when the task includes any of the following:\n\n- Create a new protobuf schema from product or API requirements.\n- Update an existing `.proto` safely.\n- Explain if a feature is `proto2`-only or `proto3`-only.\n- Generate Rust or TypeScript artifacts from `.proto` files.",
              "truncated": false,
              "loaded": []
            },
            "time": {
              "start": 1771213164144,
              "end": 1771213164154
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_00e918ad6c52f3c0016992916c0f20819592fb98725ae5777d"
            }
          },
          "id": "prt_c64880e59001TUxj9Xlq5PT9e3",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6487f3680010GhG8BR06BxlDi"
        },
        {
          "type": "tool",
          "callID": "call_mrONi6jd8Du62SolVKInWKlY",
          "tool": "grep",
          "state": {
            "status": "completed",
            "input": {
              "pattern": "protobuf-schema-authoring",
              "path": "/Users/alex/repos/vfp/dark-factory/AGENTS.md"
            },
            "output": "Found 1 matches\n/Users/alex/repos/vfp/dark-factory/AGENTS.md:\n  Line 62: - `.opencode/skills/protobuf-schema-authoring/SKILL.md` documents how to author proto2/proto3 schemas and provide Rust/TypeScript codegen workflows.",
            "title": "protobuf-schema-authoring",
            "metadata": {
              "matches": 1,
              "truncated": false
            },
            "time": {
              "start": 1771213164147,
              "end": 1771213164162
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_00e918ad6c52f3c0016992916c0f2881958485115dd6526961"
            }
          },
          "id": "prt_c64880e71001ZL2YJso20lNVXX",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6487f3680010GhG8BR06BxlDi"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "6fcaf1d4f278d8c8334034c54e2c27d3628e959a",
          "cost": 0,
          "tokens": {
            "total": 114983,
            "input": 114826,
            "output": 157,
            "reasoning": 29,
            "cache": {
              "read": 0,
              "write": 0
            }
          },
          "id": "prt_c64880eb9001bwneYN7JTv8ucD",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c6487f3680010GhG8BR06BxlDi"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771213164273,
          "completed": 1771213171457
        },
        "parentID": "msg_c6484620d0011ltzji40BSbVp5",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 117984,
          "input": 2960,
          "output": 208,
          "reasoning": 57,
          "cache": {
            "read": 114816,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "tool-calls",
        "id": "msg_c64880ef1001Oj08ejT0Q6nWGg",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "6fcaf1d4f278d8c8334034c54e2c27d3628e959a",
          "id": "prt_c64881abc001CaNZ35zNTrshVd",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64880ef1001Oj08ejT0Q6nWGg"
        },
        {
          "type": "reasoning",
          "text": "**Assessing formatting and naming compliance**",
          "metadata": {
            "openai": {
              "itemId": "rs_066dce436f86370f016992916fac148196853554e3e9956987",
              "reasoningEncryptedContent": "gAAAAABpkpFxSRQzmiL7IKsu1YuNJtIy0529RbvktlNFXPl7vkkeIH0ZcUbxqqf1gZcLBFdvW2cJ8jGUhighawuTQqyiRC1DZQ82yt60sxlieqGE4g0zo7fhTkVLPX12mVs5oQojLuBgXY1a-Okw_hZYqKLGTglRuOxP3dr-YaxHGG4B4nnJVUdrzjYy6HkB1ZNVzUotQQSHU7K5ci02uouWUbyJTj-VY50onIdPQWRx0GZJZ9SfUHRVmv5dK_fZ0wtJDtnfN5laOLUVP6-LxcmtTcBVSkiDQtiuJhBqbjEWzDsg0pxS61GFGWFrwUCvLiB1FQsaKSrtBPoQMgxfWl_tGKdJ6r5h25x9pPzauoPnMwYoeRVSIhzQN3fSvsrqjpuyyFWHLY2JXtTnTUZiy25AFWZEZWQ1MYJmVGlVS8FIgAk2LesPx6-h73UbTAK_Ef3T7n9kshfdv6ayICvQPNgQBIBUuPRLjiG-Nsv8uozuV34b7Ed04kjgsza1Rfn9Bq5bsNtWkO52AIM9QaA6ug3sY7gxYCCnJedxZcMpnppyfrCwCosGFozgtnTmvz5ccfBH-xnzKJj3jWq7J49AtOtHDlud0kjFLwFVSajCueXwty9QeeRXGTuVlhW6ym30OJV1LDNjYuRpLJHNzrBYI4dNWMqYiWbBdb0LwgzqRvBkL5rQdepgztgtoTfUxmZw439GM9-n8J9BoQZQN3a9wQE_trIJas5E1GASoSxrt2fYa9VLxUZsLuGAuT1M9xLZCPJ_XkCokdksbEPlCHqJaFH-LFVhJSkDGdVku4slx_cd6NC_KfHAIs1yVBhXMf_p97J9ydUWKVJCZ_42LYbnp6ymtmezBkLyeS6t2CCzhspHT4U33aTxOK86A-L44IOkbNWaByYzsZwWtKNdlQA8wxewujbp2T9sdTL6DvKGDZR6-FaZoXm5wTt44hIKveGDQJpGdUutJ7I7ohhMDRGHYBc9RkUdvBOwRr_9CQkY9ZMnsxETdw2PLPwuLEAhJkzoo5PQNFNkpW3Pcvh1nm-eJgjSt6EqywcJT_s5lCTeUq44aBieJSP_0l8rurkEk34cBgFM51k8THC3qUO6D4oLcrF8PX_EtuYjCsacO-HqYGZZBNCBQbJENGBBmDfYzGsgJqbQ6E555BiAtu8W4VDdAom34a7hPowaPqnNqqqv8vALXC2XjzuNxeVH2Y7tWmyBaPruBlweHcTb"
            }
          },
          "time": {
            "start": 1771213167740,
            "end": 1771213169192
          },
          "id": "prt_c64881c7c001I03SLKI2yeFqLE",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64880ef1001Oj08ejT0Q6nWGg"
        },
        {
          "type": "tool",
          "callID": "call_HSaCii5o3uZOWbaGbM8XQtJk",
          "tool": "todowrite",
          "state": {
            "status": "completed",
            "input": {
              "todos": [
                {
                  "content": "Collect authoritative web references for proto2/proto3 differences and protoc usage",
                  "status": "completed",
                  "priority": "high"
                },
                {
                  "content": "Write research notes under docs/ covering schema design, v2/v3 differences, and Rust/TypeScript generation",
                  "status": "completed",
                  "priority": "high"
                },
                {
                  "content": "Create new OpenCode skill under .opencode/skills for protobuf schema authoring workflow",
                  "status": "completed",
                  "priority": "high"
                },
                {
                  "content": "Update AGENTS.md skill inventory to mention the new protobuf schema skill",
                  "status": "completed",
                  "priority": "medium"
                },
                {
                  "content": "Verify resulting files and summarize deliverables",
                  "status": "in_progress",
                  "priority": "medium"
                }
              ]
            },
            "output": "[\n  {\n    \"content\": \"Collect authoritative web references for proto2/proto3 differences and protoc usage\",\n    \"status\": \"completed\",\n    \"priority\": \"high\"\n  },\n  {\n    \"content\": \"Write research notes under docs/ covering schema design, v2/v3 differences, and Rust/TypeScript generation\",\n    \"status\": \"completed\",\n    \"priority\": \"high\"\n  },\n  {\n    \"content\": \"Create new OpenCode skill under .opencode/skills for protobuf schema authoring workflow\",\n    \"status\": \"completed\",\n    \"priority\": \"high\"\n  },\n  {\n    \"content\": \"Update AGENTS.md skill inventory to mention the new protobuf schema skill\",\n    \"status\": \"completed\",\n    \"priority\": \"medium\"\n  },\n  {\n    \"content\": \"Verify resulting files and summarize deliverables\",\n    \"status\": \"in_progress\",\n    \"priority\": \"medium\"\n  }\n]",
            "title": "1 todos",
            "metadata": {
              "todos": [
                {
                  "content": "Collect authoritative web references for proto2/proto3 differences and protoc usage",
                  "status": "completed",
                  "priority": "high"
                },
                {
                  "content": "Write research notes under docs/ covering schema design, v2/v3 differences, and Rust/TypeScript generation",
                  "status": "completed",
                  "priority": "high"
                },
                {
                  "content": "Create new OpenCode skill under .opencode/skills for protobuf schema authoring workflow",
                  "status": "completed",
                  "priority": "high"
                },
                {
                  "content": "Update AGENTS.md skill inventory to mention the new protobuf schema skill",
                  "status": "completed",
                  "priority": "medium"
                },
                {
                  "content": "Verify resulting files and summarize deliverables",
                  "status": "in_progress",
                  "priority": "medium"
                }
              ],
              "truncated": false
            },
            "time": {
              "start": 1771213171361,
              "end": 1771213171362
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_066dce436f86370f01699291711a9881968310b9e9c9b8262d"
            }
          },
          "id": "prt_c64882229001EM9DnxRZSUK47X",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64880ef1001Oj08ejT0Q6nWGg"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "6fcaf1d4f278d8c8334034c54e2c27d3628e959a",
          "cost": 0,
          "tokens": {
            "total": 117984,
            "input": 2960,
            "output": 208,
            "reasoning": 57,
            "cache": {
              "read": 114816,
              "write": 0
            }
          },
          "id": "prt_c64882acf0010bxZn0OBUHcPwV",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64880ef1001Oj08ejT0Q6nWGg"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771213171462,
          "completed": 1771213175298
        },
        "parentID": "msg_c6484620d0011ltzji40BSbVp5",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 118256,
          "input": 305,
          "output": 63,
          "reasoning": 33,
          "cache": {
            "read": 117888,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "tool-calls",
        "id": "msg_c64882b06001M5ufxG6PkjGNxh",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "6fcaf1d4f278d8c8334034c54e2c27d3628e959a",
          "id": "prt_c6488334c001IuyEi60WRbbeO7",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64882b06001M5ufxG6PkjGNxh"
        },
        {
          "type": "reasoning",
          "text": "**Verifying uncommitted changes**",
          "metadata": {
            "openai": {
              "itemId": "rs_01b84db2b2f92e2c0169929176214c8193822e218216bb6936",
              "reasoningEncryptedContent": "gAAAAABpkpF3pZ0ax6sVZvquwkLs9pvGdEiU82Gb7hvrHXieSshIN74RuOl8A6Md-lFfxhBRkLvR6lGQiu6vN6mskHEe4v_7Hkf99EurOXvhFYQ-0d56nFzUEkgqAvz7Kk-bpqmvYzpEaRC28zmIP2Lis_XtdE8Lpm_p69c2kNKZodHu76wYpqBXIDASP6fkjL7pI-ILpOUHy_j_IKKrvYFE6supO0j2r-l1uWscxEf01kP0ZyV2d2vLaJsHFUjPDPUB7L0Kg85r3LGEW8DZ2aov_WjVyIHNrOpBYGPqJD1BYqRqAmk0N8BVo7nNrG1sDTfBj8sGDOP2Fd1NQewIJaEZeAuB17BmjmTN-DoqquNBr8_aZTg-AxwJ_nVuRAr8LGCWr7cw2bdH3o6hYFazlgthdFuK2rcOy38cvBBfoOyFTWv0FIskeQJO7ybaMFK63et2KMCC466FpG-akbppY_mm608x1EqGZ56cE5styfox7YPQS6E_r3Rcs4khzKkUrxujAipFihfMJptuZiUJr7HSYAuzSH3wE6aZ6Pkv0J7eVzAq8WEQxfF-2DBm1vMz07LwH_RWm0mCWIu0UbkWEPnPj91gYYew0KNiF2j8XxIvztadydN4vqjK0JACSLj6ZOquEM-xxv9yaabUWwlEKlrsm8vueSTqm2CI2NQBlk-I7zLLW9pu3_uWeWIjCiCeuThMZ1n2fs8ITVk4LixUNwNIeXOJlKc3JAHLJvo-BofkcksnNSimgG0pOiiM-5HoLmqFkV-4s4hDV0j3DrVGhvlPE07aGKTbHsV5Y4i6Fi7rZqZsL2s0jcWAlohKR_7lLOek_dl7A7pv9T6tf2omRybR_GSCkDWRwJVFKs91bz5YE8gBs0vxGIwEmshALWMbNNfo16Ly95KFuCrfk34qCc-TbWpzgj04qZ01c5lVjMU6kG89nttsjYMmMV8AkHXJ9nqe0P-D1Y8jrkgK5lqA8-fGuUARgBgOg8pLKH0ZiFUG23vGfv494rTP_JHDGciK6HtY_g23vFhF"
            }
          },
          "time": {
            "start": 1771213174160,
            "end": 1771213175040
          },
          "id": "prt_c64883590001JX50RmBTcsfkv5",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64882b06001M5ufxG6PkjGNxh"
        },
        {
          "type": "tool",
          "callID": "call_qWz3sTxkPfTKp3IFWVhXV1Uk",
          "tool": "bash",
          "state": {
            "status": "completed",
            "input": {
              "command": "git status --short",
              "description": "Show changed files summary"
            },
            "output": " M AGENTS.md\n M README.md\n M docs/designs/core_gen1.design.md\n?? .opencode/skills/protobuf-schema-authoring/\n?? docs/external/\n?? docs/readmes/protobuf-schema-research.md\n?? scripts/scrape_moon_docs.sh.ts\n",
            "title": "Show changed files summary",
            "metadata": {
              "output": " M AGENTS.md\n M README.md\n M docs/designs/core_gen1.design.md\n?? .opencode/skills/protobuf-schema-authoring/\n?? docs/external/\n?? docs/readmes/protobuf-schema-research.md\n?? scripts/scrape_moon_docs.sh.ts\n",
              "exit": 0,
              "description": "Show changed files summary",
              "truncated": false
            },
            "time": {
              "start": 1771213175194,
              "end": 1771213175228
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_01b84db2b2f92e2c0169929177014881938e1a6c60f4eff59b"
            }
          },
          "id": "prt_c64883902001I9WpzV2jtQ6WXh",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64882b06001M5ufxG6PkjGNxh"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "6fcaf1d4f278d8c8334034c54e2c27d3628e959a",
          "cost": 0,
          "tokens": {
            "total": 118256,
            "input": 305,
            "output": 63,
            "reasoning": 33,
            "cache": {
              "read": 117888,
              "write": 0
            }
          },
          "id": "prt_c648839cb001WnPeEVxKs67ILT",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64882b06001M5ufxG6PkjGNxh"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771213175303,
          "completed": 1771213181472
        },
        "parentID": "msg_c6484620d0011ltzji40BSbVp5",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 118559,
          "input": 181,
          "output": 234,
          "reasoning": 84,
          "cache": {
            "read": 118144,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "tool-calls",
        "id": "msg_c64883a07001u4gp4DqyygeRQh",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "6fcaf1d4f278d8c8334034c54e2c27d3628e959a",
          "id": "prt_c64884109001nQvFp1W1CTKbMK",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64883a07001u4gp4DqyygeRQh"
        },
        {
          "type": "reasoning",
          "text": "**Preparing final change summary**",
          "metadata": {
            "openai": {
              "itemId": "rs_04659241e3eccf7c0169929179a0cc8190a41e0227a8d51e59",
              "reasoningEncryptedContent": "gAAAAABpkpF7jqq3OJEcULzFg-ywAkzIUONTFGZ5OBX9-MxRMfikGAx6BDGW0Jp_9qCgQ7xADhmsnYzlPPluVhBWbAhnSXnay5C3BvLxJAypP6WRei8WSOW6CvbxKD6vkcz_xM_XkDNcL39YU99QaJFov5vCpp3mumJfkRN7JVcNJ6jsg3EezfKcKR_26Hf1aNq-0tmvbyKjKfl_o1ltBgp3RBAywlTUOM3kXVcn1abxxrjYTMzO6_3Oc2A5ieS64tn4xlaoCptjQ-yOA8c8m5rZd6b6HmVbZQeyJYHL73Bwk8R3xmwVPXDgO8YXxkrMON3o2nR94ZYvfguS_fRGfso9nKtzsdlu-IqdjgOy9bhUWszAiy08ep0O-PMNizpUpMvp5ehXSbMDGaxVJQyvSqx8f9K7-MIB629e9nESO7_WhiSYVb6RiBmZHBg1GjcDGg5JCUpUEH6Za_5IcJsWBK4iOaLiSRa9BLKjoMq0JfkC_3COtUGwmtStFiJc6yOYVfIzOv3FZWw8-4nfPWX6uFOVZ2WW-yBeHZFiLanrdtEPrM_kXBtuaketFzfOsfkXEuHb7MwqmTIktWJmCvQ_FJYoQHK0eceDtCmvtPifCxZ3wkfXbj7pWyhMNxiIiyxI2rK_6DXrDXJg3D23t0GFrtWy7iT4ZjhbeDhjJT859vZbULtd1DRMppgeVbepc_HHnPBl1auU9UJCo-JbTjoCOQdFIgVS3c5hdjYlWUU1kA6sOQveFFpXPdtSjP9C1kHL5NtSaZLIvzvoAkTOcA_oUbrNyRdr7mvnys0U8v17VhZptqeTXj_ftX5sbhtS3M3d1ulJdQcXbeYk8T41XvQ9aBMJC7OwnkPdVKq6L8vjM9I5SJqvJCMC-euEieBm7FFYJT8lcfMZ7fxUoA4S7Pgjb1wGdheczWLth0LLdeKH4sd2XxPDCZxaUR78Ka7fwX2iM19QfdDLbqc65eKCgYL1ApjseOYoq_mjt855-EOx8CUPbgMuXTSmtRu-5fNIRDelE_D9HCSgN0RFGexYJyZfUNS_HoXH8cDeX-DG9oAAUJJMWtjQ24D6SgF-pmSP6dmSHo0b0IHqC4UMvCSr4SGpqdQxBtUaG4hjgnOC6UYnQIoqygbC5JlozzfvCPhk9RRaKzIVQx6wkH9RFkFSlUo7gyfSJCzX_eZ5LzhzfHSXpSAH67Jmk7GswkSnZdnqPesveh3jg7GwFRPArfhCg_3iUteBnCHCBma3Ooo1Gh3DYa_jvnyRiIGlaX47j9k8VkXpeqxqR_My7-ut8nfIMK38IaSOhbLEtmT_uNtJ5S-CBrtOaCSFM-KrI2z15MBMTMpBfvUH67BbJTrvCROCQxyW3D1ShLcwLJXxgPdpEhW1WMQWNHk1CVP3njQ="
            }
          },
          "time": {
            "start": 1771213177656,
            "end": 1771213179528
          },
          "id": "prt_c64884338001oLVXJfUebU0QAt",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64883a07001u4gp4DqyygeRQh"
        },
        {
          "type": "tool",
          "callID": "call_oct8HRNnr0bUGm8QmVMsMR1N",
          "tool": "todowrite",
          "state": {
            "status": "completed",
            "input": {
              "todos": [
                {
                  "content": "Collect authoritative web references for proto2/proto3 differences and protoc usage",
                  "status": "completed",
                  "priority": "high"
                },
                {
                  "content": "Write research notes under docs/ covering schema design, v2/v3 differences, and Rust/TypeScript generation",
                  "status": "completed",
                  "priority": "high"
                },
                {
                  "content": "Create new OpenCode skill under .opencode/skills for protobuf schema authoring workflow",
                  "status": "completed",
                  "priority": "high"
                },
                {
                  "content": "Update AGENTS.md skill inventory to mention the new protobuf schema skill",
                  "status": "completed",
                  "priority": "medium"
                },
                {
                  "content": "Verify resulting files and summarize deliverables",
                  "status": "completed",
                  "priority": "medium"
                }
              ]
            },
            "output": "[\n  {\n    \"content\": \"Collect authoritative web references for proto2/proto3 differences and protoc usage\",\n    \"status\": \"completed\",\n    \"priority\": \"high\"\n  },\n  {\n    \"content\": \"Write research notes under docs/ covering schema design, v2/v3 differences, and Rust/TypeScript generation\",\n    \"status\": \"completed\",\n    \"priority\": \"high\"\n  },\n  {\n    \"content\": \"Create new OpenCode skill under .opencode/skills for protobuf schema authoring workflow\",\n    \"status\": \"completed\",\n    \"priority\": \"high\"\n  },\n  {\n    \"content\": \"Update AGENTS.md skill inventory to mention the new protobuf schema skill\",\n    \"status\": \"completed\",\n    \"priority\": \"medium\"\n  },\n  {\n    \"content\": \"Verify resulting files and summarize deliverables\",\n    \"status\": \"completed\",\n    \"priority\": \"medium\"\n  }\n]",
            "title": "0 todos",
            "metadata": {
              "todos": [
                {
                  "content": "Collect authoritative web references for proto2/proto3 differences and protoc usage",
                  "status": "completed",
                  "priority": "high"
                },
                {
                  "content": "Write research notes under docs/ covering schema design, v2/v3 differences, and Rust/TypeScript generation",
                  "status": "completed",
                  "priority": "high"
                },
                {
                  "content": "Create new OpenCode skill under .opencode/skills for protobuf schema authoring workflow",
                  "status": "completed",
                  "priority": "high"
                },
                {
                  "content": "Update AGENTS.md skill inventory to mention the new protobuf schema skill",
                  "status": "completed",
                  "priority": "medium"
                },
                {
                  "content": "Verify resulting files and summarize deliverables",
                  "status": "completed",
                  "priority": "medium"
                }
              ],
              "truncated": false
            },
            "time": {
              "start": 1771213181343,
              "end": 1771213181344
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_04659241e3eccf7c016992917b7df0819097c29e95e6acfc5c"
            }
          },
          "id": "prt_c64884a89001eZ2c5bgTA2ja5M",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64883a07001u4gp4DqyygeRQh"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "b27d262025dbd7289f908de3b5847cc280e1a2b5",
          "cost": 0,
          "tokens": {
            "total": 118559,
            "input": 181,
            "output": 234,
            "reasoning": 84,
            "cache": {
              "read": 118144,
              "write": 0
            }
          },
          "id": "prt_c648851d30016d8slLXR6a0EhI",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64883a07001u4gp4DqyygeRQh"
        },
        {
          "type": "patch",
          "hash": "6fcaf1d4f278d8c8334034c54e2c27d3628e959a",
          "files": [
            "/Users/alex/repos/vfp/dark-factory/docs/designs/core_gen1.design.md"
          ],
          "id": "prt_c6488521b001nvfVVdSaOLw7Y1",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64883a07001u4gp4DqyygeRQh"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771213181477,
          "completed": 1771213195463
        },
        "parentID": "msg_c6484620d0011ltzji40BSbVp5",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 119438,
          "input": 367,
          "output": 671,
          "reasoning": 342,
          "cache": {
            "read": 118400,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "stop",
        "id": "msg_c64885225001SooY2cNazdtLMS",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "b27d262025dbd7289f908de3b5847cc280e1a2b5",
          "id": "prt_c64885ba1001qDPWBXw5QRSOOA",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64885225001SooY2cNazdtLMS"
        },
        {
          "type": "reasoning",
          "text": "**Done**\n\n- Researched official protobuf documentation and documented findings in `docs/readmes/protobuf-schema-research.md`.  \n- Created a new skill for protobuf schema authoring with an interactive clarification flow in `.opencode/skills/protobuf-schema-authoring/SKILL.md`.  \n- Updated the AGENTS index to register the new skill (`AGENTS.md` around line 62).  \n- The skill includes user prompt handling to ask clarifying questions and note differences in input.  \n- The current worktree also contains unrelated, pre-existing modifications not touched by this update.  \n- Next steps: load the new skill and test with sample requests; optionally commit changes via the usual workflow.  \n\nNo tests were added, as this change is primarily documentation and skill authoring.",
          "metadata": {
            "openai": {
              "itemId": "rs_0384b1ba82b064e301699291806994819785487301d3cd2a45",
              "reasoningEncryptedContent": "gAAAAABpkpGHbfzGPc1Laduav8qwvrLqP2ocMGVCazhfR2G4U2nOHi57oHDjn0zCBoftIMPINjZQtD4PKcNRYvV10ivJszn-QdTqUl8YIg30A3Z4swZ8vF8Er2njMXnmOK_9kBbS-YkREWcyWqiHha9PefF4UqOyuDQXDNEGFuXrpNHTGXbArtNPeEfF2eKDYZuy_abNdASN7rzlhr7EZGY-ujjUnOOXVZpTgWt7SGaNcyRIzY4mkZDwAC7DiuK79zCa6zHCc5JQf2ZhQerj-F-r97dED9XbgvuPRfC6Va817G-wZQ_MEE_bgQn9U_C5TuX_NsgALnSkKzgWh-guzITmDdW-0is-q5kgB7L8mIWZutqaQ6oNMhaUSgy3q3C17A3b--cVdQkFq35N8sjzsjlsteMQMqecbpiJtTMFGNaM0QT-fx-5rumTIVl27_R4sxFUziWvFBydbe-EYvcTDqzTk1yfdUw9g33y8TaHk357PCJY_yQfnHBCDbZdPfx2bBT-0qA4pZoAHaqgvg5arY8qbmFasTj9CwQw5bHpOQe8zVw43_MPBOuiO-ie-5TU2b5X44koaoAtiAfJ6c2Wb6aH4nyZCFYed-Vg6-iTsO3qI0KfpmH7Q-En620pMvsdNWNIWjeE80h6Q83NM4bK3eqyLDN_qBFZrcFY_AP-7KEbTgbWi4GUnB26XyttsnqN-YT2b5lWDUo68eQgCC3ObjcsC_yJvvukFIHJSZiQtX-4R9JN_Rtnl1LmxLvCm7ww6E2Fa3mKVxfR07XTU9G8uaemVE7RKvBO2lunFmuo_Z-qMYAp_HBpLLFX8Gm3iscsdmhCbT4aPq9lqieRQaLtZx86EH8q17TocchxNmTM-lgCGRQDjNCq47Akb_t0Bmt_8Til_qIpflqtQ8QgJBPhrP7hzFP0pTl41J9etmMH4XCF802dEGIUzPsJptDROqAvedNJqL3stNdCVSmVOnDeK4ESRRs7mAJZIXUViPT3km5xmVrOtorusG2k5CJb5IjVolJ6zNvTp8FfB6Qcwqo_Q3-P2bCKbrQubGEJc9180thnN3-Vjao9vBEtwlkS2Z286c0Qol1fqOAo7wzd0RTi5f96yilquUzD4Cit_zazaQ77Wnw0cX35gbn5MEObLDWQvEJJyQhytvqqA7rzExMHQCLUOm2YrNmekh3mx7mHQkLYcrJ8jn8iYSzB5hZKuX_C-BsKl1_r7LmjvgW_xwphvLy_PLK4LBFcTy_sKrxIbgQkdh5U5VpjVVfpD8cNsqEmCXqgQ6mNo7H-SPsgyw1piCH8EsPBpWVgUUGqQM12BPPObRp_DQ_DOHCA7ykoBLpQfbBh92NWjPLLRw2ZU3sdsJg1NyFlh8BL-5oK_uUaSO9Az7fOQwJnyCCN9XH_3NZ0HOBIbv1FIBDHpJ_JF9pe59q4swH02AnfJgUkcACbYXJtcnh8AMU06gYaW8_IwqcIoYI5yAeZ2boiFXIH_WXtgzHchb6tvfE06VDbmBKKO-d_xpqSRk4eRFJKvRNBIqr0MgaaeHbf3LOYb9SNdUWwb3FVEFiZXFYVy5-mXX_0-dUnaSu1C_7yoHCWNxJ_ncMCAfi-JEcauLaTMokzHP8gpfv0Ys1vHAFtcL1kgUKZEaFbe3wrrdm2WMsmdWt4mfFapiL3Q2XVVNr3nyqXu8rwWqzlpLhFPCxj5gSf3wC42SXUghiEpZfPThUrTtyfWcEHQYS6ycu4oSpvErHbGrrQmdyK0CvZX3Nt2doNNlBVdMCr57Idd1A7GMlJAW4rBPP3ZuxOwowlSbowzjuahvWwFP5EMbR9Gf4oNWcc2uulkRQNswge2GSwrPmuBuMo5iw10RoKSGZ1JL0L2rOTESB1BEtRHCf41pOZaZneDs7ff8v0lssy-NqN9UWjPgqwgfsBfeJ8sTYhd6mrVkdATk6O3j4ZZuVOSEyCM-0fm2UbhPSux9xbxlG1cUcbVX5LpK-VRLOoCLiWR_CkLiSxvu_1wYxvfVDRcAulF58tZlupDudyMhtbrFs_EWJqNC_2W9HNzdlyI3njP4pGzgF2wKBR2zGyGg_sgSdGcBcfp0f9i-nFgpywGBtcM9OrESXK0OjQf9ckFTzPeH6kg1AsjeaoCf_W-57m_fQULr5m8BwrjOUV31GKSZ7y4knpZWCcT3uh1uPl9WkLKG22vN6qmNAjMo9Grd65pfTuOtRiBE53X1zaezW8MIPzIRwAAQT8wqyrbSna15pMhFP1v3hciG4lmM7_VesdA5aiivyrYWyCwLbZtiCqBUAatndNrmFCF9yLo3Fi3dH1kDx9GkWr3zSb8joweXzIBjAiF7v9FZ4906e1eYVPqE4R9U3_wpy4YK_FbuKrEqkiAxJHO9mP0GjyiYnKZv09e2fEAmDc0CMriSfbay7UZxd3FNkIucWtTTSlpzttEYnoiLEv7VyAJlIINJyH4eqWyoJXkR6Vo12FG9dQFwhbmkG2xkoZVFXI9U1cVniYm2hGH5LXMqSdlKVFfyZUNB56UZXl2MneGJVeH-u9mk5HV3oKVVKNikjgArYtgMOOCEmZ2AekwATZSMZFP8ZW2F-Rm6KYN2pVsfCEWs682Wa_LyMDlXsVhmecQeqFFhtaQJ26hmBuvz7fdj9keDRcn6ilSgl0r5Xpqtj8ksLDQYcdKLKrEjp-DN1A4D3NBlDxW-EwIW4lmht15jIjq_tC0695x3tq02PURHVQPTay7KU-99lT2rDE_wdNvmeaDwZIeLc2BnPSmaFtWdvSJDz_FzMEUTlm_ypo68CILSbf9ZtwFPcpaPQe6ZXjExZyC6jlVr1bcf44D7lG7ApHlLfOnYdLxxIFVC-jOM6640LLPERZEa6rUfpV8I9kbGv7qwZIE6c6aOMl2b1fLZDNmZGSPrM1l1NfwXo9z2hGIWLfNQbHiiJ8YaRSEqTa6f_pAjEZa285W_grSZSOtnVNwacMso9U2hqe6-Kdu4UrMLjG9GzWdQyYZr7SEE-6zpiVwDub9mY4kSnYbYFKHmmzkESFIPtA0GO_fhmRWdYFvCQV-JiQHROd020IkChsro3cmM51XjfH8kIlw81zkprG6MZNryxYLG2ywJZxg2d6_12IMkU7a-UbRn3vY24UOBdMknOpwie7LV0riefq041As3pvv6DYuaKvLg=="
            }
          },
          "time": {
            "start": 1771213184449,
            "end": 1771213191980
          },
          "id": "prt_c64885dc1001U9flXOv0F0D3Wn",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64885225001SooY2cNazdtLMS"
        },
        {
          "type": "text",
          "text": "Implemented. I researched the web sources and added both the notes and a reusable OpenCode skill for protobuf schema authoring.\n\n- Added research notes at `docs/readmes/protobuf-schema-research.md` with:\n  - proto2 vs proto3 differences (including version-specific features)\n  - schema evolution guardrails\n  - `protoc` usage patterns\n  - Rust (`prost-build`, `tonic-prost-build`, `protobuf_codegen`) and TypeScript (`ts-proto`, `@protobuf-ts/plugin`) generation workflows\n  - source links used for the research\n- Added new skill at `.opencode/skills/protobuf-schema-authoring/SKILL.md` that:\n  - supports both proto2/proto3\n  - explicitly asks which syntax to use if unspecified (with recommended default)\n  - asks which TS plugin to target if unspecified\n  - calls out proto2-only/proto3-only constraints\n  - provides command templates for validation and codegen\n- Updated skill inventory in `AGENTS.md:62` to include the new skill.\n\nNote on workspace state:\n- Your repo already has other unrelated uncommitted changes (`README.md`, `docs/designs/core_gen1.design.md`, `docs/external/`, `scripts/scrape_moon_docs.sh.ts`, etc.). I did not modify/revert those.\n\nIf you want, I can next:\n1. Run a quick dry-run by loading `protobuf-schema-authoring` and testing it against a sample schema request.\n2. Group and commit just these protobuf-note/skill changes via `@gitter`.",
          "time": {
            "start": 1771213195289,
            "end": 1771213195289
          },
          "metadata": {
            "openai": {
              "itemId": "msg_0384b1ba82b064e30169929187f000819798dd1a9476ab8b12"
            }
          },
          "id": "prt_c64887b2f001LpFeFub6jvnLVA",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64885225001SooY2cNazdtLMS"
        },
        {
          "type": "step-finish",
          "reason": "stop",
          "snapshot": "93097f6348eb49e9b1effa606e598f8c03077fee",
          "cost": 0,
          "tokens": {
            "total": 119438,
            "input": 367,
            "output": 671,
            "reasoning": 342,
            "cache": {
              "read": 118400,
              "write": 0
            }
          },
          "id": "prt_c64888891001zQfVLI9KKnXOUB",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64885225001SooY2cNazdtLMS"
        },
        {
          "type": "patch",
          "hash": "b27d262025dbd7289f908de3b5847cc280e1a2b5",
          "files": [
            "/Users/alex/repos/vfp/dark-factory/docs/designs/core_gen1.design.md"
          ],
          "id": "prt_c648888bf001zbO3WKxGtQC77k",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c64885225001SooY2cNazdtLMS"
        }
      ]
    },
    {
      "info": {
        "role": "user",
        "time": {
          "created": 1771213421936
        },
        "summary": {
          "title": "Protobuf schemas and boilerplate for skill addition",
          "diffs": [
            {
              "file": ".opencode/skills/protobuf-schema-authoring/SKILL.md",
              "before": "---\nname: protobuf-schema-authoring\ndescription: Author proto2/proto3 schemas and provide protoc generation workflows for Rust and TypeScript.\n---\n\n## What I do\n\n- Turn user requirements into clear, evolvable `.proto` schemas.\n- Support both `proto2` and `proto3` syntax.\n- Ask for syntax preference when not explicitly provided, and explain version-specific constraints.\n- Provide practical `protoc` workflows for Rust and TypeScript.\n\n## When to use me\n\nUse this when the task includes any of the following:\n\n- Create a new protobuf schema from product or API requirements.\n- Update an existing `.proto` safely.\n- Explain if a feature is `proto2`-only or `proto3`-only.\n- Generate Rust or TypeScript artifacts from `.proto` files.\n\n## Required clarification flow\n\nIf not already specified, ask these in order:\n\n1. Which schema syntax should be used: `proto2` or `proto3`?\n   - Recommended default: `proto3` with explicit `optional` on scalar fields when presence matters.\n2. For TypeScript generation, which plugin should be targeted: `ts-proto` or `@protobuf-ts/plugin`?\n   - Recommended default: `ts-proto`.\n\nWhen answering, always note version-specific features involved in the request.\n\n## Proto2 vs proto3 guardrails\n\n- `required` fields are proto2-only and should be avoided for new design.\n- Explicit scalar defaults (`[default = ...]`) are proto2-only.\n- Extensions are proto2-oriented; not a general proto3 field pattern.\n- Groups are deprecated legacy proto2 and should not be introduced.\n- Proto3 enums must start with a zero-valued first entry.\n- Proto3 scalar presence should use `optional` when presence semantics are needed.\n- Repeated scalar numerics are packed-by-default in proto3; in proto2, use `[packed = true]` for new fields.\n\n## Schema authoring workflow\n\n1. Confirm syntax version and target language outputs.\n2. Propose package and file layout.\n3. Define messages/enums/services with stable field numbering.\n4. Add comments only where semantics are non-obvious.\n5. Reserve removed field numbers and names.\n6. Validate with `protoc` descriptor output when possible.\n7. Provide generation commands for Rust and TypeScript.\n\n## Command templates\n\n- Validate schema and emit descriptor:\n\n```bash\nprotoc -I proto --include_imports --descriptor_set_out=gen/schema.pb proto/path/to/file.proto\n```\n\n- Rust via `prost-build` (`build.rs`):\n\n```rust\nfn main() -> std::io::Result<()> {\n    prost_build::compile_protos(&[\"proto/service.proto\"], &[\"proto\"])?;\n    Ok(())\n}\n```\n\n- Rust via `tonic-prost-build` (`build.rs`):\n\n```rust\nfn main() {\n    tonic_prost_build::configure()\n        .compile_protos(&[\"proto/service.proto\"], &[\"proto\"])\n        .unwrap();\n}\n```\n\n- TypeScript via `ts-proto`:\n\n```bash\nprotoc \\\n  --plugin=./node_modules/.bin/protoc-gen-ts_proto \\\n  --ts_proto_out=gen/ts \\\n  --ts_proto_opt=esModuleInterop=true \\\n  -I proto \\\n  proto/path/to/file.proto\n```\n\n- TypeScript via `@protobuf-ts/plugin`:\n\n```bash\nnpx protoc --ts_out gen/ts --proto_path proto proto/path/to/file.proto\n```\n\n## Output expectations\n\n- Deliver the requested `.proto` file(s) and a short note on compatibility choices.\n- Explicitly call out any use of proto2-only/proto3-only features.\n- Include exact generation commands for the selected Rust and TypeScript toolchains.\n",
              "after": "---\nname: protobuf-schema-authoring\ndescription: Author proto2/proto3 schemas and provide protoc generation workflows for Rust and TypeScript.\n---\n\n## What I do\n\n- Turn user requirements into clear, evolvable `.proto` schemas.\n- Support both `proto2` and `proto3` syntax.\n- Ask for syntax preference when not explicitly provided, and explain version-specific constraints.\n- Provide practical `protoc` workflows for Rust and TypeScript.\n- Use the full type/layout reference in `docs/readmes/protobuf-schema-research.md`.\n\n## When to use me\n\nUse this when the task includes any of the following:\n\n- Create a new protobuf schema from product or API requirements.\n- Update an existing `.proto` safely.\n- Explain if a feature is `proto2`-only or `proto3`-only.\n- Generate Rust or TypeScript artifacts from `.proto` files.\n\n## Required clarification flow\n\nIf not already specified, ask these in order:\n\n1. Which schema syntax should be used: `proto2` or `proto3`?\n   - Recommended default: `proto3` with explicit `optional` on scalar fields when presence matters.\n2. For TypeScript generation, which plugin should be targeted: `ts-proto` or `@protobuf-ts/plugin`?\n   - Recommended default: `ts-proto`.\n\nWhen answering, always note version-specific features involved in the request.\n\n## Proto2 vs proto3 guardrails\n\n- `required` fields are proto2-only and should be avoided for new design.\n- Explicit scalar defaults (`[default = ...]`) are proto2-only.\n- Extensions are proto2-oriented; not a general proto3 field pattern.\n- Groups are deprecated legacy proto2 and should not be introduced.\n- Proto3 enums must start with a zero-valued first entry.\n- Proto3 scalar presence should use `optional` when presence semantics are needed.\n- Repeated scalar numerics are packed-by-default in proto3; in proto2, use `[packed = true]` for new fields.\n\n## Complete reference location\n\nUse `docs/readmes/protobuf-schema-research.md` as the canonical in-repo reference for:\n\n- Complete valid scalar type list and non-scalar type forms.\n- Full schema definition layout (top-level, message, enum, service).\n- Proto2 and proto3 boilerplate templates.\n- Wire constraints and field numbering guardrails.\n\nWhen drafting schemas, follow that reference and include only the subset needed for the user request.\n\n## Schema authoring workflow\n\n1. Confirm syntax version and target language outputs.\n2. Propose package and file layout.\n3. Define messages/enums/services with stable field numbering.\n4. Add comments only where semantics are non-obvious.\n5. Reserve removed field numbers and names.\n6. Validate with `protoc` descriptor output when possible.\n7. Provide generation commands for Rust and TypeScript.\n\n## Command templates\n\n- Validate schema and emit descriptor:\n\n```bash\nprotoc -I proto --include_imports --descriptor_set_out=gen/schema.pb proto/path/to/file.proto\n```\n\n- Rust via `prost-build` (`build.rs`):\n\n```rust\nfn main() -> std::io::Result<()> {\n    prost_build::compile_protos(&[\"proto/service.proto\"], &[\"proto\"])?;\n    Ok(())\n}\n```\n\n- Rust via `tonic-prost-build` (`build.rs`):\n\n```rust\nfn main() {\n    tonic_prost_build::configure()\n        .compile_protos(&[\"proto/service.proto\"], &[\"proto\"])\n        .unwrap();\n}\n```\n\n- TypeScript via `ts-proto`:\n\n```bash\nprotoc \\\n  --plugin=./node_modules/.bin/protoc-gen-ts_proto \\\n  --ts_proto_out=gen/ts \\\n  --ts_proto_opt=esModuleInterop=true \\\n  -I proto \\\n  proto/path/to/file.proto\n```\n\n- TypeScript via `@protobuf-ts/plugin`:\n\n```bash\nnpx protoc --ts_out gen/ts --proto_path proto proto/path/to/file.proto\n```\n\n## Output expectations\n\n- Deliver the requested `.proto` file(s) and a short note on compatibility choices.\n- Explicitly call out any use of proto2-only/proto3-only features.\n- Include exact generation commands for the selected Rust and TypeScript toolchains.\n",
              "additions": 12,
              "deletions": 0,
              "status": "modified"
            },
            {
              "file": "docs/readmes/protobuf-schema-research.md",
              "before": "# Protobuf Schema Research Notes\n\nLast reviewed: 2026-02-15\n\n## Scope\n\n- Capture practical notes for authoring new `.proto` schemas.\n- Support both `proto2` and `proto3` workflows.\n- Document `protoc` usage for Rust and TypeScript generation paths.\n\n## Primary web sources\n\n- OpenCode skills docs: https://opencode.ai/docs/skills/\n- Protoc install docs: https://protobuf.dev/installation/\n- Proto2 guide: https://protobuf.dev/programming-guides/proto2/\n- Proto3 guide: https://protobuf.dev/programming-guides/proto3/\n- Field presence note: https://protobuf.dev/programming-guides/field_presence/\n- Rust generated code guide: https://protobuf.dev/reference/rust/rust-generated/\n- Rust build reference: https://protobuf.dev/reference/rust/building-rust-protos/\n- `prost-build` docs: https://docs.rs/prost-build/latest/prost_build/\n- `tonic-prost-build` docs: https://docs.rs/tonic-prost-build/latest/tonic_prost_build/\n- `ts-proto` README: https://github.com/stephenh/ts-proto\n- `protobuf-ts` README: https://github.com/timostamm/protobuf-ts\n\n## Proto2 vs proto3 (what matters most)\n\n- **Syntax line**\n  - `proto2`: `syntax = \"proto2\";`\n  - `proto3`: `syntax = \"proto3\";`\n- **Cardinality labels**\n  - `proto2`: `optional`, `required` (strongly discouraged), `repeated`, `map`.\n  - `proto3`: `optional` (recommended), implicit singular (legacy style), `repeated`, `map`.\n- **Required fields**\n  - `proto2` only, but strongly discouraged for new schemas.\n  - Not available in `proto3`.\n- **Scalar default overrides**\n  - `proto2`: supports `[default = ...]` on singular non-message fields.\n  - `proto3`: no custom scalar defaults; language defaults apply.\n- **Field presence**\n  - `proto2`: explicit presence for singular fields.\n  - `proto3`: explicit presence only with `optional` (or oneof/message); otherwise implicit for basic scalars.\n  - Proto docs recommend using `optional` in proto3 for smoother compatibility.\n- **Enum zero value**\n  - `proto3`: first enum value must be `0`.\n  - `proto2`: first value is default; using `_UNSPECIFIED = 0` is still safest.\n- **Extensions and groups**\n  - `proto2`: supports extensions; groups exist but are deprecated.\n  - `proto3`: no general extension fields/groups in the same way.\n- **Repeated scalar packing**\n  - `proto2`: use `[packed = true]` for new repeated numeric fields.\n  - `proto3`: repeated scalar numerics are packed by default.\n- **Unknown fields**\n  - Preserved in both proto2 and proto3 (binary format).\n- **Interop note**\n  - Proto2 and proto3 messages can interoperate across imports, but proto2 enums cannot be used directly in proto3 syntax.\n\n## Safe schema evolution checklist\n\n- Never renumber existing fields.\n- Never reuse deleted field numbers.\n- Reserve removed field numbers and names using `reserved`.\n- Prefer additive changes: add new fields, do not mutate existing wire meaning.\n- Avoid `required` for new work.\n- Use `oneof` when exactly one field must be present.\n\n## Protoc usage basics\n\n- Verify installation:\n\n```bash\nprotoc --version\n```\n\n- General compile shape:\n\n```bash\nprotoc -I proto --<LANG>_out=gen/<lang> proto/path/to/file.proto\n```\n\n- Validate schema and emit descriptor set (useful for CI checks):\n\n```bash\nprotoc -I proto --include_imports --descriptor_set_out=gen/schema.pb proto/path/to/file.proto\n```\n\n## Rust generation patterns\n\nRust codegen is commonly done in `build.rs` wrappers that call `protoc` for you.\n\n- `prost-build` example (`build.rs`):\n\n```rust\nfn main() -> std::io::Result<()> {\n    prost_build::compile_protos(&[\"proto/service.proto\"], &[\"proto\"])?;\n    Ok(())\n}\n```\n\n- `tonic-prost-build` example (`build.rs`):\n\n```rust\nfn main() {\n    tonic_prost_build::configure()\n        .compile_protos(&[\"proto/service.proto\"], &[\"proto\"])\n        .unwrap();\n}\n```\n\n- `protobuf` crate ecosystem example (`build.rs`, from protobuf-example):\n\n```rust\nuse protobuf_codegen::CodeGen;\n\nfn main() {\n    CodeGen::new()\n        .inputs([\"proto_example/foo.proto\", \"proto_example/bar/bar.proto\"])\n        .include(\"proto\")\n        .dependency(protobuf_well_known_types::get_dependency(\"protobuf_well_known_types\"))\n        .generate_and_compile()\n        .unwrap();\n}\n```\n\n## TypeScript generation patterns\n\nTypeScript typically uses `protoc` plugins.\n\n- `ts-proto` quickstart:\n\n```bash\nprotoc \\\n  --plugin=./node_modules/.bin/protoc-gen-ts_proto \\\n  --ts_proto_out=gen/ts \\\n  --ts_proto_opt=esModuleInterop=true \\\n  -I proto \\\n  proto/path/to/file.proto\n```\n\n- `@protobuf-ts/plugin` quickstart:\n\n```bash\nnpx protoc --ts_out gen/ts --proto_path proto proto/path/to/file.proto\n```\n\n## Agent defaults for new schema requests\n\n- Ask which syntax to use: `proto2` or `proto3`.\n- If unspecified, recommend `proto3` with explicit `optional` for scalar presence.\n- Ask which TypeScript generator to target: `ts-proto` or `@protobuf-ts/plugin`.\n- If unspecified, recommend `ts-proto` for idiomatic TS interfaces and flexible options.\n- Always call out features that are syntax-specific (for example `required`/extensions/default overrides in proto2).\n",
              "after": "# Protobuf Schema Research Notes\n\nLast reviewed: 2026-02-15\n\n## Scope\n\n- Capture practical notes for authoring new `.proto` schemas.\n- Support both `proto2` and `proto3` workflows.\n- Document `protoc` usage for Rust and TypeScript generation paths.\n\n## Primary web sources\n\n- OpenCode skills docs: https://opencode.ai/docs/skills/\n- Protoc install docs: https://protobuf.dev/installation/\n- Proto2 guide: https://protobuf.dev/programming-guides/proto2/\n- Proto3 guide: https://protobuf.dev/programming-guides/proto3/\n- Field presence note: https://protobuf.dev/programming-guides/field_presence/\n- Rust generated code guide: https://protobuf.dev/reference/rust/rust-generated/\n- Rust build reference: https://protobuf.dev/reference/rust/building-rust-protos/\n- `prost-build` docs: https://docs.rs/prost-build/latest/prost_build/\n- `tonic-prost-build` docs: https://docs.rs/tonic-prost-build/latest/tonic_prost_build/\n- `ts-proto` README: https://github.com/stephenh/ts-proto\n- `protobuf-ts` README: https://github.com/timostamm/protobuf-ts\n\n## Proto2 vs proto3 (what matters most)\n\n- **Syntax line**\n  - `proto2`: `syntax = \"proto2\";`\n  - `proto3`: `syntax = \"proto3\";`\n- **Cardinality labels**\n  - `proto2`: `optional`, `required` (strongly discouraged), `repeated`, `map`.\n  - `proto3`: `optional` (recommended), implicit singular (legacy style), `repeated`, `map`.\n- **Required fields**\n  - `proto2` only, but strongly discouraged for new schemas.\n  - Not available in `proto3`.\n- **Scalar default overrides**\n  - `proto2`: supports `[default = ...]` on singular non-message fields.\n  - `proto3`: no custom scalar defaults; language defaults apply.\n- **Field presence**\n  - `proto2`: explicit presence for singular fields.\n  - `proto3`: explicit presence only with `optional` (or oneof/message); otherwise implicit for basic scalars.\n  - Proto docs recommend using `optional` in proto3 for smoother compatibility.\n- **Enum zero value**\n  - `proto3`: first enum value must be `0`.\n  - `proto2`: first value is default; using `_UNSPECIFIED = 0` is still safest.\n- **Extensions and groups**\n  - `proto2`: supports extensions; groups exist but are deprecated.\n  - `proto3`: no general extension fields/groups in the same way.\n- **Repeated scalar packing**\n  - `proto2`: use `[packed = true]` for new repeated numeric fields.\n  - `proto3`: repeated scalar numerics are packed by default.\n- **Unknown fields**\n  - Preserved in both proto2 and proto3 (binary format).\n- **Interop note**\n  - Proto2 and proto3 messages can interoperate across imports, but proto2 enums cannot be used directly in proto3 syntax.\n\n## Complete valid type list\n\n### Scalar field types (all proto syntaxes)\n\n- `double`\n- `float`\n- `int32`\n- `int64`\n- `uint32`\n- `uint64`\n- `sint32`\n- `sint64`\n- `fixed32`\n- `fixed64`\n- `sfixed32`\n- `sfixed64`\n- `bool`\n- `string`\n- `bytes`\n\n### Non-scalar field type forms\n\n- Message type (local or imported), for example `my.pkg.User`.\n- Enum type (local or imported), for example `Status`.\n- `map<K, V>` field form.\n  - Valid map key types: `int32`, `int64`, `uint32`, `uint64`, `sint32`, `sint64`, `fixed32`, `fixed64`, `sfixed32`, `sfixed64`, `bool`, `string`.\n  - Map values can be scalar, enum, or message types.\n- `oneof` members (each member is a normal singular field declaration).\n\n### Well-known imported message types (common in schemas)\n\n- `google.protobuf.Any`\n- `google.protobuf.Timestamp`\n- `google.protobuf.Duration`\n- `google.protobuf.Empty`\n- `google.protobuf.FieldMask`\n- `google.protobuf.Struct`\n- Wrapper messages in `google/protobuf/wrappers.proto`\n\n## Complete schema definition layout (reference)\n\nThe grammar allows flexible ordering in many places, but this layout is the safest boilerplate for new files.\n\n### Top-level statements\n\n- `syntax = \"proto2\";` or `syntax = \"proto3\";` (first non-comment line)\n- `package ...;` (optional, recommended)\n- `import \"...\";`, `import public \"...\";`, or `import weak \"...\";`\n- `option ... = ...;`\n- `message ... { ... }`\n- `enum ... { ... }`\n- `service ... { ... }`\n- `extend ... { ... }` (proto2 and custom-option patterns)\n\n### Message body statements\n\n- Field declarations (`optional`/`required`/`repeated` in proto2, `optional`/implicit/repeated in proto3)\n- `oneof ... { ... }`\n- `map<key, value> ... = N;`\n- Nested `message` and nested `enum`\n- `reserved ...;` (numbers and/or names)\n- `option ... = ...;`\n- `extensions ...;` (proto2)\n- `group` (proto2 legacy, deprecated)\n- `extend ... { ... }`\n\n### Enum body statements\n\n- Enum values: `NAME = N;`\n- `option allow_alias = true;` and other enum options\n- `reserved ...;` (numbers and/or names)\n\n### Service body statements\n\n- Unary RPC:\n\n```proto\nrpc GetThing(GetThingRequest) returns (GetThingResponse);\n```\n\n- Streaming RPC:\n\n```proto\nrpc Chat(stream ChatMessage) returns (stream ChatMessage);\n```\n\n- RPC with method options block:\n\n```proto\nrpc GetThing(GetThingRequest) returns (GetThingResponse) {\n  option deprecated = true;\n}\n```\n\n## Boilerplate templates\n\n### Proto3 boilerplate\n\n```proto\nsyntax = \"proto3\";\n\npackage example.v1;\n\nimport \"google/protobuf/timestamp.proto\";\n\noption java_multiple_files = true;\n\nmessage User {\n  // Use optional for explicit scalar presence in proto3.\n  optional string display_name = 1;\n  string email = 2;\n  google.protobuf.Timestamp created_at = 3;\n\n  oneof contact_method {\n    string phone = 4;\n    string slack = 5;\n  }\n\n  map<string, string> labels = 6;\n\n  reserved 7, 8;\n  reserved \"legacy_id\";\n}\n\nenum UserState {\n  USER_STATE_UNSPECIFIED = 0;\n  USER_STATE_ACTIVE = 1;\n  USER_STATE_DISABLED = 2;\n}\n\nservice UserService {\n  rpc GetUser(GetUserRequest) returns (GetUserResponse);\n}\n\nmessage GetUserRequest {\n  string user_id = 1;\n}\n\nmessage GetUserResponse {\n  User user = 1;\n}\n```\n\n### Proto2 boilerplate\n\n```proto\nsyntax = \"proto2\";\n\npackage example.v1;\n\nmessage User {\n  optional string display_name = 1 [default = \"unknown\"];\n  optional string email = 2;\n  repeated string tags = 3;\n\n  // Required is proto2-only and discouraged for new design.\n  // required string id = 4;\n\n  extensions 100 to max;\n\n  reserved 5;\n  reserved \"legacy_id\";\n}\n\nenum UserState {\n  USER_STATE_UNSPECIFIED = 0;\n  USER_STATE_ACTIVE = 1;\n}\n\nextend User {\n  optional string external_profile = 100;\n}\n```\n\n## Numbering and wire constraints quick reference\n\n- Field numbers must be in `1..536870911`.\n- Field numbers `19000..19999` are reserved by protobuf implementation.\n- Never renumber existing fields.\n- Never reuse removed field numbers or names.\n\n## Safe schema evolution checklist\n\n- Never renumber existing fields.\n- Never reuse deleted field numbers.\n- Reserve removed field numbers and names using `reserved`.\n- Prefer additive changes: add new fields, do not mutate existing wire meaning.\n- Avoid `required` for new work.\n- Use `oneof` when exactly one field must be present.\n\n## Protoc usage basics\n\n- Verify installation:\n\n```bash\nprotoc --version\n```\n\n- General compile shape:\n\n```bash\nprotoc -I proto --<LANG>_out=gen/<lang> proto/path/to/file.proto\n```\n\n- Validate schema and emit descriptor set (useful for CI checks):\n\n```bash\nprotoc -I proto --include_imports --descriptor_set_out=gen/schema.pb proto/path/to/file.proto\n```\n\n## Rust generation patterns\n\nRust codegen is commonly done in `build.rs` wrappers that call `protoc` for you.\n\n- `prost-build` example (`build.rs`):\n\n```rust\nfn main() -> std::io::Result<()> {\n    prost_build::compile_protos(&[\"proto/service.proto\"], &[\"proto\"])?;\n    Ok(())\n}\n```\n\n- `tonic-prost-build` example (`build.rs`):\n\n```rust\nfn main() {\n    tonic_prost_build::configure()\n        .compile_protos(&[\"proto/service.proto\"], &[\"proto\"])\n        .unwrap();\n}\n```\n\n- `protobuf` crate ecosystem example (`build.rs`, from protobuf-example):\n\n```rust\nuse protobuf_codegen::CodeGen;\n\nfn main() {\n    CodeGen::new()\n        .inputs([\"proto_example/foo.proto\", \"proto_example/bar/bar.proto\"])\n        .include(\"proto\")\n        .dependency(protobuf_well_known_types::get_dependency(\"protobuf_well_known_types\"))\n        .generate_and_compile()\n        .unwrap();\n}\n```\n\n## TypeScript generation patterns\n\nTypeScript typically uses `protoc` plugins.\n\n- `ts-proto` quickstart:\n\n```bash\nprotoc \\\n  --plugin=./node_modules/.bin/protoc-gen-ts_proto \\\n  --ts_proto_out=gen/ts \\\n  --ts_proto_opt=esModuleInterop=true \\\n  -I proto \\\n  proto/path/to/file.proto\n```\n\n- `@protobuf-ts/plugin` quickstart:\n\n```bash\nnpx protoc --ts_out gen/ts --proto_path proto proto/path/to/file.proto\n```\n\n## Agent defaults for new schema requests\n\n- Ask which syntax to use: `proto2` or `proto3`.\n- If unspecified, recommend `proto3` with explicit `optional` for scalar presence.\n- Ask which TypeScript generator to target: `ts-proto` or `@protobuf-ts/plugin`.\n- If unspecified, recommend `ts-proto` for idiomatic TS interfaces and flexible options.\n- Always call out features that are syntax-specific (for example `required`/extensions/default overrides in proto2).\n",
              "additions": 181,
              "deletions": 0,
              "status": "modified"
            }
          ]
        },
        "agent": "build",
        "model": {
          "providerID": "openai",
          "modelID": "gpt-5.3-codex"
        },
        "variant": "high",
        "id": "msg_c648bfd6d001GV4FuhQmsmhQe3",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "text",
          "text": "Add to skill - either directly or reference (one research a complete list) - all the valid proto types / schemas defintion layout / boilerplate ",
          "id": "prt_c648bfd6d002ioLdbrnsQNPk9H",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648bfd6d001GV4FuhQmsmhQe3"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771213421943,
          "completed": 1771213487001
        },
        "parentID": "msg_c648bfd6d001GV4FuhQmsmhQe3",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 116956,
          "input": 113323,
          "output": 3633,
          "reasoning": 2175,
          "cache": {
            "read": 0,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "tool-calls",
        "id": "msg_c648bfd77001iFpwKpVg4Z2G2b",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "37f68ceed79b1d94d2e8dd2c56dfe86f08c21423",
          "id": "prt_c648c0526001qQxdmUmM1vUisS",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648bfd77001iFpwKpVg4Z2G2b"
        },
        {
          "type": "reasoning",
          "text": "**Planning complete proto schema reference**",
          "metadata": {
            "openai": {
              "itemId": "rs_0424ddf25538f9920169929272697c8195a6854ca93cdd35db",
              "reasoningEncryptedContent": "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"
            }
          },
          "time": {
            "start": 1771213426506,
            "end": 1771213469110
          },
          "id": "prt_c648c0f4a001TPXLCNiM00kkdP",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648bfd77001iFpwKpVg4Z2G2b"
        },
        {
          "type": "tool",
          "callID": "call_mRoC2g0naSOCx769GFZOA2f5",
          "tool": "apply_patch",
          "state": {
            "status": "completed",
            "input": {
              "patchText": "*** Begin Patch\n*** Update File: docs/readmes/protobuf-schema-research.md\n@@\n ## Proto2 vs proto3 (what matters most)\n@@\n - **Interop note**\n   - Proto2 and proto3 messages can interoperate across imports, but proto2 enums cannot be used directly in proto3 syntax.\n+\n+## Complete valid type list\n+\n+### Scalar field types (all proto syntaxes)\n+\n+- `double`\n+- `float`\n+- `int32`\n+- `int64`\n+- `uint32`\n+- `uint64`\n+- `sint32`\n+- `sint64`\n+- `fixed32`\n+- `fixed64`\n+- `sfixed32`\n+- `sfixed64`\n+- `bool`\n+- `string`\n+- `bytes`\n+\n+### Non-scalar field type forms\n+\n+- Message type (local or imported), for example `my.pkg.User`.\n+- Enum type (local or imported), for example `Status`.\n+- `map<K, V>` field form.\n+  - Valid map key types: `int32`, `int64`, `uint32`, `uint64`, `sint32`, `sint64`, `fixed32`, `fixed64`, `sfixed32`, `sfixed64`, `bool`, `string`.\n+  - Map values can be scalar, enum, or message types.\n+- `oneof` members (each member is a normal singular field declaration).\n+\n+### Well-known imported message types (common in schemas)\n+\n+- `google.protobuf.Any`\n+- `google.protobuf.Timestamp`\n+- `google.protobuf.Duration`\n+- `google.protobuf.Empty`\n+- `google.protobuf.FieldMask`\n+- `google.protobuf.Struct`\n+- Wrapper messages in `google/protobuf/wrappers.proto`\n+\n+## Complete schema definition layout (reference)\n+\n+The grammar allows flexible ordering in many places, but this layout is the safest boilerplate for new files.\n+\n+### Top-level statements\n+\n+- `syntax = \"proto2\";` or `syntax = \"proto3\";` (first non-comment line)\n+- `package ...;` (optional, recommended)\n+- `import \"...\";`, `import public \"...\";`, or `import weak \"...\";`\n+- `option ... = ...;`\n+- `message ... { ... }`\n+- `enum ... { ... }`\n+- `service ... { ... }`\n+- `extend ... { ... }` (proto2 and custom-option patterns)\n+\n+### Message body statements\n+\n+- Field declarations (`optional`/`required`/`repeated` in proto2, `optional`/implicit/repeated in proto3)\n+- `oneof ... { ... }`\n+- `map<key, value> ... = N;`\n+- Nested `message` and nested `enum`\n+- `reserved ...;` (numbers and/or names)\n+- `option ... = ...;`\n+- `extensions ...;` (proto2)\n+- `group` (proto2 legacy, deprecated)\n+- `extend ... { ... }`\n+\n+### Enum body statements\n+\n+- Enum values: `NAME = N;`\n+- `option allow_alias = true;` and other enum options\n+- `reserved ...;` (numbers and/or names)\n+\n+### Service body statements\n+\n+- Unary RPC:\n+\n+```proto\n+rpc GetThing(GetThingRequest) returns (GetThingResponse);\n+```\n+\n+- Streaming RPC:\n+\n+```proto\n+rpc Chat(stream ChatMessage) returns (stream ChatMessage);\n+```\n+\n+- RPC with method options block:\n+\n+```proto\n+rpc GetThing(GetThingRequest) returns (GetThingResponse) {\n+  option deprecated = true;\n+}\n+```\n+\n+## Boilerplate templates\n+\n+### Proto3 boilerplate\n+\n+```proto\n+syntax = \"proto3\";\n+\n+package example.v1;\n+\n+import \"google/protobuf/timestamp.proto\";\n+\n+option java_multiple_files = true;\n+\n+message User {\n+  // Use optional for explicit scalar presence in proto3.\n+  optional string display_name = 1;\n+  string email = 2;\n+  google.protobuf.Timestamp created_at = 3;\n+\n+  oneof contact_method {\n+    string phone = 4;\n+    string slack = 5;\n+  }\n+\n+  map<string, string> labels = 6;\n+\n+  reserved 7, 8;\n+  reserved \"legacy_id\";\n+}\n+\n+enum UserState {\n+  USER_STATE_UNSPECIFIED = 0;\n+  USER_STATE_ACTIVE = 1;\n+  USER_STATE_DISABLED = 2;\n+}\n+\n+service UserService {\n+  rpc GetUser(GetUserRequest) returns (GetUserResponse);\n+}\n+\n+message GetUserRequest {\n+  string user_id = 1;\n+}\n+\n+message GetUserResponse {\n+  User user = 1;\n+}\n+```\n+\n+### Proto2 boilerplate\n+\n+```proto\n+syntax = \"proto2\";\n+\n+package example.v1;\n+\n+message User {\n+  optional string display_name = 1 [default = \"unknown\"];\n+  optional string email = 2;\n+  repeated string tags = 3;\n+\n+  // Required is proto2-only and discouraged for new design.\n+  // required string id = 4;\n+\n+  extensions 100 to max;\n+\n+  reserved 5;\n+  reserved \"legacy_id\";\n+}\n+\n+enum UserState {\n+  USER_STATE_UNSPECIFIED = 0;\n+  USER_STATE_ACTIVE = 1;\n+}\n+\n+extend User {\n+  optional string external_profile = 100;\n+}\n+```\n+\n+## Numbering and wire constraints quick reference\n+\n+- Field numbers must be in `1..536870911`.\n+- Field numbers `19000..19999` are reserved by protobuf implementation.\n+- Never renumber existing fields.\n+- Never reuse removed field numbers or names.\n*** End Patch"
            },
            "output": "Success. Updated the following files:\nM docs/readmes/protobuf-schema-research.md",
            "title": "Success. Updated the following files:\nM docs/readmes/protobuf-schema-research.md",
            "metadata": {
              "diff": "Index: /Users/alex/repos/vfp/dark-factory/docs/readmes/protobuf-schema-research.md\n===================================================================\n--- /Users/alex/repos/vfp/dark-factory/docs/readmes/protobuf-schema-research.md\n+++ /Users/alex/repos/vfp/dark-factory/docs/readmes/protobuf-schema-research.md\n@@ -53,8 +53,189 @@\n   - Preserved in both proto2 and proto3 (binary format).\n - **Interop note**\n   - Proto2 and proto3 messages can interoperate across imports, but proto2 enums cannot be used directly in proto3 syntax.\n \n+## Complete valid type list\n+\n+### Scalar field types (all proto syntaxes)\n+\n+- `double`\n+- `float`\n+- `int32`\n+- `int64`\n+- `uint32`\n+- `uint64`\n+- `sint32`\n+- `sint64`\n+- `fixed32`\n+- `fixed64`\n+- `sfixed32`\n+- `sfixed64`\n+- `bool`\n+- `string`\n+- `bytes`\n+\n+### Non-scalar field type forms\n+\n+- Message type (local or imported), for example `my.pkg.User`.\n+- Enum type (local or imported), for example `Status`.\n+- `map<K, V>` field form.\n+  - Valid map key types: `int32`, `int64`, `uint32`, `uint64`, `sint32`, `sint64`, `fixed32`, `fixed64`, `sfixed32`, `sfixed64`, `bool`, `string`.\n+  - Map values can be scalar, enum, or message types.\n+- `oneof` members (each member is a normal singular field declaration).\n+\n+### Well-known imported message types (common in schemas)\n+\n+- `google.protobuf.Any`\n+- `google.protobuf.Timestamp`\n+- `google.protobuf.Duration`\n+- `google.protobuf.Empty`\n+- `google.protobuf.FieldMask`\n+- `google.protobuf.Struct`\n+- Wrapper messages in `google/protobuf/wrappers.proto`\n+\n+## Complete schema definition layout (reference)\n+\n+The grammar allows flexible ordering in many places, but this layout is the safest boilerplate for new files.\n+\n+### Top-level statements\n+\n+- `syntax = \"proto2\";` or `syntax = \"proto3\";` (first non-comment line)\n+- `package ...;` (optional, recommended)\n+- `import \"...\";`, `import public \"...\";`, or `import weak \"...\";`\n+- `option ... = ...;`\n+- `message ... { ... }`\n+- `enum ... { ... }`\n+- `service ... { ... }`\n+- `extend ... { ... }` (proto2 and custom-option patterns)\n+\n+### Message body statements\n+\n+- Field declarations (`optional`/`required`/`repeated` in proto2, `optional`/implicit/repeated in proto3)\n+- `oneof ... { ... }`\n+- `map<key, value> ... = N;`\n+- Nested `message` and nested `enum`\n+- `reserved ...;` (numbers and/or names)\n+- `option ... = ...;`\n+- `extensions ...;` (proto2)\n+- `group` (proto2 legacy, deprecated)\n+- `extend ... { ... }`\n+\n+### Enum body statements\n+\n+- Enum values: `NAME = N;`\n+- `option allow_alias = true;` and other enum options\n+- `reserved ...;` (numbers and/or names)\n+\n+### Service body statements\n+\n+- Unary RPC:\n+\n+```proto\n+rpc GetThing(GetThingRequest) returns (GetThingResponse);\n+```\n+\n+- Streaming RPC:\n+\n+```proto\n+rpc Chat(stream ChatMessage) returns (stream ChatMessage);\n+```\n+\n+- RPC with method options block:\n+\n+```proto\n+rpc GetThing(GetThingRequest) returns (GetThingResponse) {\n+  option deprecated = true;\n+}\n+```\n+\n+## Boilerplate templates\n+\n+### Proto3 boilerplate\n+\n+```proto\n+syntax = \"proto3\";\n+\n+package example.v1;\n+\n+import \"google/protobuf/timestamp.proto\";\n+\n+option java_multiple_files = true;\n+\n+message User {\n+  // Use optional for explicit scalar presence in proto3.\n+  optional string display_name = 1;\n+  string email = 2;\n+  google.protobuf.Timestamp created_at = 3;\n+\n+  oneof contact_method {\n+    string phone = 4;\n+    string slack = 5;\n+  }\n+\n+  map<string, string> labels = 6;\n+\n+  reserved 7, 8;\n+  reserved \"legacy_id\";\n+}\n+\n+enum UserState {\n+  USER_STATE_UNSPECIFIED = 0;\n+  USER_STATE_ACTIVE = 1;\n+  USER_STATE_DISABLED = 2;\n+}\n+\n+service UserService {\n+  rpc GetUser(GetUserRequest) returns (GetUserResponse);\n+}\n+\n+message GetUserRequest {\n+  string user_id = 1;\n+}\n+\n+message GetUserResponse {\n+  User user = 1;\n+}\n+```\n+\n+### Proto2 boilerplate\n+\n+```proto\n+syntax = \"proto2\";\n+\n+package example.v1;\n+\n+message User {\n+  optional string display_name = 1 [default = \"unknown\"];\n+  optional string email = 2;\n+  repeated string tags = 3;\n+\n+  // Required is proto2-only and discouraged for new design.\n+  // required string id = 4;\n+\n+  extensions 100 to max;\n+\n+  reserved 5;\n+  reserved \"legacy_id\";\n+}\n+\n+enum UserState {\n+  USER_STATE_UNSPECIFIED = 0;\n+  USER_STATE_ACTIVE = 1;\n+}\n+\n+extend User {\n+  optional string external_profile = 100;\n+}\n+```\n+\n+## Numbering and wire constraints quick reference\n+\n+- Field numbers must be in `1..536870911`.\n+- Field numbers `19000..19999` are reserved by protobuf implementation.\n+- Never renumber existing fields.\n+- Never reuse removed field numbers or names.\n+\n ## Safe schema evolution checklist\n \n - Never renumber existing fields.\n - Never reuse deleted field numbers.\n\n",
              "files": [
                {
                  "filePath": "/Users/alex/repos/vfp/dark-factory/docs/readmes/protobuf-schema-research.md",
                  "relativePath": "docs/readmes/protobuf-schema-research.md",
                  "type": "update",
                  "diff": "Index: /Users/alex/repos/vfp/dark-factory/docs/readmes/protobuf-schema-research.md\n===================================================================\n--- /Users/alex/repos/vfp/dark-factory/docs/readmes/protobuf-schema-research.md\n+++ /Users/alex/repos/vfp/dark-factory/docs/readmes/protobuf-schema-research.md\n@@ -53,8 +53,189 @@\n   - Preserved in both proto2 and proto3 (binary format).\n - **Interop note**\n   - Proto2 and proto3 messages can interoperate across imports, but proto2 enums cannot be used directly in proto3 syntax.\n \n+## Complete valid type list\n+\n+### Scalar field types (all proto syntaxes)\n+\n+- `double`\n+- `float`\n+- `int32`\n+- `int64`\n+- `uint32`\n+- `uint64`\n+- `sint32`\n+- `sint64`\n+- `fixed32`\n+- `fixed64`\n+- `sfixed32`\n+- `sfixed64`\n+- `bool`\n+- `string`\n+- `bytes`\n+\n+### Non-scalar field type forms\n+\n+- Message type (local or imported), for example `my.pkg.User`.\n+- Enum type (local or imported), for example `Status`.\n+- `map<K, V>` field form.\n+  - Valid map key types: `int32`, `int64`, `uint32`, `uint64`, `sint32`, `sint64`, `fixed32`, `fixed64`, `sfixed32`, `sfixed64`, `bool`, `string`.\n+  - Map values can be scalar, enum, or message types.\n+- `oneof` members (each member is a normal singular field declaration).\n+\n+### Well-known imported message types (common in schemas)\n+\n+- `google.protobuf.Any`\n+- `google.protobuf.Timestamp`\n+- `google.protobuf.Duration`\n+- `google.protobuf.Empty`\n+- `google.protobuf.FieldMask`\n+- `google.protobuf.Struct`\n+- Wrapper messages in `google/protobuf/wrappers.proto`\n+\n+## Complete schema definition layout (reference)\n+\n+The grammar allows flexible ordering in many places, but this layout is the safest boilerplate for new files.\n+\n+### Top-level statements\n+\n+- `syntax = \"proto2\";` or `syntax = \"proto3\";` (first non-comment line)\n+- `package ...;` (optional, recommended)\n+- `import \"...\";`, `import public \"...\";`, or `import weak \"...\";`\n+- `option ... = ...;`\n+- `message ... { ... }`\n+- `enum ... { ... }`\n+- `service ... { ... }`\n+- `extend ... { ... }` (proto2 and custom-option patterns)\n+\n+### Message body statements\n+\n+- Field declarations (`optional`/`required`/`repeated` in proto2, `optional`/implicit/repeated in proto3)\n+- `oneof ... { ... }`\n+- `map<key, value> ... = N;`\n+- Nested `message` and nested `enum`\n+- `reserved ...;` (numbers and/or names)\n+- `option ... = ...;`\n+- `extensions ...;` (proto2)\n+- `group` (proto2 legacy, deprecated)\n+- `extend ... { ... }`\n+\n+### Enum body statements\n+\n+- Enum values: `NAME = N;`\n+- `option allow_alias = true;` and other enum options\n+- `reserved ...;` (numbers and/or names)\n+\n+### Service body statements\n+\n+- Unary RPC:\n+\n+```proto\n+rpc GetThing(GetThingRequest) returns (GetThingResponse);\n+```\n+\n+- Streaming RPC:\n+\n+```proto\n+rpc Chat(stream ChatMessage) returns (stream ChatMessage);\n+```\n+\n+- RPC with method options block:\n+\n+```proto\n+rpc GetThing(GetThingRequest) returns (GetThingResponse) {\n+  option deprecated = true;\n+}\n+```\n+\n+## Boilerplate templates\n+\n+### Proto3 boilerplate\n+\n+```proto\n+syntax = \"proto3\";\n+\n+package example.v1;\n+\n+import \"google/protobuf/timestamp.proto\";\n+\n+option java_multiple_files = true;\n+\n+message User {\n+  // Use optional for explicit scalar presence in proto3.\n+  optional string display_name = 1;\n+  string email = 2;\n+  google.protobuf.Timestamp created_at = 3;\n+\n+  oneof contact_method {\n+    string phone = 4;\n+    string slack = 5;\n+  }\n+\n+  map<string, string> labels = 6;\n+\n+  reserved 7, 8;\n+  reserved \"legacy_id\";\n+}\n+\n+enum UserState {\n+  USER_STATE_UNSPECIFIED = 0;\n+  USER_STATE_ACTIVE = 1;\n+  USER_STATE_DISABLED = 2;\n+}\n+\n+service UserService {\n+  rpc GetUser(GetUserRequest) returns (GetUserResponse);\n+}\n+\n+message GetUserRequest {\n+  string user_id = 1;\n+}\n+\n+message GetUserResponse {\n+  User user = 1;\n+}\n+```\n+\n+### Proto2 boilerplate\n+\n+```proto\n+syntax = \"proto2\";\n+\n+package example.v1;\n+\n+message User {\n+  optional string display_name = 1 [default = \"unknown\"];\n+  optional string email = 2;\n+  repeated string tags = 3;\n+\n+  // Required is proto2-only and discouraged for new design.\n+  // required string id = 4;\n+\n+  extensions 100 to max;\n+\n+  reserved 5;\n+  reserved \"legacy_id\";\n+}\n+\n+enum UserState {\n+  USER_STATE_UNSPECIFIED = 0;\n+  USER_STATE_ACTIVE = 1;\n+}\n+\n+extend User {\n+  optional string external_profile = 100;\n+}\n+```\n+\n+## Numbering and wire constraints quick reference\n+\n+- Field numbers must be in `1..536870911`.\n+- Field numbers `19000..19999` are reserved by protobuf implementation.\n+- Never renumber existing fields.\n+- Never reuse removed field numbers or names.\n+\n ## Safe schema evolution checklist\n \n - Never renumber existing fields.\n - Never reuse deleted field numbers.\n",
                  "before": "# Protobuf Schema Research Notes\n\nLast reviewed: 2026-02-15\n\n## Scope\n\n- Capture practical notes for authoring new `.proto` schemas.\n- Support both `proto2` and `proto3` workflows.\n- Document `protoc` usage for Rust and TypeScript generation paths.\n\n## Primary web sources\n\n- OpenCode skills docs: https://opencode.ai/docs/skills/\n- Protoc install docs: https://protobuf.dev/installation/\n- Proto2 guide: https://protobuf.dev/programming-guides/proto2/\n- Proto3 guide: https://protobuf.dev/programming-guides/proto3/\n- Field presence note: https://protobuf.dev/programming-guides/field_presence/\n- Rust generated code guide: https://protobuf.dev/reference/rust/rust-generated/\n- Rust build reference: https://protobuf.dev/reference/rust/building-rust-protos/\n- `prost-build` docs: https://docs.rs/prost-build/latest/prost_build/\n- `tonic-prost-build` docs: https://docs.rs/tonic-prost-build/latest/tonic_prost_build/\n- `ts-proto` README: https://github.com/stephenh/ts-proto\n- `protobuf-ts` README: https://github.com/timostamm/protobuf-ts\n\n## Proto2 vs proto3 (what matters most)\n\n- **Syntax line**\n  - `proto2`: `syntax = \"proto2\";`\n  - `proto3`: `syntax = \"proto3\";`\n- **Cardinality labels**\n  - `proto2`: `optional`, `required` (strongly discouraged), `repeated`, `map`.\n  - `proto3`: `optional` (recommended), implicit singular (legacy style), `repeated`, `map`.\n- **Required fields**\n  - `proto2` only, but strongly discouraged for new schemas.\n  - Not available in `proto3`.\n- **Scalar default overrides**\n  - `proto2`: supports `[default = ...]` on singular non-message fields.\n  - `proto3`: no custom scalar defaults; language defaults apply.\n- **Field presence**\n  - `proto2`: explicit presence for singular fields.\n  - `proto3`: explicit presence only with `optional` (or oneof/message); otherwise implicit for basic scalars.\n  - Proto docs recommend using `optional` in proto3 for smoother compatibility.\n- **Enum zero value**\n  - `proto3`: first enum value must be `0`.\n  - `proto2`: first value is default; using `_UNSPECIFIED = 0` is still safest.\n- **Extensions and groups**\n  - `proto2`: supports extensions; groups exist but are deprecated.\n  - `proto3`: no general extension fields/groups in the same way.\n- **Repeated scalar packing**\n  - `proto2`: use `[packed = true]` for new repeated numeric fields.\n  - `proto3`: repeated scalar numerics are packed by default.\n- **Unknown fields**\n  - Preserved in both proto2 and proto3 (binary format).\n- **Interop note**\n  - Proto2 and proto3 messages can interoperate across imports, but proto2 enums cannot be used directly in proto3 syntax.\n\n## Safe schema evolution checklist\n\n- Never renumber existing fields.\n- Never reuse deleted field numbers.\n- Reserve removed field numbers and names using `reserved`.\n- Prefer additive changes: add new fields, do not mutate existing wire meaning.\n- Avoid `required` for new work.\n- Use `oneof` when exactly one field must be present.\n\n## Protoc usage basics\n\n- Verify installation:\n\n```bash\nprotoc --version\n```\n\n- General compile shape:\n\n```bash\nprotoc -I proto --<LANG>_out=gen/<lang> proto/path/to/file.proto\n```\n\n- Validate schema and emit descriptor set (useful for CI checks):\n\n```bash\nprotoc -I proto --include_imports --descriptor_set_out=gen/schema.pb proto/path/to/file.proto\n```\n\n## Rust generation patterns\n\nRust codegen is commonly done in `build.rs` wrappers that call `protoc` for you.\n\n- `prost-build` example (`build.rs`):\n\n```rust\nfn main() -> std::io::Result<()> {\n    prost_build::compile_protos(&[\"proto/service.proto\"], &[\"proto\"])?;\n    Ok(())\n}\n```\n\n- `tonic-prost-build` example (`build.rs`):\n\n```rust\nfn main() {\n    tonic_prost_build::configure()\n        .compile_protos(&[\"proto/service.proto\"], &[\"proto\"])\n        .unwrap();\n}\n```\n\n- `protobuf` crate ecosystem example (`build.rs`, from protobuf-example):\n\n```rust\nuse protobuf_codegen::CodeGen;\n\nfn main() {\n    CodeGen::new()\n        .inputs([\"proto_example/foo.proto\", \"proto_example/bar/bar.proto\"])\n        .include(\"proto\")\n        .dependency(protobuf_well_known_types::get_dependency(\"protobuf_well_known_types\"))\n        .generate_and_compile()\n        .unwrap();\n}\n```\n\n## TypeScript generation patterns\n\nTypeScript typically uses `protoc` plugins.\n\n- `ts-proto` quickstart:\n\n```bash\nprotoc \\\n  --plugin=./node_modules/.bin/protoc-gen-ts_proto \\\n  --ts_proto_out=gen/ts \\\n  --ts_proto_opt=esModuleInterop=true \\\n  -I proto \\\n  proto/path/to/file.proto\n```\n\n- `@protobuf-ts/plugin` quickstart:\n\n```bash\nnpx protoc --ts_out gen/ts --proto_path proto proto/path/to/file.proto\n```\n\n## Agent defaults for new schema requests\n\n- Ask which syntax to use: `proto2` or `proto3`.\n- If unspecified, recommend `proto3` with explicit `optional` for scalar presence.\n- Ask which TypeScript generator to target: `ts-proto` or `@protobuf-ts/plugin`.\n- If unspecified, recommend `ts-proto` for idiomatic TS interfaces and flexible options.\n- Always call out features that are syntax-specific (for example `required`/extensions/default overrides in proto2).\n",
                  "after": "# Protobuf Schema Research Notes\n\nLast reviewed: 2026-02-15\n\n## Scope\n\n- Capture practical notes for authoring new `.proto` schemas.\n- Support both `proto2` and `proto3` workflows.\n- Document `protoc` usage for Rust and TypeScript generation paths.\n\n## Primary web sources\n\n- OpenCode skills docs: https://opencode.ai/docs/skills/\n- Protoc install docs: https://protobuf.dev/installation/\n- Proto2 guide: https://protobuf.dev/programming-guides/proto2/\n- Proto3 guide: https://protobuf.dev/programming-guides/proto3/\n- Field presence note: https://protobuf.dev/programming-guides/field_presence/\n- Rust generated code guide: https://protobuf.dev/reference/rust/rust-generated/\n- Rust build reference: https://protobuf.dev/reference/rust/building-rust-protos/\n- `prost-build` docs: https://docs.rs/prost-build/latest/prost_build/\n- `tonic-prost-build` docs: https://docs.rs/tonic-prost-build/latest/tonic_prost_build/\n- `ts-proto` README: https://github.com/stephenh/ts-proto\n- `protobuf-ts` README: https://github.com/timostamm/protobuf-ts\n\n## Proto2 vs proto3 (what matters most)\n\n- **Syntax line**\n  - `proto2`: `syntax = \"proto2\";`\n  - `proto3`: `syntax = \"proto3\";`\n- **Cardinality labels**\n  - `proto2`: `optional`, `required` (strongly discouraged), `repeated`, `map`.\n  - `proto3`: `optional` (recommended), implicit singular (legacy style), `repeated`, `map`.\n- **Required fields**\n  - `proto2` only, but strongly discouraged for new schemas.\n  - Not available in `proto3`.\n- **Scalar default overrides**\n  - `proto2`: supports `[default = ...]` on singular non-message fields.\n  - `proto3`: no custom scalar defaults; language defaults apply.\n- **Field presence**\n  - `proto2`: explicit presence for singular fields.\n  - `proto3`: explicit presence only with `optional` (or oneof/message); otherwise implicit for basic scalars.\n  - Proto docs recommend using `optional` in proto3 for smoother compatibility.\n- **Enum zero value**\n  - `proto3`: first enum value must be `0`.\n  - `proto2`: first value is default; using `_UNSPECIFIED = 0` is still safest.\n- **Extensions and groups**\n  - `proto2`: supports extensions; groups exist but are deprecated.\n  - `proto3`: no general extension fields/groups in the same way.\n- **Repeated scalar packing**\n  - `proto2`: use `[packed = true]` for new repeated numeric fields.\n  - `proto3`: repeated scalar numerics are packed by default.\n- **Unknown fields**\n  - Preserved in both proto2 and proto3 (binary format).\n- **Interop note**\n  - Proto2 and proto3 messages can interoperate across imports, but proto2 enums cannot be used directly in proto3 syntax.\n\n## Complete valid type list\n\n### Scalar field types (all proto syntaxes)\n\n- `double`\n- `float`\n- `int32`\n- `int64`\n- `uint32`\n- `uint64`\n- `sint32`\n- `sint64`\n- `fixed32`\n- `fixed64`\n- `sfixed32`\n- `sfixed64`\n- `bool`\n- `string`\n- `bytes`\n\n### Non-scalar field type forms\n\n- Message type (local or imported), for example `my.pkg.User`.\n- Enum type (local or imported), for example `Status`.\n- `map<K, V>` field form.\n  - Valid map key types: `int32`, `int64`, `uint32`, `uint64`, `sint32`, `sint64`, `fixed32`, `fixed64`, `sfixed32`, `sfixed64`, `bool`, `string`.\n  - Map values can be scalar, enum, or message types.\n- `oneof` members (each member is a normal singular field declaration).\n\n### Well-known imported message types (common in schemas)\n\n- `google.protobuf.Any`\n- `google.protobuf.Timestamp`\n- `google.protobuf.Duration`\n- `google.protobuf.Empty`\n- `google.protobuf.FieldMask`\n- `google.protobuf.Struct`\n- Wrapper messages in `google/protobuf/wrappers.proto`\n\n## Complete schema definition layout (reference)\n\nThe grammar allows flexible ordering in many places, but this layout is the safest boilerplate for new files.\n\n### Top-level statements\n\n- `syntax = \"proto2\";` or `syntax = \"proto3\";` (first non-comment line)\n- `package ...;` (optional, recommended)\n- `import \"...\";`, `import public \"...\";`, or `import weak \"...\";`\n- `option ... = ...;`\n- `message ... { ... }`\n- `enum ... { ... }`\n- `service ... { ... }`\n- `extend ... { ... }` (proto2 and custom-option patterns)\n\n### Message body statements\n\n- Field declarations (`optional`/`required`/`repeated` in proto2, `optional`/implicit/repeated in proto3)\n- `oneof ... { ... }`\n- `map<key, value> ... = N;`\n- Nested `message` and nested `enum`\n- `reserved ...;` (numbers and/or names)\n- `option ... = ...;`\n- `extensions ...;` (proto2)\n- `group` (proto2 legacy, deprecated)\n- `extend ... { ... }`\n\n### Enum body statements\n\n- Enum values: `NAME = N;`\n- `option allow_alias = true;` and other enum options\n- `reserved ...;` (numbers and/or names)\n\n### Service body statements\n\n- Unary RPC:\n\n```proto\nrpc GetThing(GetThingRequest) returns (GetThingResponse);\n```\n\n- Streaming RPC:\n\n```proto\nrpc Chat(stream ChatMessage) returns (stream ChatMessage);\n```\n\n- RPC with method options block:\n\n```proto\nrpc GetThing(GetThingRequest) returns (GetThingResponse) {\n  option deprecated = true;\n}\n```\n\n## Boilerplate templates\n\n### Proto3 boilerplate\n\n```proto\nsyntax = \"proto3\";\n\npackage example.v1;\n\nimport \"google/protobuf/timestamp.proto\";\n\noption java_multiple_files = true;\n\nmessage User {\n  // Use optional for explicit scalar presence in proto3.\n  optional string display_name = 1;\n  string email = 2;\n  google.protobuf.Timestamp created_at = 3;\n\n  oneof contact_method {\n    string phone = 4;\n    string slack = 5;\n  }\n\n  map<string, string> labels = 6;\n\n  reserved 7, 8;\n  reserved \"legacy_id\";\n}\n\nenum UserState {\n  USER_STATE_UNSPECIFIED = 0;\n  USER_STATE_ACTIVE = 1;\n  USER_STATE_DISABLED = 2;\n}\n\nservice UserService {\n  rpc GetUser(GetUserRequest) returns (GetUserResponse);\n}\n\nmessage GetUserRequest {\n  string user_id = 1;\n}\n\nmessage GetUserResponse {\n  User user = 1;\n}\n```\n\n### Proto2 boilerplate\n\n```proto\nsyntax = \"proto2\";\n\npackage example.v1;\n\nmessage User {\n  optional string display_name = 1 [default = \"unknown\"];\n  optional string email = 2;\n  repeated string tags = 3;\n\n  // Required is proto2-only and discouraged for new design.\n  // required string id = 4;\n\n  extensions 100 to max;\n\n  reserved 5;\n  reserved \"legacy_id\";\n}\n\nenum UserState {\n  USER_STATE_UNSPECIFIED = 0;\n  USER_STATE_ACTIVE = 1;\n}\n\nextend User {\n  optional string external_profile = 100;\n}\n```\n\n## Numbering and wire constraints quick reference\n\n- Field numbers must be in `1..536870911`.\n- Field numbers `19000..19999` are reserved by protobuf implementation.\n- Never renumber existing fields.\n- Never reuse removed field numbers or names.\n\n## Safe schema evolution checklist\n\n- Never renumber existing fields.\n- Never reuse deleted field numbers.\n- Reserve removed field numbers and names using `reserved`.\n- Prefer additive changes: add new fields, do not mutate existing wire meaning.\n- Avoid `required` for new work.\n- Use `oneof` when exactly one field must be present.\n\n## Protoc usage basics\n\n- Verify installation:\n\n```bash\nprotoc --version\n```\n\n- General compile shape:\n\n```bash\nprotoc -I proto --<LANG>_out=gen/<lang> proto/path/to/file.proto\n```\n\n- Validate schema and emit descriptor set (useful for CI checks):\n\n```bash\nprotoc -I proto --include_imports --descriptor_set_out=gen/schema.pb proto/path/to/file.proto\n```\n\n## Rust generation patterns\n\nRust codegen is commonly done in `build.rs` wrappers that call `protoc` for you.\n\n- `prost-build` example (`build.rs`):\n\n```rust\nfn main() -> std::io::Result<()> {\n    prost_build::compile_protos(&[\"proto/service.proto\"], &[\"proto\"])?;\n    Ok(())\n}\n```\n\n- `tonic-prost-build` example (`build.rs`):\n\n```rust\nfn main() {\n    tonic_prost_build::configure()\n        .compile_protos(&[\"proto/service.proto\"], &[\"proto\"])\n        .unwrap();\n}\n```\n\n- `protobuf` crate ecosystem example (`build.rs`, from protobuf-example):\n\n```rust\nuse protobuf_codegen::CodeGen;\n\nfn main() {\n    CodeGen::new()\n        .inputs([\"proto_example/foo.proto\", \"proto_example/bar/bar.proto\"])\n        .include(\"proto\")\n        .dependency(protobuf_well_known_types::get_dependency(\"protobuf_well_known_types\"))\n        .generate_and_compile()\n        .unwrap();\n}\n```\n\n## TypeScript generation patterns\n\nTypeScript typically uses `protoc` plugins.\n\n- `ts-proto` quickstart:\n\n```bash\nprotoc \\\n  --plugin=./node_modules/.bin/protoc-gen-ts_proto \\\n  --ts_proto_out=gen/ts \\\n  --ts_proto_opt=esModuleInterop=true \\\n  -I proto \\\n  proto/path/to/file.proto\n```\n\n- `@protobuf-ts/plugin` quickstart:\n\n```bash\nnpx protoc --ts_out gen/ts --proto_path proto proto/path/to/file.proto\n```\n\n## Agent defaults for new schema requests\n\n- Ask which syntax to use: `proto2` or `proto3`.\n- If unspecified, recommend `proto3` with explicit `optional` for scalar presence.\n- Ask which TypeScript generator to target: `ts-proto` or `@protobuf-ts/plugin`.\n- If unspecified, recommend `ts-proto` for idiomatic TS interfaces and flexible options.\n- Always call out features that are syntax-specific (for example `required`/extensions/default overrides in proto2).\n",
                  "additions": 181,
                  "deletions": 0
                }
              ],
              "diagnostics": {},
              "truncated": false
            },
            "time": {
              "start": 1771213486914,
              "end": 1771213486939
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_0424ddf25538f992016992929d0b788195858bdb7a99e5bcd3"
            }
          },
          "id": "prt_c648cb5b600130ABCopAihS6Ln",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648bfd77001iFpwKpVg4Z2G2b"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "6fb77aae5b3312bd8dda6d40d22b34a2aaf81514",
          "cost": 0,
          "tokens": {
            "total": 116956,
            "input": 113323,
            "output": 3633,
            "reasoning": 2175,
            "cache": {
              "read": 0,
              "write": 0
            }
          },
          "id": "prt_c648cfb5e0017ATtlne1vQJvqC",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648bfd77001iFpwKpVg4Z2G2b"
        },
        {
          "type": "patch",
          "hash": "37f68ceed79b1d94d2e8dd2c56dfe86f08c21423",
          "files": [
            "/Users/alex/repos/vfp/dark-factory/docs/readmes/protobuf-schema-research.md"
          ],
          "id": "prt_c648cfb90001asd5moK2jK1soy",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648bfd77001iFpwKpVg4Z2G2b"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771213487006,
          "completed": 1771213497998
        },
        "parentID": "msg_c648bfd6d001GV4FuhQmsmhQe3",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 117290,
          "input": 2807,
          "output": 307,
          "reasoning": 14,
          "cache": {
            "read": 114176,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "tool-calls",
        "id": "msg_c648cfb9e001vTXCA7JpFmDwvR",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "6fb77aae5b3312bd8dda6d40d22b34a2aaf81514",
          "id": "prt_c648d051e001f0T8tT5joEC3UM",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648cfb9e001vTXCA7JpFmDwvR"
        },
        {
          "type": "reasoning",
          "text": "**Updating skill file references**",
          "metadata": {
            "openai": {
              "itemId": "rs_0d0ae22f7be70d5101699292b55d0881978101f4d973f158c0",
              "reasoningEncryptedContent": "gAAAAABpkpK1fJgxsjDuv3RXyHQFc6XamaxJuVy5l1tFRPzmmRfRoPuLm-zBSI5Z-Q2zMyA-FqG710FQdoTEoRKj7LDYZ7xbYdy7rujIrqMlQlP7Dg1BrF5r32jqVXGbD05zqlMKbRSAmMQEQVTAqTSBixwUl9sq7ONLYVj15utvp49ZpkK3r3KkbIRILPpZm2TgT9U6cPZpqpbT7vWjF_KNlUx-M5dYlNwBxVwzhMpxF_Bx6gutgaXX9kkAgdf81Ah6PrjsBcKPD-vNOvD6jLd6IlsLfD_OhTMd4hYpWa4afxmOFektwpPHa7TI5EQ1Px7xoezaIYQlWl8ktZ7CcL79PPgxK1XVBofnw8OthD4P61O2vcBXzncyCciPGzD30hkczsTvep1nYhL67NVQK-4IXOz-LHEGLDPH3dAnIUo5qzdgiZoQAlKiMF9XIwtVwVfQv6IMspkBhHeEqpkxYZZQkJiIGNR55qJDGQ6beKkABV4MHt31lyHRDMHuBfQv02GtmDkp2C-AcRxf8uCZOhVSh0NsYQ0xEWljDK7BQ19VhkdkYpRruTdda3ZltjTfU3LcLxilNPLbnjFaxZLUd1L8anjvAqjv0rGOKO1hqWqrQCkdtc2LbI_wYG6AWjDR--toIUOhWZyiXaHYK8HQctJbaZami_xguv4hVoLXVoYYAQvNTgvMy8V7_lmwKD0JyXdJ1byfLKVRgDhS3BQEZMSQ_vhw9taDmdlclKxIsTabsLsvz1ad9t9t9H_9BJCkLztDNa3O7WkAlDe3xNWUg2ZkjI-sH0d3aiXrpr-P4YbEr4j5dWiYv29JaxBVGpNRzzEjQ86DHjGJgXm8IHDRL33gSSvv0zmkUYwGGHqhUkpb_Naya6L17b9ogzCsVoQ2-oy88iEWhUlxYcKfUSo4nol1FUqQopbZXw=="
            }
          },
          "time": {
            "start": 1771213493396,
            "end": 1771213493990
          },
          "id": "prt_c648d14940019uGcnARSJdds6S",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648cfb9e001vTXCA7JpFmDwvR"
        },
        {
          "type": "tool",
          "callID": "call_smizj2u339nrVKEouSrvfDmH",
          "tool": "apply_patch",
          "state": {
            "status": "completed",
            "input": {
              "patchText": "*** Begin Patch\n*** Update File: .opencode/skills/protobuf-schema-authoring/SKILL.md\n@@\n ## What I do\n \n - Turn user requirements into clear, evolvable `.proto` schemas.\n - Support both `proto2` and `proto3` syntax.\n - Ask for syntax preference when not explicitly provided, and explain version-specific constraints.\n - Provide practical `protoc` workflows for Rust and TypeScript.\n+- Use the full type/layout reference in `docs/readmes/protobuf-schema-research.md`.\n@@\n ## Proto2 vs proto3 guardrails\n@@\n - Repeated scalar numerics are packed-by-default in proto3; in proto2, use `[packed = true]` for new fields.\n+\n+## Complete reference location\n+\n+Use `docs/readmes/protobuf-schema-research.md` as the canonical in-repo reference for:\n+\n+- Complete valid scalar type list and non-scalar type forms.\n+- Full schema definition layout (top-level, message, enum, service).\n+- Proto2 and proto3 boilerplate templates.\n+- Wire constraints and field numbering guardrails.\n+\n+When drafting schemas, follow that reference and include only the subset needed for the user request.\n*** End Patch"
            },
            "output": "Success. Updated the following files:\nM .opencode/skills/protobuf-schema-authoring/SKILL.md",
            "title": "Success. Updated the following files:\nM .opencode/skills/protobuf-schema-authoring/SKILL.md",
            "metadata": {
              "diff": "Index: /Users/alex/repos/vfp/dark-factory/.opencode/skills/protobuf-schema-authoring/SKILL.md\n===================================================================\n--- /Users/alex/repos/vfp/dark-factory/.opencode/skills/protobuf-schema-authoring/SKILL.md\n+++ /Users/alex/repos/vfp/dark-factory/.opencode/skills/protobuf-schema-authoring/SKILL.md\n@@ -8,8 +8,9 @@\n - Turn user requirements into clear, evolvable `.proto` schemas.\n - Support both `proto2` and `proto3` syntax.\n - Ask for syntax preference when not explicitly provided, and explain version-specific constraints.\n - Provide practical `protoc` workflows for Rust and TypeScript.\n+- Use the full type/layout reference in `docs/readmes/protobuf-schema-research.md`.\n \n ## When to use me\n \n Use this when the task includes any of the following:\n@@ -39,8 +40,19 @@\n - Proto3 enums must start with a zero-valued first entry.\n - Proto3 scalar presence should use `optional` when presence semantics are needed.\n - Repeated scalar numerics are packed-by-default in proto3; in proto2, use `[packed = true]` for new fields.\n \n+## Complete reference location\n+\n+Use `docs/readmes/protobuf-schema-research.md` as the canonical in-repo reference for:\n+\n+- Complete valid scalar type list and non-scalar type forms.\n+- Full schema definition layout (top-level, message, enum, service).\n+- Proto2 and proto3 boilerplate templates.\n+- Wire constraints and field numbering guardrails.\n+\n+When drafting schemas, follow that reference and include only the subset needed for the user request.\n+\n ## Schema authoring workflow\n \n 1. Confirm syntax version and target language outputs.\n 2. Propose package and file layout.\n\n",
              "files": [
                {
                  "filePath": "/Users/alex/repos/vfp/dark-factory/.opencode/skills/protobuf-schema-authoring/SKILL.md",
                  "relativePath": ".opencode/skills/protobuf-schema-authoring/SKILL.md",
                  "type": "update",
                  "diff": "Index: /Users/alex/repos/vfp/dark-factory/.opencode/skills/protobuf-schema-authoring/SKILL.md\n===================================================================\n--- /Users/alex/repos/vfp/dark-factory/.opencode/skills/protobuf-schema-authoring/SKILL.md\n+++ /Users/alex/repos/vfp/dark-factory/.opencode/skills/protobuf-schema-authoring/SKILL.md\n@@ -8,8 +8,9 @@\n - Turn user requirements into clear, evolvable `.proto` schemas.\n - Support both `proto2` and `proto3` syntax.\n - Ask for syntax preference when not explicitly provided, and explain version-specific constraints.\n - Provide practical `protoc` workflows for Rust and TypeScript.\n+- Use the full type/layout reference in `docs/readmes/protobuf-schema-research.md`.\n \n ## When to use me\n \n Use this when the task includes any of the following:\n@@ -39,8 +40,19 @@\n - Proto3 enums must start with a zero-valued first entry.\n - Proto3 scalar presence should use `optional` when presence semantics are needed.\n - Repeated scalar numerics are packed-by-default in proto3; in proto2, use `[packed = true]` for new fields.\n \n+## Complete reference location\n+\n+Use `docs/readmes/protobuf-schema-research.md` as the canonical in-repo reference for:\n+\n+- Complete valid scalar type list and non-scalar type forms.\n+- Full schema definition layout (top-level, message, enum, service).\n+- Proto2 and proto3 boilerplate templates.\n+- Wire constraints and field numbering guardrails.\n+\n+When drafting schemas, follow that reference and include only the subset needed for the user request.\n+\n ## Schema authoring workflow\n \n 1. Confirm syntax version and target language outputs.\n 2. Propose package and file layout.\n",
                  "before": "---\nname: protobuf-schema-authoring\ndescription: Author proto2/proto3 schemas and provide protoc generation workflows for Rust and TypeScript.\n---\n\n## What I do\n\n- Turn user requirements into clear, evolvable `.proto` schemas.\n- Support both `proto2` and `proto3` syntax.\n- Ask for syntax preference when not explicitly provided, and explain version-specific constraints.\n- Provide practical `protoc` workflows for Rust and TypeScript.\n\n## When to use me\n\nUse this when the task includes any of the following:\n\n- Create a new protobuf schema from product or API requirements.\n- Update an existing `.proto` safely.\n- Explain if a feature is `proto2`-only or `proto3`-only.\n- Generate Rust or TypeScript artifacts from `.proto` files.\n\n## Required clarification flow\n\nIf not already specified, ask these in order:\n\n1. Which schema syntax should be used: `proto2` or `proto3`?\n   - Recommended default: `proto3` with explicit `optional` on scalar fields when presence matters.\n2. For TypeScript generation, which plugin should be targeted: `ts-proto` or `@protobuf-ts/plugin`?\n   - Recommended default: `ts-proto`.\n\nWhen answering, always note version-specific features involved in the request.\n\n## Proto2 vs proto3 guardrails\n\n- `required` fields are proto2-only and should be avoided for new design.\n- Explicit scalar defaults (`[default = ...]`) are proto2-only.\n- Extensions are proto2-oriented; not a general proto3 field pattern.\n- Groups are deprecated legacy proto2 and should not be introduced.\n- Proto3 enums must start with a zero-valued first entry.\n- Proto3 scalar presence should use `optional` when presence semantics are needed.\n- Repeated scalar numerics are packed-by-default in proto3; in proto2, use `[packed = true]` for new fields.\n\n## Schema authoring workflow\n\n1. Confirm syntax version and target language outputs.\n2. Propose package and file layout.\n3. Define messages/enums/services with stable field numbering.\n4. Add comments only where semantics are non-obvious.\n5. Reserve removed field numbers and names.\n6. Validate with `protoc` descriptor output when possible.\n7. Provide generation commands for Rust and TypeScript.\n\n## Command templates\n\n- Validate schema and emit descriptor:\n\n```bash\nprotoc -I proto --include_imports --descriptor_set_out=gen/schema.pb proto/path/to/file.proto\n```\n\n- Rust via `prost-build` (`build.rs`):\n\n```rust\nfn main() -> std::io::Result<()> {\n    prost_build::compile_protos(&[\"proto/service.proto\"], &[\"proto\"])?;\n    Ok(())\n}\n```\n\n- Rust via `tonic-prost-build` (`build.rs`):\n\n```rust\nfn main() {\n    tonic_prost_build::configure()\n        .compile_protos(&[\"proto/service.proto\"], &[\"proto\"])\n        .unwrap();\n}\n```\n\n- TypeScript via `ts-proto`:\n\n```bash\nprotoc \\\n  --plugin=./node_modules/.bin/protoc-gen-ts_proto \\\n  --ts_proto_out=gen/ts \\\n  --ts_proto_opt=esModuleInterop=true \\\n  -I proto \\\n  proto/path/to/file.proto\n```\n\n- TypeScript via `@protobuf-ts/plugin`:\n\n```bash\nnpx protoc --ts_out gen/ts --proto_path proto proto/path/to/file.proto\n```\n\n## Output expectations\n\n- Deliver the requested `.proto` file(s) and a short note on compatibility choices.\n- Explicitly call out any use of proto2-only/proto3-only features.\n- Include exact generation commands for the selected Rust and TypeScript toolchains.\n",
                  "after": "---\nname: protobuf-schema-authoring\ndescription: Author proto2/proto3 schemas and provide protoc generation workflows for Rust and TypeScript.\n---\n\n## What I do\n\n- Turn user requirements into clear, evolvable `.proto` schemas.\n- Support both `proto2` and `proto3` syntax.\n- Ask for syntax preference when not explicitly provided, and explain version-specific constraints.\n- Provide practical `protoc` workflows for Rust and TypeScript.\n- Use the full type/layout reference in `docs/readmes/protobuf-schema-research.md`.\n\n## When to use me\n\nUse this when the task includes any of the following:\n\n- Create a new protobuf schema from product or API requirements.\n- Update an existing `.proto` safely.\n- Explain if a feature is `proto2`-only or `proto3`-only.\n- Generate Rust or TypeScript artifacts from `.proto` files.\n\n## Required clarification flow\n\nIf not already specified, ask these in order:\n\n1. Which schema syntax should be used: `proto2` or `proto3`?\n   - Recommended default: `proto3` with explicit `optional` on scalar fields when presence matters.\n2. For TypeScript generation, which plugin should be targeted: `ts-proto` or `@protobuf-ts/plugin`?\n   - Recommended default: `ts-proto`.\n\nWhen answering, always note version-specific features involved in the request.\n\n## Proto2 vs proto3 guardrails\n\n- `required` fields are proto2-only and should be avoided for new design.\n- Explicit scalar defaults (`[default = ...]`) are proto2-only.\n- Extensions are proto2-oriented; not a general proto3 field pattern.\n- Groups are deprecated legacy proto2 and should not be introduced.\n- Proto3 enums must start with a zero-valued first entry.\n- Proto3 scalar presence should use `optional` when presence semantics are needed.\n- Repeated scalar numerics are packed-by-default in proto3; in proto2, use `[packed = true]` for new fields.\n\n## Complete reference location\n\nUse `docs/readmes/protobuf-schema-research.md` as the canonical in-repo reference for:\n\n- Complete valid scalar type list and non-scalar type forms.\n- Full schema definition layout (top-level, message, enum, service).\n- Proto2 and proto3 boilerplate templates.\n- Wire constraints and field numbering guardrails.\n\nWhen drafting schemas, follow that reference and include only the subset needed for the user request.\n\n## Schema authoring workflow\n\n1. Confirm syntax version and target language outputs.\n2. Propose package and file layout.\n3. Define messages/enums/services with stable field numbering.\n4. Add comments only where semantics are non-obvious.\n5. Reserve removed field numbers and names.\n6. Validate with `protoc` descriptor output when possible.\n7. Provide generation commands for Rust and TypeScript.\n\n## Command templates\n\n- Validate schema and emit descriptor:\n\n```bash\nprotoc -I proto --include_imports --descriptor_set_out=gen/schema.pb proto/path/to/file.proto\n```\n\n- Rust via `prost-build` (`build.rs`):\n\n```rust\nfn main() -> std::io::Result<()> {\n    prost_build::compile_protos(&[\"proto/service.proto\"], &[\"proto\"])?;\n    Ok(())\n}\n```\n\n- Rust via `tonic-prost-build` (`build.rs`):\n\n```rust\nfn main() {\n    tonic_prost_build::configure()\n        .compile_protos(&[\"proto/service.proto\"], &[\"proto\"])\n        .unwrap();\n}\n```\n\n- TypeScript via `ts-proto`:\n\n```bash\nprotoc \\\n  --plugin=./node_modules/.bin/protoc-gen-ts_proto \\\n  --ts_proto_out=gen/ts \\\n  --ts_proto_opt=esModuleInterop=true \\\n  -I proto \\\n  proto/path/to/file.proto\n```\n\n- TypeScript via `@protobuf-ts/plugin`:\n\n```bash\nnpx protoc --ts_out gen/ts --proto_path proto proto/path/to/file.proto\n```\n\n## Output expectations\n\n- Deliver the requested `.proto` file(s) and a short note on compatibility choices.\n- Explicitly call out any use of proto2-only/proto3-only features.\n- Include exact generation commands for the selected Rust and TypeScript toolchains.\n",
                  "additions": 12,
                  "deletions": 0
                }
              ],
              "diagnostics": {},
              "truncated": false
            },
            "time": {
              "start": 1771213497922,
              "end": 1771213497942
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_0d0ae22f7be70d5101699292b5eda481978ac4ea43235b4a7b"
            }
          },
          "id": "prt_c648d16e7001DkgUlwGwE4WOWq",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648cfb9e001vTXCA7JpFmDwvR"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "689b71acce0a09b1c69553864f5e86d1fe8cb76f",
          "cost": 0,
          "tokens": {
            "total": 117290,
            "input": 2807,
            "output": 307,
            "reasoning": 14,
            "cache": {
              "read": 114176,
              "write": 0
            }
          },
          "id": "prt_c648d2658001QsfqyPLOau4E5l",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648cfb9e001vTXCA7JpFmDwvR"
        },
        {
          "type": "patch",
          "hash": "6fb77aae5b3312bd8dda6d40d22b34a2aaf81514",
          "files": [
            "/Users/alex/repos/vfp/dark-factory/.opencode/skills/protobuf-schema-authoring/SKILL.md"
          ],
          "id": "prt_c648d26880016H0FTxHcIt3FA3",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648cfb9e001vTXCA7JpFmDwvR"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771213498003,
          "completed": 1771213502972
        },
        "parentID": "msg_c648bfd6d001GV4FuhQmsmhQe3",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 117444,
          "input": 203,
          "output": 121,
          "reasoning": 11,
          "cache": {
            "read": 117120,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "tool-calls",
        "id": "msg_c648d2693001hGafoqTo12B2To",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "689b71acce0a09b1c69553864f5e86d1fe8cb76f",
          "id": "prt_c648d2f72001u0bHrJ4yLBbo3G",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648d2693001hGafoqTo12B2To"
        },
        {
          "type": "reasoning",
          "text": "**Checking file reading approach**",
          "metadata": {
            "openai": {
              "itemId": "rs_0b2928177f3b0ab801699292bcebc08194a2d41a5cac35e04a",
              "reasoningEncryptedContent": "gAAAAABpkpK-fqXRh-222-NHD70TJrloF2VGPNi3penkr4PRabYWUMqRyeS59fcgaIU2gsdTK2qh2ek992x1dr4vXoYGTjguA_c1XAYFV59s4WNxZWC5Y1boqvFTUjUElTwiGCM3ZP89k3F8gPTN9g1BPLxFqRFbRgUweRMRrgYxnMGihO17l-3GdSSUvALa9KZlKTHkfmhlFx9jq0hEAQjqnw1-ToIjLsgjkoeIbGRBH9oK17akViT81v96rqPxHT0tj1w4XahFeY_oRcNlHQuteVQrqLrXXN0ysNVek7_ZCBtECqaV5JiKAOa_l9SlbZ4OJ16Pau7E9dkstFqno71g5x1uEcmdwbdTfliXPhiVeB2ovPYJjhKapaXaC9mOSWzASkl1BWVFE02KFDWI2ab4FHKuKhH9ltHCNlgprn18cM6IKs323TD7pMkF9WdZerrThPQGVBtSHyFkF5WjKjsYFqxua7tk58pBbL2qYpWWMbAXtaVupwawujPgDD6aBW6RY3AnAeQYvIq3rt8m1rEDSxn9II_Y85zmLBbyFBv5hEz9cF2JNrSH-bUmP5N7M3R7qZ_JKzX8y7RtOiRxijB8EtZU8bZNg0PfQoSNd8x7mHNG-1SB879XPLMxXaZwFk1WWY9APYxvrJqzbjCCY8CbdGMxXMzdO4cYbUtuU8T0YPIx2IRm4HU2fGskP1vQ7apRV3_HOMTJhGYepifvZqdS1sJ6T_K-0AUq5LFua6-Y0zsqOZa9fGDxKnhrLlgD0-Q-POkJh6_AQqBX9-q9MKQ0mK3njooDsgCnbSjSIhNosqnp_p5GLD0S8Dua9W9phB0BEEHMAC3xVzWi9h85OKFmU31nC00U3hXVBosvjCpA3ax6mKdmPWBFN0Oq-d403nV2bOVRm4vm"
            }
          },
          "time": {
            "start": 1771213500951,
            "end": 1771213502759
          },
          "id": "prt_c648d3217001Jgxkiv06a67fki",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648d2693001hGafoqTo12B2To"
        },
        {
          "type": "tool",
          "callID": "call_YICRQy8JlRzoP07zNJKnYGXi",
          "tool": "read",
          "state": {
            "status": "completed",
            "input": {
              "filePath": "/Users/alex/repos/vfp/dark-factory/.opencode/skills/protobuf-schema-authoring/SKILL.md"
            },
            "output": "<path>/Users/alex/repos/vfp/dark-factory/.opencode/skills/protobuf-schema-authoring/SKILL.md</path>\n<type>file</type>\n<content>1: ---\n2: name: protobuf-schema-authoring\n3: description: Author proto2/proto3 schemas and provide protoc generation workflows for Rust and TypeScript.\n4: ---\n5: \n6: ## What I do\n7: \n8: - Turn user requirements into clear, evolvable `.proto` schemas.\n9: - Support both `proto2` and `proto3` syntax.\n10: - Ask for syntax preference when not explicitly provided, and explain version-specific constraints.\n11: - Provide practical `protoc` workflows for Rust and TypeScript.\n12: - Use the full type/layout reference in `docs/readmes/protobuf-schema-research.md`.\n13: \n14: ## When to use me\n15: \n16: Use this when the task includes any of the following:\n17: \n18: - Create a new protobuf schema from product or API requirements.\n19: - Update an existing `.proto` safely.\n20: - Explain if a feature is `proto2`-only or `proto3`-only.\n21: - Generate Rust or TypeScript artifacts from `.proto` files.\n22: \n23: ## Required clarification flow\n24: \n25: If not already specified, ask these in order:\n26: \n27: 1. Which schema syntax should be used: `proto2` or `proto3`?\n28:    - Recommended default: `proto3` with explicit `optional` on scalar fields when presence matters.\n29: 2. For TypeScript generation, which plugin should be targeted: `ts-proto` or `@protobuf-ts/plugin`?\n30:    - Recommended default: `ts-proto`.\n31: \n32: When answering, always note version-specific features involved in the request.\n33: \n34: ## Proto2 vs proto3 guardrails\n35: \n36: - `required` fields are proto2-only and should be avoided for new design.\n37: - Explicit scalar defaults (`[default = ...]`) are proto2-only.\n38: - Extensions are proto2-oriented; not a general proto3 field pattern.\n39: - Groups are deprecated legacy proto2 and should not be introduced.\n40: - Proto3 enums must start with a zero-valued first entry.\n41: - Proto3 scalar presence should use `optional` when presence semantics are needed.\n42: - Repeated scalar numerics are packed-by-default in proto3; in proto2, use `[packed = true]` for new fields.\n43: \n44: ## Complete reference location\n45: \n46: Use `docs/readmes/protobuf-schema-research.md` as the canonical in-repo reference for:\n47: \n48: - Complete valid scalar type list and non-scalar type forms.\n49: - Full schema definition layout (top-level, message, enum, service).\n50: - Proto2 and proto3 boilerplate templates.\n51: - Wire constraints and field numbering guardrails.\n52: \n53: When drafting schemas, follow that reference and include only the subset needed for the user request.\n54: \n55: ## Schema authoring workflow\n56: \n57: 1. Confirm syntax version and target language outputs.\n58: 2. Propose package and file layout.\n59: 3. Define messages/enums/services with stable field numbering.\n60: 4. Add comments only where semantics are non-obvious.\n61: 5. Reserve removed field numbers and names.\n62: 6. Validate with `protoc` descriptor output when possible.\n63: 7. Provide generation commands for Rust and TypeScript.\n64: \n65: ## Command templates\n66: \n67: - Validate schema and emit descriptor:\n68: \n69: ```bash\n70: protoc -I proto --include_imports --descriptor_set_out=gen/schema.pb proto/path/to/file.proto\n71: ```\n72: \n73: - Rust via `prost-build` (`build.rs`):\n74: \n75: ```rust\n76: fn main() -> std::io::Result<()> {\n77:     prost_build::compile_protos(&[\"proto/service.proto\"], &[\"proto\"])?;\n78:     Ok(())\n79: }\n80: ```\n81: \n82: - Rust via `tonic-prost-build` (`build.rs`):\n83: \n84: ```rust\n85: fn main() {\n86:     tonic_prost_build::configure()\n87:         .compile_protos(&[\"proto/service.proto\"], &[\"proto\"])\n88:         .unwrap();\n89: }\n90: ```\n91: \n92: - TypeScript via `ts-proto`:\n93: \n94: ```bash\n95: protoc \\\n96:   --plugin=./node_modules/.bin/protoc-gen-ts_proto \\\n97:   --ts_proto_out=gen/ts \\\n98:   --ts_proto_opt=esModuleInterop=true \\\n99:   -I proto \\\n100:   proto/path/to/file.proto\n101: ```\n102: \n103: - TypeScript via `@protobuf-ts/plugin`:\n104: \n105: ```bash\n106: npx protoc --ts_out gen/ts --proto_path proto proto/path/to/file.proto\n107: ```\n108: \n109: ## Output expectations\n110: \n111: - Deliver the requested `.proto` file(s) and a short note on compatibility choices.\n112: - Explicitly call out any use of proto2-only/proto3-only features.\n113: - Include exact generation commands for the selected Rust and TypeScript toolchains.\n114: \n\n(End of file - total 114 lines)\n</content>",
            "title": ".opencode/skills/protobuf-schema-authoring/SKILL.md",
            "metadata": {
              "preview": "---\nname: protobuf-schema-authoring\ndescription: Author proto2/proto3 schemas and provide protoc generation workflows for Rust and TypeScript.\n---\n\n## What I do\n\n- Turn user requirements into clear, evolvable `.proto` schemas.\n- Support both `proto2` and `proto3` syntax.\n- Ask for syntax preference when not explicitly provided, and explain version-specific constraints.\n- Provide practical `protoc` workflows for Rust and TypeScript.\n- Use the full type/layout reference in `docs/readmes/protobuf-schema-research.md`.\n\n## When to use me\n\nUse this when the task includes any of the following:\n\n- Create a new protobuf schema from product or API requirements.\n- Update an existing `.proto` safely.\n- Explain if a feature is `proto2`-only or `proto3`-only.",
              "truncated": false,
              "loaded": []
            },
            "time": {
              "start": 1771213502799,
              "end": 1771213502816
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_0b2928177f3b0ab801699292beb7748194bb9392d4c0ea3dcb"
            }
          },
          "id": "prt_c648d392a001QwYK32EarD6XpS",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648d2693001hGafoqTo12B2To"
        },
        {
          "type": "tool",
          "callID": "call_PeirTw6O39PhREYHRMcMINUL",
          "tool": "grep",
          "state": {
            "status": "completed",
            "input": {
              "pattern": "Complete valid type list|Complete schema definition layout|Boilerplate templates",
              "path": "/Users/alex/repos/vfp/dark-factory/docs/readmes/protobuf-schema-research.md"
            },
            "output": "Found 3 matches\n/Users/alex/repos/vfp/dark-factory/docs/readmes/protobuf-schema-research.md:\n  Line 57: ## Complete valid type list\n  Line 96: ## Complete schema definition layout (reference)\n  Line 151: ## Boilerplate templates",
            "title": "Complete valid type list|Complete schema definition layout|Boilerplate templates",
            "metadata": {
              "matches": 3,
              "truncated": false
            },
            "time": {
              "start": 1771213502815,
              "end": 1771213502839
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_0b2928177f3b0ab801699292beb7848194a7516ec4af0e215f"
            }
          },
          "id": "prt_c648d3955001Swkeyqyx3uOpbi",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648d2693001hGafoqTo12B2To"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "689b71acce0a09b1c69553864f5e86d1fe8cb76f",
          "cost": 0,
          "tokens": {
            "total": 117444,
            "input": 203,
            "output": 121,
            "reasoning": 11,
            "cache": {
              "read": 117120,
              "write": 0
            }
          },
          "id": "prt_c648d39b10013O2xNWGSYOcCqh",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648d2693001hGafoqTo12B2To"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771213502979,
          "completed": 1771213512269
        },
        "parentID": "msg_c648bfd6d001GV4FuhQmsmhQe3",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 119158,
          "input": 1473,
          "output": 437,
          "reasoning": 241,
          "cache": {
            "read": 117248,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "stop",
        "id": "msg_c648d3a03001saQHv6HBpXm9JW",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "689b71acce0a09b1c69553864f5e86d1fe8cb76f",
          "id": "prt_c648d430a0013JtJkjmhA9hADj",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648d3a03001saQHv6HBpXm9JW"
        },
        {
          "type": "reasoning",
          "text": "**Summarizing proto field types update**\n\nAdded complete proto field types list by reference in skill; expanded research doc with this full list covering scalar types, map keys, non-scalars, top-level enums/messages/services, proto2/proto3 templates, and wire constraints. Referenced relevant file paths (without line ranges) where added; no other files changed beyond those previously noted. Suggested if the user prefers, the list can be copied directly into the skill instead of referencing. Next steps: 1) review changes, 2) optionally commit with git, 3) proceed with further integration or testing.",
          "metadata": {
            "openai": {
              "itemId": "rs_0d63aeed4bd11a9e01699292c17eb48197af0a6d0506c98b71",
              "reasoningEncryptedContent": "gAAAAABpkpLHr7Ck36h0Fsqh7SYxIo9pp6XJ1lyrQUYHkGipS3-hb5x13YgSMAqUMjSJJRTEfhoU1yAHZteC0nfXwpZ1_l5Qlu-L3dr2htbRf-H1BYngVn4yZr2PVh1zZkGJGNpG12vH9sa8YrDETp6rYqJ672jvJg1kRGUOyZJcoDxKvEp7C2bYNKJlfMpyYHPBt9D0OAtQ6zoSC1GU7MY5jvNqvrPrIPBAnFAZttJwqplNKqmdQixtal9um_aaZuP3YhhGTkCQlLqdoVRLjcW423VLzFJEv9ixJREa7oJDZ4dWDKepqUXvETfpAG17eca8CtvZfUYYJxHxPEornYpqHTxKbi54Iy07PH41QCia1UcSLMz9omBRH50VqkFQN1PfrXzbEJXFxsK1DTtLk7yykXhMHbayNUH3j6uhz1ctSdIODx5wXcYPnU87avUD1jWUn26_2Q9KuupG6TJpNikuFaLutVC5J74g9JDdtoyQGjlLe60sg3TJ2QiVI0ZO2Ro9LGBvsR0Ms4bOVw8U5bQPaWhQrDHKuSla5OQn5qfWC9y6wnYRelpipkM5PdVrIR1zKYB-9tcOZWGiMV8f7lsPd2Po5J43wJbv3cIWHOJatE1XAbJumz90Mney93ti6lgIrsBhMmKhwtpjhj2pbfVCCQpu7WOGe8eobHb3mlrCdf2OOG8mupYumQ4AlNSKZKKaP1N84ecqwTQw-kBaA8RoMMCtySei3UBXezd-yNZ-Xn5Y95kzBeJ_jhF9lJsQ4VeeAcgKgWilbgQUOzHchGGvFyWVjUfsk99-7aPs9wxIQG5fOYrFQst503TTcIyO6aw0vops9fIdyQWj3RMdUNYQSGsnh3sIRPrHBeO7yHAlfcJ30owtoFiWT43_JCLdOvInQjPladqOLzf4TNJhfsyVMF7_46Wqrp_5NG27tOXisJHH-cEpV7yKr-d5MXqy_1M6xGVTOQXNBqEDhs9JXIbD-o9fZZwejzX-azhFe7mnpBEm0T6umFirS4h5FJ6tHIecBygXQM9Y-vqzY0suQC_ek4xriNvPAgRYoV3-BgrmHnCYfMEdzANfgvjaavVBZFwGL9p0cnz5MhR2lZ8HNw9adcFiQKYr3kX2XxC-xvYNnysSYzh1z6BqZHNm1z0ESKmxwIeiC85tMUekcUDF7bRFebF6l_bFZt9SM5a9J0sULohtGDrIwquKzo1FpMiJ-n4GSZgo-Jo-BM5e7oYNE6MBs54Q8eQ0RNjclSRXBU7D93JyUR0k3SqoWNanSd7o06MTAWDhIUr9v4h7HlYmRsFFr6uGz8Cy2sOtCTeraK3se-pX1-0qkwdKQNfGHOUDxZAw2NvB5-liQPxBrJTK5Sbs_sYESBFIX4GRdv2vwQlR9zE4YlrbXma0sYQt_uviOaZpmE823wkKyC5iuVHlopQ0WUVObFLyxORamwLPzxhg2DG8KOir8IdN5Jmo8SOLxOcvfLC1-tXE_C9DCYjHwFXrluaixizx7V28YnPcKrq9YuBIDSJ3qsG1qeuAGmP0e_Puy5OlfRHXYBTS9s0OYjxZly_JVY_HFK2kbxrJRNSczqSVqeH0VITQ5cxdB3Z5nBdSGuVTExNSX4s0MaqWaxYfnrGrmAnJq4SK2ejRsKsg10BCRAab8os8eNvxhkOonD0X-r3yAyZziC-otdNfmS3ZAlKqlnNl8Ihdm8wyzhvudAacL1WliNu1sh8mJU0P5LpWJcosl7fSehSST71CYhSMeGtiJ-W9-JnfdKA941tBt_9VhndjOp_0z5RkDLrG4E-uLucwX91pfpp3ANASOY5xs1z36VD2EjVJv586uS8ZJLXPP8ndjEZcUr9qtpO9rHbeJonogRILS9_f942O1Yei65zX8i6Al2v21E9Gzsf473cdsXrgDkbmx2FUfATx6YXKHA1Ybznaoe9x2A3YNIGqJ0uHtG6l12hPJK5OorChIBs42tOUckQH0L-EZiNeWLke6al0pcB_Fy-n4g-9a2VMd_1hWfpcRLNXXVZ5r_G7hFGEwKy4Ys8n8Jt1r_FlBjDgfdR_7mgNMVLE-iuVcS7AJLnqJBAB98UJOKv-qKepY5S-SW8c3R_vTzuGXNiiVdczB7aXqDSR5jp2JnpCWsn0CL35v1h4QS69JuW4yY30hZvZa-elc6QlAjkFdisn4V5oDaYJmlNxkZq7oPCmPMd_vD63CS5A_BSwPS-BAH6q6HmJNZIuVCt8mKmholct0sFBHznCF9jEXpVVHyz_eryW_Qg9CQxv_qLkR2RDUCkClhWJK1JDwj_SKvAL8jU2VmPQ70cQArkCJhoXxPeihr5IfvkRryB8CF1MjtovRmSMwjRDENklLbGgRAYVFyCZY5v9hBk3Kz28pSJhKiSNBcKYs3zqt01GRi-Q0BQI1VMvb21KqNoa6r4yBL9lm7cVursiYLp0_TBGxYyXnpaUjOFkOC3wx3d8MI8O_M-1NhDMoxu4oKktkutFa1FVHdYud_4mSCOsmqrKnlPkTtyCIrhD8Pf4oSJ4op5z6Q-8lPW_lA5dYv0-e1cDRd9NPqsNGgZ9IZSkoB60"
            }
          },
          "time": {
            "start": 1771213505604,
            "end": 1771213511217
          },
          "id": "prt_c648d4444001y083tcNpm337fx",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648d3a03001saQHv6HBpXm9JW"
        },
        {
          "type": "text",
          "text": "Done ‚Äî I added it via a canonical reference and linked it from the skill.\n\n- Updated `docs/readmes/protobuf-schema-research.md` with a complete protobuf reference:\n  - full valid scalar type list\n  - non-scalar forms (`message`, `enum`, `map`, `oneof`)\n  - map key/value constraints\n  - complete schema layout (top-level + message/enum/service bodies)\n  - proto2 and proto3 boilerplate templates\n  - numbering/wire constraints\n- Updated `.opencode/skills/protobuf-schema-authoring/SKILL.md` to explicitly use that doc as the canonical source for:\n  - valid types\n  - schema definition layout\n  - boilerplate templates\n  - guardrails\n\nIf you want, I can also inline the full type/layout list directly inside `.opencode/skills/protobuf-schema-authoring/SKILL.md` (duplicated, not just referenced).",
          "time": {
            "start": 1771213512204,
            "end": 1771213512204
          },
          "metadata": {
            "openai": {
              "itemId": "msg_0d63aeed4bd11a9e01699292c72d5c819780d5a463136f3d25"
            }
          },
          "id": "prt_c648d5a32001AoWG3ecjPdFJqO",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648d3a03001saQHv6HBpXm9JW"
        },
        {
          "type": "step-finish",
          "reason": "stop",
          "snapshot": "689b71acce0a09b1c69553864f5e86d1fe8cb76f",
          "cost": 0,
          "tokens": {
            "total": 119158,
            "input": 1473,
            "output": 437,
            "reasoning": 241,
            "cache": {
              "read": 117248,
              "write": 0
            }
          },
          "id": "prt_c648d5e180014c4tzwvGOR5JFF",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648d3a03001saQHv6HBpXm9JW"
        }
      ]
    },
    {
      "info": {
        "role": "user",
        "time": {
          "created": 1771213518918
        },
        "summary": {
          "title": "Brief affirmative reply prompt",
          "diffs": [
            {
              "file": ".opencode/skills/protobuf-schema-authoring/SKILL.md",
              "before": "---\nname: protobuf-schema-authoring\ndescription: Author proto2/proto3 schemas and provide protoc generation workflows for Rust and TypeScript.\n---\n\n## What I do\n\n- Turn user requirements into clear, evolvable `.proto` schemas.\n- Support both `proto2` and `proto3` syntax.\n- Ask for syntax preference when not explicitly provided, and explain version-specific constraints.\n- Provide practical `protoc` workflows for Rust and TypeScript.\n- Use the full type/layout reference in `docs/readmes/protobuf-schema-research.md`.\n\n## When to use me\n\nUse this when the task includes any of the following:\n\n- Create a new protobuf schema from product or API requirements.\n- Update an existing `.proto` safely.\n- Explain if a feature is `proto2`-only or `proto3`-only.\n- Generate Rust or TypeScript artifacts from `.proto` files.\n\n## Required clarification flow\n\nIf not already specified, ask these in order:\n\n1. Which schema syntax should be used: `proto2` or `proto3`?\n   - Recommended default: `proto3` with explicit `optional` on scalar fields when presence matters.\n2. For TypeScript generation, which plugin should be targeted: `ts-proto` or `@protobuf-ts/plugin`?\n   - Recommended default: `ts-proto`.\n\nWhen answering, always note version-specific features involved in the request.\n\n## Proto2 vs proto3 guardrails\n\n- `required` fields are proto2-only and should be avoided for new design.\n- Explicit scalar defaults (`[default = ...]`) are proto2-only.\n- Extensions are proto2-oriented; not a general proto3 field pattern.\n- Groups are deprecated legacy proto2 and should not be introduced.\n- Proto3 enums must start with a zero-valued first entry.\n- Proto3 scalar presence should use `optional` when presence semantics are needed.\n- Repeated scalar numerics are packed-by-default in proto3; in proto2, use `[packed = true]` for new fields.\n\n## Complete reference location\n\nUse `docs/readmes/protobuf-schema-research.md` as the canonical in-repo reference for:\n\n- Complete valid scalar type list and non-scalar type forms.\n- Full schema definition layout (top-level, message, enum, service).\n- Proto2 and proto3 boilerplate templates.\n- Wire constraints and field numbering guardrails.\n\nWhen drafting schemas, follow that reference and include only the subset needed for the user request.\n\n## Schema authoring workflow\n\n1. Confirm syntax version and target language outputs.\n2. Propose package and file layout.\n3. Define messages/enums/services with stable field numbering.\n4. Add comments only where semantics are non-obvious.\n5. Reserve removed field numbers and names.\n6. Validate with `protoc` descriptor output when possible.\n7. Provide generation commands for Rust and TypeScript.\n\n## Command templates\n\n- Validate schema and emit descriptor:\n\n```bash\nprotoc -I proto --include_imports --descriptor_set_out=gen/schema.pb proto/path/to/file.proto\n```\n\n- Rust via `prost-build` (`build.rs`):\n\n```rust\nfn main() -> std::io::Result<()> {\n    prost_build::compile_protos(&[\"proto/service.proto\"], &[\"proto\"])?;\n    Ok(())\n}\n```\n\n- Rust via `tonic-prost-build` (`build.rs`):\n\n```rust\nfn main() {\n    tonic_prost_build::configure()\n        .compile_protos(&[\"proto/service.proto\"], &[\"proto\"])\n        .unwrap();\n}\n```\n\n- TypeScript via `ts-proto`:\n\n```bash\nprotoc \\\n  --plugin=./node_modules/.bin/protoc-gen-ts_proto \\\n  --ts_proto_out=gen/ts \\\n  --ts_proto_opt=esModuleInterop=true \\\n  -I proto \\\n  proto/path/to/file.proto\n```\n\n- TypeScript via `@protobuf-ts/plugin`:\n\n```bash\nnpx protoc --ts_out gen/ts --proto_path proto proto/path/to/file.proto\n```\n\n## Output expectations\n\n- Deliver the requested `.proto` file(s) and a short note on compatibility choices.\n- Explicitly call out any use of proto2-only/proto3-only features.\n- Include exact generation commands for the selected Rust and TypeScript toolchains.\n",
              "after": "---\nname: protobuf-schema-authoring\ndescription: Author proto2/proto3 schemas and provide protoc generation workflows for Rust and TypeScript.\n---\n\n## What I do\n\n- Turn user requirements into clear, evolvable `.proto` schemas.\n- Support both `proto2` and `proto3` syntax.\n- Ask for syntax preference when not explicitly provided, and explain version-specific constraints.\n- Provide practical `protoc` workflows for Rust and TypeScript.\n- Use the full type/layout reference in `docs/readmes/protobuf-schema-research.md`.\n\n## When to use me\n\nUse this when the task includes any of the following:\n\n- Create a new protobuf schema from product or API requirements.\n- Update an existing `.proto` safely.\n- Explain if a feature is `proto2`-only or `proto3`-only.\n- Generate Rust or TypeScript artifacts from `.proto` files.\n\n## Required clarification flow\n\nIf not already specified, ask these in order:\n\n1. Which schema syntax should be used: `proto2` or `proto3`?\n   - Recommended default: `proto3` with explicit `optional` on scalar fields when presence matters.\n2. For TypeScript generation, which plugin should be targeted: `ts-proto` or `@protobuf-ts/plugin`?\n   - Recommended default: `ts-proto`.\n\nWhen answering, always note version-specific features involved in the request.\n\n## Proto2 vs proto3 guardrails\n\n- `required` fields are proto2-only and should be avoided for new design.\n- Explicit scalar defaults (`[default = ...]`) are proto2-only.\n- Extensions are proto2-oriented; not a general proto3 field pattern.\n- Groups are deprecated legacy proto2 and should not be introduced.\n- Proto3 enums must start with a zero-valued first entry.\n- Proto3 scalar presence should use `optional` when presence semantics are needed.\n- Repeated scalar numerics are packed-by-default in proto3; in proto2, use `[packed = true]` for new fields.\n\n## Complete valid type reference (inline)\n\n### Scalar field types\n\n- `double`\n- `float`\n- `int32`\n- `int64`\n- `uint32`\n- `uint64`\n- `sint32`\n- `sint64`\n- `fixed32`\n- `fixed64`\n- `sfixed32`\n- `sfixed64`\n- `bool`\n- `string`\n- `bytes`\n\n### Non-scalar forms\n\n- Message type fields (local or imported), for example `my.pkg.User`.\n- Enum type fields (local or imported).\n- `map<K, V>` fields.\n  - Valid map key types: `int32`, `int64`, `uint32`, `uint64`, `sint32`, `sint64`, `fixed32`, `fixed64`, `sfixed32`, `sfixed64`, `bool`, `string`.\n  - Map value types: scalar, enum, or message.\n- `oneof` blocks.\n\n## Complete schema layout reference (inline)\n\n### Top-level statements\n\n- `syntax = \"proto2\";` or `syntax = \"proto3\";` (first non-comment line)\n- `package ...;`\n- `import \"...\";`, `import public \"...\";`, `import weak \"...\";`\n- `option ... = ...;`\n- `message ... { ... }`\n- `enum ... { ... }`\n- `service ... { ... }`\n- `extend ... { ... }`\n\n### Message body statements\n\n- Field declarations (`optional`/`required`/`repeated` in proto2; `optional`/implicit/repeated in proto3)\n- `oneof ... { ... }`\n- `map<K, V> ... = N;`\n- Nested `message` and nested `enum`\n- `reserved ...;`\n- `option ... = ...;`\n- `extensions ...;` (proto2)\n- `group` (deprecated legacy proto2)\n- `extend ... { ... }`\n\n### Enum body statements\n\n- Enum values: `NAME = N;`\n- Enum options (for example `option allow_alias = true;`)\n- `reserved ...;`\n\n### Service body statements\n\n- `rpc Method(Request) returns (Response);`\n- `rpc Stream(stream Request) returns (stream Response);`\n- Method options blocks on RPC definitions.\n\n## Boilerplate stubs (inline)\n\n### Proto3 starter\n\n```proto\nsyntax = \"proto3\";\n\npackage example.v1;\n\nimport \"google/protobuf/timestamp.proto\";\n\nmessage Resource {\n  optional string display_name = 1;\n  string id = 2;\n  google.protobuf.Timestamp created_at = 3;\n  map<string, string> labels = 4;\n\n  oneof owner {\n    string user_id = 5;\n    string team_id = 6;\n  }\n\n  reserved 7;\n  reserved \"legacy_id\";\n}\n\nenum ResourceState {\n  RESOURCE_STATE_UNSPECIFIED = 0;\n  RESOURCE_STATE_ACTIVE = 1;\n}\n\nservice ResourceService {\n  rpc GetResource(GetResourceRequest) returns (GetResourceResponse);\n}\n\nmessage GetResourceRequest {\n  string id = 1;\n}\n\nmessage GetResourceResponse {\n  Resource resource = 1;\n}\n```\n\n### Proto2 starter\n\n```proto\nsyntax = \"proto2\";\n\npackage example.v1;\n\nmessage Resource {\n  optional string display_name = 1 [default = \"unknown\"];\n  optional string id = 2;\n  repeated string tags = 3;\n\n  extensions 100 to max;\n\n  reserved 4;\n  reserved \"legacy_id\";\n}\n\nenum ResourceState {\n  RESOURCE_STATE_UNSPECIFIED = 0;\n  RESOURCE_STATE_ACTIVE = 1;\n}\n\nextend Resource {\n  optional string external_profile = 100;\n}\n```\n\n## Complete reference location\n\nUse `docs/readmes/protobuf-schema-research.md` as the canonical in-repo reference for:\n\n- Complete valid scalar type list and non-scalar type forms.\n- Full schema definition layout (top-level, message, enum, service).\n- Proto2 and proto3 boilerplate templates.\n- Wire constraints and field numbering guardrails.\n\nWhen drafting schemas, follow that reference and include only the subset needed for the user request.\n\n## Schema authoring workflow\n\n1. Confirm syntax version and target language outputs.\n2. Propose package and file layout.\n3. Define messages/enums/services with stable field numbering.\n4. Add comments only where semantics are non-obvious.\n5. Reserve removed field numbers and names.\n6. Validate with `protoc` descriptor output when possible.\n7. Provide generation commands for Rust and TypeScript.\n\n## Command templates\n\n- Validate schema and emit descriptor:\n\n```bash\nprotoc -I proto --include_imports --descriptor_set_out=gen/schema.pb proto/path/to/file.proto\n```\n\n- Rust via `prost-build` (`build.rs`):\n\n```rust\nfn main() -> std::io::Result<()> {\n    prost_build::compile_protos(&[\"proto/service.proto\"], &[\"proto\"])?;\n    Ok(())\n}\n```\n\n- Rust via `tonic-prost-build` (`build.rs`):\n\n```rust\nfn main() {\n    tonic_prost_build::configure()\n        .compile_protos(&[\"proto/service.proto\"], &[\"proto\"])\n        .unwrap();\n}\n```\n\n- TypeScript via `ts-proto`:\n\n```bash\nprotoc \\\n  --plugin=./node_modules/.bin/protoc-gen-ts_proto \\\n  --ts_proto_out=gen/ts \\\n  --ts_proto_opt=esModuleInterop=true \\\n  -I proto \\\n  proto/path/to/file.proto\n```\n\n- TypeScript via `@protobuf-ts/plugin`:\n\n```bash\nnpx protoc --ts_out gen/ts --proto_path proto proto/path/to/file.proto\n```\n\n## Output expectations\n\n- Deliver the requested `.proto` file(s) and a short note on compatibility choices.\n- Explicitly call out any use of proto2-only/proto3-only features.\n- Include exact generation commands for the selected Rust and TypeScript toolchains.\n",
              "additions": 138,
              "deletions": 0,
              "status": "modified"
            }
          ]
        },
        "agent": "build",
        "model": {
          "providerID": "openai",
          "modelID": "gpt-5.3-codex"
        },
        "variant": "high",
        "id": "msg_c648d7841001uj74J30rDC55TU",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "text",
          "text": "yes please",
          "id": "prt_c648d7841002ENqfxU9Rla7bzG",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648d7841001uj74J30rDC55TU"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771213518924,
          "completed": 1771213540712
        },
        "parentID": "msg_c648d7841001uj74J30rDC55TU",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 118035,
          "input": 3566,
          "output": 1317,
          "reasoning": 186,
          "cache": {
            "read": 113152,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "tool-calls",
        "id": "msg_c648d784c0019ABdCN42MajDoh",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "689b71acce0a09b1c69553864f5e86d1fe8cb76f",
          "id": "prt_c648d8174001MIoncJLxdTQ1FN",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648d784c0019ABdCN42MajDoh"
        },
        {
          "type": "reasoning",
          "text": "**Patching skill with inline reference lists**",
          "metadata": {
            "openai": {
              "itemId": "rs_0e7bb8a5c575dca901699292d1dec88193a0cbd6003b70ae45",
              "reasoningEncryptedContent": "gAAAAABpkpLV4fIziP1NcKm1zOVdfgqzjxIak87qXsJkX7_JZ2-edtaXJunnORzjp4EKlkYJ22yflDWjB5QU_30E5ZQ5RT8rL20t5uX1k9Y-aEhGPFEREetrYlT2DDufyEesY8HiKIqlDdC-Tr_TLiRXY9QDnIu5EfLC6Tt4B4GRWjpK_mFUhUfzuI6b-jm26LN4I2J8YKEkHraCW4Kxd8b9-7LTItN7GDJSZ9Xl7vozjVpOyYCA0BB0j6zGfSMAS7lfZQ9p3YqObx5gaGwr_Xxn29URxbO0pb0Ij3BWGzzSkejnbfO3UJzCnLG0BZ5_oKIB4Q8K4FodU_4DDRLG6hNNcgfgGfKJo0BpyQbCq278-TeweIRCya2e4dek6GcYroI5q-iz3QkOvNnw2kcCMbHtPI16wtAVp03Kw-lejypRw9Nz571iE-KFMVal5Szb0a__ZoRK6TcFx350nN5kkFJQrj_8bOwwVb9Ca_f6fK9-7SyQgqXaoPjDeD12WRmihC06fokwUxt9TqEAyG-e79hZvPB4D6UfiDE9ICGJlYXfYPyHu65CJFxxqR2slHbb5GLvH60V8jstvvrrx8E-0zoHQvy1WjOjQYkc46NlajdL7-itj-_hCTd88vpdZZt9lKTJmV4VkP8fPfdMHgbtx_KUQkYLTmn62HvqZuvOgvrna9HllSF2US5O8CWx7l9DZ8LrFm3UwxPuOA9LEUgrcjYapja0aaModpyVHBdFZczrIPysP3kKHDdsntrvw9PH8RyuwWGL1uBMtUxn_r1yvcvH3NPCY1wHB6y57UskqB2SEaFNxSES-4xkYviRqQPC-N6Q21a2HnODKn8jizjgNCwWq-jpY9eF-yeBJJ4hNaFPjYpKALwTzH0hVzzeZMyDqdYyd95q2lZCobZcI3rBjzg9TzE42gyNG3D256d8V3c-AucKKxroVoTBrIcX2FcZ9KYU2_-VV8S-1ABLIelFKNfERUOPkB3_vy0qxsvrlp5FLXsY-jgwRSglk2BsccykBrNkMDgdH54Yu80NZt6dpJMKW1zLzkmiTZcO76__Xd2Ean8Ibt0w1ms48eigxPgr6xNEjs6ZLkVXKBeezdUiyD5eExAQIFvDCeBa5DLWyk29wcw8jdtHYrY_W-Yp5QoWjBnkommzGsES7Gb0vzY0DlGU2KcfjsBxti_hw6Ayp4BHxVjJ_yjUS2oS5ejnJVwDm0rbV7EKbke6DjJQoWyweJRAG0uLKSAapb9FSiKd-1zxRXQpLsQJURSafUSfJI-9VHpMK3HbmReqcN2LjBRjHIAgcSL-oK5tMlPALLCLfh0xHpXc8khghfBiQWu7F6gZyzmgHXT4vQ89g3w2IJBFea53vbYZDGUF9DEGF7IF4-s-AMiYpQY_mzTSDPZNXubiK845uvSEf2EuJSQk9JsLLtRKtGdrSBX1h1ooWwGAeoRCRqG54Fxxd2yZCjlkzvbQLnC1MSaeiu7499U8IQoyjwTawL6IF6UOyBmt4h8r-r-0zxamg83Wu0ICDrjSxfN_5U-K1LLttp4L1sSk6AA8rg4YFrqpF5P5-WYsYFpA4UYHp_IKKdbUnINL_XZf4Gt45xZ6PGyD0Lkh2wjwdKsd4yVx5irH2IUdyYStX2s_i_JQk0v5Rq9ehcSfWxjp_uk7uLOH3Kg3rM6Mb1bqcKusM_N3arnL3Omgllr_HWvr_25-l1WCAq-t7KWQ_YUkg5ABWDFYlNpO97iLN-Hpg48ttSmelRV6t7uVGCNDwLOE3eYvuWNS3eewtPDEKOe29GNZqnnij0qwEFIc-uv7F6L6P0ctvnb-9EnZmenQDVtm6PwkX2TBWl2kw1y_TZRixYOE1EJwBLDHifg1FbrInxv4W85ho8qeB4p2VaoELD_F5-4YMpYg1VpAWCB_1jJv3IKGwF-Kgv4s_e0Z-kBCG5GuzXuDBqGQfErcX-HSpAqfJxiZFdwJ8nHdzJYgCw6X615YHGLGnPeWGrgic1cWJS03IKEft-RI3e8z1Yyx9JHuiI8gV6evKUhLKjrTVNFr9z1uB8VXKLeEdX2C"
            }
          },
          "time": {
            "start": 1771213521930,
            "end": 1771213525945
          },
          "id": "prt_c648d840a001mmn3FPNwwYdQIP",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648d784c0019ABdCN42MajDoh"
        },
        {
          "type": "tool",
          "callID": "call_lSyAGoF0AsNGmunYnFp4aN8Q",
          "tool": "apply_patch",
          "state": {
            "status": "completed",
            "input": {
              "patchText": "*** Begin Patch\n*** Update File: .opencode/skills/protobuf-schema-authoring/SKILL.md\n@@\n ## Proto2 vs proto3 guardrails\n@@\n - Proto3 scalar presence should use `optional` when presence semantics are needed.\n - Repeated scalar numerics are packed-by-default in proto3; in proto2, use `[packed = true]` for new fields.\n+\n+## Complete valid type reference (inline)\n+\n+### Scalar field types\n+\n+- `double`\n+- `float`\n+- `int32`\n+- `int64`\n+- `uint32`\n+- `uint64`\n+- `sint32`\n+- `sint64`\n+- `fixed32`\n+- `fixed64`\n+- `sfixed32`\n+- `sfixed64`\n+- `bool`\n+- `string`\n+- `bytes`\n+\n+### Non-scalar forms\n+\n+- Message type fields (local or imported), for example `my.pkg.User`.\n+- Enum type fields (local or imported).\n+- `map<K, V>` fields.\n+  - Valid map key types: `int32`, `int64`, `uint32`, `uint64`, `sint32`, `sint64`, `fixed32`, `fixed64`, `sfixed32`, `sfixed64`, `bool`, `string`.\n+  - Map value types: scalar, enum, or message.\n+- `oneof` blocks.\n+\n+## Complete schema layout reference (inline)\n+\n+### Top-level statements\n+\n+- `syntax = \"proto2\";` or `syntax = \"proto3\";` (first non-comment line)\n+- `package ...;`\n+- `import \"...\";`, `import public \"...\";`, `import weak \"...\";`\n+- `option ... = ...;`\n+- `message ... { ... }`\n+- `enum ... { ... }`\n+- `service ... { ... }`\n+- `extend ... { ... }`\n+\n+### Message body statements\n+\n+- Field declarations (`optional`/`required`/`repeated` in proto2; `optional`/implicit/repeated in proto3)\n+- `oneof ... { ... }`\n+- `map<K, V> ... = N;`\n+- Nested `message` and nested `enum`\n+- `reserved ...;`\n+- `option ... = ...;`\n+- `extensions ...;` (proto2)\n+- `group` (deprecated legacy proto2)\n+- `extend ... { ... }`\n+\n+### Enum body statements\n+\n+- Enum values: `NAME = N;`\n+- Enum options (for example `option allow_alias = true;`)\n+- `reserved ...;`\n+\n+### Service body statements\n+\n+- `rpc Method(Request) returns (Response);`\n+- `rpc Stream(stream Request) returns (stream Response);`\n+- Method options blocks on RPC definitions.\n+\n+## Boilerplate stubs (inline)\n+\n+### Proto3 starter\n+\n+```proto\n+syntax = \"proto3\";\n+\n+package example.v1;\n+\n+import \"google/protobuf/timestamp.proto\";\n+\n+message Resource {\n+  optional string display_name = 1;\n+  string id = 2;\n+  google.protobuf.Timestamp created_at = 3;\n+  map<string, string> labels = 4;\n+\n+  oneof owner {\n+    string user_id = 5;\n+    string team_id = 6;\n+  }\n+\n+  reserved 7;\n+  reserved \"legacy_id\";\n+}\n+\n+enum ResourceState {\n+  RESOURCE_STATE_UNSPECIFIED = 0;\n+  RESOURCE_STATE_ACTIVE = 1;\n+}\n+\n+service ResourceService {\n+  rpc GetResource(GetResourceRequest) returns (GetResourceResponse);\n+}\n+\n+message GetResourceRequest {\n+  string id = 1;\n+}\n+\n+message GetResourceResponse {\n+  Resource resource = 1;\n+}\n+```\n+\n+### Proto2 starter\n+\n+```proto\n+syntax = \"proto2\";\n+\n+package example.v1;\n+\n+message Resource {\n+  optional string display_name = 1 [default = \"unknown\"];\n+  optional string id = 2;\n+  repeated string tags = 3;\n+\n+  extensions 100 to max;\n+\n+  reserved 4;\n+  reserved \"legacy_id\";\n+}\n+\n+enum ResourceState {\n+  RESOURCE_STATE_UNSPECIFIED = 0;\n+  RESOURCE_STATE_ACTIVE = 1;\n+}\n+\n+extend Resource {\n+  optional string external_profile = 100;\n+}\n+```\n \n ## Complete reference location\n*** End Patch"
            },
            "output": "Success. Updated the following files:\nM .opencode/skills/protobuf-schema-authoring/SKILL.md",
            "title": "Success. Updated the following files:\nM .opencode/skills/protobuf-schema-authoring/SKILL.md",
            "metadata": {
              "diff": "Index: /Users/alex/repos/vfp/dark-factory/.opencode/skills/protobuf-schema-authoring/SKILL.md\n===================================================================\n--- /Users/alex/repos/vfp/dark-factory/.opencode/skills/protobuf-schema-authoring/SKILL.md\n+++ /Users/alex/repos/vfp/dark-factory/.opencode/skills/protobuf-schema-authoring/SKILL.md\n@@ -40,8 +40,146 @@\n - Proto3 enums must start with a zero-valued first entry.\n - Proto3 scalar presence should use `optional` when presence semantics are needed.\n - Repeated scalar numerics are packed-by-default in proto3; in proto2, use `[packed = true]` for new fields.\n \n+## Complete valid type reference (inline)\n+\n+### Scalar field types\n+\n+- `double`\n+- `float`\n+- `int32`\n+- `int64`\n+- `uint32`\n+- `uint64`\n+- `sint32`\n+- `sint64`\n+- `fixed32`\n+- `fixed64`\n+- `sfixed32`\n+- `sfixed64`\n+- `bool`\n+- `string`\n+- `bytes`\n+\n+### Non-scalar forms\n+\n+- Message type fields (local or imported), for example `my.pkg.User`.\n+- Enum type fields (local or imported).\n+- `map<K, V>` fields.\n+  - Valid map key types: `int32`, `int64`, `uint32`, `uint64`, `sint32`, `sint64`, `fixed32`, `fixed64`, `sfixed32`, `sfixed64`, `bool`, `string`.\n+  - Map value types: scalar, enum, or message.\n+- `oneof` blocks.\n+\n+## Complete schema layout reference (inline)\n+\n+### Top-level statements\n+\n+- `syntax = \"proto2\";` or `syntax = \"proto3\";` (first non-comment line)\n+- `package ...;`\n+- `import \"...\";`, `import public \"...\";`, `import weak \"...\";`\n+- `option ... = ...;`\n+- `message ... { ... }`\n+- `enum ... { ... }`\n+- `service ... { ... }`\n+- `extend ... { ... }`\n+\n+### Message body statements\n+\n+- Field declarations (`optional`/`required`/`repeated` in proto2; `optional`/implicit/repeated in proto3)\n+- `oneof ... { ... }`\n+- `map<K, V> ... = N;`\n+- Nested `message` and nested `enum`\n+- `reserved ...;`\n+- `option ... = ...;`\n+- `extensions ...;` (proto2)\n+- `group` (deprecated legacy proto2)\n+- `extend ... { ... }`\n+\n+### Enum body statements\n+\n+- Enum values: `NAME = N;`\n+- Enum options (for example `option allow_alias = true;`)\n+- `reserved ...;`\n+\n+### Service body statements\n+\n+- `rpc Method(Request) returns (Response);`\n+- `rpc Stream(stream Request) returns (stream Response);`\n+- Method options blocks on RPC definitions.\n+\n+## Boilerplate stubs (inline)\n+\n+### Proto3 starter\n+\n+```proto\n+syntax = \"proto3\";\n+\n+package example.v1;\n+\n+import \"google/protobuf/timestamp.proto\";\n+\n+message Resource {\n+  optional string display_name = 1;\n+  string id = 2;\n+  google.protobuf.Timestamp created_at = 3;\n+  map<string, string> labels = 4;\n+\n+  oneof owner {\n+    string user_id = 5;\n+    string team_id = 6;\n+  }\n+\n+  reserved 7;\n+  reserved \"legacy_id\";\n+}\n+\n+enum ResourceState {\n+  RESOURCE_STATE_UNSPECIFIED = 0;\n+  RESOURCE_STATE_ACTIVE = 1;\n+}\n+\n+service ResourceService {\n+  rpc GetResource(GetResourceRequest) returns (GetResourceResponse);\n+}\n+\n+message GetResourceRequest {\n+  string id = 1;\n+}\n+\n+message GetResourceResponse {\n+  Resource resource = 1;\n+}\n+```\n+\n+### Proto2 starter\n+\n+```proto\n+syntax = \"proto2\";\n+\n+package example.v1;\n+\n+message Resource {\n+  optional string display_name = 1 [default = \"unknown\"];\n+  optional string id = 2;\n+  repeated string tags = 3;\n+\n+  extensions 100 to max;\n+\n+  reserved 4;\n+  reserved \"legacy_id\";\n+}\n+\n+enum ResourceState {\n+  RESOURCE_STATE_UNSPECIFIED = 0;\n+  RESOURCE_STATE_ACTIVE = 1;\n+}\n+\n+extend Resource {\n+  optional string external_profile = 100;\n+}\n+```\n+\n ## Complete reference location\n \n Use `docs/readmes/protobuf-schema-research.md` as the canonical in-repo reference for:\n \n\n",
              "files": [
                {
                  "filePath": "/Users/alex/repos/vfp/dark-factory/.opencode/skills/protobuf-schema-authoring/SKILL.md",
                  "relativePath": ".opencode/skills/protobuf-schema-authoring/SKILL.md",
                  "type": "update",
                  "diff": "Index: /Users/alex/repos/vfp/dark-factory/.opencode/skills/protobuf-schema-authoring/SKILL.md\n===================================================================\n--- /Users/alex/repos/vfp/dark-factory/.opencode/skills/protobuf-schema-authoring/SKILL.md\n+++ /Users/alex/repos/vfp/dark-factory/.opencode/skills/protobuf-schema-authoring/SKILL.md\n@@ -40,8 +40,146 @@\n - Proto3 enums must start with a zero-valued first entry.\n - Proto3 scalar presence should use `optional` when presence semantics are needed.\n - Repeated scalar numerics are packed-by-default in proto3; in proto2, use `[packed = true]` for new fields.\n \n+## Complete valid type reference (inline)\n+\n+### Scalar field types\n+\n+- `double`\n+- `float`\n+- `int32`\n+- `int64`\n+- `uint32`\n+- `uint64`\n+- `sint32`\n+- `sint64`\n+- `fixed32`\n+- `fixed64`\n+- `sfixed32`\n+- `sfixed64`\n+- `bool`\n+- `string`\n+- `bytes`\n+\n+### Non-scalar forms\n+\n+- Message type fields (local or imported), for example `my.pkg.User`.\n+- Enum type fields (local or imported).\n+- `map<K, V>` fields.\n+  - Valid map key types: `int32`, `int64`, `uint32`, `uint64`, `sint32`, `sint64`, `fixed32`, `fixed64`, `sfixed32`, `sfixed64`, `bool`, `string`.\n+  - Map value types: scalar, enum, or message.\n+- `oneof` blocks.\n+\n+## Complete schema layout reference (inline)\n+\n+### Top-level statements\n+\n+- `syntax = \"proto2\";` or `syntax = \"proto3\";` (first non-comment line)\n+- `package ...;`\n+- `import \"...\";`, `import public \"...\";`, `import weak \"...\";`\n+- `option ... = ...;`\n+- `message ... { ... }`\n+- `enum ... { ... }`\n+- `service ... { ... }`\n+- `extend ... { ... }`\n+\n+### Message body statements\n+\n+- Field declarations (`optional`/`required`/`repeated` in proto2; `optional`/implicit/repeated in proto3)\n+- `oneof ... { ... }`\n+- `map<K, V> ... = N;`\n+- Nested `message` and nested `enum`\n+- `reserved ...;`\n+- `option ... = ...;`\n+- `extensions ...;` (proto2)\n+- `group` (deprecated legacy proto2)\n+- `extend ... { ... }`\n+\n+### Enum body statements\n+\n+- Enum values: `NAME = N;`\n+- Enum options (for example `option allow_alias = true;`)\n+- `reserved ...;`\n+\n+### Service body statements\n+\n+- `rpc Method(Request) returns (Response);`\n+- `rpc Stream(stream Request) returns (stream Response);`\n+- Method options blocks on RPC definitions.\n+\n+## Boilerplate stubs (inline)\n+\n+### Proto3 starter\n+\n+```proto\n+syntax = \"proto3\";\n+\n+package example.v1;\n+\n+import \"google/protobuf/timestamp.proto\";\n+\n+message Resource {\n+  optional string display_name = 1;\n+  string id = 2;\n+  google.protobuf.Timestamp created_at = 3;\n+  map<string, string> labels = 4;\n+\n+  oneof owner {\n+    string user_id = 5;\n+    string team_id = 6;\n+  }\n+\n+  reserved 7;\n+  reserved \"legacy_id\";\n+}\n+\n+enum ResourceState {\n+  RESOURCE_STATE_UNSPECIFIED = 0;\n+  RESOURCE_STATE_ACTIVE = 1;\n+}\n+\n+service ResourceService {\n+  rpc GetResource(GetResourceRequest) returns (GetResourceResponse);\n+}\n+\n+message GetResourceRequest {\n+  string id = 1;\n+}\n+\n+message GetResourceResponse {\n+  Resource resource = 1;\n+}\n+```\n+\n+### Proto2 starter\n+\n+```proto\n+syntax = \"proto2\";\n+\n+package example.v1;\n+\n+message Resource {\n+  optional string display_name = 1 [default = \"unknown\"];\n+  optional string id = 2;\n+  repeated string tags = 3;\n+\n+  extensions 100 to max;\n+\n+  reserved 4;\n+  reserved \"legacy_id\";\n+}\n+\n+enum ResourceState {\n+  RESOURCE_STATE_UNSPECIFIED = 0;\n+  RESOURCE_STATE_ACTIVE = 1;\n+}\n+\n+extend Resource {\n+  optional string external_profile = 100;\n+}\n+```\n+\n ## Complete reference location\n \n Use `docs/readmes/protobuf-schema-research.md` as the canonical in-repo reference for:\n \n",
                  "before": "---\nname: protobuf-schema-authoring\ndescription: Author proto2/proto3 schemas and provide protoc generation workflows for Rust and TypeScript.\n---\n\n## What I do\n\n- Turn user requirements into clear, evolvable `.proto` schemas.\n- Support both `proto2` and `proto3` syntax.\n- Ask for syntax preference when not explicitly provided, and explain version-specific constraints.\n- Provide practical `protoc` workflows for Rust and TypeScript.\n- Use the full type/layout reference in `docs/readmes/protobuf-schema-research.md`.\n\n## When to use me\n\nUse this when the task includes any of the following:\n\n- Create a new protobuf schema from product or API requirements.\n- Update an existing `.proto` safely.\n- Explain if a feature is `proto2`-only or `proto3`-only.\n- Generate Rust or TypeScript artifacts from `.proto` files.\n\n## Required clarification flow\n\nIf not already specified, ask these in order:\n\n1. Which schema syntax should be used: `proto2` or `proto3`?\n   - Recommended default: `proto3` with explicit `optional` on scalar fields when presence matters.\n2. For TypeScript generation, which plugin should be targeted: `ts-proto` or `@protobuf-ts/plugin`?\n   - Recommended default: `ts-proto`.\n\nWhen answering, always note version-specific features involved in the request.\n\n## Proto2 vs proto3 guardrails\n\n- `required` fields are proto2-only and should be avoided for new design.\n- Explicit scalar defaults (`[default = ...]`) are proto2-only.\n- Extensions are proto2-oriented; not a general proto3 field pattern.\n- Groups are deprecated legacy proto2 and should not be introduced.\n- Proto3 enums must start with a zero-valued first entry.\n- Proto3 scalar presence should use `optional` when presence semantics are needed.\n- Repeated scalar numerics are packed-by-default in proto3; in proto2, use `[packed = true]` for new fields.\n\n## Complete reference location\n\nUse `docs/readmes/protobuf-schema-research.md` as the canonical in-repo reference for:\n\n- Complete valid scalar type list and non-scalar type forms.\n- Full schema definition layout (top-level, message, enum, service).\n- Proto2 and proto3 boilerplate templates.\n- Wire constraints and field numbering guardrails.\n\nWhen drafting schemas, follow that reference and include only the subset needed for the user request.\n\n## Schema authoring workflow\n\n1. Confirm syntax version and target language outputs.\n2. Propose package and file layout.\n3. Define messages/enums/services with stable field numbering.\n4. Add comments only where semantics are non-obvious.\n5. Reserve removed field numbers and names.\n6. Validate with `protoc` descriptor output when possible.\n7. Provide generation commands for Rust and TypeScript.\n\n## Command templates\n\n- Validate schema and emit descriptor:\n\n```bash\nprotoc -I proto --include_imports --descriptor_set_out=gen/schema.pb proto/path/to/file.proto\n```\n\n- Rust via `prost-build` (`build.rs`):\n\n```rust\nfn main() -> std::io::Result<()> {\n    prost_build::compile_protos(&[\"proto/service.proto\"], &[\"proto\"])?;\n    Ok(())\n}\n```\n\n- Rust via `tonic-prost-build` (`build.rs`):\n\n```rust\nfn main() {\n    tonic_prost_build::configure()\n        .compile_protos(&[\"proto/service.proto\"], &[\"proto\"])\n        .unwrap();\n}\n```\n\n- TypeScript via `ts-proto`:\n\n```bash\nprotoc \\\n  --plugin=./node_modules/.bin/protoc-gen-ts_proto \\\n  --ts_proto_out=gen/ts \\\n  --ts_proto_opt=esModuleInterop=true \\\n  -I proto \\\n  proto/path/to/file.proto\n```\n\n- TypeScript via `@protobuf-ts/plugin`:\n\n```bash\nnpx protoc --ts_out gen/ts --proto_path proto proto/path/to/file.proto\n```\n\n## Output expectations\n\n- Deliver the requested `.proto` file(s) and a short note on compatibility choices.\n- Explicitly call out any use of proto2-only/proto3-only features.\n- Include exact generation commands for the selected Rust and TypeScript toolchains.\n",
                  "after": "---\nname: protobuf-schema-authoring\ndescription: Author proto2/proto3 schemas and provide protoc generation workflows for Rust and TypeScript.\n---\n\n## What I do\n\n- Turn user requirements into clear, evolvable `.proto` schemas.\n- Support both `proto2` and `proto3` syntax.\n- Ask for syntax preference when not explicitly provided, and explain version-specific constraints.\n- Provide practical `protoc` workflows for Rust and TypeScript.\n- Use the full type/layout reference in `docs/readmes/protobuf-schema-research.md`.\n\n## When to use me\n\nUse this when the task includes any of the following:\n\n- Create a new protobuf schema from product or API requirements.\n- Update an existing `.proto` safely.\n- Explain if a feature is `proto2`-only or `proto3`-only.\n- Generate Rust or TypeScript artifacts from `.proto` files.\n\n## Required clarification flow\n\nIf not already specified, ask these in order:\n\n1. Which schema syntax should be used: `proto2` or `proto3`?\n   - Recommended default: `proto3` with explicit `optional` on scalar fields when presence matters.\n2. For TypeScript generation, which plugin should be targeted: `ts-proto` or `@protobuf-ts/plugin`?\n   - Recommended default: `ts-proto`.\n\nWhen answering, always note version-specific features involved in the request.\n\n## Proto2 vs proto3 guardrails\n\n- `required` fields are proto2-only and should be avoided for new design.\n- Explicit scalar defaults (`[default = ...]`) are proto2-only.\n- Extensions are proto2-oriented; not a general proto3 field pattern.\n- Groups are deprecated legacy proto2 and should not be introduced.\n- Proto3 enums must start with a zero-valued first entry.\n- Proto3 scalar presence should use `optional` when presence semantics are needed.\n- Repeated scalar numerics are packed-by-default in proto3; in proto2, use `[packed = true]` for new fields.\n\n## Complete valid type reference (inline)\n\n### Scalar field types\n\n- `double`\n- `float`\n- `int32`\n- `int64`\n- `uint32`\n- `uint64`\n- `sint32`\n- `sint64`\n- `fixed32`\n- `fixed64`\n- `sfixed32`\n- `sfixed64`\n- `bool`\n- `string`\n- `bytes`\n\n### Non-scalar forms\n\n- Message type fields (local or imported), for example `my.pkg.User`.\n- Enum type fields (local or imported).\n- `map<K, V>` fields.\n  - Valid map key types: `int32`, `int64`, `uint32`, `uint64`, `sint32`, `sint64`, `fixed32`, `fixed64`, `sfixed32`, `sfixed64`, `bool`, `string`.\n  - Map value types: scalar, enum, or message.\n- `oneof` blocks.\n\n## Complete schema layout reference (inline)\n\n### Top-level statements\n\n- `syntax = \"proto2\";` or `syntax = \"proto3\";` (first non-comment line)\n- `package ...;`\n- `import \"...\";`, `import public \"...\";`, `import weak \"...\";`\n- `option ... = ...;`\n- `message ... { ... }`\n- `enum ... { ... }`\n- `service ... { ... }`\n- `extend ... { ... }`\n\n### Message body statements\n\n- Field declarations (`optional`/`required`/`repeated` in proto2; `optional`/implicit/repeated in proto3)\n- `oneof ... { ... }`\n- `map<K, V> ... = N;`\n- Nested `message` and nested `enum`\n- `reserved ...;`\n- `option ... = ...;`\n- `extensions ...;` (proto2)\n- `group` (deprecated legacy proto2)\n- `extend ... { ... }`\n\n### Enum body statements\n\n- Enum values: `NAME = N;`\n- Enum options (for example `option allow_alias = true;`)\n- `reserved ...;`\n\n### Service body statements\n\n- `rpc Method(Request) returns (Response);`\n- `rpc Stream(stream Request) returns (stream Response);`\n- Method options blocks on RPC definitions.\n\n## Boilerplate stubs (inline)\n\n### Proto3 starter\n\n```proto\nsyntax = \"proto3\";\n\npackage example.v1;\n\nimport \"google/protobuf/timestamp.proto\";\n\nmessage Resource {\n  optional string display_name = 1;\n  string id = 2;\n  google.protobuf.Timestamp created_at = 3;\n  map<string, string> labels = 4;\n\n  oneof owner {\n    string user_id = 5;\n    string team_id = 6;\n  }\n\n  reserved 7;\n  reserved \"legacy_id\";\n}\n\nenum ResourceState {\n  RESOURCE_STATE_UNSPECIFIED = 0;\n  RESOURCE_STATE_ACTIVE = 1;\n}\n\nservice ResourceService {\n  rpc GetResource(GetResourceRequest) returns (GetResourceResponse);\n}\n\nmessage GetResourceRequest {\n  string id = 1;\n}\n\nmessage GetResourceResponse {\n  Resource resource = 1;\n}\n```\n\n### Proto2 starter\n\n```proto\nsyntax = \"proto2\";\n\npackage example.v1;\n\nmessage Resource {\n  optional string display_name = 1 [default = \"unknown\"];\n  optional string id = 2;\n  repeated string tags = 3;\n\n  extensions 100 to max;\n\n  reserved 4;\n  reserved \"legacy_id\";\n}\n\nenum ResourceState {\n  RESOURCE_STATE_UNSPECIFIED = 0;\n  RESOURCE_STATE_ACTIVE = 1;\n}\n\nextend Resource {\n  optional string external_profile = 100;\n}\n```\n\n## Complete reference location\n\nUse `docs/readmes/protobuf-schema-research.md` as the canonical in-repo reference for:\n\n- Complete valid scalar type list and non-scalar type forms.\n- Full schema definition layout (top-level, message, enum, service).\n- Proto2 and proto3 boilerplate templates.\n- Wire constraints and field numbering guardrails.\n\nWhen drafting schemas, follow that reference and include only the subset needed for the user request.\n\n## Schema authoring workflow\n\n1. Confirm syntax version and target language outputs.\n2. Propose package and file layout.\n3. Define messages/enums/services with stable field numbering.\n4. Add comments only where semantics are non-obvious.\n5. Reserve removed field numbers and names.\n6. Validate with `protoc` descriptor output when possible.\n7. Provide generation commands for Rust and TypeScript.\n\n## Command templates\n\n- Validate schema and emit descriptor:\n\n```bash\nprotoc -I proto --include_imports --descriptor_set_out=gen/schema.pb proto/path/to/file.proto\n```\n\n- Rust via `prost-build` (`build.rs`):\n\n```rust\nfn main() -> std::io::Result<()> {\n    prost_build::compile_protos(&[\"proto/service.proto\"], &[\"proto\"])?;\n    Ok(())\n}\n```\n\n- Rust via `tonic-prost-build` (`build.rs`):\n\n```rust\nfn main() {\n    tonic_prost_build::configure()\n        .compile_protos(&[\"proto/service.proto\"], &[\"proto\"])\n        .unwrap();\n}\n```\n\n- TypeScript via `ts-proto`:\n\n```bash\nprotoc \\\n  --plugin=./node_modules/.bin/protoc-gen-ts_proto \\\n  --ts_proto_out=gen/ts \\\n  --ts_proto_opt=esModuleInterop=true \\\n  -I proto \\\n  proto/path/to/file.proto\n```\n\n- TypeScript via `@protobuf-ts/plugin`:\n\n```bash\nnpx protoc --ts_out gen/ts --proto_path proto proto/path/to/file.proto\n```\n\n## Output expectations\n\n- Deliver the requested `.proto` file(s) and a short note on compatibility choices.\n- Explicitly call out any use of proto2-only/proto3-only features.\n- Include exact generation commands for the selected Rust and TypeScript toolchains.\n",
                  "additions": 138,
                  "deletions": 0
                }
              ],
              "diagnostics": {},
              "truncated": false
            },
            "time": {
              "start": 1771213540583,
              "end": 1771213540602
            }
          },
          "metadata": {
            "openai": {
              "itemId": "fc_0e7bb8a5c575dca901699292d5e62c819380aa5334f0070a71"
            }
          },
          "id": "prt_c648d93ba001uQy72uNzOvKokL",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648d784c0019ABdCN42MajDoh"
        },
        {
          "type": "step-finish",
          "reason": "tool-calls",
          "snapshot": "c5874264105db34ae5f3d79ff3e370e1b349fbf6",
          "cost": 0,
          "tokens": {
            "total": 118035,
            "input": 3566,
            "output": 1317,
            "reasoning": 186,
            "cache": {
              "read": 113152,
              "write": 0
            }
          },
          "id": "prt_c648dcd3300120nopE4iXS9pcP",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648d784c0019ABdCN42MajDoh"
        },
        {
          "type": "patch",
          "hash": "689b71acce0a09b1c69553864f5e86d1fe8cb76f",
          "files": [
            "/Users/alex/repos/vfp/dark-factory/.opencode/skills/protobuf-schema-authoring/SKILL.md"
          ],
          "id": "prt_c648dcd61001yy6Zsg9fnWUI3f",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648d784c0019ABdCN42MajDoh"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771213540717,
          "completed": 1771213545678
        },
        "parentID": "msg_c648d7841001uj74J30rDC55TU",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "build",
        "agent": "build",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "cost": 0,
        "tokens": {
          "total": 118210,
          "input": 180,
          "output": 142,
          "reasoning": 27,
          "cache": {
            "read": 117888,
            "write": 0
          }
        },
        "variant": "high",
        "finish": "stop",
        "id": "msg_c648dcd6d001OegXE3GcpBvCk5",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "c5874264105db34ae5f3d79ff3e370e1b349fbf6",
          "id": "prt_c648dd5770017JBPG7lGb82hwK",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648dcd6d001OegXE3GcpBvCk5"
        },
        {
          "type": "reasoning",
          "text": "**Confirming completion with references**",
          "metadata": {
            "openai": {
              "itemId": "rs_0c31c77af9e430ea01699292e769948193bffb73a6a0353c20",
              "reasoningEncryptedContent": "gAAAAABpkpLoY0GGLmHjXFyDNPy1oV0gTNvd9VuNiYrcx5dqdsZ2IgmoQblAm3exThBmeIGnFgM5R-Ih37dQPfwbXzBk8jzADoSzi4DhTR-MLfXCT62W87oSulSm0L7MqhHnjADBYOvF_wWcby2jO_si3hUfvuN2kG0__6N6phe4jh3xEE3vKvTOgBBmgCiCoNrLPFQBIABOQnjhZmaKAWzA07rmEoE6yKCgMg3a0BzCuH2bscmxG1tn8c3t6Q9nhL8IyRzSRBjIDaBlUh5T-8VQ689LJ2-3qCnJ_3F2t_ckb9a-K9lj2m1g09Nm_8elLuskeircOQNajDyOA-1163McTSTIAYmInELijESIyu6SRVq0dwskv_lgngFsP8GSI1eURPNAlkWtPWnGo8k-jHDBKuqjrQfIK8BgiSB8xxa6fN6vqBB3Cj7GIYcf3cpOoasQse8htk0XSyyGnd5-1Kw8X5G38CmysA5iVPq3SolotvwQ_JX4cO3_HlLOKIus09ZLh1A5Hh7-fnR1o0cCy7dQ0KI35YzNX-v7BdO6_JfN4juWFo5vrQEF5-ymNmY78a3lU9JbQvMvsn0Z-8TGXsJiztkdnI_ici2cweZOhCjUgPCWVPUE0EuWSnYX-JhFTlFTNKWTFbL9HTWNw_4hQTQAhcp1deRy56WC__RC2uin3V5GKNGAFZcEEu5m8WqVvkkx8FRxIx_G-TaKEN6BlNFP_T1AemzXgF7GNykj2aKLLCjY99FGGO3wvGEaR5ms7ZXX28YK2LkbG1Ax_C7VUEasNEH0zfUj5o0sFjOaG2kzLImLF648nPgjoukV6j9xxM9sD-i_VWKtAzaYK29Y2s3mLBiTYzDxffAaNdABtvNxa9FsW8wNU2Yk_Unqa6QL_5FCWKbCbjMhwRTNGv9JQ0QgabFpG_SaBkvMXa28imBXuZyOo7qSuE8zubZRrSAfaYrX5Enx2Gq3Cqmv4KYQYNnRCieGeVAUKkVrqBWzP9z_pBqT_r-IdPI="
            }
          },
          "time": {
            "start": 1771213543530,
            "end": 1771213544156
          },
          "id": "prt_c648dd86a001wop71fVNhY4D36",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648dcd6d001OegXE3GcpBvCk5"
        },
        {
          "type": "text",
          "text": "Added ‚Äî the skill now includes the full inline reference directly.\n\nUpdated ` .opencode/skills/protobuf-schema-authoring/SKILL.md` with:\n\n- complete valid protobuf scalar type list\n- non-scalar forms and map key/value constraints\n- complete schema layout (top-level, message, enum, service)\n- proto3 and proto2 boilerplate starter templates\n\nI kept the existing pointer to `docs/readmes/protobuf-schema-research.md` too, so the skill now has both inline quick reference and a deeper canonical doc.",
          "time": {
            "start": 1771213545627,
            "end": 1771213545627
          },
          "metadata": {
            "openai": {
              "itemId": "msg_0c31c77af9e430ea01699292e81e2481938901f10f21c7fe17"
            }
          },
          "id": "prt_c648ddadd001lPqHuh3l4agZ17",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648dcd6d001OegXE3GcpBvCk5"
        },
        {
          "type": "step-finish",
          "reason": "stop",
          "snapshot": "c5874264105db34ae5f3d79ff3e370e1b349fbf6",
          "cost": 0,
          "tokens": {
            "total": 118210,
            "input": 180,
            "output": 142,
            "reasoning": 27,
            "cache": {
              "read": 117888,
              "write": 0
            }
          },
          "id": "prt_c648de09d001eDHqz8uAvY2KZo",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648dcd6d001OegXE3GcpBvCk5"
        }
      ]
    },
    {
      "info": {
        "role": "user",
        "time": {
          "created": 1771213559782
        },
        "summary": {
          "diffs": [
            {
              "file": "scripts/scrape_moon_docs.sh.ts",
              "before": "#!/usr/bin/env bun\n\nimport { mkdirSync } from \"node:fs\";\nimport { dirname, resolve } from \"node:path\";\nimport { findRepoRoot } from \"./helpers/run_root.sh.ts\";\n\ntype ScrapeResult = {\n  url: string;\n  ok: boolean;\n  markdown?: string;\n  error?: string;\n};\n\nconst SITEMAP_URL = \"https://moonrepo.dev/sitemap.xml\";\nconst DOCS_ROOT = \"https://moonrepo.dev/docs\";\nconst DEFAULT_OUTPUT_RELATIVE =\n  \"docs/external/moonrepo/moonrepo_docs.ext.md\";\nconst CONCURRENCY = 4;\n\nfunction decodeEntities(value: string): string {\n  return value\n    .replaceAll(\"&amp;\", \"&\")\n    .replaceAll(\"&quot;\", '\"')\n    .replaceAll(\"&apos;\", \"'\")\n    .replaceAll(\"&#x27;\", \"'\")\n    .replaceAll(\"&#39;\", \"'\")\n    .replaceAll(\"&nbsp;\", \" \")\n    .replaceAll(\"&lt;\", \"<\")\n    .replaceAll(\"&gt;\", \">\");\n}\n\nfunction stripJinaEnvelope(markdown: string): string {\n  return markdown\n    .replace(/^Title:.*?\\nURL Source:.*?\\nMarkdown Content:\\n/s, \"\")\n    .trim();\n}\n\nfunction stripTags(value: string): string {\n  return value.replace(/<[^>]+>/g, \"\");\n}\n\nfunction plainTextFromHtml(value: string): string {\n  return decodeEntities(stripTags(value).replace(/\\s+/g, \" \")).trim();\n}\n\nfunction extractMainHtml(html: string): string {\n  const markdownBlockMatch = html.match(\n    /<div class=\"theme-doc-markdown markdown\">([\\s\\S]*?)<footer class=\"theme-doc-footer/s,\n  );\n\n  if (markdownBlockMatch?.[1]) {\n    return markdownBlockMatch[1];\n  }\n\n  const articleMatch = html.match(/<article>([\\s\\S]*?)<\\/article>/s);\n  if (articleMatch?.[1]) {\n    return articleMatch[1];\n  }\n\n  const mainMatch = html.match(/<main[^>]*>([\\s\\S]*?)<\\/main>/s);\n  return mainMatch?.[1] ?? html;\n}\n\nfunction htmlToMarkdown(html: string): string {\n  let content = extractMainHtml(html);\n\n  content = content\n    .replace(/<script[\\s\\S]*?<\\/script>/gi, \"\")\n    .replace(/<style[\\s\\S]*?<\\/style>/gi, \"\")\n    .replace(/<a[^>]*class=\"hash-link\"[^>]*>[\\s\\S]*?<\\/a>/gi, \"\")\n    .replace(/<span[^>]*aria-hidden=\"true\"[^>]*>[\\s\\S]*?<\\/span>/gi, \"\");\n\n  content = content.replace(\n    /<pre[^>]*><code[^>]*>([\\s\\S]*?)<\\/code><\\/pre>/gi,\n    (_match, code) => {\n      const normalizedCode = decodeEntities(\n        stripTags(code)\n          .replace(/<br\\s*\\/?>/gi, \"\\n\")\n          .replace(/\\n{3,}/g, \"\\n\\n\")\n          .trim(),\n      );\n\n      if (!normalizedCode) {\n        return \"\";\n      }\n\n      return `\\n\\n\\`\\`\\`\\n${normalizedCode}\\n\\`\\`\\`\\n\\n`;\n    },\n  );\n\n  content = content.replace(/<code[^>]*>([\\s\\S]*?)<\\/code>/gi, (_match, code) => {\n    const normalizedCode = decodeEntities(stripTags(code)).trim();\n    return normalizedCode ? `\\`${normalizedCode}\\`` : \"\";\n  });\n\n  content = content.replace(/<a[^>]*href=\"([^\"]+)\"[^>]*>([\\s\\S]*?)<\\/a>/gi, (_m, href, label) => {\n    const text = plainTextFromHtml(label);\n    if (!text) {\n      return \"\";\n    }\n\n    return `[${text}](${decodeEntities(href)})`;\n  });\n\n  content = content.replace(/<h([1-6])[^>]*>([\\s\\S]*?)<\\/h\\1>/gi, (_match, level, inner) => {\n    const heading = plainTextFromHtml(inner);\n    if (!heading) {\n      return \"\";\n    }\n\n    return `\\n\\n${\"#\".repeat(Number(level))} ${heading}\\n\\n`;\n  });\n\n  content = content.replace(/<li[^>]*>([\\s\\S]*?)<\\/li>/gi, (_match, inner) => {\n    const line = plainTextFromHtml(inner);\n    return line ? `- ${line}\\n` : \"\";\n  });\n\n  content = content\n    .replace(/<br\\s*\\/?>/gi, \"\\n\")\n    .replace(/<\\/(p|div|section|article|header|ul|ol|table|tr)>/gi, \"\\n\\n\")\n    .replace(/<(p|div|section|article|header|ul|ol|table|tr)[^>]*>/gi, \"\\n\")\n    .replace(/<t[hd][^>]*>([\\s\\S]*?)<\\/t[hd]>/gi, (_match, inner) => {\n      const cell = plainTextFromHtml(inner);\n      return cell ? `${cell} ` : \"\";\n    });\n\n  content = decodeEntities(content)\n    .replace(/<[^>]+>/g, \"\")\n    .replace(/[ \\t]+\\n/g, \"\\n\")\n    .replace(/\\n{3,}/g, \"\\n\\n\")\n    .trim();\n\n  return content;\n}\n\nfunction extractDocsUrls(sitemapXml: string): string[] {\n  const urls = Array.from(sitemapXml.matchAll(/<loc>(.*?)<\\/loc>/g), (match) =>\n    decodeEntities(match[1]?.trim() ?? \"\"),\n  )\n    .filter((url) => url.startsWith(DOCS_ROOT))\n    .filter((url) => !url.includes(\"/docs/tags\"))\n    .filter((url) => !url.includes(\"#\"));\n\n  return Array.from(new Set(urls)).sort((a, b) => a.localeCompare(b));\n}\n\nasync function fetchText(url: string): Promise<string> {\n  const response = await fetch(url, {\n    headers: {\n      \"user-agent\": \"dark-factory-doc-scraper/1.0\",\n    },\n  });\n\n  if (!response.ok) {\n    throw new Error(`Request failed (${response.status}) for ${url}`);\n  }\n\n  return await response.text();\n}\n\nasync function mapConcurrent<T, R>(\n  values: T[],\n  limit: number,\n  map: (value: T, index: number) => Promise<R>,\n): Promise<R[]> {\n  const results = new Array<R>(values.length);\n  let index = 0;\n\n  async function worker(): Promise<void> {\n    while (true) {\n      const currentIndex = index;\n      index += 1;\n\n      if (currentIndex >= values.length) {\n        return;\n      }\n\n      results[currentIndex] = await map(values[currentIndex], currentIndex);\n    }\n  }\n\n  const workerCount = Math.min(limit, values.length);\n  await Promise.all(Array.from({ length: workerCount }, () => worker()));\n  return results;\n}\n\nasync function scrapeDocsPage(url: string, count: number, total: number): Promise<ScrapeResult> {\n  const jinaUrl = `https://r.jina.ai/http://${url.replace(/^https?:\\/\\//, \"\")}`;\n\n  try {\n    console.log(`Docs // Scrape // ${count}/${total} ${url}`);\n    try {\n      const markdown = stripJinaEnvelope(await fetchText(jinaUrl));\n\n      if (markdown) {\n        return {\n          url,\n          ok: true,\n          markdown,\n        };\n      }\n    } catch {\n      // Fall through to direct HTML scrape.\n    }\n\n    const html = await fetchText(url);\n    const markdown = htmlToMarkdown(html);\n\n    if (!markdown) {\n      return {\n        url,\n        ok: false,\n        error: \"No markdown content returned from HTML fallback\",\n      };\n    }\n\n    return {\n      url,\n      ok: true,\n      markdown,\n    };\n  } catch (error) {\n    return {\n      url,\n      ok: false,\n      error: error instanceof Error ? error.message : \"Unknown scrape error\",\n    };\n  }\n}\n\nfunction buildHeader(urlCount: number, capturedAt: string): string {\n  return [\n    \"----\",\n    \"## External Docs Snapshot // moonrepo\",\n    \"\",\n    `- Captured: ${capturedAt}`,\n    `- Source root: ${DOCS_ROOT}`,\n    `- Scope: ${urlCount} pages under /docs (excluding /docs/tags)`,\n    \"- Keywords: moon, monorepo, task graph, hashing, cache, toolchain, proto, workspace, codegen, query, migration, CI\",\n    \"- Summary: moonrepo documentation centers on deterministic task orchestration, project/dependency graphs, and reproducible toolchains with proto-backed version pinning.\",\n    \"----\",\n    \"\",\n  ].join(\"\\n\");\n}\n\nfunction buildFooter(successCount: number, failureCount: number): string {\n  return [\n    \"\",\n    \"----\",\n    \"## Notes / Comments / Lessons\",\n    \"\",\n    \"- Collection method: sitemap URL discovery + markdown conversion (r.jina.ai primary, direct HTML fallback parser secondary).\",\n    \"- Most docs pages are content-rich and command-oriented; command reference and config schemas are the highest-density sections.\",\n    \"- For ongoing updates, re-run this script to refresh snapshots and compare diffs over time.\",\n    `- Capture results: success=${successCount}, failed=${failureCount}.`,\n    \"----\",\n    \"\",\n  ].join(\"\\n\");\n}\n\nfunction buildPageSection(result: ScrapeResult): string {\n  if (!result.ok) {\n    return [\n      `## ${result.url.replace(\"https://moonrepo.dev\", \"\")}`,\n      \"\",\n      `Source: ${result.url}`,\n      \"\",\n      `> Scrape failed: ${result.error ?? \"unknown error\"}`,\n      \"\",\n    ].join(\"\\n\");\n  }\n\n  return [\n    `## ${result.url.replace(\"https://moonrepo.dev\", \"\")}`,\n    \"\",\n    `Source: ${result.url}`,\n    \"\",\n    result.markdown?.trim() ?? \"\",\n    \"\",\n  ].join(\"\\n\");\n}\n\nconst repoRoot = findRepoRoot(import.meta.dir);\nconst outputArg = Bun.argv[2];\nconst outputPath = resolve(repoRoot, outputArg ?? DEFAULT_OUTPUT_RELATIVE);\n\nconst sitemapXml = await fetchText(SITEMAP_URL);\nconst docsUrls = extractDocsUrls(sitemapXml);\n\nif (docsUrls.length === 0) {\n  throw new Error(\"No docs URLs found in moonrepo sitemap\");\n}\n\nconst results = await mapConcurrent(docsUrls, CONCURRENCY, (url, index) =>\n  scrapeDocsPage(url, index + 1, docsUrls.length),\n);\n\nconst successCount = results.filter((result) => result.ok).length;\nconst failureCount = results.length - successCount;\nconst capturedAt = new Date().toISOString();\n\nconst content = [\n  buildHeader(docsUrls.length, capturedAt),\n  ...results.map(buildPageSection),\n  buildFooter(successCount, failureCount),\n].join(\"\\n\");\n\nmkdirSync(dirname(outputPath), { recursive: true });\nawait Bun.write(outputPath, content);\n\nconsole.log(\n  `Docs // Scrape // Wrote external docs snapshot (pages=${docsUrls.length},ok=${successCount},failed=${failureCount},path=${outputPath})`,\n);\n",
              "after": "",
              "additions": 0,
              "deletions": 314,
              "status": "deleted"
            }
          ]
        },
        "agent": "build",
        "model": {
          "providerID": "openai",
          "modelID": "gpt-5.3-codex"
        },
        "id": "msg_c648e17e6001YM54MG29gGQBfQ",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "compaction",
          "auto": false,
          "id": "prt_c648e17e7001bDWLJI0WznttOm",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648e17e6001YM54MG29gGQBfQ"
        }
      ]
    },
    {
      "info": {
        "role": "assistant",
        "time": {
          "created": 1771213559788,
          "completed": 1771213578893
        },
        "parentID": "msg_c648e17e6001YM54MG29gGQBfQ",
        "modelID": "gpt-5.3-codex",
        "providerID": "openai",
        "mode": "compaction",
        "agent": "compaction",
        "path": {
          "cwd": "/Users/alex/repos/vfp/dark-factory",
          "root": "/Users/alex/repos/vfp/dark-factory"
        },
        "summary": true,
        "cost": 0,
        "tokens": {
          "total": 54382,
          "input": 53375,
          "output": 1007,
          "reasoning": 74,
          "cache": {
            "read": 0,
            "write": 0
          }
        },
        "finish": "stop",
        "id": "msg_c648e17ec0017ewG6GOaVULORx",
        "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW"
      },
      "parts": [
        {
          "type": "step-start",
          "snapshot": "c5874264105db34ae5f3d79ff3e370e1b349fbf6",
          "id": "prt_c648e1998001wUUBTbULthKbfG",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648e17ec0017ewG6GOaVULORx"
        },
        {
          "type": "reasoning",
          "text": "**Preparing detailed summary prompt**",
          "metadata": {
            "openai": {
              "itemId": "rs_0fa1a7ad30e7c72401699292f983108190832df16b89c0627c",
              "reasoningEncryptedContent": "gAAAAABpkpL7vEi3_oxj4nTmbvf3xkmaFxeyludel0YTwASTtY-MBtcM_aNsQ3Da9XFb33zWD1qlKYjAjI_u0BZewST4HF30wE5zRUmN3vgYSMUb8OW3qGrUAbmih6RKCxisluO5nd9ReyWh7g2ESrfR_5iOCJh56XfzyOosTp2hp7ea5Ab4oHeUUUOIJjNoD3GPA7wNVsVqfXXcy9MkUd2D9e1K38W9dppha0jovKKSmBhlKvVrRX9LrnnEALvFouGumMs5RyNquuNqOVtO0WFtDjtWloO_o3OIZ_TIz85XRjOsGZtQnhCRwKBfGRfPqcoqsKOsbggpDy46RsbP32hiCeVElMktn88nBfrIWmYlpbWuQFO7bsQqR0Dtub6KCRHkwoV2ehB8RjAWcZdA_J4049W3biWFRlH3nTDTBoIDED4ec36LLq1MZd-fGC7UmwjImZwoIQBexYWSe3f0_gpyddS5ctB-1wurKzIBVLXCdipfOndpyhkJYpWdb4QtCg8OAbe5ZzGC7mC2XaqbJfPiDvgzIsobmqrAKr32Ynq_P4ULlTCcbCYhWoF8tYS8efz_CMxbQCvx7IlwzSDomcoTfqtYmK6GUc4KajftyEr-itgELXa8KSeolu7zf4-qPdz3fZDmslYk6ALo8V0z1nLXAIUUA8mE3i7lDFkrUoq2JEg7zzLfFl5yrD1vEpXMwCkqxURmjJG0s_81qf5RdBOEdpxgqQa3Kv5xMXZ4YnwZv041JS8SDUM7VByZVWji2B_Sfo-MoL1SXMMgrTYtTGm94I0KMPxGCkXLFKAYO3NKt1Vaog4QophQdoT_5QMb3ulvf8yNuRaZTHSzDDCEOAgdOVs_Sjxd67hA_fPmLpXKA0YaG72jw2E7QzfQSz0VP7zfHolh9_0xJqsFMF9V14X8YWlRnUluRaCXaUIUrvayiXWWSUVMDFDq3U6r1Ixt1aUKArZV2uSFZQdRRkbzdUtMdjriRbfSejMVJOcRe3RQUlkPub3ltkP3FR0mpxPHnTwLCIgzz89zmZWH2HLMbULe9-hFpguBXAorcSxX2wzc_8yPmThN8BbjibRA3mFhl_3duoP-MFJPPIKXulUyl8soqP0lG8xG9MsgiNk0Qs4lRkyKClsxMV9fje90iJlW6p3wgryMsuVd3MNp52apPkPDAhcJYl9hACfotRy6r4NnnjwdvNQzJ9-1w0tOC5eAxjygKk1wGg0D3hSVp2EJFCgnK1qfrGmDNUYtJZ-TKSieOx4Fh-2_RMKeWU_RznQV3oDWtJdtho88Po_gTiXPNwo7vBqWGivNsPoEiZj7ZBpsVvZiWnyEkyc669AzIMyvKN7AnICaG6tvAqZz7KNk5QdXjrzshGSapQ_0_63bpgAFwzwqcoeL3X0leVKk2UPPcpaN3j5F7L0h"
            }
          },
          "time": {
            "start": 1771213561572,
            "end": 1771213563339
          },
          "id": "prt_c648e1ee4001cvo4LwfvqduBZm",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648e17ec0017ewG6GOaVULORx"
        },
        {
          "type": "text",
          "text": "## Goal\n\nCreate research notes and an OpenCode skill so the agent can help users author new Protocol Buffer schemas (`.proto`) with support for both proto2 and proto3, including clear version-specific differences and practical `protoc` codegen usage for Rust and TypeScript.\n\n## Instructions\n\n- Research on the web and take notes under `docs/`.\n- Create a new skill under `.opencode/skills/` based on OpenCode skills docs (`https://opencode.ai/docs/skills/`).\n- Skill scope must include:\n  - Authoring protobuf files/schemas.\n  - Support for both v2 (proto2) and v3 (proto3).\n  - Explicitly ask user which syntax/version to use when needed.\n  - Clearly call out proto2-only vs proto3-only features.\n  - `protoc` usage for Rust and TypeScript toolchains.\n- Then expand the skill so it includes (or references) a complete list of valid proto types, schema definition layout, and boilerplate.\n- User confirmed: ‚Äúyes please‚Äù to inlining those details directly in the skill file.\n\n## Discoveries\n\n- OpenCode skill structure was confirmed from `https://opencode.ai/docs/skills/` and existing local skills (`gitter-commit`, `proto-install`, `script-authoring`) were used as style/context references.\n- Authoritative protobuf sources used included:\n  - proto2/proto3/field presence docs on `protobuf.dev`\n  - protoc installation docs\n  - Rust generated/build docs\n  - `prost-build`, `tonic-prost-build`, `ts-proto`, and `@protobuf-ts/plugin` docs/README references\n- Important semantic findings captured:\n  - proto2-only: `required`, scalar `[default=...]`, extensions/groups (groups deprecated)\n  - proto3: recommend explicit `optional` for scalar presence semantics\n  - proto3 enums must start with zero value\n  - packing behavior differs by syntax defaults\n  - schema evolution guardrails: never renumber/reuse removed fields, reserve names/numbers\n- Repo was already dirty with unrelated files; only targeted files were edited for this task.\n\n## Accomplished\n\n- Completed web research and captured structured notes in:\n  - `docs/readmes/protobuf-schema-research.md`\n- Created new skill:\n  - `.opencode/skills/protobuf-schema-authoring/SKILL.md`\n- Updated agent guide inventory to include the new skill:\n  - `AGENTS.md`\n- Extended skill per follow-up request:\n  - Added inline ‚Äúcomplete valid type reference‚Äù\n  - Added inline ‚Äúcomplete schema layout reference‚Äù\n  - Added inline proto2/proto3 boilerplate starters\n  - Kept canonical reference pointer to research doc for deeper detail\n\nCurrent status:\n- This protobuf skill + research work is complete from an editing perspective.\n- No commit for these new edits has been made in this conversation segment.\n- Working tree still contains unrelated pre-existing changes.\n\nLikely next steps:\n1. Review wording/strictness of proto grammar claims if needed (optional hardening pass).\n2. Commit these protobuf-skill changes (if requested), ideally as a focused docs/skills commit.\n3. Optionally test skill behavior by running a sample schema request through the new skill flow.\n\n## Relevant files / directories\n\n- `docs/readmes/protobuf-schema-research.md` (created, then expanded)\n  - Contains source links, proto2/proto3 differences, full valid type lists, schema layout, boilerplates, evolution rules, Rust/TS codegen command patterns.\n- `.opencode/skills/protobuf-schema-authoring/SKILL.md` (created, then expanded)\n  - Skill behavior, clarification flow, proto2/proto3 guardrails, inline full type/layout/boilerplate references, codegen templates.\n- `AGENTS.md` (edited)\n  - Added reference to new protobuf schema skill in OpenCode integration section.\n- `.opencode/skills/` (directory context)\n  - Existing skills read for style/reference: `gitter-commit/`, `proto-install/`, `script-authoring/`.\n- `docs/` (directory context)\n  - Existing docs tree inspected; new protobuf research note added under `docs/readmes/`.\n\nUnrelated but present in current git status (not modified by this protobuf task in this phase):\n- `README.md`\n- `docs/designs/core_gen1.design.md`\n- `docs/external/`\n- `scripts/scrape_moon_docs.sh.ts`",
          "time": {
            "start": 1771213578788,
            "end": 1771213578788
          },
          "metadata": {
            "openai": {
              "itemId": "msg_0fa1a7ad30e7c72401699292fb4dd8819098ef17496b12a2bc"
            }
          },
          "id": "prt_c648e25cb001E8eSHfsJvqCPxp",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648e17ec0017ewG6GOaVULORx"
        },
        {
          "type": "step-finish",
          "reason": "stop",
          "snapshot": "7c546ac04417b7ff35b3d29909841f670e9a513d",
          "cost": 0,
          "tokens": {
            "total": 54382,
            "input": 53375,
            "output": 1007,
            "reasoning": 74,
            "cache": {
              "read": 0,
              "write": 0
            }
          },
          "id": "prt_c648e62290010HgOT4B6gwaj2f",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648e17ec0017ewG6GOaVULORx"
        },
        {
          "type": "patch",
          "hash": "c5874264105db34ae5f3d79ff3e370e1b349fbf6",
          "files": [
            "/Users/alex/repos/vfp/dark-factory/scripts/scrape_moon_docs.sh.ts"
          ],
          "id": "prt_c648e6282001QMUEGNhnZ6off0",
          "sessionID": "ses_39b7f9e89ffe7J0WzLzYrUt4eW",
          "messageID": "msg_c648e17ec0017ewG6GOaVULORx"
        }
      ]
    }
  ]
}
